Container nvidia build =  13409399
XLA activated
--------------------------------------------------------------------------
WARNING: Open MPI tried to bind a process but failed.  This is a
warning only; your job will continue, though performance may
be degraded.

  Local host:        yq01-gpu-255-129-15-00
  Application name:  /usr/bin/python
  Error message:     failed to bind memory
  Location:          rtc_hwloc.c:445

--------------------------------------------------------------------------
2020-12-17 11:16:30.680209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:16:30.680201: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:16:30.680194: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:16:30.680171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:16:30.680161: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:16:30.680157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:16:30.680186: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:16:30.680178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 11:16:32.569156 140047690766144 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 11:16:32.569157 140451614897984 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 11:16:32.569178 140228096599872 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 11:16:32.569222 140395977164608 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 11:16:32.569214 139866384443200 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 11:16:32.569187 139675893147456 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 11:16:32.569433 139834186573632 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 11:16:32.569730 140022762432320 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 11:16:34.066031 140228096599872 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 11:16:34.066042 139866384443200 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 11:16:34.066149 140047690766144 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f34bdc74320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f88f580c4e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 11:16:34.066769 139866384443200 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f34bdc74320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 11:16:34.066802 140228096599872 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f88f580c4e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5ef47a34e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 11:16:34.066864 140047690766144 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5ef47a34e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f34bdc6ea60>) includes params argument, but params are not passed to Estimator.
W1217 11:16:34.067525 139866384443200 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f34bdc6ea60>) includes params argument, but params are not passed to Estimator.
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f88f5806a60>) includes params argument, but params are not passed to Estimator.
W1217 11:16:34.067574 140228096599872 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f88f5806a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
INFO:tensorflow:***** Running training *****
I1217 11:16:34.067959 139866384443200 run_pretraining.py:623] ***** Running training *****
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5ef479da60>) includes params argument, but params are not passed to Estimator.
I1217 11:16:34.067996 140228096599872 run_pretraining.py:623] ***** Running training *****
W1217 11:16:34.067742 140047690766144 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5ef479da60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 11:16:34.068164 140047690766144 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 96
INFO:tensorflow:  Batch size = 96
I1217 11:16:34.068035 139866384443200 run_pretraining.py:624]   Batch size = 96
I1217 11:16:34.068064 140228096599872 run_pretraining.py:624]   Batch size = 96
INFO:tensorflow:  Batch size = 96
I1217 11:16:34.068242 140047690766144 run_pretraining.py:624]   Batch size = 96
INFO:tensorflow:***** Configuaration *****
I1217 11:16:34.077541 140022762432320 run_pretraining.py:577] ***** Configuaration *****
INFO:tensorflow:  logtostderr: False
I1217 11:16:34.077812 140022762432320 run_pretraining.py:579]   logtostderr: False
INFO:tensorflow:  alsologtostderr: False
I1217 11:16:34.077891 140022762432320 run_pretraining.py:579]   alsologtostderr: False
INFO:tensorflow:  log_dir:
I1217 11:16:34.078001 140022762432320 run_pretraining.py:579]   log_dir:
INFO:tensorflow:  v: 0
I1217 11:16:34.078218 140022762432320 run_pretraining.py:579]   v: 0
INFO:tensorflow:  verbosity: 0
I1217 11:16:34.078273 140022762432320 run_pretraining.py:579]   verbosity: 0
INFO:tensorflow:  stderrthreshold: fatal
I1217 11:16:34.078338 140022762432320 run_pretraining.py:579]   stderrthreshold: fatal
INFO:tensorflow:  showprefixforinfo: True
I1217 11:16:34.078387 140022762432320 run_pretraining.py:579]   showprefixforinfo: True
INFO:tensorflow:  run_with_pdb: False
I1217 11:16:34.078437 140022762432320 run_pretraining.py:579]   run_with_pdb: False
INFO:tensorflow:  pdb_post_mortem: False
I1217 11:16:34.078486 140022762432320 run_pretraining.py:579]   pdb_post_mortem: False
INFO:tensorflow:  run_with_profiling: False
I1217 11:16:34.078534 140022762432320 run_pretraining.py:579]   run_with_profiling: False
INFO:tensorflow:  profile_file: None
I1217 11:16:34.078583 140022762432320 run_pretraining.py:579]   profile_file: None
INFO:tensorflow:  use_cprofile_for_profiling: True
I1217 11:16:34.078631 140022762432320 run_pretraining.py:579]   use_cprofile_for_profiling: True
INFO:tensorflow:  only_check_args: False
I1217 11:16:34.078688 140022762432320 run_pretraining.py:579]   only_check_args: False
INFO:tensorflow:  op_conversion_fallback_to_while_loop: False
I1217 11:16:34.078737 140022762432320 run_pretraining.py:579]   op_conversion_fallback_to_while_loop: False
INFO:tensorflow:  test_random_seed: 301
I1217 11:16:34.078787 140022762432320 run_pretraining.py:579]   test_random_seed: 301
INFO:tensorflow:  test_srcdir:
I1217 11:16:34.078835 140022762432320 run_pretraining.py:579]   test_srcdir:
INFO:tensorflow:  test_tmpdir: /tmp/absl_testing
I1217 11:16:34.078883 140022762432320 run_pretraining.py:579]   test_tmpdir: /tmp/absl_testing
INFO:tensorflow:  test_randomize_ordering_seed:
I1217 11:16:34.078931 140022762432320 run_pretraining.py:579]   test_randomize_ordering_seed:
INFO:tensorflow:  xml_output_file:
I1217 11:16:34.078979 140022762432320 run_pretraining.py:579]   xml_output_file:
INFO:tensorflow:  bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
I1217 11:16:34.079027 140022762432320 run_pretraining.py:579]   bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
INFO:tensorflow:  input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
I1217 11:16:34.079076 140022762432320 run_pretraining.py:579]   input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
INFO:tensorflow:  eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
I1217 11:16:34.079125 140022762432320 run_pretraining.py:579]   eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
INFO:tensorflow:  output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1
I1217 11:16:34.079173 140022762432320 run_pretraining.py:579]   output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1
INFO:tensorflow:  dllog_path: /results/bert_dllog.json
I1217 11:16:34.079370 140022762432320 run_pretraining.py:579]   dllog_path: /results/bert_dllog.json
INFO:tensorflow:  init_checkpoint: None
I1217 11:16:34.079547 140022762432320 run_pretraining.py:579]   init_checkpoint: None
INFO:tensorflow:  optimizer_type: lamb
I1217 11:16:34.079596 140022762432320 run_pretraining.py:579]   optimizer_type: lamb
INFO:tensorflow:  max_seq_length: 128
I1217 11:16:34.079646 140022762432320 run_pretraining.py:579]   max_seq_length: 128
INFO:tensorflow:  max_predictions_per_seq: 20
I1217 11:16:34.079701 140022762432320 run_pretraining.py:579]   max_predictions_per_seq: 20
INFO:tensorflow:  do_train: True
I1217 11:16:34.079751 140022762432320 run_pretraining.py:579]   do_train: True
INFO:tensorflow:  do_eval: True
I1217 11:16:34.079819 140022762432320 run_pretraining.py:579]   do_eval: True
INFO:tensorflow:  train_batch_size: 96
I1217 11:16:34.079867 140022762432320 run_pretraining.py:579]   train_batch_size: 96
INFO:tensorflow:  eval_batch_size: 8
I1217 11:16:34.079915 140022762432320 run_pretraining.py:579]   eval_batch_size: 8
INFO:tensorflow:  learning_rate: 0.00075
I1217 11:16:34.079968 140022762432320 run_pretraining.py:579]   learning_rate: 0.00075
INFO:tensorflow:  num_train_steps: 50
I1217 11:16:34.080016 140022762432320 run_pretraining.py:579]   num_train_steps: 50
INFO:tensorflow:  num_warmup_steps: 2000
I1217 11:16:34.080064 140022762432320 run_pretraining.py:579]   num_warmup_steps: 2000
INFO:tensorflow:  save_checkpoints_steps: 200
I1217 11:16:34.080111 140022762432320 run_pretraining.py:579]   save_checkpoints_steps: 200
INFO:tensorflow:  display_loss_steps: 1
I1217 11:16:34.080158 140022762432320 run_pretraining.py:579]   display_loss_steps: 1
INFO:tensorflow:  iterations_per_loop: 1000
I1217 11:16:34.080205 140022762432320 run_pretraining.py:579]   iterations_per_loop: 1000
INFO:tensorflow:  max_eval_steps: 100
I1217 11:16:34.080252 140022762432320 run_pretraining.py:579]   max_eval_steps: 100
INFO:tensorflow:  num_accumulation_steps: 88
I1217 11:16:34.080310 140022762432320 run_pretraining.py:579]   num_accumulation_steps: 88
INFO:tensorflow:  allreduce_post_accumulation: True
I1217 11:16:34.080359 140022762432320 run_pretraining.py:579]   allreduce_post_accumulation: True
INFO:tensorflow:  verbose_logging: False
I1217 11:16:34.080406 140022762432320 run_pretraining.py:579]   verbose_logging: False
INFO:tensorflow:  horovod: True
I1217 11:16:34.080453 140022762432320 run_pretraining.py:579]   horovod: True
INFO:tensorflow:  report_loss: True
I1217 11:16:34.080501 140022762432320 run_pretraining.py:579]   report_loss: True
INFO:tensorflow:  manual_fp16: False
I1217 11:16:34.080548 140022762432320 run_pretraining.py:579]   manual_fp16: False
INFO:tensorflow:  amp: True
I1217 11:16:34.080595 140022762432320 run_pretraining.py:579]   amp: True
INFO:tensorflow:  use_xla: True
I1217 11:16:34.080643 140022762432320 run_pretraining.py:579]   use_xla: True
INFO:tensorflow:  init_loss_scale: 4294967296
I1217 11:16:34.080697 140022762432320 run_pretraining.py:579]   init_loss_scale: 4294967296
INFO:tensorflow:  ?: False
I1217 11:16:34.080746 140022762432320 run_pretraining.py:579]   ?: False
INFO:tensorflow:  help: False
I1217 11:16:34.080794 140022762432320 run_pretraining.py:579]   help: False
INFO:tensorflow:  helpshort: False
I1217 11:16:34.080843 140022762432320 run_pretraining.py:579]   helpshort: False
INFO:tensorflow:  helpfull: False
I1217 11:16:34.080892 140022762432320 run_pretraining.py:579]   helpfull: False
INFO:tensorflow:  helpxml: False
I1217 11:16:34.080947 140022762432320 run_pretraining.py:579]   helpxml: False
INFO:tensorflow:**************************
I1217 11:16:34.080990 140022762432320 run_pretraining.py:580] **************************
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 11:16:34.081150 140022762432320 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 11:16:34.081582 140395977164608 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5926a20390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 11:16:34.081710 140022762432320 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5926a20390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5926a1abf8>) includes params argument, but params are not passed to Estimator.
W1217 11:16:34.082478 140022762432320 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5926a1abf8>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 11:16:34.082943 140022762432320 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1217 11:16:34.083016 140022762432320 run_pretraining.py:624]   Batch size = 96
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb00bf6e320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 11:16:34.084354 140395977164608 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb00bf6e320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb00bf68a60>) includes params argument, but params are not passed to Estimator.
W1217 11:16:34.085150 140395977164608 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb00bf68a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 11:16:34.085610 140395977164608 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1217 11:16:34.085695 140395977164608 run_pretraining.py:624]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 11:16:34.089422 140451614897984 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbd003b5470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 11:16:34.090130 140451614897984 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbd003b5470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fbd003afa60>) includes params argument, but params are not passed to Estimator.
W1217 11:16:34.090936 140451614897984 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fbd003afa60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 11:16:34.091384 140451614897984 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1217 11:16:34.091462 140451614897984 run_pretraining.py:624]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 11:16:34.100229 139675893147456 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f08639cc320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 11:16:34.100953 139675893147456 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f08639cc320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f08639c6a60>) includes params argument, but params are not passed to Estimator.
W1217 11:16:34.101737 139675893147456 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f08639c6a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 11:16:34.102186 139675893147456 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1217 11:16:34.102261 139675893147456 run_pretraining.py:624]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 11:16:34.142353 139834186573632 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2d3ea2c4e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 11:16:34.143075 139834186573632 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2d3ea2c4e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2d3ea26a60>) includes params argument, but params are not passed to Estimator.
W1217 11:16:34.145799 139834186573632 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2d3ea26a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 11:16:34.146243 139834186573632 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1217 11:16:34.146333 139834186573632 run_pretraining.py:624]   Batch size = 96
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 11:16:34.195190 139866384443200 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 11:16:34.195428 140228096599872 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 11:16:34.195803 140047690766144 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 11:16:34.213932 140022762432320 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 11:16:34.302628 140451614897984 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 11:16:34.298340 140395977164608 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 11:16:34.309876 139675893147456 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1217 11:16:34.327383 140228096599872 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 11:16:34.327639 140228096599872 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1217 11:16:34.327767 140228096599872 run_pretraining.py:259]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1217 11:16:34.327855 140228096599872 run_pretraining.py:259]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1217 11:16:34.327932 140228096599872 run_pretraining.py:259]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1217 11:16:34.328006 140228096599872 run_pretraining.py:259]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1217 11:16:34.328080 140228096599872 run_pretraining.py:259]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1217 11:16:34.328152 140228096599872 run_pretraining.py:259]   name = next_sentence_labels, shape = (96, 1)
I1217 11:16:34.328072 139866384443200 estimator.py:1148] Calling model_fn.
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1217 11:16:34.328222 140228096599872 run_pretraining.py:259]   name = segment_ids, shape = (96, 128)
INFO:tensorflow:*** Features ***
I1217 11:16:34.328298 139866384443200 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1217 11:16:34.328420 139866384443200 run_pretraining.py:259]   name = input_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = input_mask, shape = (96, 128)
W1217 11:16:34.328472 140228096599872 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

I1217 11:16:34.328509 139866384443200 run_pretraining.py:259]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1217 11:16:34.328584 139866384443200 run_pretraining.py:259]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1217 11:16:34.328669 139866384443200 run_pretraining.py:259]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1217 11:16:34.328745 139866384443200 run_pretraining.py:259]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1217 11:16:34.328819 139866384443200 run_pretraining.py:259]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1217 11:16:34.328891 139866384443200 run_pretraining.py:259]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 11:16:34.329132 139866384443200 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
I1217 11:16:34.329360 140047690766144 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 11:16:34.329576 140047690766144 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1217 11:16:34.329703 140047690766144 run_pretraining.py:259]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

I1217 11:16:34.329791 140047690766144 run_pretraining.py:259]   name = input_mask, shape = (96, 128)
W1217 11:16:34.329776 140228096599872 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1217 11:16:34.329868 140047690766144 run_pretraining.py:259]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1217 11:16:34.329936 140047690766144 run_pretraining.py:259]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1217 11:16:34.330009 140047690766144 run_pretraining.py:259]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1217 11:16:34.330080 140047690766144 run_pretraining.py:259]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1217 11:16:34.330150 140047690766144 run_pretraining.py:259]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 11:16:34.330417 140047690766144 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 11:16:34.330435 139866384443200 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 11:16:34.331709 140047690766144 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 11:16:34.338474 139834186573632 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1217 11:16:34.347720 140022762432320 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 11:16:34.347938 140022762432320 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1217 11:16:34.348097 140022762432320 run_pretraining.py:259]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1217 11:16:34.348183 140022762432320 run_pretraining.py:259]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1217 11:16:34.348259 140022762432320 run_pretraining.py:259]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1217 11:16:34.348344 140022762432320 run_pretraining.py:259]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1217 11:16:34.348417 140022762432320 run_pretraining.py:259]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1217 11:16:34.348488 140022762432320 run_pretraining.py:259]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1217 11:16:34.348558 140022762432320 run_pretraining.py:259]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 11:16:34.348835 140022762432320 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 11:16:34.350216 140022762432320 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 11:16:34.540825 140395977164608 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 11:16:34.541054 140395977164608 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1217 11:16:34.541173 140395977164608 run_pretraining.py:259]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1217 11:16:34.541264 140395977164608 run_pretraining.py:259]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1217 11:16:34.541360 140395977164608 run_pretraining.py:259]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1217 11:16:34.541437 140395977164608 run_pretraining.py:259]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1217 11:16:34.541512 140395977164608 run_pretraining.py:259]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1217 11:16:34.541585 140395977164608 run_pretraining.py:259]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1217 11:16:34.541668 140395977164608 run_pretraining.py:259]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 11:16:34.541903 140395977164608 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
I1217 11:16:34.542127 139675893147456 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 11:16:34.542369 139675893147456 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1217 11:16:34.542493 139675893147456 run_pretraining.py:259]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1217 11:16:34.542579 139675893147456 run_pretraining.py:259]   name = input_mask, shape = (96, 128)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1217 11:16:34.542665 139675893147456 run_pretraining.py:259]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1217 11:16:34.542577 140451614897984 estimator.py:1148] Calling model_fn.
I1217 11:16:34.542740 139675893147456 run_pretraining.py:259]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1217 11:16:34.542814 139675893147456 run_pretraining.py:259]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1217 11:16:34.542886 139675893147456 run_pretraining.py:259]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1217 11:16:34.542957 139675893147456 run_pretraining.py:259]   name = segment_ids, shape = (96, 128)
INFO:tensorflow:*** Features ***
I1217 11:16:34.545338 140451614897984 run_pretraining.py:257] *** Features ***
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:  name = input_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

I1217 11:16:34.545478 140451614897984 run_pretraining.py:259]   name = input_ids, shape = (96, 128)
I1217 11:16:34.545397 139834186573632 estimator.py:1148] Calling model_fn.
W1217 11:16:34.545504 139675893147456 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1217 11:16:34.545562 140451614897984 run_pretraining.py:259]   name = input_mask, shape = (96, 128)
INFO:tensorflow:*** Features ***
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1217 11:16:34.545613 139834186573632 run_pretraining.py:257] *** Features ***
I1217 11:16:34.545634 140451614897984 run_pretraining.py:259]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1217 11:16:34.545713 140451614897984 run_pretraining.py:259]   name = masked_lm_positions, shape = (96, 20)
I1217 11:16:34.545740 139834186573632 run_pretraining.py:259]   name = input_ids, shape = (96, 128)
W1217 11:16:34.545683 140395977164608 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1217 11:16:34.545789 140451614897984 run_pretraining.py:259]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1217 11:16:34.545821 139834186573632 run_pretraining.py:259]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1217 11:16:34.545856 140451614897984 run_pretraining.py:259]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1217 11:16:34.545893 139834186573632 run_pretraining.py:259]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1217 11:16:34.545921 140451614897984 run_pretraining.py:259]   name = segment_ids, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1217 11:16:34.545962 139834186573632 run_pretraining.py:259]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1217 11:16:34.546030 139834186573632 run_pretraining.py:259]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1217 11:16:34.546104 139834186573632 run_pretraining.py:259]   name = next_sentence_labels, shape = (96, 1)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1217 11:16:34.546175 139834186573632 run_pretraining.py:259]   name = segment_ids, shape = (96, 128)
W1217 11:16:34.546155 140451614897984 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 11:16:34.546428 139834186573632 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 11:16:34.546839 139675893147456 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 11:16:34.547473 140451614897984 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 11:16:34.547736 139834186573632 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 11:16:36.418254 140022762432320 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 11:16:36.483613 140228096599872 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 11:16:36.515867 139866384443200 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 11:16:36.523058 140047690766144 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 11:16:37.827720 139834186573632 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 11:16:38.458777 139675893147456 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 11:16:38.648777 140451614897984 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 11:16:38.649574 140395977164608 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 11:16:43.604464 140022762432320 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 11:16:43.722647 140047690766144 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 11:16:43.728719 140228096599872 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 11:16:43.781675 139866384443200 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 11:16:43.964223 140022762432320 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 11:16:44.081411 140047690766144 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 11:16:44.089341 140228096599872 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 11:16:44.144060 139866384443200 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 11:16:44.578654 139834186573632 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 11:16:44.841395 139675893147456 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 11:16:44.875588 139834186573632 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 11:16:44.943344 140395977164608 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 11:16:44.977320 140451614897984 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 11:16:45.145420 139675893147456 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 11:16:45.250031 140395977164608 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 11:16:45.284221 140451614897984 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1217 11:16:57.691434 140022762432320 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1217 11:16:57.693181 140022762432320 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Done calling model_fn.
I1217 11:16:57.935870 140228096599872 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 11:16:58.385447 139834186573632 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 11:16:59.183135 139866384443200 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 11:16:59.954391 140047690766144 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 11:17:01.310659 139675893147456 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 11:17:01.850788 140451614897984 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 11:17:01.917326 140395977164608 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Graph was finalized.
I1217 11:17:10.813132 140022762432320 monitored_session.py:240] Graph was finalized.
2020-12-17 11:17:10.847488: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 11:17:10.847649: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5d3b9f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:10.847912: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 11:17:10.851005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 11:17:11.122320 140228096599872 monitored_session.py:240] Graph was finalized.
2020-12-17 11:17:11.151091: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 11:17:11.151264: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ea0290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:11.151493: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 11:17:11.154685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 11:17:11.809480 139834186573632 monitored_session.py:240] Graph was finalized.
2020-12-17 11:17:11.842806: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 11:17:11.842961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6143cb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:11.842980: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 11:17:11.846134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 11:17:12.121034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:12.121423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:12.129769: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x174a2250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:12.129796: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 11:17:12.130097: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x184f87e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:12.130121: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 11:17:12.131725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:12.132114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:12.139108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0c.0
2020-12-17 11:17:12.139172: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:12.139417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0a.0
2020-12-17 11:17:12.139488: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:12.142909: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:17:12.142924: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:17:12.144572: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 11:17:12.144562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 11:17:12.144976: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 11:17:12.144981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 11:17:12.148023: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 11:17:12.148747: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 11:17:12.149015: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:17:12.149196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:12.152880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 11:17:12.153547: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 11:17:12.153782: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:17:12.153910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:12.156616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:12.161484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:12.164522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-17 11:17:12.164571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:12.168515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 2
2020-12-17 11:17:12.168554: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
INFO:tensorflow:Graph was finalized.
I1217 11:17:12.370025 139866384443200 monitored_session.py:240] Graph was finalized.
2020-12-17 11:17:12.392495: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 11:17:12.392674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a658c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:12.392693: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 11:17:12.395767: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 11:17:12.902112 140047690766144 monitored_session.py:240] Graph was finalized.
2020-12-17 11:17:12.929493: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 11:17:12.929649: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c595e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:12.929661: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 11:17:12.932810: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 11:17:13.033323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.041827: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6137b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:13.041874: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 11:17:13.043722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.062526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0d.0
2020-12-17 11:17:13.062592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:13.065990: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:17:13.067554: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 11:17:13.067973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 11:17:13.070845: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 11:17:13.071541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 11:17:13.071817: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:17:13.071961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.087076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.092513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 3
2020-12-17 11:17:13.092578: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:13.452809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 11:17:13.452860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      2
2020-12-17 11:17:13.452871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   N
2020-12-17 11:17:13.453226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.455586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 11:17:13.455626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-17 11:17:13.455636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-17 11:17:13.461088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.475824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.478100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.480856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0c.0, compute capability: 7.0)
2020-12-17 11:17:13.483232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0a.0, compute capability: 7.0)
2020-12-17 11:17:13.544621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.558491: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1705b3b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:13.558522: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 11:17:13.559359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.561812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:10.0
2020-12-17 11:17:13.561861: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:13.565270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:17:13.566754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 11:17:13.567183: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 11:17:13.569971: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 11:17:13.570667: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 11:17:13.570935: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:17:13.571079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.576373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.590857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 6
2020-12-17 11:17:13.590907: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:13.782965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.784831: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaadaf50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:13.784860: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 11:17:13.785500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.786792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0e.0
2020-12-17 11:17:13.786840: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:13.790079: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:17:13.791572: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 11:17:13.791978: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 11:17:13.794725: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 11:17:13.795422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 11:17:13.795672: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:17:13.795810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.797260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:13.798513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 4
2020-12-17 11:17:13.798554: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
INFO:tensorflow:Graph was finalized.
I1217 11:17:14.322249 139675893147456 monitored_session.py:240] Graph was finalized.
2020-12-17 11:17:14.332403: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 11:17:14.332552: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5263940 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:14.332571: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 11:17:14.335533: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 11:17:14.346956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 11:17:14.346997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      3
2020-12-17 11:17:14.347007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   N
2020-12-17 11:17:14.354695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:14.377361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:14.380376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0d.0, compute capability: 7.0)
2020-12-17 11:17:14.657990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 11:17:14.658043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      6
2020-12-17 11:17:14.658054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N
2020-12-17 11:17:14.698551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:14.701969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:14.706144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:10.0, compute capability: 7.0)
INFO:tensorflow:Graph was finalized.
I1217 11:17:14.854559 140451614897984 monitored_session.py:240] Graph was finalized.
2020-12-17 11:17:14.877498: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 11:17:14.877658: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x65a27d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:14.877759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 11:17:14.880796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 11:17:14.914815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 11:17:14.914861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      4
2020-12-17 11:17:14.914872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N
2020-12-17 11:17:14.915570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:14.917893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:14.942878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0e.0, compute capability: 7.0)
INFO:tensorflow:Graph was finalized.
I1217 11:17:14.966561 140395977164608 monitored_session.py:240] Graph was finalized.
2020-12-17 11:17:14.991894: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 11:17:14.992073: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13b6fa70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:14.992092: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 11:17:14.995204: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 11:17:15.018465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:15.021712: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xa0e35d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:15.021742: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 11:17:15.024091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:15.026932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:11.0
2020-12-17 11:17:15.026980: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:15.030391: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:17:15.031883: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 11:17:15.032313: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 11:17:15.035258: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 11:17:15.035941: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 11:17:15.036215: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:17:15.036367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:15.043711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:15.047104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 7
2020-12-17 11:17:15.047157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:15.536539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:15.543166: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb422ce0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:15.543197: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 11:17:15.544420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:15.550398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0f.0
2020-12-17 11:17:15.550452: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:15.553775: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:17:15.555249: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 11:17:15.555673: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 11:17:15.558479: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 11:17:15.559152: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 11:17:15.559432: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:17:15.559567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:15.577186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:15.582914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 5
2020-12-17 11:17:15.582965: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:15.979456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:15.985973: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb282690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 11:17:15.986004: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 11:17:15.987166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:15.991740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0b.0
2020-12-17 11:17:15.991788: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:15.995141: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:17:15.996647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 11:17:15.997047: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 11:17:15.999803: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 11:17:16.000493: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 11:17:16.000743: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:17:16.000875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:16.013632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:16.018516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 1
2020-12-17 11:17:16.018572: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:17:16.290293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 11:17:16.290347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      7
2020-12-17 11:17:16.290358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   N
2020-12-17 11:17:16.291442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:16.320244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:16.325326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:11.0, compute capability: 7.0)
2020-12-17 11:17:16.790811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 11:17:16.790865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      5
2020-12-17 11:17:16.790875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N
2020-12-17 11:17:16.791215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:16.792638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:16.793923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0f.0, compute capability: 7.0)
2020-12-17 11:17:17.237987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 11:17:17.238039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      1
2020-12-17 11:17:17.238050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N
2020-12-17 11:17:17.238443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:17.239855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:17:17.241155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0b.0, compute capability: 7.0)
2020-12-17 11:17:21.916607: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:21.963306: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:21.965590: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:22.013211: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:23.062116: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:23.103814: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:23.112390: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:23.150893: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:23.391462: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:23.440716: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:24.954589: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:25.009468: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:25.415197: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:25.449666: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:25.890230: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:25.938819: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:28.200707: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 11:17:28.358825: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 11:17:29.385118: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 11:17:29.553966: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 11:17:29.743713: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 11:17:31.190330: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 11:17:31.534807: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 11:17:31.932802: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 11:17:36.328314: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:36.337778: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:36.676450: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:36.686274: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:37.309238: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:37.332305: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:37.547101: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:37.557941: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:37.862449: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:37.887554: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1217 11:17:38.295078 140228096599872 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 11:17:38.588081 140022762432320 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 11:17:39.273491 139866384443200 session_manager.py:500] Running local_init_op.
2020-12-17 11:17:39.394343: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:39.423579: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1217 11:17:39.527274 139834186573632 session_manager.py:500] Running local_init_op.
2020-12-17 11:17:39.683925: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:39.684195: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:39.733270: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:39.758983: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1217 11:17:39.782723 140047690766144 session_manager.py:500] Running local_init_op.
2020-12-17 11:17:39.964459: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:39.964727: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 11:17:40.024405 140228096599872 session_manager.py:502] Done running local_init_op.
2020-12-17 11:17:40.048109: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:40.071619: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 11:17:40.283026 140022762432320 session_manager.py:502] Done running local_init_op.
2020-12-17 11:17:40.664558: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:40.664832: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:40.901430: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:40.901696: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 11:17:40.987491 139866384443200 session_manager.py:502] Done running local_init_op.
2020-12-17 11:17:41.114056: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:41.114349: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 11:17:41.231428 139834186573632 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 11:17:41.269945 139675893147456 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 11:17:41.440404 140047690766144 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 11:17:41.571953 140451614897984 session_manager.py:500] Running local_init_op.
2020-12-17 11:17:41.820934: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:41.848016: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1217 11:17:41.873487 140395977164608 session_manager.py:500] Running local_init_op.
2020-12-17 11:17:42.010042: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:42.023035: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:42.296252: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:42.296545: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:42.370885: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:42.381922: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:42.451572: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:42.452247: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 11:17:42.477460 139675893147456 session_manager.py:502] Done running local_init_op.
2020-12-17 11:17:42.518787: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:42.530164: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:42.624969: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:42.625236: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 11:17:42.636170 140451614897984 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 11:17:42.807122 140395977164608 session_manager.py:502] Done running local_init_op.
2020-12-17 11:17:42.824114: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:42.838859: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:43.790879: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:43.817100: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:43.869973: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:43.883423: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:43.889339: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:43.891660: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:43.894808: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:44.058810: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:44.068990: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:44.335358: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:44.363248: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:44.576192: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:44.576560: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:44.885706: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:44.886113: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:44.894108: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:44.909425: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:44.912659: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:45.204095: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:45.204513: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:45.223595: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:45.225957: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:45.229148: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:45.922968: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:45.935696: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:45.941599: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:45.943931: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:45.951501: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:46.428524: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:46.461518: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.075539: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:47.088717: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.094791: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.097218: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.113566: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.246197: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:47.259720: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.265876: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.268241: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.271486: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.484708: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:47.520444: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:47.520949: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.526942: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.528968: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.529372: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.532597: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:47.802387: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:47.867591: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:48.443534: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:48.494720: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:49.719123: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:49.773046: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:49.847937: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:49.899267: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:17:50.195132: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:17:50.244495: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1/model.ckpt.
I1217 11:18:00.154553 140022762432320 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1/model.ckpt.
2020-12-17 11:18:01.228762: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:01.239452: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:18:08.907756: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:08.908326: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:18:08.914299: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:18:08.916645: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:18:08.919836: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:18:10.190131: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:10.208517: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1217 11:18:13.650314 140022762432320 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2020-12-17 11:18:15.126077: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:15.126401: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:18:54.744575: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:54.852564: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:54.883320: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:54.889918: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:54.976829: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:54.984059: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:55.247585: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:18:55.327781: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:18:55.378028: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:18:55.392652: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:55.403579: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:18:55.474701: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:18:55.483978: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:18:55.897588: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:18:57.391442: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:18:57.796752: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:19:22.466316: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:19:22.484768: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:19:23.049300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:19:23.242728: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:19:23.462095: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:19:23.543308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:19:23.614266: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:19:24.237593: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:19:24.252584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:19:24.891358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:19:25.088677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:19:25.378518: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:19:25.417816: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:19:25.689623: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:19:25.738831: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:19:27.481399: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:20:42.445031: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 11:20:42.857454: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 11:20:43.543452: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 11:20:44.151070: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 11:20:44.311577: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 11:20:44.476326: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 11:20:46.072543: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 11:20:46.852341: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.121572, step = 0
I1217 11:20:50.088116 140022762432320 basic_session_run_hooks.py:262] loss = 11.121572, step = 0
2020-12-17 11:20:51.607137: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:20:51.607550: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:20:51.630806: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:20:51.631175: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:20:51.631998: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:20:51.632362: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:20:51.642773: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:20:51.643113: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:20:51.646961: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:20:51.659534: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:20:51.659877: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:20:51.660316: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:20:51.661583: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:20:51.661918: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:loss = 11.1419, step = 0
I1217 11:20:51.986457 140451614897984 basic_session_run_hooks.py:262] loss = 11.1419, step = 0
INFO:tensorflow:loss = 11.166566, step = 0
I1217 11:20:52.019145 139834186573632 basic_session_run_hooks.py:262] loss = 11.166566, step = 0
INFO:tensorflow:loss = 11.15233, step = 0
I1217 11:20:52.022455 140047690766144 basic_session_run_hooks.py:262] loss = 11.15233, step = 0
INFO:tensorflow:loss = 11.158863, step = 0
I1217 11:20:52.028466 139675893147456 basic_session_run_hooks.py:262] loss = 11.158863, step = 0
INFO:tensorflow:loss = 11.179362, step = 0
I1217 11:20:52.048066 140395977164608 basic_session_run_hooks.py:262] loss = 11.179362, step = 0
INFO:tensorflow:loss = 11.191325, step = 0
I1217 11:20:52.053541 140228096599872 basic_session_run_hooks.py:262] loss = 11.191325, step = 0
INFO:tensorflow:loss = 11.15086, step = 0
I1217 11:20:52.059359 139866384443200 basic_session_run_hooks.py:262] loss = 11.15086, step = 0
2020-12-17 11:21:31.802251: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:21:32.314473: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:21:33.119934: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:21:33.286608: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:21:33.457435: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:21:33.512252: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:21:33.613272: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:21:33.698292: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:21:33.758541: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:21:33.821752: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:21:33.955951: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:21:34.023462: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:21:34.221528: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:21:34.261964: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 11:21:34.292817: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:21:34.804241: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:20.962214 140451614897984 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:20.964560 140022762432320 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:20.965342 140228096599872 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:20.974396 139866384443200 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:20.974327 140047690766144 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:20.974410 139834186573632 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:20.974394 140395977164608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:20.989555 139675893147456 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.192037 140451614897984 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.192054 139834186573632 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.192033 140228096599872 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.192033 139866384443200 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.192040 140047690766144 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.192034 139675893147456 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.192358 140022762432320 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.192392 140395977164608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.398663 139675893147456 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.398672 140451614897984 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.398695 139834186573632 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.398745 140047690766144 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.398750 140395977164608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.398699 140228096599872 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.398763 139866384443200 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.399698 140022762432320 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.595691 139675893147456 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.595708 139834186573632 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.595765 140228096599872 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.595753 140047690766144 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.595774 139866384443200 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.595787 140451614897984 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.595785 140395977164608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.596069 140022762432320 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.803021 140451614897984 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.803008 139675893147456 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.803013 139834186573632 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.803047 139866384443200 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.803039 140047690766144 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.803085 140395977164608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.803383 140022762432320 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 11:23:21.803652 140228096599872 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:23:56.206687 - Iteration: 1  throughput_train : 198.393 seq/s mlm_loss : 10.4631  nsp_loss : 0.6845  total_loss : 11.1476  avg_loss_step : 11.1535  learning_rate : 0.0  loss_scaler : 4294967296
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:24:14.730580 - Iteration: 1  throughput_train : 3651.336 seq/s mlm_loss : 10.4886  nsp_loss : 0.7036  total_loss : 11.1922  avg_loss_step : 11.1567  learning_rate : 0.0  loss_scaler : 2147483648
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:24:32.882008 - Iteration: 1  throughput_train : 3726.377 seq/s mlm_loss : 10.4968  nsp_loss : 0.7089  total_loss : 11.2058  avg_loss_step : 11.1554  learning_rate : 0.0  loss_scaler : 1073741824
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:24:51.071634 - Iteration: 1  throughput_train : 3718.461 seq/s mlm_loss : 10.4808  nsp_loss : 0.6851  total_loss : 11.1658  avg_loss_step : 11.1571  learning_rate : 0.0  loss_scaler : 536870912
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:25:09.281031 - Iteration: 1  throughput_train : 3714.582 seq/s mlm_loss : 10.4661  nsp_loss : 0.6753  total_loss : 11.1414  avg_loss_step : 11.1555  learning_rate : 0.0  loss_scaler : 268435456
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:25:27.540214 - Iteration: 1  throughput_train : 3705.061 seq/s mlm_loss : 10.4948  nsp_loss : 0.6949  total_loss : 11.1897  avg_loss_step : 11.1565  learning_rate : 0.0  loss_scaler : 134217728
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:25:45.937986 - Iteration: 1  throughput_train : 3676.415 seq/s mlm_loss : 10.4751  nsp_loss : 0.6934  total_loss : 11.1686  avg_loss_step : 11.1558  learning_rate : 0.0  loss_scaler : 67108864
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:26:20.969348 - Iteration: 1  throughput_train : 1930.051 seq/s mlm_loss : 10.4895  nsp_loss : 0.6979  total_loss : 11.1873  avg_loss_step : 11.1549  learning_rate : 0.0  loss_scaler : 33554432
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:27:48.168144 - Iteration: 2  throughput_train : 775.192 seq/s mlm_loss : 10.4655  nsp_loss : 0.6744  total_loss : 11.1400  avg_loss_step : 11.1567  learning_rate : 0.0  loss_scaler : 16777216
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:28:07.377645 - Iteration: 3  throughput_train : 3523.191 seq/s mlm_loss : 10.4625  nsp_loss : 0.7090  total_loss : 11.1716  avg_loss_step : 11.1518  learning_rate : 3e-06  loss_scaler : 16777216
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:28:26.442242 - Iteration: 4  throughput_train : 3547.855 seq/s mlm_loss : 10.4751  nsp_loss : 0.6862  total_loss : 11.1613  avg_loss_step : 11.1580  learning_rate : 6e-06  loss_scaler : 16777216
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:28:45.483338 - Iteration: 5  throughput_train : 3552.078 seq/s mlm_loss : 10.4527  nsp_loss : 0.7014  total_loss : 11.1541  avg_loss_step : 11.1505  learning_rate : 9e-06  loss_scaler : 16777216
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 11:29:04.745849 - Iteration: 6  throughput_train : 3511.352 seq/s mlm_loss : 10.4433  nsp_loss : 0.7015  total_loss : 11.1449  avg_loss_step : 11.1477  learning_rate : 1.2e-05  loss_scaler : 16777216
DLL 2020-12-17 11:29:23.931160 - Iteration: 7  throughput_train : 3525.649 seq/s mlm_loss : 10.4735  nsp_loss : 0.6918  total_loss : 11.1653  avg_loss_step : 11.1462  learning_rate : 1.50000005e-05  loss_scaler : 16777216
DLL 2020-12-17 11:29:43.091952 - Iteration: 8  throughput_train : 3529.907 seq/s mlm_loss : 10.4573  nsp_loss : 0.6910  total_loss : 11.1483  avg_loss_step : 11.1468  learning_rate : 1.8e-05  loss_scaler : 16777216
DLL 2020-12-17 11:30:02.195209 - Iteration: 9  throughput_train : 3540.681 seq/s mlm_loss : 10.4630  nsp_loss : 0.7057  total_loss : 11.1687  avg_loss_step : 11.1367  learning_rate : 2.1e-05  loss_scaler : 16777216
DLL 2020-12-17 11:30:21.334252 - Iteration: 10  throughput_train : 3533.895 seq/s mlm_loss : 10.4365  nsp_loss : 0.6906  total_loss : 11.1271  avg_loss_step : 11.1339  learning_rate : 2.4e-05  loss_scaler : 16777216
DLL 2020-12-17 11:30:40.487309 - Iteration: 11  throughput_train : 3531.295 seq/s mlm_loss : 10.4538  nsp_loss : 0.6809  total_loss : 11.1347  avg_loss_step : 11.1236  learning_rate : 2.7000002e-05  loss_scaler : 16777216
DLL 2020-12-17 11:30:59.751571 - Iteration: 12  throughput_train : 3510.917 seq/s mlm_loss : 10.4132  nsp_loss : 0.6734  total_loss : 11.0866  avg_loss_step : 11.1187  learning_rate : 3.0000001e-05  loss_scaler : 16777216
DLL 2020-12-17 11:31:18.985683 - Iteration: 13  throughput_train : 3516.497 seq/s mlm_loss : 10.4310  nsp_loss : 0.6893  total_loss : 11.1203  avg_loss_step : 11.1076  learning_rate : 3.3e-05  loss_scaler : 16777216
DLL 2020-12-17 11:31:38.147424 - Iteration: 14  throughput_train : 3529.712 seq/s mlm_loss : 10.4216  nsp_loss : 0.7058  total_loss : 11.1274  avg_loss_step : 11.1004  learning_rate : 3.6e-05  loss_scaler : 16777216
DLL 2020-12-17 11:31:57.312422 - Iteration: 15  throughput_train : 3529.269 seq/s mlm_loss : 10.3925  nsp_loss : 0.6741  total_loss : 11.0666  avg_loss_step : 11.0862  learning_rate : 3.9000002e-05  loss_scaler : 16777216
DLL 2020-12-17 11:32:16.442774 - Iteration: 16  throughput_train : 3535.621 seq/s mlm_loss : 10.3889  nsp_loss : 0.6808  total_loss : 11.0697  avg_loss_step : 11.0788  learning_rate : 4.2e-05  loss_scaler : 16777216
DLL 2020-12-17 11:32:35.564621 - Iteration: 17  throughput_train : 3537.155 seq/s mlm_loss : 10.3688  nsp_loss : 0.7025  total_loss : 11.0712  avg_loss_step : 11.0700  learning_rate : 4.5e-05  loss_scaler : 16777216
DLL 2020-12-17 11:32:54.937216 - Iteration: 18  throughput_train : 3491.186 seq/s mlm_loss : 10.3890  nsp_loss : 0.6822  total_loss : 11.0711  avg_loss_step : 11.0557  learning_rate : 4.8e-05  loss_scaler : 16777216
DLL 2020-12-17 11:33:13.973723 - Iteration: 19  throughput_train : 3553.632 seq/s mlm_loss : 10.3583  nsp_loss : 0.7082  total_loss : 11.0664  avg_loss_step : 11.0462  learning_rate : 5.1000003e-05  loss_scaler : 16777216
DLL 2020-12-17 11:33:33.089371 - Iteration: 20  throughput_train : 3538.366 seq/s mlm_loss : 10.3116  nsp_loss : 0.6861  total_loss : 10.9977  avg_loss_step : 11.0286  learning_rate : 5.4000004e-05  loss_scaler : 16777216
DLL 2020-12-17 11:33:52.180642 - Iteration: 21  throughput_train : 3543.203 seq/s mlm_loss : 10.3150  nsp_loss : 0.6896  total_loss : 11.0046  avg_loss_step : 11.0118  learning_rate : 5.7e-05  loss_scaler : 16777216
DLL 2020-12-17 11:34:11.340166 - Iteration: 22  throughput_train : 3530.325 seq/s mlm_loss : 10.3212  nsp_loss : 0.6934  total_loss : 11.0146  avg_loss_step : 11.0011  learning_rate : 6.0000002e-05  loss_scaler : 16777216
DLL 2020-12-17 11:34:30.463003 - Iteration: 23  throughput_train : 3536.897 seq/s mlm_loss : 10.2801  nsp_loss : 0.6487  total_loss : 10.9288  avg_loss_step : 10.9798  learning_rate : 6.3e-05  loss_scaler : 16777216
DLL 2020-12-17 11:34:49.641792 - Iteration: 24  throughput_train : 3526.569 seq/s mlm_loss : 10.2555  nsp_loss : 0.6714  total_loss : 10.9269  avg_loss_step : 10.9646  learning_rate : 6.6e-05  loss_scaler : 16777216
DLL 2020-12-17 11:35:08.738367 - Iteration: 25  throughput_train : 3541.995 seq/s mlm_loss : 10.2725  nsp_loss : 0.6940  total_loss : 10.9665  avg_loss_step : 10.9461  learning_rate : 6.9e-05  loss_scaler : 16777216
DLL 2020-12-17 11:35:27.890373 - Iteration: 26  throughput_train : 3531.563 seq/s mlm_loss : 10.2515  nsp_loss : 0.7042  total_loss : 10.9557  avg_loss_step : 10.9316  learning_rate : 7.2e-05  loss_scaler : 16777216
DLL 2020-12-17 11:35:47.054505 - Iteration: 27  throughput_train : 3529.203 seq/s mlm_loss : 10.2422  nsp_loss : 0.6903  total_loss : 10.9325  avg_loss_step : 10.9150  learning_rate : 7.5e-05  loss_scaler : 16777216
DLL 2020-12-17 11:36:06.287702 - Iteration: 28  throughput_train : 3516.695 seq/s mlm_loss : 10.2455  nsp_loss : 0.6864  total_loss : 10.9319  avg_loss_step : 10.8959  learning_rate : 7.8000005e-05  loss_scaler : 16777216
DLL 2020-12-17 11:36:25.357016 - Iteration: 29  throughput_train : 3546.730 seq/s mlm_loss : 10.1956  nsp_loss : 0.6658  total_loss : 10.8614  avg_loss_step : 10.8798  learning_rate : 8.1000006e-05  loss_scaler : 16777216
DLL 2020-12-17 11:36:44.593072 - Iteration: 30  throughput_train : 3516.495 seq/s mlm_loss : 10.1593  nsp_loss : 0.6796  total_loss : 10.8389  avg_loss_step : 10.8560  learning_rate : 8.4e-05  loss_scaler : 16777216
DLL 2020-12-17 11:37:03.846167 - Iteration: 31  throughput_train : 3513.217 seq/s mlm_loss : 10.1555  nsp_loss : 0.6807  total_loss : 10.8362  avg_loss_step : 10.8363  learning_rate : 8.7e-05  loss_scaler : 16777216
DLL 2020-12-17 11:37:22.995006 - Iteration: 32  throughput_train : 3532.102 seq/s mlm_loss : 10.1401  nsp_loss : 0.7008  total_loss : 10.8409  avg_loss_step : 10.8102  learning_rate : 9e-05  loss_scaler : 16777216
DLL 2020-12-17 11:37:42.070720 - Iteration: 33  throughput_train : 3545.735 seq/s mlm_loss : 10.1073  nsp_loss : 0.6781  total_loss : 10.7854  avg_loss_step : 10.7946  learning_rate : 9.3e-05  loss_scaler : 16777216
DLL 2020-12-17 11:38:01.282300 - Iteration: 34  throughput_train : 3520.994 seq/s mlm_loss : 10.0877  nsp_loss : 0.6650  total_loss : 10.7526  avg_loss_step : 10.7702  learning_rate : 9.6e-05  loss_scaler : 16777216
DLL 2020-12-17 11:38:20.469399 - Iteration: 35  throughput_train : 3525.506 seq/s mlm_loss : 10.0764  nsp_loss : 0.6967  total_loss : 10.7731  avg_loss_step : 10.7543  learning_rate : 9.9000004e-05  loss_scaler : 16777216
DLL 2020-12-17 11:38:39.617827 - Iteration: 36  throughput_train : 3532.137 seq/s mlm_loss : 10.0865  nsp_loss : 0.6784  total_loss : 10.7649  avg_loss_step : 10.7356  learning_rate : 0.000102000005  loss_scaler : 16777216
DLL 2020-12-17 11:38:59.010457 - Iteration: 37  throughput_train : 3487.700 seq/s mlm_loss : 10.0108  nsp_loss : 0.6792  total_loss : 10.6900  avg_loss_step : 10.7042  learning_rate : 0.00010500001  loss_scaler : 16777216
DLL 2020-12-17 11:39:18.075211 - Iteration: 38  throughput_train : 3547.722 seq/s mlm_loss : 9.9972  nsp_loss : 0.6806  total_loss : 10.6778  avg_loss_step : 10.6817  learning_rate : 0.00010800001  loss_scaler : 16777216
DLL 2020-12-17 11:39:37.219968 - Iteration: 39  throughput_train : 3532.701 seq/s mlm_loss : 9.9802  nsp_loss : 0.7014  total_loss : 10.6816  avg_loss_step : 10.6690  learning_rate : 0.000111  loss_scaler : 16777216
DLL 2020-12-17 11:39:56.378467 - Iteration: 40  throughput_train : 3530.201 seq/s mlm_loss : 9.9838  nsp_loss : 0.7208  total_loss : 10.7046  avg_loss_step : 10.6630  learning_rate : 0.000114  loss_scaler : 8388608
DLL 2020-12-17 11:40:15.549024 - Iteration: 41  throughput_train : 3528.033 seq/s mlm_loss : 9.9716  nsp_loss : 0.7142  total_loss : 10.6858  avg_loss_step : 10.6406  learning_rate : 0.000117  loss_scaler : 8388608
DLL 2020-12-17 11:40:34.719251 - Iteration: 42  throughput_train : 3528.492 seq/s mlm_loss : 9.9123  nsp_loss : 0.6771  total_loss : 10.5894  avg_loss_step : 10.6134  learning_rate : 0.000120000004  loss_scaler : 8388608
DLL 2020-12-17 11:40:53.765877 - Iteration: 43  throughput_train : 3551.216 seq/s mlm_loss : 9.8599  nsp_loss : 0.6927  total_loss : 10.5526  avg_loss_step : 10.5951  learning_rate : 0.000123  loss_scaler : 8388608
DLL 2020-12-17 11:41:12.837914 - Iteration: 44  throughput_train : 3546.632 seq/s mlm_loss : 9.9146  nsp_loss : 0.6605  total_loss : 10.5751  avg_loss_step : 10.5707  learning_rate : 0.000126  loss_scaler : 8388608
DLL 2020-12-17 11:41:32.078740 - Iteration: 45  throughput_train : 3515.166 seq/s mlm_loss : 9.8760  nsp_loss : 0.6944  total_loss : 10.5704  avg_loss_step : 10.5505  learning_rate : 0.00012900001  loss_scaler : 8388608
DLL 2020-12-17 11:41:51.310258 - Iteration: 46  throughput_train : 3516.931 seq/s mlm_loss : 9.8061  nsp_loss : 0.7098  total_loss : 10.5158  avg_loss_step : 10.5229  learning_rate : 0.000132  loss_scaler : 8388608
DLL 2020-12-17 11:42:10.479904 - Iteration: 47  throughput_train : 3528.186 seq/s mlm_loss : 9.8173  nsp_loss : 0.6928  total_loss : 10.5101  avg_loss_step : 10.5015  learning_rate : 0.00013500001  loss_scaler : 8388608
DLL 2020-12-17 11:42:29.583195 - Iteration: 48  throughput_train : 3540.443 seq/s mlm_loss : 9.7747  nsp_loss : 0.6738  total_loss : 10.4485  avg_loss_step : 10.4798  learning_rate : 0.000138  loss_scaler : 8388608
DLL 2020-12-17 11:42:48.849456 - Iteration: 49  throughput_train : 3510.492 seq/s mlm_loss : 9.7802  nsp_loss : 0.6535  total_loss : 10.4338  avg_loss_step : 10.4537  learning_rate : 0.00014100001  loss_scaler : 8388608
DLL 2020-12-17 11:43:07.976975 - Iteration: 50  throughput_train : 3536.197 seq/s mlm_loss : 9.7982  nsp_loss : 0.6842  total_loss : 10.4824  avg_loss_step : 10.4301  learning_rate : 0.000144  loss_scaler : 8388608
DLL 2020-12-17 11:43:27.275207 - Iteration: 51  throughput_train : 3516.397 seq/s mlm_loss : 9.7227  nsp_loss : 0.6925  total_loss : 10.4152  avg_loss_step : 10.4060  learning_rate : 0.000147  loss_scaler : 8388608
INFO:tensorflow:Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1/model.ckpt.
I1217 11:43:27.277129 140022762432320 basic_session_run_hooks.py:606] Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 10.425656.
I1217 11:43:29.229891 140451614897984 estimator.py:371] Loss for final step: 10.425656.
INFO:tensorflow:Loss for final step: 10.347505.
I1217 11:43:29.230815 140047690766144 estimator.py:371] Loss for final step: 10.347505.
INFO:tensorflow:Loss for final step: 10.36901.
I1217 11:43:29.241028 139866384443200 estimator.py:371] Loss for final step: 10.36901.
INFO:tensorflow:Loss for final step: 10.420385.
I1217 11:43:29.252789 140228096599872 estimator.py:371] Loss for final step: 10.420385.
INFO:tensorflow:Loss for final step: 10.466461.
I1217 11:43:29.331307 139834186573632 estimator.py:371] Loss for final step: 10.466461.
INFO:tensorflow:Loss for final step: 10.419777.
I1217 11:43:29.351655 140395977164608 estimator.py:371] Loss for final step: 10.419777.
INFO:tensorflow:Loss for final step: 10.376382.
I1217 11:43:29.377379 139675893147456 estimator.py:371] Loss for final step: 10.376382.
INFO:tensorflow:Loss for final step: 10.415229.
I1217 11:43:33.973663 140022762432320 estimator.py:371] Loss for final step: 10.415229.
INFO:tensorflow:-----------------------------
I1217 11:43:33.975002 140022762432320 run_pretraining.py:642] -----------------------------
INFO:tensorflow:Total Training Time = 1619.89 for Sentences = 3379200
I1217 11:43:33.975096 140022762432320 run_pretraining.py:644] Total Training Time = 1619.89 for Sentences = 3379200
INFO:tensorflow:Total Training Time W/O Overhead = 861.78 for Sentences = 2500608
I1217 11:43:33.975175 140022762432320 run_pretraining.py:646] Total Training Time W/O Overhead = 861.78 for Sentences = 2500608
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 2086.07
I1217 11:43:33.975236 140022762432320 run_pretraining.py:647] Throughput Average (sentences/sec) with overhead = 2086.07
INFO:tensorflow:Throughput Average (sentences/sec) = 2901.66
I1217 11:43:33.975319 140022762432320 run_pretraining.py:648] Throughput Average (sentences/sec) = 2901.66
DLL 2020-12-17 11:43:33.975381 -  throughput_train : 2901.663 seq/s
INFO:tensorflow:-----------------------------
I1217 11:43:33.975567 140022762432320 run_pretraining.py:650] -----------------------------
INFO:tensorflow:***** Running evaluation *****
I1217 11:43:33.975663 140022762432320 run_pretraining.py:653] ***** Running evaluation *****
INFO:tensorflow:  Batch size = 8
I1217 11:43:33.975726 140022762432320 run_pretraining.py:654]   Batch size = 8
INFO:tensorflow:Calling model_fn.
I1217 11:43:34.019163 140022762432320 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 11:43:34.019362 140022762432320 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (?, 128)
I1217 11:43:34.019473 140022762432320 run_pretraining.py:259]   name = input_ids, shape = (?, 128)
INFO:tensorflow:  name = input_mask, shape = (?, 128)
I1217 11:43:34.019559 140022762432320 run_pretraining.py:259]   name = input_mask, shape = (?, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (?, 20)
I1217 11:43:34.019639 140022762432320 run_pretraining.py:259]   name = masked_lm_ids, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (?, 20)
I1217 11:43:34.019715 140022762432320 run_pretraining.py:259]   name = masked_lm_positions, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (?, 20)
I1217 11:43:34.019792 140022762432320 run_pretraining.py:259]   name = masked_lm_weights, shape = (?, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (?, 1)
I1217 11:43:34.019864 140022762432320 run_pretraining.py:259]   name = next_sentence_labels, shape = (?, 1)
INFO:tensorflow:  name = segment_ids, shape = (?, 128)
I1217 11:43:34.019944 140022762432320 run_pretraining.py:259]   name = segment_ids, shape = (?, 128)
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

W1217 11:43:35.813087 140022762432320 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

W1217 11:43:35.861407 140022762432320 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

INFO:tensorflow:Done calling model_fn.
I1217 11:43:35.938826 140022762432320 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-12-17T11:43:35Z
I1217 11:43:35.959067 140022762432320 evaluation.py:255] Starting evaluation at 2020-12-17T11:43:35Z
INFO:tensorflow:Graph was finalized.
I1217 11:43:36.319385 140022762432320 monitored_session.py:240] Graph was finalized.
2020-12-17 11:43:36.320360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:43:36.322854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0a.0
2020-12-17 11:43:36.322959: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 11:43:36.323028: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 11:43:36.323046: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 11:43:36.323058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 11:43:36.323070: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 11:43:36.323082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 11:43:36.323094: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 11:43:36.323190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:43:36.325623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:43:36.329149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-17 11:43:36.329208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 11:43:36.329220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-17 11:43:36.329226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-17 11:43:36.329464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:43:36.331976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 11:43:36.334425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0a.0, compute capability: 7.0)
INFO:tensorflow:Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1/model.ckpt-50
I1217 11:43:36.335557 140022762432320 saver.py:1284] Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1/model.ckpt-50
2020-12-17 11:43:36.515300: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:43:36.518582: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:43:37.242332: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:43:37.244408: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1217 11:43:37.463687 140022762432320 session_manager.py:500] Running local_init_op.
2020-12-17 11:43:37.516849: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:43:37.517269: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 11:43:37.721946 140022762432320 session_manager.py:502] Done running local_init_op.
2020-12-17 11:43:37.823496: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:43:37.825658: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:43:38.114591: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:43:38.114960: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:43:38.120377: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:43:38.123226: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 11:43:38.428471: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:43:38.440436: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 2026
Recognized nodes available for conversion: 1004
Total nodes converted: 276
Total FP16 Cast ops used (excluding Const and Variable casts): 39
Whitelisted nodes converted: 100
Blacklisted nodes blocking conversion: 139
Nodes blocked from conversion by blacklisted nodes: 239

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


INFO:tensorflow:Evaluation [10/100]
I1217 11:43:45.593173 140022762432320 evaluation.py:167] Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
I1217 11:43:45.715754 140022762432320 evaluation.py:167] Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
I1217 11:43:45.837131 140022762432320 evaluation.py:167] Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
I1217 11:43:45.960406 140022762432320 evaluation.py:167] Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
I1217 11:43:46.082186 140022762432320 evaluation.py:167] Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
I1217 11:43:46.204302 140022762432320 evaluation.py:167] Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
I1217 11:43:46.326855 140022762432320 evaluation.py:167] Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
I1217 11:43:46.453512 140022762432320 evaluation.py:167] Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
I1217 11:43:46.575381 140022762432320 evaluation.py:167] Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
I1217 11:43:46.698354 140022762432320 evaluation.py:167] Evaluation [100/100]
2020-12-17 11:43:46.771328: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 11:43:46.771790: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Finished evaluation at 2020-12-17-11:43:47
I1217 11:43:47.076052 140022762432320 evaluation.py:275] Finished evaluation at 2020-12-17-11:43:47
INFO:tensorflow:Saving dict for global step 50: global_step = 50, loss = 10.373198, masked_lm_accuracy = 0.054486316, masked_lm_loss = 9.67641, next_sentence_accuracy = 0.53, next_sentence_loss = 0.6961024
I1217 11:43:47.076727 140022762432320 estimator.py:2049] Saving dict for global step 50: global_step = 50, loss = 10.373198, masked_lm_accuracy = 0.054486316, masked_lm_loss = 9.67641, next_sentence_accuracy = 0.53, next_sentence_loss = 0.6961024
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1/model.ckpt-50
I1217 11:43:47.477311 140022762432320 estimator.py:2109] Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217111630/phase_1/model.ckpt-50
INFO:tensorflow:-----------------------------
I1217 11:43:47.478527 140022762432320 run_pretraining.py:682] -----------------------------
INFO:tensorflow:Total Inference Time = 13.50 for Sentences = 800
I1217 11:43:47.478698 140022762432320 run_pretraining.py:684] Total Inference Time = 13.50 for Sentences = 800
INFO:tensorflow:Total Inference Time W/O Overhead = 1.21 for Sentences = 792
I1217 11:43:47.478783 140022762432320 run_pretraining.py:686] Total Inference Time W/O Overhead = 1.21 for Sentences = 792
INFO:tensorflow:Summary Inference Statistics on EVAL set
I1217 11:43:47.478852 140022762432320 run_pretraining.py:687] Summary Inference Statistics on EVAL set
INFO:tensorflow:Batch size = 8
I1217 11:43:47.478912 140022762432320 run_pretraining.py:688] Batch size = 8
INFO:tensorflow:Sequence Length = 128
I1217 11:43:47.479018 140022762432320 run_pretraining.py:689] Sequence Length = 128
INFO:tensorflow:Precision = fp16
I1217 11:43:47.479084 140022762432320 run_pretraining.py:690] Precision = fp16
INFO:tensorflow:Throughput Average (sentences/sec) = 653.65
I1217 11:43:47.479147 140022762432320 run_pretraining.py:691] Throughput Average (sentences/sec) = 653.65
DLL 2020-12-17 11:43:47.479223 -  throughput_val : 653.648505570169
INFO:tensorflow:-----------------------------
I1217 11:43:47.479504 140022762432320 run_pretraining.py:693] -----------------------------
INFO:tensorflow:***** Eval results *****
I1217 11:43:47.479784 140022762432320 run_pretraining.py:697] ***** Eval results *****
INFO:tensorflow:  global_step = 50
I1217 11:43:47.479877 140022762432320 run_pretraining.py:699]   global_step = 50
INFO:tensorflow:  loss = 10.373198
I1217 11:43:47.480040 140022762432320 run_pretraining.py:699]   loss = 10.373198
INFO:tensorflow:  masked_lm_accuracy = 0.054486316
I1217 11:43:47.480114 140022762432320 run_pretraining.py:699]   masked_lm_accuracy = 0.054486316
INFO:tensorflow:  masked_lm_loss = 9.67641
I1217 11:43:47.480178 140022762432320 run_pretraining.py:699]   masked_lm_loss = 9.67641
INFO:tensorflow:  next_sentence_accuracy = 0.53
I1217 11:43:47.480238 140022762432320 run_pretraining.py:699]   next_sentence_accuracy = 0.53
INFO:tensorflow:  next_sentence_loss = 0.6961024
I1217 11:43:47.480311 140022762432320 run_pretraining.py:699]   next_sentence_loss = 0.6961024

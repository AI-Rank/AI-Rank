total time: 416.4824092388153
Logs written to /root/paddlejob/workspace/env_run/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs65536.210420165659.log
+ python -m torch.distributed.launch --nproc_per_node=8 --nnodes=4 --node_rank=0 --master_addr=10.127.44.149 --master_port=60001 /root/paddlejob/workspace/env_run/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=./wikicorpus_en --output_dir=/root/paddlejob/workspace/env_run/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/checkpoints --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=8192 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=10000 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12345 --eval_dir=./eval_data --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /root/paddlejob/workspace/env_run/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json
device: cuda:5 n_gpu: 1, distributed training: True, 16-bits training: True
device: cuda:6 n_gpu: 1, distributed training: True, 16-bits training: True
device: cuda:3 n_gpu: 1, distributed training: True, 16-bits training: True
device: cuda:4 n_gpu: 1, distributed training: True, 16-bits training: True
device: cuda:7 n_gpu: 1, distributed training: True, 16-bits training: True
device: cuda:2 n_gpu: 1, distributed training: True, 16-bits training: True
device: cuda:1 n_gpu: 1, distributed training: True, 16-bits training: True
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34464 [0] NCCL INFO Bootstrap : Using [0]xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34464 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34464 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
libibverbs: Warning: couldn't load driver '/usr/lib/libibverbs/libmlx5-rdmav25.so': /usr/lib/libibverbs/libmlx5-rdmav25.so: cannot open shared object file: No such file or directory
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34464 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE ; OOB xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34464 [0] NCCL INFO Using network IB
NCCL version 2.7.5+cuda11.0
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34469 [5] NCCL INFO Bootstrap : Using [0]xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34469 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34465 [1] NCCL INFO Bootstrap : Using [0]xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34470 [6] NCCL INFO Bootstrap : Using [0]xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34470 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34465 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34469 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34465 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34470 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
libibverbs: Warning: couldn't load driver '/usr/lib/libibverbs/libmlx5-rdmav25.so': /usr/lib/libibverbs/libmlx5-rdmav25.so: cannot open shared object file: No such file or directory
libibverbs: Warning: couldn't load driver '/usr/lib/libibverbs/libmlx5-rdmav25.so': /usr/lib/libibverbs/libmlx5-rdmav25.so: cannot open shared object file: No such file or directory
libibverbs: Warning: couldn't load driver '/usr/lib/libibverbs/libmlx5-rdmav25.so': /usr/lib/libibverbs/libmlx5-rdmav25.so: cannot open shared object file: No such file or directory
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34470 [6] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE ; OOB xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34470 [6] NCCL INFO Using network IB
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34465 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE ; OOB xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34469 [5] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE ; OOB xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34469 [5] NCCL INFO Using network IB
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34465 [1] NCCL INFO Using network IB
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34471 [7] NCCL INFO Bootstrap : Using [0]xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34471 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34471 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
libibverbs: Warning: couldn't load driver '/usr/lib/libibverbs/libmlx5-rdmav25.so': /usr/lib/libibverbs/libmlx5-rdmav25.so: cannot open shared object file: No such file or directory
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34471 [7] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE ; OOB xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34471 [7] NCCL INFO Using network IB
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34467 [3] NCCL INFO Bootstrap : Using [0]xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34467 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34466 [2] NCCL INFO Bootstrap : Using [0]xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34466 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34467 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
libibverbs: Warning: couldn't load driver '/usr/lib/libibverbs/libmlx5-rdmav25.so': /usr/lib/libibverbs/libmlx5-rdmav25.so: cannot open shared object file: No such file or directory
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34466 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
libibverbs: Warning: couldn't load driver '/usr/lib/libibverbs/libmlx5-rdmav25.so': /usr/lib/libibverbs/libmlx5-rdmav25.so: cannot open shared object file: No such file or directory
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34467 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE ; OOB xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34467 [3] NCCL INFO Using network IB
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34466 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE ; OOB xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34466 [2] NCCL INFO Using network IB
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34468 [4] NCCL INFO Bootstrap : Using [0]xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34468 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34468 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
libibverbs: Warning: couldn't load driver '/usr/lib/libibverbs/libmlx5-rdmav25.so': /usr/lib/libibverbs/libmlx5-rdmav25.so: cannot open shared object file: No such file or directory
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34468 [4] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE ; OOB xgbe0:10.127.44.149<0>
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34468 [4] NCCL INFO Using network IB
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO Channel 00/02 :    0   1   5   4   6   7   3   2   8   9  13  12  14  15  11  10  16  17  21  20
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO Channel 01/02 :    0   1   5   4   6   7   3   2   8   9  13  12  14  15  11  10  16  17  21  20
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 8/8/64
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34536 [2] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 8/8/64
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34535 [3] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 8/8/64
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO Trees [0] 5/16/-1->1->0|0->1->5/16/-1 [1] 5/-1/-1->1->0|0->1->5/-1/-1
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34536 [2] NCCL INFO Trees [0] -1/-1/-1->2->3|3->2->-1/-1/-1 [1] -1/-1/-1->2->3|3->2->-1/-1/-1
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34535 [3] NCCL INFO Trees [0] 2/-1/-1->3->7|7->3->2/-1/-1 [1] 2/-1/-1->3->7|7->3->2/-1/-1
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34537 [4] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 8/8/64
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34535 [3] NCCL INFO Setting affinity for GPU 3 to ffffff
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34536 [2] NCCL INFO Setting affinity for GPU 2 to ffffff
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO Setting affinity for GPU 1 to ffffff
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34537 [4] NCCL INFO Trees [0] 6/-1/-1->4->5|5->4->6/-1/-1 [1] 6/-1/-1->4->5|5->4->6/-1/-1
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34537 [4] NCCL INFO Setting affinity for GPU 4 to ffffff
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34529 [5] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 8/8/64
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34527 [6] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 8/8/64
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34533 [7] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 8/8/64
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34529 [5] NCCL INFO Trees [0] 4/-1/-1->5->1|1->5->4/-1/-1 [1] 4/-1/-1->5->1|1->5->4/-1/-1
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34527 [6] NCCL INFO Trees [0] 7/-1/-1->6->4|4->6->7/-1/-1 [1] 7/-1/-1->6->4|4->6->7/-1/-1
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 8/8/64
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34533 [7] NCCL INFO Trees [0] 3/-1/-1->7->6|6->7->3/-1/-1 [1] 3/-1/-1->7->6|6->7->3/-1/-1
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1|-1->0->1/-1/-1 [1] 1/-1/-1->0->25|25->0->1/-1/-1
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34529 [5] NCCL INFO Setting affinity for GPU 5 to ffffff
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34527 [6] NCCL INFO Setting affinity for GPU 6 to ffffff
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34533 [7] NCCL INFO Setting affinity for GPU 7 to ffffff
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34527 [6] NCCL INFO Channel 00 : 6[64000] -> 7[65000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34529 [5] NCCL INFO Channel 00 : 5[63000] -> 4[62000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34536 [2] NCCL INFO Channel 00 : 2[41000] -> 8[3f000] [send] via NET/IB/0
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34537 [4] NCCL INFO Channel 00 : 4[62000] -> 6[64000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34535 [3] NCCL INFO Channel 00 : 3[42000] -> 2[41000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO Channel 00 : 1[40000] -> 5[63000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34533 [7] NCCL INFO Channel 00 : 7[65000] -> 3[42000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34536 [2] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO Channel 00 : 26[41000] -> 0[3f000] [receive] via NET/IB/0
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO Channel 00 : 0[3f000] -> 1[40000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34537 [4] NCCL INFO Channel 00 : 4[62000] -> 5[63000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34536 [2] NCCL INFO Channel 00 : 2[41000] -> 3[42000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34527 [6] NCCL INFO Channel 00 : 6[64000] -> 4[62000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34529 [5] NCCL INFO Channel 00 : 5[63000] -> 1[40000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34535 [3] NCCL INFO Channel 00 : 3[42000] -> 7[65000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34533 [7] NCCL INFO Channel 00 : 7[65000] -> 6[64000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34537 [4] NCCL INFO Channel 01 : 4[62000] -> 6[64000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34527 [6] NCCL INFO Channel 01 : 6[64000] -> 7[65000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO Channel 00 : 16[3f000] -> 1[40000] [receive] via NET/IB/0
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34535 [3] NCCL INFO Channel 01 : 3[42000] -> 2[41000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34533 [7] NCCL INFO Channel 01 : 7[65000] -> 3[42000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34529 [5] NCCL INFO Channel 01 : 5[63000] -> 4[62000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34536 [2] NCCL INFO Channel 01 : 2[41000] -> 8[3f000] [send] via NET/IB/0
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO Channel 00 : 1[40000] -> 0[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34527 [6] NCCL INFO Channel 01 : 6[64000] -> 4[62000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34537 [4] NCCL INFO Channel 01 : 4[62000] -> 5[63000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34535 [3] NCCL INFO Channel 01 : 3[42000] -> 7[65000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34533 [7] NCCL INFO Channel 01 : 7[65000] -> 6[64000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34527 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
yq01-sys-hic-k8s-v100-box-a225-0804:34470:34527 [6] NCCL INFO comm 0x7f0c28006880 rank 6 nranks 32 cudaDev 6 busId 64000 - Init COMPLETE
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34533 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
yq01-sys-hic-k8s-v100-box-a225-0804:34471:34533 [7] NCCL INFO comm 0x7fdfd8006880 rank 7 nranks 32 cudaDev 7 busId 65000 - Init COMPLETE
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO Channel 01 : 26[41000] -> 0[3f000] [receive] via NET/IB/0
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO Channel 01 : 0[3f000] -> 1[40000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO Channel 00 : 1[40000] -> 16[3f000] [send] via NET/IB/0
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO Channel 01 : 1[40000] -> 5[63000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34529 [5] NCCL INFO Channel 01 : 5[63000] -> 1[40000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34537 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
yq01-sys-hic-k8s-v100-box-a225-0804:34468:34537 [4] NCCL INFO comm 0x7f9ecc006880 rank 4 nranks 32 cudaDev 4 busId 62000 - Init COMPLETE
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO Channel 01 : 1[40000] -> 0[3f000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34529 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
yq01-sys-hic-k8s-v100-box-a225-0804:34469:34529 [5] NCCL INFO comm 0x7fe05c006880 rank 5 nranks 32 cudaDev 5 busId 63000 - Init COMPLETE
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
yq01-sys-hic-k8s-v100-box-a225-0804:34465:34530 [1] NCCL INFO comm 0x7fd7b4006880 rank 1 nranks 32 cudaDev 1 busId 40000 - Init COMPLETE
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO Channel 01 : 0[3f000] -> 25[40000] [send] via NET/IB/0
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34536 [2] NCCL INFO Channel 01 : 2[41000] -> 3[42000] via P2P/IPC
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34536 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34535 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
yq01-sys-hic-k8s-v100-box-a225-0804:34466:34536 [2] NCCL INFO comm 0x7fb0f4006880 rank 2 nranks 32 cudaDev 2 busId 41000 - Init COMPLETE
yq01-sys-hic-k8s-v100-box-a225-0804:34467:34535 [3] NCCL INFO comm 0x7f3380006880 rank 3 nranks 32 cudaDev 3 busId 42000 - Init COMPLETE
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO Channel 01 : 25[40000] -> 0[3f000] [receive] via NET/IB/0
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34526 [0] NCCL INFO comm 0x7f918c006880 rank 0 nranks 32 cudaDev 0 busId 3f000 - Init COMPLETE
yq01-sys-hic-k8s-v100-box-a225-0804:34464:34464 [0] NCCL INFO Launch mode Parallel
- AI-Rank-log  1618909036.4376376  load_data
- AI-Rank-log  1618909036.4376376  test_begin
- AI-Rank-log  1618909036.4394772  load_data
- AI-Rank-log  1618909036.4394772  test_begin
- AI-Rank-log  1618909036.4399562  load_data
- AI-Rank-log  1618909036.4399562  test_begin
- AI-Rank-log  1618909036.44039  load_data
- AI-Rank-log  1618909036.44039  test_begin
- AI-Rank-log  1618909036.4439995  load_data
- AI-Rank-log  1618909036.4439995  test_begin
- AI-Rank-log  1618909036.4444995  load_data
- AI-Rank-log  1618909036.4444995  test_begin
- AI-Rank-log  1618909036.445757  load_data
- AI-Rank-log  1618909036.445757  test_begin
- AI-Rank-log  1618909036.446389  load_data
- AI-Rank-log  1618909036.446389  test_begin
- AI-Rank-log  1618909295.7782745  eval_accuracy: 1.1095087756984867e-05 , global_step: 1
- AI-Rank-log  1618909339.5742784  eval_accuracy: 1.1095087756984867e-05 , global_step: 2
- AI-Rank-log  1618909383.4108713  eval_accuracy: 1.1095087756984867e-05 , global_step: 3
- AI-Rank-log  1618909427.2839432  eval_accuracy: 1.1095087756984867e-05 , global_step: 4
- AI-Rank-log  1618909471.1537902  eval_accuracy: 1.1095087756984867e-05 , global_step: 5
- AI-Rank-log  1618909515.0669408  eval_accuracy: 1.1095087756984867e-05 , global_step: 6
- AI-Rank-log  1618909559.0106258  eval_accuracy: 1.1095087756984867e-05 , global_step: 7
- AI-Rank-log  1618909602.9781508  eval_accuracy: 5.5470354709541425e-06 , global_step: 8
- AI-Rank-log  1618909646.974077  eval_accuracy: 5.5470354709541425e-06 , global_step: 9
- AI-Rank-log  1618909690.863855  eval_accuracy: 5.5470354709541425e-06 , global_step: 10
- AI-Rank-log  1618909734.81133  eval_accuracy: 5.5470354709541425e-06 , global_step: 11
- AI-Rank-log  1618909778.8225498  eval_accuracy: 0.0 , global_step: 12
- AI-Rank-log  1618909822.7313912  eval_accuracy: 0.0 , global_step: 13
- AI-Rank-log  1618909866.6577368  eval_accuracy: 0.0 , global_step: 14
- AI-Rank-log  1618909910.644158  eval_accuracy: 5.546401553147007e-06 , global_step: 15
- AI-Rank-log  1618909954.5912344  eval_accuracy: 3.328584352857433e-05 , global_step: 16
- AI-Rank-log  1618909998.6616685  eval_accuracy: 0.0002552200749050826 , global_step: 17
- AI-Rank-log  1618910042.5830293  eval_accuracy: 0.05664371699094772 , global_step: 18
- AI-Rank-log  1618910086.5378969  eval_accuracy: 0.057724326848983765 , global_step: 19
- AI-Rank-log  1618910130.5521932  eval_accuracy: 0.05793881043791771 , global_step: 20
- AI-Rank-log  1618910174.4672873  eval_accuracy: 0.0582052543759346 , global_step: 21
- AI-Rank-log  1618910218.3933532  eval_accuracy: 0.05818938463926315 , global_step: 22
- AI-Rank-log  1618910262.390482  eval_accuracy: 0.05818938463926315 , global_step: 23
- AI-Rank-log  1618910306.3226178  eval_accuracy: 0.05818938463926315 , global_step: 24
- AI-Rank-log  1618910350.2792718  eval_accuracy: 0.05818938463926315 , global_step: 25
- AI-Rank-log  1618910394.290493  eval_accuracy: 0.05818938463926315 , global_step: 26
- AI-Rank-log  1618910438.221011  eval_accuracy: 0.05818938463926315 , global_step: 27
- AI-Rank-log  1618910482.2271686  eval_accuracy: 0.05818938463926315 , global_step: 28
- AI-Rank-log  1618910526.182953  eval_accuracy: 0.05818938463926315 , global_step: 29
- AI-Rank-log  1618910570.1017995  eval_accuracy: 0.05818938463926315 , global_step: 30
- AI-Rank-log  1618910614.125487  eval_accuracy: 0.05818938463926315 , global_step: 31
- AI-Rank-log  1618910658.0536206  eval_accuracy: 0.05818938463926315 , global_step: 32
- AI-Rank-log  1618910702.005843  eval_accuracy: 0.05818938463926315 , global_step: 33
- AI-Rank-log  1618910746.017147  eval_accuracy: 0.05818938463926315 , global_step: 34
- AI-Rank-log  1618910789.9722238  eval_accuracy: 0.05818938463926315 , global_step: 35
- AI-Rank-log  1618910833.9497085  eval_accuracy: 0.05818938463926315 , global_step: 36
- AI-Rank-log  1618910877.864199  eval_accuracy: 0.05818938463926315 , global_step: 37
- AI-Rank-log  1618910921.7746751  eval_accuracy: 0.05818938463926315 , global_step: 38
- AI-Rank-log  1618910965.758761  eval_accuracy: 0.05818938463926315 , global_step: 39
- AI-Rank-log  1618911009.6620245  eval_accuracy: 0.05818938463926315 , global_step: 40
- AI-Rank-log  1618911053.5844958  eval_accuracy: 0.05818938463926315 , global_step: 41
- AI-Rank-log  1618911097.5768657  eval_accuracy: 0.05818938463926315 , global_step: 42
- AI-Rank-log  1618911141.510893  eval_accuracy: 0.05818938463926315 , global_step: 43
- AI-Rank-log  1618911185.4171796  eval_accuracy: 0.05818938463926315 , global_step: 44
- AI-Rank-log  1618911229.3423245  eval_accuracy: 0.05818938463926315 , global_step: 45
- AI-Rank-log  1618911273.3108122  eval_accuracy: 0.05818938463926315 , global_step: 46

yq01-sys-hic-k8s-v100-box-a225-0804:34465:34525 [0] misc/ibvwrap.cc:220 NCCL WARN Call to ibv_get_async_event failed
- AI-Rank-log  1618911317.2757342  eval_accuracy: 0.05818938463926315 , global_step: 47
- AI-Rank-log  1618911361.194385  eval_accuracy: 0.05818938463926315 , global_step: 48
- AI-Rank-log  1618911405.110272  eval_accuracy: 0.05818938463926315 , global_step: 49
- AI-Rank-log  1618911449.0444856  eval_accuracy: 0.05818938463926315 , global_step: 50
- AI-Rank-log  1618911492.9462566  eval_accuracy: 0.05818938463926315 , global_step: 51
- AI-Rank-log  1618911536.9116437  eval_accuracy: 0.05818938463926315 , global_step: 52
- AI-Rank-log  1618911580.8540025  eval_accuracy: 0.05818938463926315 , global_step: 53
- AI-Rank-log  1618911624.794632  eval_accuracy: 0.05818938463926315 , global_step: 54
- AI-Rank-log  1618911668.6955523  eval_accuracy: 0.05818938463926315 , global_step: 55
- AI-Rank-log  1618911712.6186352  eval_accuracy: 0.05818938463926315 , global_step: 56
- AI-Rank-log  1618911756.5108764  eval_accuracy: 0.05818938463926315 , global_step: 57
- AI-Rank-log  1618911800.3831391  eval_accuracy: 0.05818938463926315 , global_step: 58
- AI-Rank-log  1618911844.3220797  eval_accuracy: 0.05818938463926315 , global_step: 59
- AI-Rank-log  1618911888.234633  eval_accuracy: 0.05818938463926315 , global_step: 60
- AI-Rank-log  1618911932.187613  eval_accuracy: 0.05818938463926315 , global_step: 61
- AI-Rank-log  1618911976.0651011  eval_accuracy: 0.05818938463926315 , global_step: 62
- AI-Rank-log  1618912019.931663  eval_accuracy: 0.05818938463926315 , global_step: 63
- AI-Rank-log  1618912063.8821738  eval_accuracy: 0.05818938463926315 , global_step: 64
- AI-Rank-log  1618912107.717864  eval_accuracy: 0.05818938463926315 , global_step: 65
- AI-Rank-log  1618912151.517528  eval_accuracy: 0.05818938463926315 , global_step: 66
- AI-Rank-log  1618912195.3854067  eval_accuracy: 0.05818938463926315 , global_step: 67
- AI-Rank-log  1618912239.306209  eval_accuracy: 0.05818938463926315 , global_step: 68
- AI-Rank-log  1618912283.2751417  eval_accuracy: 0.05818938463926315 , global_step: 69
- AI-Rank-log  1618912327.1139982  eval_accuracy: 0.05818938463926315 , global_step: 70
- AI-Rank-log  1618912370.9808874  eval_accuracy: 0.05818938463926315 , global_step: 71
- AI-Rank-log  1618912414.9540858  eval_accuracy: 0.05818938463926315 , global_step: 72
- AI-Rank-log  1618912460.0793316  eval_accuracy: 0.05818938463926315 , global_step: 73
- AI-Rank-log  1618912504.0613794  eval_accuracy: 0.05818938463926315 , global_step: 74
- AI-Rank-log  1618912548.1271  eval_accuracy: 0.05818938463926315 , global_step: 75
- AI-Rank-log  1618912592.053435  eval_accuracy: 0.05818938463926315 , global_step: 76
- AI-Rank-log  1618912636.0461347  eval_accuracy: 0.05818938463926315 , global_step: 77
- AI-Rank-log  1618912680.056414  eval_accuracy: 0.05818938463926315 , global_step: 78
- AI-Rank-log  1618912723.959814  eval_accuracy: 0.05818938463926315 , global_step: 79
- AI-Rank-log  1618912767.95083  eval_accuracy: 0.05818938463926315 , global_step: 80
- AI-Rank-log  1618912811.936542  eval_accuracy: 0.05818938463926315 , global_step: 81
- AI-Rank-log  1618912855.8821213  eval_accuracy: 0.05818938463926315 , global_step: 82
- AI-Rank-log  1618912899.9001086  eval_accuracy: 0.05818938463926315 , global_step: 83
- AI-Rank-log  1618912943.8217406  eval_accuracy: 0.05818938463926315 , global_step: 84
- AI-Rank-log  1618912987.7631965  eval_accuracy: 0.05818938463926315 , global_step: 85
- AI-Rank-log  1618913031.8281825  eval_accuracy: 0.05818938463926315 , global_step: 86
- AI-Rank-log  1618913075.7719793  eval_accuracy: 0.05818938463926315 , global_step: 87
- AI-Rank-log  1618913119.6887705  eval_accuracy: 0.05818938463926315 , global_step: 88
- AI-Rank-log  1618913163.719473  eval_accuracy: 0.05818938463926315 , global_step: 89
- AI-Rank-log  1618913207.7289898  eval_accuracy: 0.05818938463926315 , global_step: 90
- AI-Rank-log  1618913251.7505376  eval_accuracy: 0.05818938463926315 , global_step: 91
- AI-Rank-log  1618913295.688802  eval_accuracy: 0.05818938463926315 , global_step: 92
- AI-Rank-log  1618913339.6344085  eval_accuracy: 0.05818938463926315 , global_step: 93
- AI-Rank-log  1618913383.724966  eval_accuracy: 0.058261264115571976 , global_step: 94
- AI-Rank-log  1618913427.6806111  eval_accuracy: 0.05820039287209511 , global_step: 95
- AI-Rank-log  1618913471.598166  eval_accuracy: 0.058505233377218246 , global_step: 96
- AI-Rank-log  1618913515.6770043  eval_accuracy: 0.058850765228271484 , global_step: 97
- AI-Rank-log  1618913559.6308541  eval_accuracy: 0.060265932232141495 , global_step: 98
- AI-Rank-log  1618913603.6015291  eval_accuracy: 0.060714270919561386 , global_step: 99
- AI-Rank-log  1618913647.587921  eval_accuracy: 0.06203499436378479 , global_step: 100
- AI-Rank-log  1618913691.5762265  eval_accuracy: 0.06340131163597107 , global_step: 101
- AI-Rank-log  1618913735.6212354  eval_accuracy: 0.06273869425058365 , global_step: 102
- AI-Rank-log  1618913779.5745912  eval_accuracy: 0.058397337794303894 , global_step: 103
- AI-Rank-log  1618913823.594544  eval_accuracy: 0.05861803889274597 , global_step: 104
- AI-Rank-log  1618913867.5700533  eval_accuracy: 0.06324233114719391 , global_step: 105
- AI-Rank-log  1618913911.5129142  eval_accuracy: 0.05747383087873459 , global_step: 106
- AI-Rank-log  1618913955.4999561  eval_accuracy: 0.06440041959285736 , global_step: 107
- AI-Rank-log  1618913999.5204127  eval_accuracy: 0.06408045440912247 , global_step: 108
- AI-Rank-log  1618914043.435704  eval_accuracy: 0.06443343311548233 , global_step: 109
- AI-Rank-log  1618914087.381637  eval_accuracy: 0.0633116215467453 , global_step: 110
- AI-Rank-log  1618914131.4123292  eval_accuracy: 0.0670805349946022 , global_step: 111
- AI-Rank-log  1618914175.3847146  eval_accuracy: 0.06610716879367828 , global_step: 112
- AI-Rank-log  1618914219.3639843  eval_accuracy: 0.06117727607488632 , global_step: 113
- AI-Rank-log  1618914263.3105795  eval_accuracy: 0.0697186216711998 , global_step: 114
- AI-Rank-log  1618914307.3092785  eval_accuracy: 0.07046405225992203 , global_step: 115
- AI-Rank-log  1618914351.2965481  eval_accuracy: 0.07188300043344498 , global_step: 116
- AI-Rank-log  1618914395.3304203  eval_accuracy: 0.06676879525184631 , global_step: 117
- AI-Rank-log  1618914439.2716625  eval_accuracy: 0.07021833956241608 , global_step: 118
- AI-Rank-log  1618914483.3153954  eval_accuracy: 0.07350347936153412 , global_step: 119
- AI-Rank-log  1618914527.2854154  eval_accuracy: 0.0606343038380146 , global_step: 120
- AI-Rank-log  1618914571.3590367  eval_accuracy: 0.0690760463476181 , global_step: 121
- AI-Rank-log  1618914615.310637  eval_accuracy: 0.07217872887849808 , global_step: 122
- AI-Rank-log  1618914659.2597404  eval_accuracy: 0.07205309718847275 , global_step: 123
- AI-Rank-log  1618914703.331395  eval_accuracy: 0.06599778681993484 , global_step: 124
- AI-Rank-log  1618914747.3104079  eval_accuracy: 0.05941125005483627 , global_step: 125
- AI-Rank-log  1618914791.1165683  eval_accuracy: 0.07002381980419159 , global_step: 126
- AI-Rank-log  1618914835.1737864  eval_accuracy: 0.07386288046836853 , global_step: 127
- AI-Rank-log  1618914879.0934904  eval_accuracy: 0.07556910067796707 , global_step: 128
- AI-Rank-log  1618914923.0865254  eval_accuracy: 0.07323911041021347 , global_step: 129
- AI-Rank-log  1618914967.0842905  eval_accuracy: 0.07524049282073975 , global_step: 130
- AI-Rank-log  1618915011.0821447  eval_accuracy: 0.07218877226114273 , global_step: 131
- AI-Rank-log  1618915055.080125  eval_accuracy: 0.059804767370224 , global_step: 132
- AI-Rank-log  1618915099.1466923  eval_accuracy: 0.07464657723903656 , global_step: 133
- AI-Rank-log  1618915143.1142938  eval_accuracy: 0.07633581012487411 , global_step: 134
- AI-Rank-log  1618915187.1433606  eval_accuracy: 0.0775640532374382 , global_step: 135
- AI-Rank-log  1618915231.1323166  eval_accuracy: 0.07912269234657288 , global_step: 136
- AI-Rank-log  1618915275.060963  eval_accuracy: 0.07121200114488602 , global_step: 137
- AI-Rank-log  1618915319.1031375  eval_accuracy: 0.0728803277015686 , global_step: 138
- AI-Rank-log  1618915363.0387447  eval_accuracy: 0.07762973010540009 , global_step: 139
- AI-Rank-log  1618915406.9687583  eval_accuracy: 0.08099619299173355 , global_step: 140
- AI-Rank-log  1618915451.053998  eval_accuracy: 0.08120577782392502 , global_step: 141
- AI-Rank-log  1618915494.9843783  eval_accuracy: 0.07157959789037704 , global_step: 142
- AI-Rank-log  1618915539.00224  eval_accuracy: 0.08166683465242386 , global_step: 143
- AI-Rank-log  1618915582.9889948  eval_accuracy: 0.08200334757566452 , global_step: 144
- AI-Rank-log  1618915626.9431589  eval_accuracy: 0.08106730878353119 , global_step: 145
- AI-Rank-log  1618915670.9737074  eval_accuracy: 0.07280024886131287 , global_step: 146
- AI-Rank-log  1618915714.9236374  eval_accuracy: 0.08044165372848511 , global_step: 147
- AI-Rank-log  1618915758.855345  eval_accuracy: 0.08152023702859879 , global_step: 148
- AI-Rank-log  1618915802.8740141  eval_accuracy: 0.08209562301635742 , global_step: 149
- AI-Rank-log  1618915848.3531213  eval_accuracy: 0.08257341384887695 , global_step: 150
- AI-Rank-log  1618915893.1919408  eval_accuracy: 0.08089057356119156 , global_step: 151
- AI-Rank-log  1618915937.0090697  eval_accuracy: 0.0815737321972847 , global_step: 152
- AI-Rank-log  1618915981.039907  eval_accuracy: 0.08226405084133148 , global_step: 153
- AI-Rank-log  1618916025.0827494  eval_accuracy: 0.07869839668273926 , global_step: 154
- AI-Rank-log  1618916069.0665245  eval_accuracy: 0.07657289505004883 , global_step: 155
- AI-Rank-log  1618916113.0269706  eval_accuracy: 0.08219824731349945 , global_step: 156
- AI-Rank-log  1618916157.0136375  eval_accuracy: 0.0768187865614891 , global_step: 157
- AI-Rank-log  1618916200.9831069  eval_accuracy: 0.07839412987232208 , global_step: 158
- AI-Rank-log  1618916244.976008  eval_accuracy: 0.08371111750602722 , global_step: 159
- AI-Rank-log  1618916289.0023623  eval_accuracy: 0.08501257002353668 , global_step: 160
- AI-Rank-log  1618916332.9786904  eval_accuracy: 0.08535480499267578 , global_step: 161
- AI-Rank-log  1618916376.9562247  eval_accuracy: 0.08640443533658981 , global_step: 162
- AI-Rank-log  1618916420.7679527  eval_accuracy: 0.08655958622694016 , global_step: 163
- AI-Rank-log  1618916464.752294  eval_accuracy: 0.08668528497219086 , global_step: 164
- AI-Rank-log  1618916508.8097017  eval_accuracy: 0.08774186670780182 , global_step: 165
- AI-Rank-log  1618916552.8053758  eval_accuracy: 0.08785456418991089 , global_step: 166
- AI-Rank-log  1618916596.8030407  eval_accuracy: 0.08787055313587189 , global_step: 167
- AI-Rank-log  1618916640.863586  eval_accuracy: 0.08912055939435959 , global_step: 168
- AI-Rank-log  1618916684.8448958  eval_accuracy: 0.08756274729967117 , global_step: 169
- AI-Rank-log  1618916728.8043115  eval_accuracy: 0.08891474455595016 , global_step: 170
- AI-Rank-log  1618916772.8295188  eval_accuracy: 0.08735377341508865 , global_step: 171
- AI-Rank-log  1618916816.7609034  eval_accuracy: 0.09253905713558197 , global_step: 172
- AI-Rank-log  1618916860.7695625  eval_accuracy: 0.09059907495975494 , global_step: 173
- AI-Rank-log  1618916904.7662952  eval_accuracy: 0.09320022910833359 , global_step: 174
- AI-Rank-log  1618916948.5444367  eval_accuracy: 0.09255312383174896 , global_step: 175
- AI-Rank-log  1618916992.605103  eval_accuracy: 0.09395290166139603 , global_step: 176
- AI-Rank-log  1618917036.5729694  eval_accuracy: 0.09143349528312683 , global_step: 177
- AI-Rank-log  1618917080.584315  eval_accuracy: 0.09396994858980179 , global_step: 178
- AI-Rank-log  1618917124.4265335  eval_accuracy: 0.09401419758796692 , global_step: 179
- AI-Rank-log  1618917168.3883607  eval_accuracy: 0.09368611872196198 , global_step: 180
- AI-Rank-log  1618917212.3706985  eval_accuracy: 0.09378491342067719 , global_step: 181
- AI-Rank-log  1618917256.3741775  eval_accuracy: 0.094450443983078 , global_step: 182
- AI-Rank-log  1618917300.319227  eval_accuracy: 0.09217355400323868 , global_step: 183
- AI-Rank-log  1618917344.3034127  eval_accuracy: 0.09185314923524857 , global_step: 184
- AI-Rank-log  1618917388.3921416  eval_accuracy: 0.09486766904592514 , global_step: 185
- AI-Rank-log  1618917432.3230462  eval_accuracy: 0.0940404161810875 , global_step: 186
- AI-Rank-log  1618917476.3167117  eval_accuracy: 0.09427439421415329 , global_step: 187
- AI-Rank-log  1618917520.3731406  eval_accuracy: 0.09621238708496094 , global_step: 188
- AI-Rank-log  1618917564.310382  eval_accuracy: 0.09499747306108475 , global_step: 189
- AI-Rank-log  1618917608.3809786  eval_accuracy: 0.08963818848133087 , global_step: 190
- AI-Rank-log  1618917652.3662596  eval_accuracy: 0.09592156857252121 , global_step: 191
- AI-Rank-log  1618917696.3315828  eval_accuracy: 0.09460272639989853 , global_step: 192
- AI-Rank-log  1618917740.358208  eval_accuracy: 0.0909142941236496 , global_step: 193
- AI-Rank-log  1618917784.3184533  eval_accuracy: 0.0968284010887146 , global_step: 194
- AI-Rank-log  1618917828.297145  eval_accuracy: 0.09625814855098724 , global_step: 195
- AI-Rank-log  1618917880.8306355  eval_accuracy: 0.0888623297214508 , global_step: 196
- AI-Rank-log  1618917924.7889829  eval_accuracy: 0.09653099626302719 , global_step: 197
- AI-Rank-log  1618917968.7492044  eval_accuracy: 0.09474097937345505 , global_step: 198
- AI-Rank-log  1618918012.7833  eval_accuracy: 0.09496092051267624 , global_step: 199
- AI-Rank-log  1618918056.7321548  eval_accuracy: 0.09117349237203598 , global_step: 200
- AI-Rank-log  1618918100.7193885  eval_accuracy: 0.09701300412416458 , global_step: 201
- AI-Rank-log  1618918144.705446  eval_accuracy: 0.09877888113260269 , global_step: 202
- AI-Rank-log  1618918188.6392272  eval_accuracy: 0.09656107425689697 , global_step: 203
- AI-Rank-log  1618918232.653153  eval_accuracy: 0.09786637872457504 , global_step: 204
- AI-Rank-log  1618918276.6340108  eval_accuracy: 0.09412968903779984 , global_step: 205
- AI-Rank-log  1618918320.586524  eval_accuracy: 0.09811151772737503 , global_step: 206
- AI-Rank-log  1618918364.60958  eval_accuracy: 0.09540978074073792 , global_step: 207
- AI-Rank-log  1618918408.5923169  eval_accuracy: 0.09616407752037048 , global_step: 208
- AI-Rank-log  1618918452.5449495  eval_accuracy: 0.09904877096414566 , global_step: 209
- AI-Rank-log  1618918496.629121  eval_accuracy: 0.09282922744750977 , global_step: 210
- AI-Rank-log  1618918540.62632  eval_accuracy: 0.09928572177886963 , global_step: 211
- AI-Rank-log  1618918584.653327  eval_accuracy: 0.09767871350049973 , global_step: 212
- AI-Rank-log  1618918628.650114  eval_accuracy: 0.089686818420887 , global_step: 213
- AI-Rank-log  1618918672.6541798  eval_accuracy: 0.09463018923997879 , global_step: 214
- AI-Rank-log  1618918716.7112386  eval_accuracy: 0.09859742224216461 , global_step: 215
- AI-Rank-log  1618918760.6996493  eval_accuracy: 0.09940172731876373 , global_step: 216
- AI-Rank-log  1618918804.7342358  eval_accuracy: 0.10064971446990967 , global_step: 217
- AI-Rank-log  1618918848.7663236  eval_accuracy: 0.09881599992513657 , global_step: 218
- AI-Rank-log  1618918892.7408035  eval_accuracy: 0.10010861605405807 , global_step: 219
- AI-Rank-log  1618918936.761273  eval_accuracy: 0.10059672594070435 , global_step: 220
- AI-Rank-log  1618918980.763821  eval_accuracy: 0.10113123804330826 , global_step: 221
- AI-Rank-log  1618919024.7916253  eval_accuracy: 0.1009833812713623 , global_step: 222
- AI-Rank-log  1618919068.8519113  eval_accuracy: 0.1006690040230751 , global_step: 223
- AI-Rank-log  1618919112.8182847  eval_accuracy: 0.0979878231883049 , global_step: 224
- AI-Rank-log  1618919156.8193657  eval_accuracy: 0.09814214706420898 , global_step: 225
- AI-Rank-log  1618919200.8520806  eval_accuracy: 0.1018451377749443 , global_step: 226
- AI-Rank-log  1618919245.9240427  eval_accuracy: 0.09845618158578873 , global_step: 227
- AI-Rank-log  1618919291.1735775  eval_accuracy: 0.09938453882932663 , global_step: 228
- AI-Rank-log  1618919335.2016854  eval_accuracy: 0.09019917249679565 , global_step: 229
- AI-Rank-log  1618919379.1423066  eval_accuracy: 0.10169384628534317 , global_step: 230
- AI-Rank-log  1618919423.2249856  eval_accuracy: 0.0967656672000885 , global_step: 231
- AI-Rank-log  1618919467.2006187  eval_accuracy: 0.09117375314235687 , global_step: 232
- AI-Rank-log  1618919511.185914  eval_accuracy: 0.10191516578197479 , global_step: 233
- AI-Rank-log  1618919555.2229433  eval_accuracy: 0.1022660955786705 , global_step: 234
- AI-Rank-log  1618919599.1765807  eval_accuracy: 0.10079474002122879 , global_step: 235
- AI-Rank-log  1618919643.197865  eval_accuracy: 0.10175597667694092 , global_step: 236
- AI-Rank-log  1618919687.2504714  eval_accuracy: 0.10103461891412735 , global_step: 237
- AI-Rank-log  1618919731.2413135  eval_accuracy: 0.09514672309160233 , global_step: 238
- AI-Rank-log  1618919775.2512488  eval_accuracy: 0.09476133435964584 , global_step: 239
- AI-Rank-log  1618919819.2972069  eval_accuracy: 0.10468081384897232 , global_step: 240
- AI-Rank-log  1618919863.2390118  eval_accuracy: 0.10390539467334747 , global_step: 241
- AI-Rank-log  1618919907.1898956  eval_accuracy: 0.10502191632986069 , global_step: 242
- AI-Rank-log  1618919951.284703  eval_accuracy: 0.10072391480207443 , global_step: 243
- AI-Rank-log  1618919995.2324917  eval_accuracy: 0.10446102917194366 , global_step: 244
- AI-Rank-log  1618920039.2945287  eval_accuracy: 0.10491540282964706 , global_step: 245
- AI-Rank-log  1618920083.2787097  eval_accuracy: 0.10583899915218353 , global_step: 246
- AI-Rank-log  1618920127.258365  eval_accuracy: 0.10722334682941437 , global_step: 247
- AI-Rank-log  1618920171.3333702  eval_accuracy: 0.10227923840284348 , global_step: 248
- AI-Rank-log  1618920215.2859945  eval_accuracy: 0.10609675943851471 , global_step: 249
- AI-Rank-log  1618920259.2179728  eval_accuracy: 0.1075747162103653 , global_step: 250
- AI-Rank-log  1618920303.3142958  eval_accuracy: 0.10794460773468018 , global_step: 251
- AI-Rank-log  1618920347.29874  eval_accuracy: 0.10725374519824982 , global_step: 252
- AI-Rank-log  1618920391.3243148  eval_accuracy: 0.10864020884037018 , global_step: 253
- AI-Rank-log  1618920435.300762  eval_accuracy: 0.10888293385505676 , global_step: 254
- AI-Rank-log  1618920479.2565267  eval_accuracy: 0.11058313399553299 , global_step: 255
- AI-Rank-log  1618920523.2641203  eval_accuracy: 0.10744908452033997 , global_step: 256
- AI-Rank-log  1618920567.2444406  eval_accuracy: 0.10593939572572708 , global_step: 257
- AI-Rank-log  1618920611.2157762  eval_accuracy: 0.10967455804347992 , global_step: 258
- AI-Rank-log  1618920655.251429  eval_accuracy: 0.10926566272974014 , global_step: 259
- AI-Rank-log  1618920699.2338622  eval_accuracy: 0.10635504871606827 , global_step: 260
- AI-Rank-log  1618920743.227065  eval_accuracy: 0.10719263553619385 , global_step: 261
- AI-Rank-log  1618920787.340606  eval_accuracy: 0.1082068383693695 , global_step: 262
- AI-Rank-log  1618920831.3316526  eval_accuracy: 0.10271915793418884 , global_step: 263
- AI-Rank-log  1618920875.3512044  eval_accuracy: 0.1035279706120491 , global_step: 264
- AI-Rank-log  1618920919.3231063  eval_accuracy: 0.11117787659168243 , global_step: 265
- AI-Rank-log  1618920963.2936692  eval_accuracy: 0.1108274757862091 , global_step: 266
- AI-Rank-log  1618921007.07136  eval_accuracy: 0.11230482161045074 , global_step: 267
- AI-Rank-log  1618921051.0440774  eval_accuracy: 0.1112762913107872 , global_step: 268
- AI-Rank-log  1618921094.9994812  eval_accuracy: 0.11288539320230484 , global_step: 269
- AI-Rank-log  1618921139.0096223  eval_accuracy: 0.09401065111160278 , global_step: 270
- AI-Rank-log  1618921183.0110278  eval_accuracy: 0.112772636115551 , global_step: 271
- AI-Rank-log  1618921227.0455763  eval_accuracy: 0.11163773387670517 , global_step: 272
- AI-Rank-log  1618921270.9898102  eval_accuracy: 0.10961847752332687 , global_step: 273
- AI-Rank-log  1618921314.9785602  eval_accuracy: 0.11251851916313171 , global_step: 274
- AI-Rank-log  1618921359.0454056  eval_accuracy: 0.11282220482826233 , global_step: 275
- AI-Rank-log  1618921402.9815335  eval_accuracy: 0.11503584682941437 , global_step: 276
- AI-Rank-log  1618921447.0045254  eval_accuracy: 0.1150374636054039 , global_step: 277
- AI-Rank-log  1618921491.049313  eval_accuracy: 0.11498109996318817 , global_step: 278
- AI-Rank-log  1618921535.0018914  eval_accuracy: 0.11484521627426147 , global_step: 279
- AI-Rank-log  1618921578.969751  eval_accuracy: 0.11707877367734909 , global_step: 280
- AI-Rank-log  1618921623.0186412  eval_accuracy: 0.11740732938051224 , global_step: 281
- AI-Rank-log  1618921667.0054681  eval_accuracy: 0.11855611205101013 , global_step: 282
- AI-Rank-log  1618921711.050647  eval_accuracy: 0.11183378845453262 , global_step: 283
- AI-Rank-log  1618921754.9820244  eval_accuracy: 0.11951703578233719 , global_step: 284
- AI-Rank-log  1618921798.9496267  eval_accuracy: 0.11883977800607681 , global_step: 285
- AI-Rank-log  1618921843.0486681  eval_accuracy: 0.11770720779895782 , global_step: 286
- AI-Rank-log  1618921887.0074804  eval_accuracy: 0.12268412113189697 , global_step: 287
- AI-Rank-log  1618921930.9879646  eval_accuracy: 0.11807732284069061 , global_step: 288
- AI-Rank-log  1618921975.028679  eval_accuracy: 0.11847041547298431 , global_step: 289
- AI-Rank-log  1618922018.9888015  eval_accuracy: 0.12112468481063843 , global_step: 290
- AI-Rank-log  1618922062.9586852  eval_accuracy: 0.11916471272706985 , global_step: 291
- AI-Rank-log  1618922106.991106  eval_accuracy: 0.11206609755754471 , global_step: 292
- AI-Rank-log  1618922150.977193  eval_accuracy: 0.12136644870042801 , global_step: 293
- AI-Rank-log  1618922195.0367875  eval_accuracy: 0.12099000066518784 , global_step: 294
- AI-Rank-log  1618922239.001061  eval_accuracy: 0.1178358718752861 , global_step: 295
- AI-Rank-log  1618922282.9854708  eval_accuracy: 0.12262562662363052 , global_step: 296
- AI-Rank-log  1618922327.109362  eval_accuracy: 0.10833121091127396 , global_step: 297
- AI-Rank-log  1618922371.0900385  eval_accuracy: 0.1221814677119255 , global_step: 298
- AI-Rank-log  1618922415.1493933  eval_accuracy: 0.11777669191360474 , global_step: 299
- AI-Rank-log  1618922459.1639977  eval_accuracy: 0.11149504780769348 , global_step: 300
- AI-Rank-log  1618922503.174728  eval_accuracy: 0.12074322253465652 , global_step: 301
- AI-Rank-log  1618922547.1696358  eval_accuracy: 0.1208164244890213 , global_step: 302
- AI-Rank-log  1618922591.1965406  eval_accuracy: 0.1245943233370781 , global_step: 303
- AI-Rank-log  1618922635.9426334  eval_accuracy: 0.1244807094335556 , global_step: 304
- AI-Rank-log  1618922680.717843  eval_accuracy: 0.12300173193216324 , global_step: 305
- AI-Rank-log  1618922725.6800396  eval_accuracy: 0.12435678392648697 , global_step: 306
- AI-Rank-log  1618922769.6706932  eval_accuracy: 0.12178026884794235 , global_step: 307
- AI-Rank-log  1618922813.7169652  eval_accuracy: 0.11813148111104965 , global_step: 308
- AI-Rank-log  1618922857.7310464  eval_accuracy: 0.12758708000183105 , global_step: 309
- AI-Rank-log  1618922901.7605088  eval_accuracy: 0.11973419785499573 , global_step: 310
- AI-Rank-log  1618922945.7855551  eval_accuracy: 0.1246412917971611 , global_step: 311
- AI-Rank-log  1618922989.7936547  eval_accuracy: 0.12608756124973297 , global_step: 312
- AI-Rank-log  1618923033.8676574  eval_accuracy: 0.12734921276569366 , global_step: 313
- AI-Rank-log  1618923077.8429215  eval_accuracy: 0.12390924990177155 , global_step: 314
- AI-Rank-log  1618923121.8864553  eval_accuracy: 0.12669441103935242 , global_step: 315
- AI-Rank-log  1618923165.928705  eval_accuracy: 0.12682805955410004 , global_step: 316
- AI-Rank-log  1618923209.923205  eval_accuracy: 0.1245858371257782 , global_step: 317
- AI-Rank-log  1618923253.9221678  eval_accuracy: 0.13005022704601288 , global_step: 318
- AI-Rank-log  1618923297.9471903  eval_accuracy: 0.12606680393218994 , global_step: 319
- AI-Rank-log  1618923342.0263333  eval_accuracy: 0.12182489037513733 , global_step: 320
- AI-Rank-log  1618923386.059468  eval_accuracy: 0.12831909954547882 , global_step: 321
- AI-Rank-log  1618923429.9920707  eval_accuracy: 0.12636157870292664 , global_step: 322
- AI-Rank-log  1618923474.0240676  eval_accuracy: 0.1198236420750618 , global_step: 323
- AI-Rank-log  1618923518.116368  eval_accuracy: 0.12944985926151276 , global_step: 324
- AI-Rank-log  1618923562.111072  eval_accuracy: 0.12719951570034027 , global_step: 325
- AI-Rank-log  1618923606.158185  eval_accuracy: 0.13137851655483246 , global_step: 326
- AI-Rank-log  1618923650.2900229  eval_accuracy: 0.12866461277008057 , global_step: 327
- AI-Rank-log  1618923694.0459309  eval_accuracy: 0.12615875899791718 , global_step: 328
- AI-Rank-log  1618923738.023532  eval_accuracy: 0.13183093070983887 , global_step: 329
- AI-Rank-log  1618923781.8669977  eval_accuracy: 0.13255105912685394 , global_step: 330
- AI-Rank-log  1618923825.8291428  eval_accuracy: 0.13037459552288055 , global_step: 331
- AI-Rank-log  1618923869.8737524  eval_accuracy: 0.1286822110414505 , global_step: 332
- AI-Rank-log  1618923913.8401625  eval_accuracy: 0.12347131967544556 , global_step: 333
- AI-Rank-log  1618923957.7887764  eval_accuracy: 0.12701082229614258 , global_step: 334
- AI-Rank-log  1618924001.8258274  eval_accuracy: 0.13311618566513062 , global_step: 335
- AI-Rank-log  1618924045.770228  eval_accuracy: 0.13263648748397827 , global_step: 336
- AI-Rank-log  1618924089.797143  eval_accuracy: 0.12523651123046875 , global_step: 337
- AI-Rank-log  1618924133.862103  eval_accuracy: 0.13037075102329254 , global_step: 338
- AI-Rank-log  1618924177.7905304  eval_accuracy: 0.12996865808963776 , global_step: 339
- AI-Rank-log  1618924221.7588875  eval_accuracy: 0.13279598951339722 , global_step: 340
- AI-Rank-log  1618924265.824938  eval_accuracy: 0.13194657862186432 , global_step: 341
- AI-Rank-log  1618924309.8280685  eval_accuracy: 0.13169406354427338 , global_step: 342
- AI-Rank-log  1618924353.8612776  eval_accuracy: 0.13518452644348145 , global_step: 343
- AI-Rank-log  1618924397.8913155  eval_accuracy: 0.1356307566165924 , global_step: 344
- AI-Rank-log  1618924441.8934083  eval_accuracy: 0.13420259952545166 , global_step: 345
- AI-Rank-log  1618924485.9068043  eval_accuracy: 0.13525083661079407 , global_step: 346
- AI-Rank-log  1618924529.8604126  eval_accuracy: 0.13499966263771057 , global_step: 347
- AI-Rank-log  1618924573.8526652  eval_accuracy: 0.13027186691761017 , global_step: 348
- AI-Rank-log  1618924617.9484854  eval_accuracy: 0.12944549322128296 , global_step: 349
- AI-Rank-log  1618924661.9220424  eval_accuracy: 0.13732203841209412 , global_step: 350
- AI-Rank-log  1618924705.9627383  eval_accuracy: 0.1374342143535614 , global_step: 351
- AI-Rank-log  1618924749.9916282  eval_accuracy: 0.13112561404705048 , global_step: 352
- AI-Rank-log  1618924794.0265043  eval_accuracy: 0.13422708213329315 , global_step: 353
- AI-Rank-log  1618924838.0657802  eval_accuracy: 0.13942386209964752 , global_step: 354
- AI-Rank-log  1618924882.0528393  eval_accuracy: 0.13975860178470612 , global_step: 355
- AI-Rank-log  1618924926.0182216  eval_accuracy: 0.13774771988391876 , global_step: 356
- AI-Rank-log  1618924970.0070114  eval_accuracy: 0.13562949001789093 , global_step: 357
- AI-Rank-log  1618925013.9830148  eval_accuracy: 0.13874100148677826 , global_step: 358
- AI-Rank-log  1618925057.950822  eval_accuracy: 0.1368204653263092 , global_step: 359
- AI-Rank-log  1618925101.9481006  eval_accuracy: 0.14041024446487427 , global_step: 360
- AI-Rank-log  1618925145.9628139  eval_accuracy: 0.13920019567012787 , global_step: 361
- AI-Rank-log  1618925189.95029  eval_accuracy: 0.13856641948223114 , global_step: 362
- AI-Rank-log  1618925233.9936326  eval_accuracy: 0.1382284164428711 , global_step: 363
- AI-Rank-log  1618925277.9265203  eval_accuracy: 0.13811370730400085 , global_step: 364
- AI-Rank-log  1618925322.019444  eval_accuracy: 0.1345343142747879 , global_step: 365
- AI-Rank-log  1618925366.0068223  eval_accuracy: 0.1375816911458969 , global_step: 366
- AI-Rank-log  1618925410.0393732  eval_accuracy: 0.13540251553058624 , global_step: 367
- AI-Rank-log  1618925454.085063  eval_accuracy: 0.13594502210617065 , global_step: 368
- AI-Rank-log  1618925498.0406675  eval_accuracy: 0.1386171281337738 , global_step: 369
- AI-Rank-log  1618925541.9983494  eval_accuracy: 0.13423755764961243 , global_step: 370
- AI-Rank-log  1618925586.0778697  eval_accuracy: 0.1160377785563469 , global_step: 371
- AI-Rank-log  1618925630.08927  eval_accuracy: 0.13848978281021118 , global_step: 372
- AI-Rank-log  1618925674.1310782  eval_accuracy: 0.13788080215454102 , global_step: 373
- AI-Rank-log  1618925718.101571  eval_accuracy: 0.14133597910404205 , global_step: 374
- AI-Rank-log  1618925762.056934  eval_accuracy: 0.1393134593963623 , global_step: 375
- AI-Rank-log  1618925806.1639087  eval_accuracy: 0.1345350593328476 , global_step: 376
- AI-Rank-log  1618925850.082061  eval_accuracy: 0.14248797297477722 , global_step: 377
- AI-Rank-log  1618925894.06816  eval_accuracy: 0.13787910342216492 , global_step: 378
- AI-Rank-log  1618925937.8764265  eval_accuracy: 0.13734106719493866 , global_step: 379
- AI-Rank-log  1618925981.6143992  eval_accuracy: 0.14204254746437073 , global_step: 380
- AI-Rank-log  1618926025.5926065  eval_accuracy: 0.1416352540254593 , global_step: 381
- AI-Rank-log  1618926070.3248315  eval_accuracy: 0.14110057055950165 , global_step: 382
- AI-Rank-log  1618926115.4839623  eval_accuracy: 0.14110057055950165 , global_step: 382
- AI-Rank-log  1618926159.5549555  eval_accuracy: 0.1378602236509323 , global_step: 383
- AI-Rank-log  1618926203.5115097  eval_accuracy: 0.14079956710338593 , global_step: 384

yq01-sys-hic-k8s-v100-box-a225-0804:34464:34521 [0] misc/ibvwrap.cc:220 NCCL WARN Call to ibv_get_async_event failed
- AI-Rank-log  1618926247.4434667  eval_accuracy: 0.14086377620697021 , global_step: 385
- AI-Rank-log  1618926291.4521544  eval_accuracy: 0.14474037289619446 , global_step: 386
- AI-Rank-log  1618926335.3913689  eval_accuracy: 0.14233791828155518 , global_step: 387
- AI-Rank-log  1618926379.3116338  eval_accuracy: 0.14224699139595032 , global_step: 388
- AI-Rank-log  1618926423.3937426  eval_accuracy: 0.1412591189146042 , global_step: 389
- AI-Rank-log  1618926467.3137972  eval_accuracy: 0.14277328550815582 , global_step: 390
- AI-Rank-log  1618926511.34175  eval_accuracy: 0.14457537233829498 , global_step: 391
- AI-Rank-log  1618926555.2248533  eval_accuracy: 0.14282993972301483 , global_step: 392
- AI-Rank-log  1618926599.1546361  eval_accuracy: 0.1381758600473404 , global_step: 393
- AI-Rank-log  1618926643.1347256  eval_accuracy: 0.14358657598495483 , global_step: 394
- AI-Rank-log  1618926695.051873  eval_accuracy: 0.14450962841510773 , global_step: 395
- AI-Rank-log  1618926739.0128734  eval_accuracy: 0.14221347868442535 , global_step: 396
- AI-Rank-log  1618926783.0146987  eval_accuracy: 0.1393321007490158 , global_step: 397
- AI-Rank-log  1618926826.9356377  eval_accuracy: 0.14421354234218597 , global_step: 398
- AI-Rank-log  1618926870.9183564  eval_accuracy: 0.1398974359035492 , global_step: 399
- AI-Rank-log  1618926914.9040494  eval_accuracy: 0.1405610591173172 , global_step: 400
- AI-Rank-log  1618926958.909354  eval_accuracy: 0.1421240121126175 , global_step: 401
- AI-Rank-log  1618927002.9017243  eval_accuracy: 0.14320071041584015 , global_step: 402
- AI-Rank-log  1618927046.8450234  eval_accuracy: 0.14527767896652222 , global_step: 403
- AI-Rank-log  1618927090.8443687  eval_accuracy: 0.1436566263437271 , global_step: 404
- AI-Rank-log  1618927134.8037515  eval_accuracy: 0.1398860365152359 , global_step: 405
- AI-Rank-log  1618927178.7145412  eval_accuracy: 0.14325425028800964 , global_step: 406
- AI-Rank-log  1618927222.673507  eval_accuracy: 0.14180798828601837 , global_step: 407
- AI-Rank-log  1618927266.6689117  eval_accuracy: 0.14268475770950317 , global_step: 408
- AI-Rank-log  1618927310.6067994  eval_accuracy: 0.14309561252593994 , global_step: 409
- AI-Rank-log  1618927354.604504  eval_accuracy: 0.141440749168396 , global_step: 410
- AI-Rank-log  1618927398.4821851  eval_accuracy: 0.14195331931114197 , global_step: 411
- AI-Rank-log  1618927442.4262536  eval_accuracy: 0.13396041095256805 , global_step: 412
- AI-Rank-log  1618927486.459222  eval_accuracy: 0.1369415521621704 , global_step: 413
- AI-Rank-log  1618927530.379469  eval_accuracy: 0.1376568228006363 , global_step: 414
- AI-Rank-log  1618927574.334418  eval_accuracy: 0.13797669112682343 , global_step: 415
- AI-Rank-log  1618927618.3227499  eval_accuracy: 0.14013884961605072 , global_step: 416
- AI-Rank-log  1618927662.2315216  eval_accuracy: 0.14201979339122772 , global_step: 417
- AI-Rank-log  1618927706.1833413  eval_accuracy: 0.13160081207752228 , global_step: 418
- AI-Rank-log  1618927750.1375198  eval_accuracy: 0.1300337165594101 , global_step: 419
- AI-Rank-log  1618927794.0390463  eval_accuracy: 0.13575057685375214 , global_step: 420
- AI-Rank-log  1618927838.0418527  eval_accuracy: 0.14145800471305847 , global_step: 421
- AI-Rank-log  1618927881.9293215  eval_accuracy: 0.1404651701450348 , global_step: 422
- AI-Rank-log  1618927925.8207023  eval_accuracy: 0.1401350200176239 , global_step: 423
- AI-Rank-log  1618927969.8382185  eval_accuracy: 0.14233329892158508 , global_step: 424
- AI-Rank-log  1618928013.7420106  eval_accuracy: 0.1408485621213913 , global_step: 425
- AI-Rank-log  1618928057.6994882  eval_accuracy: 0.1402214914560318 , global_step: 426
- AI-Rank-log  1618928101.682427  eval_accuracy: 0.14360864460468292 , global_step: 427
- AI-Rank-log  1618928145.5662794  eval_accuracy: 0.14216747879981995 , global_step: 428
- AI-Rank-log  1618928189.564739  eval_accuracy: 0.1444636732339859 , global_step: 429
- AI-Rank-log  1618928233.5440876  eval_accuracy: 0.14400114119052887 , global_step: 430
- AI-Rank-log  1618928277.451469  eval_accuracy: 0.1445620208978653 , global_step: 431
- AI-Rank-log  1618928321.447785  eval_accuracy: 0.14385709166526794 , global_step: 432
- AI-Rank-log  1618928365.4157643  eval_accuracy: 0.14385709166526794 , global_step: 432
- AI-Rank-log  1618928409.3241792  eval_accuracy: 0.13672001659870148 , global_step: 433
- AI-Rank-log  1618928453.3475912  eval_accuracy: 0.13945600390434265 , global_step: 434
- AI-Rank-log  1618928497.2381473  eval_accuracy: 0.14316384494304657 , global_step: 435
- AI-Rank-log  1618928541.1219542  eval_accuracy: 0.14299626648426056 , global_step: 436
- AI-Rank-log  1618928585.143252  eval_accuracy: 0.14296449720859528 , global_step: 437
- AI-Rank-log  1618928629.065811  eval_accuracy: 0.14377327263355255 , global_step: 438
- AI-Rank-log  1618928672.9950473  eval_accuracy: 0.13581699132919312 , global_step: 439
- AI-Rank-log  1618928716.9511435  eval_accuracy: 0.14137260615825653 , global_step: 440
- AI-Rank-log  1618928760.8786402  eval_accuracy: 0.14456257224082947 , global_step: 441
- AI-Rank-log  1618928804.8485866  eval_accuracy: 0.1446160525083542 , global_step: 442
- AI-Rank-log  1618928848.7376125  eval_accuracy: 0.1392366737127304 , global_step: 443
- AI-Rank-log  1618928892.6501772  eval_accuracy: 0.14132803678512573 , global_step: 444
- AI-Rank-log  1618928936.63968  eval_accuracy: 0.14138318598270416 , global_step: 445
- AI-Rank-log  1618928980.553983  eval_accuracy: 0.14141511917114258 , global_step: 446
- AI-Rank-log  1618929024.489543  eval_accuracy: 0.14310480654239655 , global_step: 447
- AI-Rank-log  1618929068.5145035  eval_accuracy: 0.14578579366207123 , global_step: 448
- AI-Rank-log  1618929112.428584  eval_accuracy: 0.145533949136734 , global_step: 449
- AI-Rank-log  1618929156.369497  eval_accuracy: 0.14653268456459045 , global_step: 450
- AI-Rank-log  1618929200.303519  eval_accuracy: 0.14593377709388733 , global_step: 451
- AI-Rank-log  1618929244.2113364  eval_accuracy: 0.14606526494026184 , global_step: 452
- AI-Rank-log  1618929288.19695  eval_accuracy: 0.1458200067281723 , global_step: 453
- AI-Rank-log  1618929332.1018717  eval_accuracy: 0.14649541676044464 , global_step: 454
- AI-Rank-log  1618929376.0051932  eval_accuracy: 0.14388832449913025 , global_step: 455
- AI-Rank-log  1618929420.0084977  eval_accuracy: 0.14620661735534668 , global_step: 456
- AI-Rank-log  1618929464.028532  eval_accuracy: 0.14648887515068054 , global_step: 457
- AI-Rank-log  1618929508.863991  eval_accuracy: 0.14731112122535706 , global_step: 458

yq01-sys-hic-k8s-v100-box-a225-0804:34469:34524 [0] misc/ibvwrap.cc:220 NCCL WARN Call to ibv_get_async_event failed
- AI-Rank-log  1618929554.0642881  eval_accuracy: 0.1458318531513214 , global_step: 459
- AI-Rank-log  1618929598.0176733  eval_accuracy: 0.1444535255432129 , global_step: 460
- AI-Rank-log  1618929642.0744991  eval_accuracy: 0.14794524013996124 , global_step: 461
- AI-Rank-log  1618929686.0024455  eval_accuracy: 0.14822831749916077 , global_step: 462
- AI-Rank-log  1618929729.9474633  eval_accuracy: 0.14513152837753296 , global_step: 463
- AI-Rank-log  1618929773.9215431  eval_accuracy: 0.1430388242006302 , global_step: 464
- AI-Rank-log  1618929817.8325412  eval_accuracy: 0.1463925838470459 , global_step: 465
- AI-Rank-log  1618929861.7769415  eval_accuracy: 0.14178141951560974 , global_step: 466
- AI-Rank-log  1618929905.757871  eval_accuracy: 0.14136312901973724 , global_step: 467
- AI-Rank-log  1618929949.6632586  eval_accuracy: 0.1396176815032959 , global_step: 468
- AI-Rank-log  1618929993.5926697  eval_accuracy: 0.14581352472305298 , global_step: 469
- AI-Rank-log  1618930037.5813572  eval_accuracy: 0.14441506564617157 , global_step: 470
- AI-Rank-log  1618930081.4755952  eval_accuracy: 0.1453763097524643 , global_step: 471
- AI-Rank-log  1618930125.476753  eval_accuracy: 0.14766980707645416 , global_step: 472
- AI-Rank-log  1618930169.3658032  eval_accuracy: 0.14819477498531342 , global_step: 473
- AI-Rank-log  1618930213.3099985  eval_accuracy: 0.14814604818820953 , global_step: 474
- AI-Rank-log  1618930257.273291  eval_accuracy: 0.14742301404476166 , global_step: 475
- AI-Rank-log  1618930301.2024572  eval_accuracy: 0.14761006832122803 , global_step: 476
- AI-Rank-log  1618930345.121821  eval_accuracy: 0.14760801196098328 , global_step: 477
- AI-Rank-log  1618930389.1108093  eval_accuracy: 0.14809530973434448 , global_step: 478
- AI-Rank-log  1618930432.9754841  eval_accuracy: 0.14870573580265045 , global_step: 479
- AI-Rank-log  1618930476.9204757  eval_accuracy: 0.1482696682214737 , global_step: 480
- AI-Rank-log  1618930520.857845  eval_accuracy: 0.14872737228870392 , global_step: 481
- AI-Rank-log  1618930564.7942998  eval_accuracy: 0.148799329996109 , global_step: 482
- AI-Rank-log  1618930608.7804654  eval_accuracy: 0.1458023339509964 , global_step: 483
- AI-Rank-log  1618930652.6634984  eval_accuracy: 0.14547471702098846 , global_step: 484
- AI-Rank-log  1618930696.5413713  eval_accuracy: 0.14536508917808533 , global_step: 485
- AI-Rank-log  1618930740.5453365  eval_accuracy: 0.1493702381849289 , global_step: 486
- AI-Rank-log  1618930784.4871902  eval_accuracy: 0.14849860966205597 , global_step: 487
- AI-Rank-log  1618930828.3774517  eval_accuracy: 0.14649859070777893 , global_step: 488
- AI-Rank-log  1618930872.389082  eval_accuracy: 0.1474183350801468 , global_step: 489
- AI-Rank-log  1618930916.3182125  eval_accuracy: 0.14748263359069824 , global_step: 490
- AI-Rank-log  1618930960.2451427  eval_accuracy: 0.14882780611515045 , global_step: 491
- AI-Rank-log  1618931004.231485  eval_accuracy: 0.14905297756195068 , global_step: 492
- AI-Rank-log  1618931048.180783  eval_accuracy: 0.14461521804332733 , global_step: 493
- AI-Rank-log  1618931092.182831  eval_accuracy: 0.14524927735328674 , global_step: 494
- AI-Rank-log  1618931136.1395884  eval_accuracy: 0.14938020706176758 , global_step: 495
- AI-Rank-log  1618931180.0595133  eval_accuracy: 0.14960382878780365 , global_step: 496
- AI-Rank-log  1618931224.0471797  eval_accuracy: 0.14670614898204803 , global_step: 497
- AI-Rank-log  1618931268.0002096  eval_accuracy: 0.1486302763223648 , global_step: 498
- AI-Rank-log  1618931311.904563  eval_accuracy: 0.14684969186782837 , global_step: 499
- AI-Rank-log  1618931355.8551803  eval_accuracy: 0.1477111428976059 , global_step: 500
- AI-Rank-log  1618931399.774672  eval_accuracy: 0.1463034451007843 , global_step: 501
- AI-Rank-log  1618931443.6734982  eval_accuracy: 0.14827829599380493 , global_step: 502
- AI-Rank-log  1618931487.696413  eval_accuracy: 0.1478448361158371 , global_step: 503
- AI-Rank-log  1618931531.6324513  eval_accuracy: 0.147340327501297 , global_step: 504
- AI-Rank-log  1618931575.598935  eval_accuracy: 0.1451544463634491 , global_step: 505
- AI-Rank-log  1618931619.5258007  eval_accuracy: 0.14830459654331207 , global_step: 506
- AI-Rank-log  1618931663.4707694  eval_accuracy: 0.14741145074367523 , global_step: 507
- AI-Rank-log  1618931707.3809028  eval_accuracy: 0.14841756224632263 , global_step: 508
- AI-Rank-log  1618931751.271602  eval_accuracy: 0.1487109512090683 , global_step: 509
- AI-Rank-log  1618931795.2128658  eval_accuracy: 0.14834164083003998 , global_step: 510
- AI-Rank-log  1618931839.1555674  eval_accuracy: 0.14585675299167633 , global_step: 511
- AI-Rank-log  1618931883.1084137  eval_accuracy: 0.14675676822662354 , global_step: 512
- AI-Rank-log  1618931927.037711  eval_accuracy: 0.14836959540843964 , global_step: 513
- AI-Rank-log  1618931970.9522207  eval_accuracy: 0.15017437934875488 , global_step: 514
- AI-Rank-log  1618932014.7039895  eval_accuracy: 0.14901766180992126 , global_step: 515
- AI-Rank-log  1618932058.6932185  eval_accuracy: 0.14844144880771637 , global_step: 516
- AI-Rank-log  1618932102.637993  eval_accuracy: 0.1482904553413391 , global_step: 517
- AI-Rank-log  1618932146.4136353  eval_accuracy: 0.14881715178489685 , global_step: 518
- AI-Rank-log  1618932190.3675394  eval_accuracy: 0.15004195272922516 , global_step: 519
- AI-Rank-log  1618932234.265192  eval_accuracy: 0.14851993322372437 , global_step: 520
- AI-Rank-log  1618932278.248529  eval_accuracy: 0.1496531069278717 , global_step: 521
- AI-Rank-log  1618932322.2182703  eval_accuracy: 0.14842508733272552 , global_step: 522
- AI-Rank-log  1618932366.176996  eval_accuracy: 0.14840133488178253 , global_step: 523
- AI-Rank-log  1618932410.1239665  eval_accuracy: 0.14995746314525604 , global_step: 524
- AI-Rank-log  1618932454.099501  eval_accuracy: 0.14490823447704315 , global_step: 525
- AI-Rank-log  1618932498.049919  eval_accuracy: 0.14746378362178802 , global_step: 526
- AI-Rank-log  1618932542.0209014  eval_accuracy: 0.14858342707157135 , global_step: 527
- AI-Rank-log  1618932585.9262419  eval_accuracy: 0.14685894548892975 , global_step: 528
- AI-Rank-log  1618932629.831453  eval_accuracy: 0.147251695394516 , global_step: 529
- AI-Rank-log  1618932673.8193312  eval_accuracy: 0.1479632556438446 , global_step: 530
- AI-Rank-log  1618932717.704902  eval_accuracy: 0.14919878542423248 , global_step: 531
- AI-Rank-log  1618932761.6188214  eval_accuracy: 0.1518923044204712 , global_step: 532
- AI-Rank-log  1618932805.66298  eval_accuracy: 0.1491805762052536 , global_step: 533
- AI-Rank-log  1618932849.556464  eval_accuracy: 0.14952495694160461 , global_step: 534
- AI-Rank-log  1618932895.285987  eval_accuracy: 0.15045267343521118 , global_step: 535
- AI-Rank-log  1618932940.4341407  eval_accuracy: 0.1511988788843155 , global_step: 536
- AI-Rank-log  1618932984.662166  eval_accuracy: 0.14955224096775055 , global_step: 537
- AI-Rank-log  1618933028.707977  eval_accuracy: 0.14938099682331085 , global_step: 538
- AI-Rank-log  1618933072.6324775  eval_accuracy: 0.15200383961200714 , global_step: 539
- AI-Rank-log  1618933116.554224  eval_accuracy: 0.14978818595409393 , global_step: 540
- AI-Rank-log  1618933160.588358  eval_accuracy: 0.15099233388900757 , global_step: 541
- AI-Rank-log  1618933204.5599725  eval_accuracy: 0.15069320797920227 , global_step: 542
- AI-Rank-log  1618933248.5039048  eval_accuracy: 0.14978642761707306 , global_step: 543
- AI-Rank-log  1618933292.5272307  eval_accuracy: 0.1504666805267334 , global_step: 544
- AI-Rank-log  1618933336.4384136  eval_accuracy: 0.1479204297065735 , global_step: 545
- AI-Rank-log  1618933380.3893828  eval_accuracy: 0.14915211498737335 , global_step: 546
- AI-Rank-log  1618933424.3339713  eval_accuracy: 0.15039820969104767 , global_step: 547
- AI-Rank-log  1618933468.243056  eval_accuracy: 0.1493823528289795 , global_step: 548
- AI-Rank-log  1618933512.27549  eval_accuracy: 0.14914435148239136 , global_step: 549
- AI-Rank-log  1618933556.1880953  eval_accuracy: 0.148826465010643 , global_step: 550
- AI-Rank-log  1618933600.0876265  eval_accuracy: 0.15115682780742645 , global_step: 551
- AI-Rank-log  1618933644.0406213  eval_accuracy: 0.14951398968696594 , global_step: 552
- AI-Rank-log  1618933687.9958992  eval_accuracy: 0.1458015888929367 , global_step: 553
- AI-Rank-log  1618933731.9167967  eval_accuracy: 0.1490885615348816 , global_step: 554
- AI-Rank-log  1618933775.881067  eval_accuracy: 0.1500207632780075 , global_step: 555
- AI-Rank-log  1618933819.8285115  eval_accuracy: 0.15035979449748993 , global_step: 556
- AI-Rank-log  1618933863.8021266  eval_accuracy: 0.1506716012954712 , global_step: 557
- AI-Rank-log  1618933907.7408276  eval_accuracy: 0.1497562825679779 , global_step: 558
- AI-Rank-log  1618933951.6766691  eval_accuracy: 0.15035131573677063 , global_step: 559
- AI-Rank-log  1618933995.6994798  eval_accuracy: 0.1500796228647232 , global_step: 560
- AI-Rank-log  1618934039.6523845  eval_accuracy: 0.14945422112941742 , global_step: 561
- AI-Rank-log  1618934083.58742  eval_accuracy: 0.1511383205652237 , global_step: 562
- AI-Rank-log  1618934127.5530603  eval_accuracy: 0.15005610883235931 , global_step: 563
- AI-Rank-log  1618934171.5342474  eval_accuracy: 0.14905816316604614 , global_step: 564
- AI-Rank-log  1618934215.4879205  eval_accuracy: 0.1490435004234314 , global_step: 565
- AI-Rank-log  1618934259.446236  eval_accuracy: 0.15202714502811432 , global_step: 566
- AI-Rank-log  1618934303.380914  eval_accuracy: 0.15117500722408295 , global_step: 567
- AI-Rank-log  1618934347.387508  eval_accuracy: 0.1502935141324997 , global_step: 568
- AI-Rank-log  1618934391.2961183  eval_accuracy: 0.14873217046260834 , global_step: 569
- AI-Rank-log  1618934435.2226331  eval_accuracy: 0.15275122225284576 , global_step: 570
- AI-Rank-log  1618934479.2314641  eval_accuracy: 0.15129762887954712 , global_step: 571
- AI-Rank-log  1618934523.1484823  eval_accuracy: 0.15153098106384277 , global_step: 572
- AI-Rank-log  1618934567.0499027  eval_accuracy: 0.14844059944152832 , global_step: 573
- AI-Rank-log  1618934611.0135288  eval_accuracy: 0.15041548013687134 , global_step: 574
- AI-Rank-log  1618934654.9329069  eval_accuracy: 0.15250571072101593 , global_step: 575
- AI-Rank-log  1618934698.9313407  eval_accuracy: 0.15140677988529205 , global_step: 576
- AI-Rank-log  1618934742.825103  eval_accuracy: 0.1512220799922943 , global_step: 577
- AI-Rank-log  1618934786.7472172  eval_accuracy: 0.15153028070926666 , global_step: 578
- AI-Rank-log  1618934830.7512422  eval_accuracy: 0.15142425894737244 , global_step: 579
- AI-Rank-log  1618934874.6319795  eval_accuracy: 0.149535670876503 , global_step: 580
- AI-Rank-log  1618934918.5651891  eval_accuracy: 0.15114490687847137 , global_step: 581
- AI-Rank-log  1618934962.561098  eval_accuracy: 0.14967086911201477 , global_step: 582
- AI-Rank-log  1618935006.4775035  eval_accuracy: 0.15050874650478363 , global_step: 583
- AI-Rank-log  1618935050.4150426  eval_accuracy: 0.15111562609672546 , global_step: 584
- AI-Rank-log  1618935094.3961396  eval_accuracy: 0.1505916267633438 , global_step: 585
- AI-Rank-log  1618935138.30114  eval_accuracy: 0.15193010866641998 , global_step: 586
- AI-Rank-log  1618935182.3159976  eval_accuracy: 0.15027238428592682 , global_step: 587
- AI-Rank-log  1618935226.272428  eval_accuracy: 0.15256156027317047 , global_step: 588
- AI-Rank-log  1618935269.9621575  eval_accuracy: 0.15232188999652863 , global_step: 589
- AI-Rank-log  1618935313.9288445  eval_accuracy: 0.15340067446231842 , global_step: 590
- AI-Rank-log  1618935357.857849  eval_accuracy: 0.15028727054595947 , global_step: 591
- AI-Rank-log  1618935401.7788146  eval_accuracy: 0.15182097256183624 , global_step: 592
- AI-Rank-log  1618935445.7748988  eval_accuracy: 0.15184910595417023 , global_step: 593
- AI-Rank-log  1618935497.85319  eval_accuracy: 0.15339551866054535 , global_step: 594
- AI-Rank-log  1618935541.7332106  eval_accuracy: 0.1526048183441162 , global_step: 595
- AI-Rank-log  1618935585.800524  eval_accuracy: 0.15035679936408997 , global_step: 596
- AI-Rank-log  1618935629.7547262  eval_accuracy: 0.15193045139312744 , global_step: 597
- AI-Rank-log  1618935673.640531  eval_accuracy: 0.15439707040786743 , global_step: 598
- AI-Rank-log  1618935717.6459079  eval_accuracy: 0.15421827137470245 , global_step: 599
- AI-Rank-log  1618935761.5656924  eval_accuracy: 0.15316849946975708 , global_step: 600
- AI-Rank-log  1618935805.532746  eval_accuracy: 0.1537194699048996 , global_step: 601
- AI-Rank-log  1618935849.493682  eval_accuracy: 0.15214240550994873 , global_step: 602
- AI-Rank-log  1618935893.4570296  eval_accuracy: 0.15024760365486145 , global_step: 603
- AI-Rank-log  1618935937.277492  eval_accuracy: 0.15332143008708954 , global_step: 604
- AI-Rank-log  1618935981.2125297  eval_accuracy: 0.15333624184131622 , global_step: 605
- AI-Rank-log  1618936025.1527617  eval_accuracy: 0.152780681848526 , global_step: 606
- AI-Rank-log  1618936069.1257775  eval_accuracy: 0.15074509382247925 , global_step: 607
- AI-Rank-log  1618936113.0155513  eval_accuracy: 0.1515527069568634 , global_step: 608
- AI-Rank-log  1618936156.9713554  eval_accuracy: 0.15217351913452148 , global_step: 609
- AI-Rank-log  1618936200.9045827  eval_accuracy: 0.1522660106420517 , global_step: 610
- AI-Rank-log  1618936244.818008  eval_accuracy: 0.15316025912761688 , global_step: 611
- AI-Rank-log  1618936289.6104426  eval_accuracy: 0.15233589708805084 , global_step: 612
- AI-Rank-log  1618936334.2964933  eval_accuracy: 0.14866028726100922 , global_step: 613
- AI-Rank-log  1618936379.2582653  eval_accuracy: 0.15370777249336243 , global_step: 614
- AI-Rank-log  1618936423.234698  eval_accuracy: 0.1539691984653473 , global_step: 615
- AI-Rank-log  1618936467.2006056  eval_accuracy: 0.15484663844108582 , global_step: 616
- AI-Rank-log  1618936511.1849499  eval_accuracy: 0.1551291048526764 , global_step: 617
- AI-Rank-log  1618936555.1400456  eval_accuracy: 0.15250930190086365 , global_step: 618
- AI-Rank-log  1618936599.0560637  eval_accuracy: 0.14905403554439545 , global_step: 619
- AI-Rank-log  1618936643.1245842  eval_accuracy: 0.15260174870491028 , global_step: 620
- AI-Rank-log  1618936687.0518208  eval_accuracy: 0.15246476233005524 , global_step: 621
- AI-Rank-log  1618936730.9636002  eval_accuracy: 0.15278248488903046 , global_step: 622
- AI-Rank-log  1618936775.0400333  eval_accuracy: 0.15359070897102356 , global_step: 623
- AI-Rank-log  1618936818.7729473  eval_accuracy: 0.1533547192811966 , global_step: 624
- AI-Rank-log  1618936862.7468858  eval_accuracy: 0.15119965374469757 , global_step: 625
- AI-Rank-log  1618936906.7578588  eval_accuracy: 0.15449118614196777 , global_step: 626
- AI-Rank-log  1618936950.693077  eval_accuracy: 0.15502096712589264 , global_step: 627
- AI-Rank-log  1618936994.6143055  eval_accuracy: 0.1547607034444809 , global_step: 628
- AI-Rank-log  1618937038.642696  eval_accuracy: 0.15423351526260376 , global_step: 629
- AI-Rank-log  1618937082.5576825  eval_accuracy: 0.15563268959522247 , global_step: 630
- AI-Rank-log  1618937126.5576015  eval_accuracy: 0.1561105102300644 , global_step: 631
- AI-Rank-log  1618937170.5024896  eval_accuracy: 0.1515188068151474 , global_step: 632
- AI-Rank-log  1618937214.412633  eval_accuracy: 0.15580086410045624 , global_step: 633
- AI-Rank-log  1618937258.2200773  eval_accuracy: 0.15584197640419006 , global_step: 634
- AI-Rank-log  1618937302.1215816  eval_accuracy: 0.15550187230110168 , global_step: 635
- AI-Rank-log  1618937346.0709827  eval_accuracy: 0.1527121365070343 , global_step: 636
- AI-Rank-log  1618937390.096984  eval_accuracy: 0.15594837069511414 , global_step: 637
- AI-Rank-log  1618937434.0817823  eval_accuracy: 0.1531389057636261 , global_step: 638
- AI-Rank-log  1618937477.9926503  eval_accuracy: 0.1557975858449936 , global_step: 639
- AI-Rank-log  1618937521.9764385  eval_accuracy: 0.15617382526397705 , global_step: 640
- AI-Rank-log  1618937565.89628  eval_accuracy: 0.15750747919082642 , global_step: 641
- AI-Rank-log  1618937609.9039078  eval_accuracy: 0.15660034120082855 , global_step: 642
- AI-Rank-log  1618937653.8510723  eval_accuracy: 0.1558384895324707 , global_step: 643
- AI-Rank-log  1618937697.799676  eval_accuracy: 0.15811288356781006 , global_step: 644
- AI-Rank-log  1618937741.8347511  eval_accuracy: 0.15310542285442352 , global_step: 645
- AI-Rank-log  1618937785.7887821  eval_accuracy: 0.15503166615962982 , global_step: 646
- AI-Rank-log  1618937829.682709  eval_accuracy: 0.15515826642513275 , global_step: 647
- AI-Rank-log  1618937873.7076626  eval_accuracy: 0.15701770782470703 , global_step: 648
- AI-Rank-log  1618937917.6356819  eval_accuracy: 0.15675857663154602 , global_step: 649
- AI-Rank-log  1618937961.5660203  eval_accuracy: 0.1567768156528473 , global_step: 650
- AI-Rank-log  1618938005.6485207  eval_accuracy: 0.15522949397563934 , global_step: 651
- AI-Rank-log  1618938049.587465  eval_accuracy: 0.14880314469337463 , global_step: 652
- AI-Rank-log  1618938093.47396  eval_accuracy: 0.15754501521587372 , global_step: 653
- AI-Rank-log  1618938137.4543335  eval_accuracy: 0.1575310081243515 , global_step: 654
- AI-Rank-log  1618938181.3923202  eval_accuracy: 0.15698862075805664 , global_step: 655
- AI-Rank-log  1618938225.34633  eval_accuracy: 0.1580827683210373 , global_step: 656
- AI-Rank-log  1618938269.2811887  eval_accuracy: 0.15774235129356384 , global_step: 657
- AI-Rank-log  1618938313.2303712  eval_accuracy: 0.1582012176513672 , global_step: 658
- AI-Rank-log  1618938357.2319486  eval_accuracy: 0.15757036209106445 , global_step: 659
- AI-Rank-log  1618938401.1556778  eval_accuracy: 0.1577915996313095 , global_step: 660
- AI-Rank-log  1618938445.0939198  eval_accuracy: 0.1582692265510559 , global_step: 661
- AI-Rank-log  1618938489.1112452  eval_accuracy: 0.1583404839038849 , global_step: 662
- AI-Rank-log  1618938533.025269  eval_accuracy: 0.1587894856929779 , global_step: 663
- AI-Rank-log  1618938577.0220876  eval_accuracy: 0.15539607405662537 , global_step: 664
- AI-Rank-log  1618938620.925767  eval_accuracy: 0.15821173787117004 , global_step: 665
- AI-Rank-log  1618938664.8238285  eval_accuracy: 0.15953949093818665 , global_step: 666
- AI-Rank-log  1618938708.7845342  eval_accuracy: 0.15912285447120667 , global_step: 667
- AI-Rank-log  1618938752.7490394  eval_accuracy: 0.1582918018102646 , global_step: 668
- AI-Rank-log  1618938796.7224586  eval_accuracy: 0.15819428861141205 , global_step: 669
- AI-Rank-log  1618938840.8214383  eval_accuracy: 0.1606387495994568 , global_step: 670

yq01-sys-hic-k8s-v100-box-a225-0804:34468:34534 [0] misc/ibvwrap.cc:220 NCCL WARN Call to ibv_get_async_event failed
- AI-Rank-log  1618938884.792852  eval_accuracy: 0.15963107347488403 , global_step: 671
- AI-Rank-log  1618938928.7467897  eval_accuracy: 0.15958654880523682 , global_step: 672
- AI-Rank-log  1618938972.7012942  eval_accuracy: 0.16181449592113495 , global_step: 673
- AI-Rank-log  1618939016.6399014  eval_accuracy: 0.16194234788417816 , global_step: 674
- AI-Rank-log  1618939060.688315  eval_accuracy: 0.16180674731731415 , global_step: 675
- AI-Rank-log  1618939104.3891783  eval_accuracy: 0.1624607890844345 , global_step: 676
- AI-Rank-log  1618939148.3242557  eval_accuracy: 0.16330482065677643 , global_step: 677
- AI-Rank-log  1618939192.2918098  eval_accuracy: 0.16211216151714325 , global_step: 678
- AI-Rank-log  1618939236.2333603  eval_accuracy: 0.15598198771476746 , global_step: 679
- AI-Rank-log  1618939280.1488762  eval_accuracy: 0.1627682000398636 , global_step: 680
- AI-Rank-log  1618939324.1815662  eval_accuracy: 0.16406086087226868 , global_step: 681
- AI-Rank-log  1618939368.1498284  eval_accuracy: 0.16195839643478394 , global_step: 682
- AI-Rank-log  1618939412.1859639  eval_accuracy: 0.16514594852924347 , global_step: 683
- AI-Rank-log  1618939456.093414  eval_accuracy: 0.1658121645450592 , global_step: 684
- AI-Rank-log  1618939500.025516  eval_accuracy: 0.16321158409118652 , global_step: 685
- AI-Rank-log  1618939544.0526645  eval_accuracy: 0.16245679557323456 , global_step: 686
- AI-Rank-log  1618939587.943046  eval_accuracy: 0.16479672491550446 , global_step: 687
- AI-Rank-log  1618939631.6711278  eval_accuracy: 0.1665852963924408 , global_step: 688
- AI-Rank-log  1618939676.621905  eval_accuracy: 0.16555646061897278 , global_step: 689
- AI-Rank-log  1618939721.7446692  eval_accuracy: 0.16382785141468048 , global_step: 690
- AI-Rank-log  1618939766.6665719  eval_accuracy: 0.16252490878105164 , global_step: 691
- AI-Rank-log  1618939810.8118646  eval_accuracy: 0.1635611653327942 , global_step: 692
- AI-Rank-log  1618939854.7159169  eval_accuracy: 0.1642940491437912 , global_step: 693
- AI-Rank-log  1618939898.7276525  eval_accuracy: 0.16272111237049103 , global_step: 694
- AI-Rank-log  1618939942.6841757  eval_accuracy: 0.16205435991287231 , global_step: 695
- AI-Rank-log  1618939986.6117222  eval_accuracy: 0.16233447194099426 , global_step: 696
- AI-Rank-log  1618940030.635152  eval_accuracy: 0.1643259972333908 , global_step: 697
- AI-Rank-log  1618940074.574566  eval_accuracy: 0.1663082391023636 , global_step: 698
- AI-Rank-log  1618940118.4787495  eval_accuracy: 0.165998637676239 , global_step: 699
- AI-Rank-log  1618940162.478816  eval_accuracy: 0.16541895270347595 , global_step: 700
- AI-Rank-log  1618940206.4424443  eval_accuracy: 0.16530941426753998 , global_step: 701
- AI-Rank-log  1618940250.3451872  eval_accuracy: 0.166680246591568 , global_step: 702
- AI-Rank-log  1618940294.3512187  eval_accuracy: 0.16965506970882416 , global_step: 703
- AI-Rank-log  1618940338.2802887  eval_accuracy: 0.16735123097896576 , global_step: 704
- AI-Rank-log  1618940382.2510872  eval_accuracy: 0.1658136248588562 , global_step: 705
- AI-Rank-log  1618940426.20224  eval_accuracy: 0.16874900460243225 , global_step: 706
- AI-Rank-log  1618940470.1653514  eval_accuracy: 0.16852717101573944 , global_step: 707
- AI-Rank-log  1618940514.1442037  eval_accuracy: 0.16909876465797424 , global_step: 708
- AI-Rank-log  1618940558.0869741  eval_accuracy: 0.17045094072818756 , global_step: 709
- AI-Rank-log  1618940602.0195801  eval_accuracy: 0.1704382300376892 , global_step: 710
- AI-Rank-log  1618940646.0223818  eval_accuracy: 0.17303448915481567 , global_step: 711
- AI-Rank-log  1618940689.9671726  eval_accuracy: 0.1737382709980011 , global_step: 712
- AI-Rank-log  1618940733.9068391  eval_accuracy: 0.16859307885169983 , global_step: 713
- AI-Rank-log  1618940777.9281929  eval_accuracy: 0.17317859828472137 , global_step: 714
- AI-Rank-log  1618940821.8897357  eval_accuracy: 0.1698867380619049 , global_step: 715
- AI-Rank-log  1618940865.8844728  eval_accuracy: 0.1762862503528595 , global_step: 716
- AI-Rank-log  1618940909.8574536  eval_accuracy: 0.1765851229429245 , global_step: 717
- AI-Rank-log  1618940953.8245137  eval_accuracy: 0.17714335024356842 , global_step: 718
- AI-Rank-log  1618940997.8049924  eval_accuracy: 0.1733565330505371 , global_step: 719
- AI-Rank-log  1618941041.756337  eval_accuracy: 0.17926737666130066 , global_step: 720
- AI-Rank-log  1618941085.7065802  eval_accuracy: 0.17918986082077026 , global_step: 721
- AI-Rank-log  1618941129.7289984  eval_accuracy: 0.17986053228378296 , global_step: 722
- AI-Rank-log  1618941173.7169352  eval_accuracy: 0.17874906957149506 , global_step: 723
- AI-Rank-log  1618941217.6466415  eval_accuracy: 0.18135668337345123 , global_step: 724
- AI-Rank-log  1618941261.6158915  eval_accuracy: 0.1851760447025299 , global_step: 725
- AI-Rank-log  1618941305.567252  eval_accuracy: 0.18356822431087494 , global_step: 726
- AI-Rank-log  1618941349.595637  eval_accuracy: 0.18504983186721802 , global_step: 727
- AI-Rank-log  1618941393.5113506  eval_accuracy: 0.1867598444223404 , global_step: 728
- AI-Rank-log  1618941437.4862256  eval_accuracy: 0.186752587556839 , global_step: 729
- AI-Rank-log  1618941481.5110824  eval_accuracy: 0.1852552741765976 , global_step: 730
- AI-Rank-log  1618941525.4336848  eval_accuracy: 0.1894896775484085 , global_step: 731
- AI-Rank-log  1618941569.376302  eval_accuracy: 0.189499169588089 , global_step: 732
- AI-Rank-log  1618941613.3795047  eval_accuracy: 0.19136247038841248 , global_step: 733
- AI-Rank-log  1618941657.309603  eval_accuracy: 0.18595832586288452 , global_step: 734
- AI-Rank-log  1618941701.2730944  eval_accuracy: 0.1872406154870987 , global_step: 735
- AI-Rank-log  1618941745.2722335  eval_accuracy: 0.19091808795928955 , global_step: 736
- AI-Rank-log  1618941789.2030778  eval_accuracy: 0.19100025296211243 , global_step: 737
- AI-Rank-log  1618941833.230054  eval_accuracy: 0.19275468587875366 , global_step: 738
- AI-Rank-log  1618941877.1752183  eval_accuracy: 0.19327278435230255 , global_step: 739
- AI-Rank-log  1618941921.1511185  eval_accuracy: 0.19060854613780975 , global_step: 740
- AI-Rank-log  1618941965.154619  eval_accuracy: 0.19064053893089294 , global_step: 741
- AI-Rank-log  1618942009.1403182  eval_accuracy: 0.19196102023124695 , global_step: 742
- AI-Rank-log  1618942053.087604  eval_accuracy: 0.1954411268234253 , global_step: 743
- AI-Rank-log  1618942096.875235  eval_accuracy: 0.197179913520813 , global_step: 744
- AI-Rank-log  1618942140.7982426  eval_accuracy: 0.1973004788160324 , global_step: 745
- AI-Rank-log  1618942184.5775144  eval_accuracy: 0.19859910011291504 , global_step: 746
- AI-Rank-log  1618942228.5775256  eval_accuracy: 0.19763587415218353 , global_step: 747
- AI-Rank-log  1618942272.5217776  eval_accuracy: 0.19847559928894043 , global_step: 748
- AI-Rank-log  1618942316.5613174  eval_accuracy: 0.19990257918834686 , global_step: 749
- AI-Rank-log  1618942360.5417864  eval_accuracy: 0.19860006868839264 , global_step: 750
- AI-Rank-log  1618942404.4394395  eval_accuracy: 0.20369261503219604 , global_step: 751
- AI-Rank-log  1618942448.4988234  eval_accuracy: 0.20472568273544312 , global_step: 752
- AI-Rank-log  1618942492.4714792  eval_accuracy: 0.20677244663238525 , global_step: 753
- AI-Rank-log  1618942536.3976228  eval_accuracy: 0.20338983833789825 , global_step: 754
- AI-Rank-log  1618942580.4199295  eval_accuracy: 0.20278669893741608 , global_step: 755
- AI-Rank-log  1618942624.3545165  eval_accuracy: 0.20864832401275635 , global_step: 756
- AI-Rank-log  1618942668.357856  eval_accuracy: 0.21035534143447876 , global_step: 757
- AI-Rank-log  1618942712.3570707  eval_accuracy: 0.20785166323184967 , global_step: 758
- AI-Rank-log  1618942756.3172522  eval_accuracy: 0.2101723998785019 , global_step: 759
- AI-Rank-log  1618942800.3682683  eval_accuracy: 0.21043850481510162 , global_step: 760
- AI-Rank-log  1618942844.2915695  eval_accuracy: 0.2128826230764389 , global_step: 761
- AI-Rank-log  1618942888.2770188  eval_accuracy: 0.2088737189769745 , global_step: 762
- AI-Rank-log  1618942932.3066726  eval_accuracy: 0.21042287349700928 , global_step: 763
- AI-Rank-log  1618942976.3108637  eval_accuracy: 0.20978960394859314 , global_step: 764
- AI-Rank-log  1618943020.2493222  eval_accuracy: 0.21105585992336273 , global_step: 765
- AI-Rank-log  1618943064.307522  eval_accuracy: 0.21405504643917084 , global_step: 766
- AI-Rank-log  1618943109.0047884  eval_accuracy: 0.21262381970882416 , global_step: 767
- AI-Rank-log  1618943153.689214  eval_accuracy: 0.21262381970882416 , global_step: 767
- AI-Rank-log  1618943198.8269877  eval_accuracy: 0.21049833297729492 , global_step: 768
- AI-Rank-log  1618943242.7610598  eval_accuracy: 0.2150702178478241 , global_step: 769
- AI-Rank-log  1618943286.7414827  eval_accuracy: 0.21696799993515015 , global_step: 770
- AI-Rank-log  1618943330.7040005  eval_accuracy: 0.2198205143213272 , global_step: 771
- AI-Rank-log  1618943374.6363797  eval_accuracy: 0.22206290066242218 , global_step: 772
- AI-Rank-log  1618943418.5835412  eval_accuracy: 0.22216109931468964 , global_step: 773
- AI-Rank-log  1618943462.5412793  eval_accuracy: 0.22176136076450348 , global_step: 774
- AI-Rank-log  1618943506.5989807  eval_accuracy: 0.22335267066955566 , global_step: 775
- AI-Rank-log  1618943550.5248046  eval_accuracy: 0.2261090725660324 , global_step: 776
- AI-Rank-log  1618943594.5014095  eval_accuracy: 0.22817781567573547 , global_step: 777
- AI-Rank-log  1618943638.5472386  eval_accuracy: 0.22776834666728973 , global_step: 778
- AI-Rank-log  1618943682.4897783  eval_accuracy: 0.2294382005929947 , global_step: 779
- AI-Rank-log  1618943726.4215662  eval_accuracy: 0.22895564138889313 , global_step: 780
- AI-Rank-log  1618943770.5005026  eval_accuracy: 0.2331971377134323 , global_step: 781
- AI-Rank-log  1618943814.4400122  eval_accuracy: 0.23279345035552979 , global_step: 782
- AI-Rank-log  1618943858.510889  eval_accuracy: 0.23344221711158752 , global_step: 783
- AI-Rank-log  1618943902.45716  eval_accuracy: 0.23845981061458588 , global_step: 784
- AI-Rank-log  1618943946.3912866  eval_accuracy: 0.23834210634231567 , global_step: 785
- AI-Rank-log  1618943990.2194254  eval_accuracy: 0.2360353320837021 , global_step: 786
- AI-Rank-log  1618944034.160964  eval_accuracy: 0.23590603470802307 , global_step: 787
- AI-Rank-log  1618944078.1181076  eval_accuracy: 0.23600885272026062 , global_step: 788
- AI-Rank-log  1618944122.1344786  eval_accuracy: 0.2372935265302658 , global_step: 789
- AI-Rank-log  1618944166.0809803  eval_accuracy: 0.24016958475112915 , global_step: 790
- AI-Rank-log  1618944210.1261184  eval_accuracy: 0.23846541345119476 , global_step: 791
- AI-Rank-log  1618944254.192537  eval_accuracy: 0.24033749103546143 , global_step: 792
- AI-Rank-log  1618944306.9767857  eval_accuracy: 0.2430187314748764 , global_step: 793
- AI-Rank-log  1618944350.9179022  eval_accuracy: 0.24775037169456482 , global_step: 794
- AI-Rank-log  1618944394.8940065  eval_accuracy: 0.24617214500904083 , global_step: 795
- AI-Rank-log  1618944438.8202639  eval_accuracy: 0.24739554524421692 , global_step: 796
- AI-Rank-log  1618944482.6065977  eval_accuracy: 0.24324798583984375 , global_step: 797
- AI-Rank-log  1618944526.578709  eval_accuracy: 0.250313401222229 , global_step: 798
- AI-Rank-log  1618944570.491076  eval_accuracy: 0.24998632073402405 , global_step: 799
- AI-Rank-log  1618944614.5290956  eval_accuracy: 0.2462792992591858 , global_step: 800
- AI-Rank-log  1618944658.497761  eval_accuracy: 0.25015926361083984 , global_step: 801
- AI-Rank-log  1618944702.4089072  eval_accuracy: 0.25085848569869995 , global_step: 802
- AI-Rank-log  1618944746.4216926  eval_accuracy: 0.24972015619277954 , global_step: 803
- AI-Rank-log  1618944790.3636084  eval_accuracy: 0.25429999828338623 , global_step: 804
- AI-Rank-log  1618944834.2770743  eval_accuracy: 0.2570774257183075 , global_step: 805
- AI-Rank-log  1618944878.2983985  eval_accuracy: 0.2544385492801666 , global_step: 806
- AI-Rank-log  1618944922.2887244  eval_accuracy: 0.2525739371776581 , global_step: 807
- AI-Rank-log  1618944966.250196  eval_accuracy: 0.2574215531349182 , global_step: 808
- AI-Rank-log  1618945010.196179  eval_accuracy: 0.2578125298023224 , global_step: 809
- AI-Rank-log  1618945054.1245358  eval_accuracy: 0.26024407148361206 , global_step: 810
- AI-Rank-log  1618945098.1275866  eval_accuracy: 0.25806164741516113 , global_step: 811
- AI-Rank-log  1618945142.1496527  eval_accuracy: 0.25766995549201965 , global_step: 812
- AI-Rank-log  1618945186.1175628  eval_accuracy: 0.25950685143470764 , global_step: 813
- AI-Rank-log  1618945230.0806684  eval_accuracy: 0.2632637619972229 , global_step: 814
- AI-Rank-log  1618945274.0521257  eval_accuracy: 0.2579959034919739 , global_step: 815
- AI-Rank-log  1618945318.0054975  eval_accuracy: 0.26461467146873474 , global_step: 816
- AI-Rank-log  1618945361.981902  eval_accuracy: 0.259492427110672 , global_step: 817
- AI-Rank-log  1618945405.9653027  eval_accuracy: 0.2608185410499573 , global_step: 818
- AI-Rank-log  1618945450.0156188  eval_accuracy: 0.26558998227119446 , global_step: 819
- AI-Rank-log  1618945493.961063  eval_accuracy: 0.2657524347305298 , global_step: 820
- AI-Rank-log  1618945537.9079406  eval_accuracy: 0.26158052682876587 , global_step: 821
- AI-Rank-log  1618945581.9439287  eval_accuracy: 0.26620036363601685 , global_step: 822
- AI-Rank-log  1618945625.8947423  eval_accuracy: 0.26707330346107483 , global_step: 823
- AI-Rank-log  1618945669.8088245  eval_accuracy: 0.2628213167190552 , global_step: 824
- AI-Rank-log  1618945713.8049278  eval_accuracy: 0.2683888077735901 , global_step: 825
- AI-Rank-log  1618945757.7702246  eval_accuracy: 0.26612892746925354 , global_step: 826
- AI-Rank-log  1618945801.852553  eval_accuracy: 0.2712171673774719 , global_step: 827
- AI-Rank-log  1618945845.7804997  eval_accuracy: 0.2704537808895111 , global_step: 828
- AI-Rank-log  1618945889.719237  eval_accuracy: 0.2734180688858032 , global_step: 829
- AI-Rank-log  1618945933.7209165  eval_accuracy: 0.2671579420566559 , global_step: 830
- AI-Rank-log  1618945977.6494522  eval_accuracy: 0.2718428671360016 , global_step: 831
- AI-Rank-log  1618946021.6109593  eval_accuracy: 0.2713727355003357 , global_step: 832
- AI-Rank-log  1618946065.6611755  eval_accuracy: 0.26626643538475037 , global_step: 833
- AI-Rank-log  1618946109.5930314  eval_accuracy: 0.27532222867012024 , global_step: 834
- AI-Rank-log  1618946153.5566187  eval_accuracy: 0.2743845582008362 , global_step: 835
- AI-Rank-log  1618946197.5629168  eval_accuracy: 0.26785019040107727 , global_step: 836
- AI-Rank-log  1618946241.4686518  eval_accuracy: 0.27493175864219666 , global_step: 837
- AI-Rank-log  1618946285.4528935  eval_accuracy: 0.27457770705223083 , global_step: 838
- AI-Rank-log  1618946329.3978164  eval_accuracy: 0.27700960636138916 , global_step: 839
- AI-Rank-log  1618946373.3462148  eval_accuracy: 0.2792082130908966 , global_step: 840
- AI-Rank-log  1618946417.371966  eval_accuracy: 0.2805914282798767 , global_step: 841
- AI-Rank-log  1618946461.3261235  eval_accuracy: 0.2810192406177521 , global_step: 842
- AI-Rank-log  1618946506.6369638  eval_accuracy: 0.2823750376701355 , global_step: 843
- AI-Rank-log  1618946551.3696692  eval_accuracy: 0.2813805937767029 , global_step: 844
- AI-Rank-log  1618946596.482925  eval_accuracy: 0.28075936436653137 , global_step: 845
- AI-Rank-log  1618946640.5858128  eval_accuracy: 0.2825053632259369 , global_step: 846
- AI-Rank-log  1618946684.6755338  eval_accuracy: 0.2814546823501587 , global_step: 847
- AI-Rank-log  1618946728.6247337  eval_accuracy: 0.28409841656684875 , global_step: 848
- AI-Rank-log  1618946772.6289585  eval_accuracy: 0.28091883659362793 , global_step: 849
- AI-Rank-log  1618946816.6023655  eval_accuracy: 0.28390732407569885 , global_step: 850
- AI-Rank-log  1618946860.5783887  eval_accuracy: 0.28681713342666626 , global_step: 851
- AI-Rank-log  1618946904.6065416  eval_accuracy: 0.28918588161468506 , global_step: 852
- AI-Rank-log  1618946948.5552282  eval_accuracy: 0.2908763587474823 , global_step: 853
- AI-Rank-log  1618946992.5200775  eval_accuracy: 0.28943920135498047 , global_step: 854
- AI-Rank-log  1618947036.56795  eval_accuracy: 0.2860647737979889 , global_step: 855
- AI-Rank-log  1618947080.5580373  eval_accuracy: 0.2850266098976135 , global_step: 856
- AI-Rank-log  1618947124.5752838  eval_accuracy: 0.28957629203796387 , global_step: 857
- AI-Rank-log  1618947168.5448825  eval_accuracy: 0.2851743698120117 , global_step: 858
- AI-Rank-log  1618947212.6020727  eval_accuracy: 0.28940436244010925 , global_step: 859
- AI-Rank-log  1618947256.6059058  eval_accuracy: 0.2868667244911194 , global_step: 860
- AI-Rank-log  1618947300.564277  eval_accuracy: 0.2912043035030365 , global_step: 861
- AI-Rank-log  1618947344.5801473  eval_accuracy: 0.29190266132354736 , global_step: 862
- AI-Rank-log  1618947388.6014078  eval_accuracy: 0.2942090332508087 , global_step: 863
- AI-Rank-log  1618947432.5893161  eval_accuracy: 0.29551512002944946 , global_step: 864
- AI-Rank-log  1618947476.5434844  eval_accuracy: 0.29438701272010803 , global_step: 865
- AI-Rank-log  1618947520.5306342  eval_accuracy: 0.2957690358161926 , global_step: 866
- AI-Rank-log  1618947564.4709299  eval_accuracy: 0.2948073148727417 , global_step: 867
- AI-Rank-log  1618947608.4998822  eval_accuracy: 0.2947998344898224 , global_step: 868
- AI-Rank-log  1618947652.4247878  eval_accuracy: 0.2944236397743225 , global_step: 869
- AI-Rank-log  1618947696.3458574  eval_accuracy: 0.2998950779438019 , global_step: 870
- AI-Rank-log  1618947740.4071462  eval_accuracy: 0.2950707674026489 , global_step: 871
- AI-Rank-log  1618947784.368822  eval_accuracy: 0.2984093129634857 , global_step: 872
- AI-Rank-log  1618947828.3108876  eval_accuracy: 0.29673367738723755 , global_step: 873
- AI-Rank-log  1618947872.3148494  eval_accuracy: 0.2935197055339813 , global_step: 874
- AI-Rank-log  1618947916.2521381  eval_accuracy: 0.2963080108165741 , global_step: 875
- AI-Rank-log  1618947960.2969031  eval_accuracy: 0.298228919506073 , global_step: 876
- AI-Rank-log  1618948004.246984  eval_accuracy: 0.2995914816856384 , global_step: 877
- AI-Rank-log  1618948048.2033875  eval_accuracy: 0.3017357289791107 , global_step: 878
- AI-Rank-log  1618948092.2330592  eval_accuracy: 0.2986390292644501 , global_step: 879
- AI-Rank-log  1618948136.1898088  eval_accuracy: 0.2998928129673004 , global_step: 880
- AI-Rank-log  1618948180.1239738  eval_accuracy: 0.30239760875701904 , global_step: 881
- AI-Rank-log  1618948224.1263227  eval_accuracy: 0.3029748797416687 , global_step: 882
- AI-Rank-log  1618948268.067207  eval_accuracy: 0.3019793927669525 , global_step: 883
- AI-Rank-log  1618948312.0429032  eval_accuracy: 0.30230140686035156 , global_step: 884
- AI-Rank-log  1618948356.088929  eval_accuracy: 0.30281195044517517 , global_step: 885
- AI-Rank-log  1618948400.011763  eval_accuracy: 0.30592575669288635 , global_step: 886
- AI-Rank-log  1618948443.9319701  eval_accuracy: 0.30467551946640015 , global_step: 887
- AI-Rank-log  1618948487.9619718  eval_accuracy: 0.30353298783302307 , global_step: 888
- AI-Rank-log  1618948531.9214764  eval_accuracy: 0.29998406767845154 , global_step: 889
- AI-Rank-log  1618948575.97226  eval_accuracy: 0.30746927857398987 , global_step: 890
- AI-Rank-log  1618948619.9274282  eval_accuracy: 0.3027397096157074 , global_step: 891
- AI-Rank-log  1618948663.870955  eval_accuracy: 0.3071594834327698 , global_step: 892
- AI-Rank-log  1618948707.9070704  eval_accuracy: 0.30617859959602356 , global_step: 893
- AI-Rank-log  1618948751.952767  eval_accuracy: 0.3076097071170807 , global_step: 894
- AI-Rank-log  1618948795.884476  eval_accuracy: 0.3092360198497772 , global_step: 895
- AI-Rank-log  1618948839.9678361  eval_accuracy: 0.30172911286354065 , global_step: 896
- AI-Rank-log  1618948883.9537864  eval_accuracy: 0.3071146607398987 , global_step: 897
- AI-Rank-log  1618948927.8618767  eval_accuracy: 0.30792301893234253 , global_step: 898
- AI-Rank-log  1618948971.8468058  eval_accuracy: 0.30811357498168945 , global_step: 899
- AI-Rank-log  1618949015.8148458  eval_accuracy: 0.3103271424770355 , global_step: 900
- AI-Rank-log  1618949059.796316  eval_accuracy: 0.31214287877082825 , global_step: 901
- AI-Rank-log  1618949103.760709  eval_accuracy: 0.31285423040390015 , global_step: 902
- AI-Rank-log  1618949147.7169387  eval_accuracy: 0.3124397397041321 , global_step: 903
- AI-Rank-log  1618949191.8137205  eval_accuracy: 0.31363674998283386 , global_step: 904
- AI-Rank-log  1618949235.740587  eval_accuracy: 0.3118138611316681 , global_step: 905
- AI-Rank-log  1618949279.7006214  eval_accuracy: 0.31226953864097595 , global_step: 906
- AI-Rank-log  1618949323.726491  eval_accuracy: 0.31570011377334595 , global_step: 907
- AI-Rank-log  1618949367.6771407  eval_accuracy: 0.3130936920642853 , global_step: 908
- AI-Rank-log  1618949411.6996045  eval_accuracy: 0.31558316946029663 , global_step: 909
- AI-Rank-log  1618949455.7211866  eval_accuracy: 0.3144378960132599 , global_step: 910
- AI-Rank-log  1618949499.6661541  eval_accuracy: 0.31571125984191895 , global_step: 911
- AI-Rank-log  1618949543.6498325  eval_accuracy: 0.3175068795681 , global_step: 912
- AI-Rank-log  1618949587.6367288  eval_accuracy: 0.31685659289360046 , global_step: 913
- AI-Rank-log  1618949631.607848  eval_accuracy: 0.3190276622772217 , global_step: 914
- AI-Rank-log  1618949675.5747666  eval_accuracy: 0.31705576181411743 , global_step: 915
- AI-Rank-log  1618949719.5435753  eval_accuracy: 0.3193749189376831 , global_step: 916
- AI-Rank-log  1618949763.4458122  eval_accuracy: 0.3182600438594818 , global_step: 917
- AI-Rank-log  1618949807.4904976  eval_accuracy: 0.3203034996986389 , global_step: 918
- AI-Rank-log  1618949851.4739547  eval_accuracy: 0.32071545720100403 , global_step: 919
- AI-Rank-log  1618949896.3248763  eval_accuracy: 0.3232131898403168 , global_step: 920
- AI-Rank-log  1618949941.785898  eval_accuracy: 0.32104942202568054 , global_step: 921
- AI-Rank-log  1618949986.0866082  eval_accuracy: 0.3215804398059845 , global_step: 922
- AI-Rank-log  1618950031.1127348  eval_accuracy: 0.3231661021709442 , global_step: 923
- AI-Rank-log  1618950074.8304617  eval_accuracy: 0.3251091539859772 , global_step: 924
- AI-Rank-log  1618950118.7931542  eval_accuracy: 0.3251325488090515 , global_step: 925
- AI-Rank-log  1618950162.8050823  eval_accuracy: 0.32247430086135864 , global_step: 926
- AI-Rank-log  1618950206.750036  eval_accuracy: 0.32567787170410156 , global_step: 927
- AI-Rank-log  1618950250.7044117  eval_accuracy: 0.32498663663864136 , global_step: 928
- AI-Rank-log  1618950294.7653584  eval_accuracy: 0.32698771357536316 , global_step: 929
- AI-Rank-log  1618950338.7183588  eval_accuracy: 0.32608890533447266 , global_step: 930
- AI-Rank-log  1618950382.7579067  eval_accuracy: 0.3281114101409912 , global_step: 931
- AI-Rank-log  1618950426.6946676  eval_accuracy: 0.3257042169570923 , global_step: 932
- AI-Rank-log  1618950470.6144228  eval_accuracy: 0.3263961374759674 , global_step: 933
- AI-Rank-log  1618950514.6164942  eval_accuracy: 0.3284315764904022 , global_step: 934
- AI-Rank-log  1618950558.5596418  eval_accuracy: 0.3293025493621826 , global_step: 935
- AI-Rank-log  1618950602.5232365  eval_accuracy: 0.3303033113479614 , global_step: 936
- AI-Rank-log  1618950646.5548046  eval_accuracy: 0.3310088515281677 , global_step: 937
- AI-Rank-log  1618950690.5339758  eval_accuracy: 0.32958149909973145 , global_step: 938
- AI-Rank-log  1618950734.5330544  eval_accuracy: 0.33237382769584656 , global_step: 939
- AI-Rank-log  1618950778.5118704  eval_accuracy: 0.33240067958831787 , global_step: 940
- AI-Rank-log  1618950822.4210918  eval_accuracy: 0.32860004901885986 , global_step: 941
- AI-Rank-log  1618950866.436178  eval_accuracy: 0.3277050852775574 , global_step: 942
- AI-Rank-log  1618950910.4454944  eval_accuracy: 0.3318537473678589 , global_step: 943
- AI-Rank-log  1618950954.3672464  eval_accuracy: 0.33398357033729553 , global_step: 944
- AI-Rank-log  1618950998.4022927  eval_accuracy: 0.33411628007888794 , global_step: 945
- AI-Rank-log  1618951042.338964  eval_accuracy: 0.33089786767959595 , global_step: 946
- AI-Rank-log  1618951086.2972488  eval_accuracy: 0.33475109934806824 , global_step: 947
- AI-Rank-log  1618951130.313668  eval_accuracy: 0.3325134813785553 , global_step: 948
- AI-Rank-log  1618951174.2478447  eval_accuracy: 0.33699873089790344 , global_step: 949
- AI-Rank-log  1618951218.260169  eval_accuracy: 0.3335185647010803 , global_step: 950
- AI-Rank-log  1618951262.2329848  eval_accuracy: 0.3363916873931885 , global_step: 951
- AI-Rank-log  1618951306.1948757  eval_accuracy: 0.3322906494140625 , global_step: 952
- AI-Rank-log  1618951350.2475002  eval_accuracy: 0.33798909187316895 , global_step: 953
- AI-Rank-log  1618951394.1723888  eval_accuracy: 0.3340407609939575 , global_step: 954
- AI-Rank-log  1618951438.1636803  eval_accuracy: 0.33597588539123535 , global_step: 955
- AI-Rank-log  1618951482.1789854  eval_accuracy: 0.33648285269737244 , global_step: 956
- AI-Rank-log  1618951526.1633146  eval_accuracy: 0.3371667265892029 , global_step: 957
- AI-Rank-log  1618951570.1233938  eval_accuracy: 0.3401951789855957 , global_step: 958
- AI-Rank-log  1618951614.1393692  eval_accuracy: 0.34161898493766785 , global_step: 959
- AI-Rank-log  1618951658.0903695  eval_accuracy: 0.3399934768676758 , global_step: 960
- AI-Rank-log  1618951702.1292217  eval_accuracy: 0.342611700296402 , global_step: 961
- AI-Rank-log  1618951746.098872  eval_accuracy: 0.34081846475601196 , global_step: 962
- AI-Rank-log  1618951790.0363045  eval_accuracy: 0.34157034754753113 , global_step: 963
- AI-Rank-log  1618951834.080831  eval_accuracy: 0.33730626106262207 , global_step: 964
- AI-Rank-log  1618951878.035366  eval_accuracy: 0.3442467153072357 , global_step: 965
- AI-Rank-log  1618951921.9881997  eval_accuracy: 0.34321191906929016 , global_step: 966
- AI-Rank-log  1618951965.9639306  eval_accuracy: 0.34518200159072876 , global_step: 967
- AI-Rank-log  1618952009.9212139  eval_accuracy: 0.34457892179489136 , global_step: 968
- AI-Rank-log  1618952053.856264  eval_accuracy: 0.34314101934432983 , global_step: 969
- AI-Rank-log  1618952097.8012455  eval_accuracy: 0.3449973165988922 , global_step: 970
- AI-Rank-log  1618952141.794381  eval_accuracy: 0.34363430738449097 , global_step: 971
- AI-Rank-log  1618952185.7857547  eval_accuracy: 0.3470964729785919 , global_step: 972
- AI-Rank-log  1618952229.7145758  eval_accuracy: 0.34658873081207275 , global_step: 973
- AI-Rank-log  1618952273.688136  eval_accuracy: 0.34545838832855225 , global_step: 974
- AI-Rank-log  1618952317.7438362  eval_accuracy: 0.3466091454029083 , global_step: 975
- AI-Rank-log  1618952361.7014933  eval_accuracy: 0.34842681884765625 , global_step: 976
- AI-Rank-log  1618952405.684129  eval_accuracy: 0.3520570397377014 , global_step: 977
- AI-Rank-log  1618952449.7446415  eval_accuracy: 0.35152867436408997 , global_step: 978
- AI-Rank-log  1618952493.6984944  eval_accuracy: 0.3494473695755005 , global_step: 979
- AI-Rank-log  1618952537.7357166  eval_accuracy: 0.35134413838386536 , global_step: 980
- AI-Rank-log  1618952581.6817737  eval_accuracy: 0.3507554233074188 , global_step: 981
- AI-Rank-log  1618952625.6284266  eval_accuracy: 0.3521472215652466 , global_step: 982
- AI-Rank-log  1618952669.6702611  eval_accuracy: 0.3519043028354645 , global_step: 983
- AI-Rank-log  1618952713.6151078  eval_accuracy: 0.3521150052547455 , global_step: 984
- AI-Rank-log  1618952757.558553  eval_accuracy: 0.35266226530075073 , global_step: 985
- AI-Rank-log  1618952801.593056  eval_accuracy: 0.3537807762622833 , global_step: 986
- AI-Rank-log  1618952845.5195084  eval_accuracy: 0.3546582758426666 , global_step: 987
- AI-Rank-log  1618952889.486976  eval_accuracy: 0.3554416298866272 , global_step: 988
- AI-Rank-log  1618952933.5064716  eval_accuracy: 0.3568514585494995 , global_step: 989
- AI-Rank-log  1618952977.4887667  eval_accuracy: 0.35545432567596436 , global_step: 990
- AI-Rank-log  1618953021.4700816  eval_accuracy: 0.3568134903907776 , global_step: 991
- AI-Rank-log  1618953065.4512181  eval_accuracy: 0.3580741882324219 , global_step: 992
- AI-Rank-log  1618953118.3920143  eval_accuracy: 0.35927221179008484 , global_step: 993
- AI-Rank-log  1618953162.4378064  eval_accuracy: 0.36028945446014404 , global_step: 994
- AI-Rank-log  1618953206.4015865  eval_accuracy: 0.3615124225616455 , global_step: 995
- AI-Rank-log  1618953250.3520436  eval_accuracy: 0.35826578736305237 , global_step: 996
- AI-Rank-log  1618953294.365696  eval_accuracy: 0.3611451983451843 , global_step: 997
- AI-Rank-log  1618953339.6572378  eval_accuracy: 0.3598928153514862 , global_step: 998
- AI-Rank-log  1618953384.3565283  eval_accuracy: 0.36246323585510254 , global_step: 999
- AI-Rank-log  1618953429.609618  eval_accuracy: 0.36261412501335144 , global_step: 1000
- AI-Rank-log  1618953473.8456173  eval_accuracy: 0.361268550157547 , global_step: 1001
- AI-Rank-log  1618953517.8910184  eval_accuracy: 0.36455100774765015 , global_step: 1002
- AI-Rank-log  1618953561.83467  eval_accuracy: 0.3657505214214325 , global_step: 1003
- AI-Rank-log  1618953605.8212292  eval_accuracy: 0.36608555912971497 , global_step: 1004
- AI-Rank-log  1618953649.8091073  eval_accuracy: 0.3677918612957001 , global_step: 1005
- AI-Rank-log  1618953693.7623532  eval_accuracy: 0.36638525128364563 , global_step: 1006
- AI-Rank-log  1618953737.6954255  eval_accuracy: 0.3695259094238281 , global_step: 1007
- AI-Rank-log  1618953781.7242382  eval_accuracy: 0.3692031502723694 , global_step: 1008
- AI-Rank-log  1618953825.6584952  eval_accuracy: 0.3705251216888428 , global_step: 1009
- AI-Rank-log  1618953869.5860405  eval_accuracy: 0.365846186876297 , global_step: 1010
- AI-Rank-log  1618953913.5966475  eval_accuracy: 0.36944302916526794 , global_step: 1011
- AI-Rank-log  1618953957.5614915  eval_accuracy: 0.37194791436195374 , global_step: 1012
- AI-Rank-log  1618954001.6293478  eval_accuracy: 0.3720867335796356 , global_step: 1013

yq01-sys-hic-k8s-v100-box-a225-0804:34467:34531 [0] misc/ibvwrap.cc:220 NCCL WARN Call to ibv_get_async_event failed
- AI-Rank-log  1618954045.5815  eval_accuracy: 0.37494465708732605 , global_step: 1014
- AI-Rank-log  1618954089.5662708  eval_accuracy: 0.370669424533844 , global_step: 1015
- AI-Rank-log  1618954133.560225  eval_accuracy: 0.3764326274394989 , global_step: 1016
- AI-Rank-log  1618954177.6015658  eval_accuracy: 0.37626370787620544 , global_step: 1017
- AI-Rank-log  1618954221.5324707  eval_accuracy: 0.3781338334083557 , global_step: 1018
- AI-Rank-log  1618954265.5443225  eval_accuracy: 0.37877655029296875 , global_step: 1019
- AI-Rank-log  1618954309.4443965  eval_accuracy: 0.3778141140937805 , global_step: 1020
- AI-Rank-log  1618954353.4762688  eval_accuracy: 0.37866899371147156 , global_step: 1021
- AI-Rank-log  1618954397.4010615  eval_accuracy: 0.38062164187431335 , global_step: 1022
- AI-Rank-log  1618954441.3338041  eval_accuracy: 0.38476064801216125 , global_step: 1023
- AI-Rank-log  1618954485.3677018  eval_accuracy: 0.38165533542633057 , global_step: 1024
- AI-Rank-log  1618954529.3126278  eval_accuracy: 0.3829883635044098 , global_step: 1025
- AI-Rank-log  1618954573.2711096  eval_accuracy: 0.3845096230506897 , global_step: 1026
- AI-Rank-log  1618954617.2954223  eval_accuracy: 0.38280534744262695 , global_step: 1027
- AI-Rank-log  1618954661.1841261  eval_accuracy: 0.3865305483341217 , global_step: 1028
- AI-Rank-log  1618954705.2281685  eval_accuracy: 0.3869609534740448 , global_step: 1029
- AI-Rank-log  1618954749.1960437  eval_accuracy: 0.3869568705558777 , global_step: 1030
- AI-Rank-log  1618954793.0966365  eval_accuracy: 0.3871857821941376 , global_step: 1031
- AI-Rank-log  1618954837.1377614  eval_accuracy: 0.3894105553627014 , global_step: 1032
- AI-Rank-log  1618954881.0674376  eval_accuracy: 0.39139366149902344 , global_step: 1033
- AI-Rank-log  1618954925.003419  eval_accuracy: 0.38953688740730286 , global_step: 1034
- AI-Rank-log  1618954969.024335  eval_accuracy: 0.39089664816856384 , global_step: 1035
- AI-Rank-log  1618955012.9598725  eval_accuracy: 0.387834370136261 , global_step: 1036
- AI-Rank-log  1618955056.8771546  eval_accuracy: 0.39052149653434753 , global_step: 1037
- AI-Rank-log  1618955100.9209754  eval_accuracy: 0.3933286666870117 , global_step: 1038
- AI-Rank-log  1618955144.8640044  eval_accuracy: 0.3914422392845154 , global_step: 1039
- AI-Rank-log  1618955188.797809  eval_accuracy: 0.3911310136318207 , global_step: 1040
- AI-Rank-log  1618955232.7308679  eval_accuracy: 0.39305949211120605 , global_step: 1041
- AI-Rank-log  1618955276.6657617  eval_accuracy: 0.39387068152427673 , global_step: 1042
- AI-Rank-log  1618955320.660568  eval_accuracy: 0.39420679211616516 , global_step: 1043
- AI-Rank-log  1618955364.6407437  eval_accuracy: 0.3946945071220398 , global_step: 1044
- AI-Rank-log  1618955408.5881248  eval_accuracy: 0.3950057029724121 , global_step: 1045
- AI-Rank-log  1618955452.5670052  eval_accuracy: 0.39705342054367065 , global_step: 1046
- AI-Rank-log  1618955496.4886446  eval_accuracy: 0.39755502343177795 , global_step: 1047
- AI-Rank-log  1618955540.390732  eval_accuracy: 0.3975290060043335 , global_step: 1048
- AI-Rank-log  1618955584.3809404  eval_accuracy: 0.39961695671081543 , global_step: 1049
- AI-Rank-log  1618955628.3171682  eval_accuracy: 0.3987707793712616 , global_step: 1050
- AI-Rank-log  1618955672.3165102  eval_accuracy: 0.3994606137275696 , global_step: 1051
- AI-Rank-log  1618955716.2464154  eval_accuracy: 0.39836326241493225 , global_step: 1052
- AI-Rank-log  1618955760.21411  eval_accuracy: 0.4013250470161438 , global_step: 1053
- AI-Rank-log  1618955804.199523  eval_accuracy: 0.39941638708114624 , global_step: 1054
- AI-Rank-log  1618955848.1055958  eval_accuracy: 0.4019056260585785 , global_step: 1055
- AI-Rank-log  1618955892.0877712  eval_accuracy: 0.40229591727256775 , global_step: 1056
- AI-Rank-log  1618955936.2072015  eval_accuracy: 0.4026462435722351 , global_step: 1057
- AI-Rank-log  1618955980.138892  eval_accuracy: 0.4022237956523895 , global_step: 1058
- AI-Rank-log  1618956024.1235352  eval_accuracy: 0.402964323759079 , global_step: 1059
- AI-Rank-log  1618956068.1272595  eval_accuracy: 0.40011006593704224 , global_step: 1060
- AI-Rank-log  1618956112.1106992  eval_accuracy: 0.40414562821388245 , global_step: 1061
- AI-Rank-log  1618956156.073344  eval_accuracy: 0.4053352177143097 , global_step: 1062
- AI-Rank-log  1618956200.062272  eval_accuracy: 0.4051673710346222 , global_step: 1063
- AI-Rank-log  1618956244.0139244  eval_accuracy: 0.4040980339050293 , global_step: 1064
- AI-Rank-log  1618956288.0341895  eval_accuracy: 0.4065006673336029 , global_step: 1065
- AI-Rank-log  1618956331.9633496  eval_accuracy: 0.4079814553260803 , global_step: 1066
- AI-Rank-log  1618956375.922862  eval_accuracy: 0.40567201375961304 , global_step: 1067
- AI-Rank-log  1618956419.9142299  eval_accuracy: 0.40780743956565857 , global_step: 1068
- AI-Rank-log  1618956463.8529468  eval_accuracy: 0.4086346924304962 , global_step: 1069
- AI-Rank-log  1618956507.7721832  eval_accuracy: 0.40827539563179016 , global_step: 1070
- AI-Rank-log  1618956551.7877145  eval_accuracy: 0.4076584577560425 , global_step: 1071
- AI-Rank-log  1618956595.70877  eval_accuracy: 0.4106219708919525 , global_step: 1072
- AI-Rank-log  1618956639.7434196  eval_accuracy: 0.4101771116256714 , global_step: 1073
- AI-Rank-log  1618956683.6587253  eval_accuracy: 0.41036614775657654 , global_step: 1074
- AI-Rank-log  1618956729.0767848  eval_accuracy: 0.41097885370254517 , global_step: 1075
- AI-Rank-log  1618956774.5797896  eval_accuracy: 0.40853407979011536 , global_step: 1076
- AI-Rank-log  1618956818.7562814  eval_accuracy: 0.41074925661087036 , global_step: 1077
- AI-Rank-log  1618956864.0005615  eval_accuracy: 0.41130590438842773 , global_step: 1078
- AI-Rank-log  1618956908.1347902  eval_accuracy: 0.4119553565979004 , global_step: 1079
- AI-Rank-log  1618956952.0694385  eval_accuracy: 0.41115665435791016 , global_step: 1080
- AI-Rank-log  1618956996.0338268  eval_accuracy: 0.41297200322151184 , global_step: 1081
- AI-Rank-log  1618957040.0642383  eval_accuracy: 0.41246145963668823 , global_step: 1082
- AI-Rank-log  1618957083.9661424  eval_accuracy: 0.4126209020614624 , global_step: 1083
- AI-Rank-log  1618957128.0058517  eval_accuracy: 0.41237419843673706 , global_step: 1084
- AI-Rank-log  1618957171.9271877  eval_accuracy: 0.4138893187046051 , global_step: 1085
- AI-Rank-log  1618957215.879533  eval_accuracy: 0.414414644241333 , global_step: 1086
- AI-Rank-log  1618957259.868726  eval_accuracy: 0.4164923131465912 , global_step: 1087
- AI-Rank-log  1618957303.8416555  eval_accuracy: 0.4123917520046234 , global_step: 1088
- AI-Rank-log  1618957347.74357  eval_accuracy: 0.4161512553691864 , global_step: 1089
- AI-Rank-log  1618957391.7518141  eval_accuracy: 0.41855931282043457 , global_step: 1090
- AI-Rank-log  1618957435.7265887  eval_accuracy: 0.41636955738067627 , global_step: 1091
- AI-Rank-log  1618957479.7169392  eval_accuracy: 0.41619977355003357 , global_step: 1092
- AI-Rank-log  1618957523.721787  eval_accuracy: 0.41822072863578796 , global_step: 1093
- AI-Rank-log  1618957567.705885  eval_accuracy: 0.41870516538619995 , global_step: 1094
- AI-Rank-log  1618957611.6847303  eval_accuracy: 0.41883230209350586 , global_step: 1095
- AI-Rank-log  1618957655.6692982  eval_accuracy: 0.42212966084480286 , global_step: 1096
- AI-Rank-log  1618957699.5899017  eval_accuracy: 0.4210319221019745 , global_step: 1097
- AI-Rank-log  1618957743.5846205  eval_accuracy: 0.42007479071617126 , global_step: 1098
- AI-Rank-log  1618957787.6066458  eval_accuracy: 0.42000189423561096 , global_step: 1099
- AI-Rank-log  1618957831.5380578  eval_accuracy: 0.41930052638053894 , global_step: 1100
- AI-Rank-log  1618957875.562166  eval_accuracy: 0.42140430212020874 , global_step: 1101
- AI-Rank-log  1618957919.5535524  eval_accuracy: 0.4221886098384857 , global_step: 1102
- AI-Rank-log  1618957963.5291173  eval_accuracy: 0.4223564565181732 , global_step: 1103
- AI-Rank-log  1618958007.4785438  eval_accuracy: 0.42201900482177734 , global_step: 1104
- AI-Rank-log  1618958051.4877439  eval_accuracy: 0.42336657643318176 , global_step: 1105
- AI-Rank-log  1618958095.5239758  eval_accuracy: 0.4213106334209442 , global_step: 1106
- AI-Rank-log  1618958139.4255998  eval_accuracy: 0.42433154582977295 , global_step: 1107
- AI-Rank-log  1618958183.4162946  eval_accuracy: 0.42294105887413025 , global_step: 1108
- AI-Rank-log  1618958227.399197  eval_accuracy: 0.42492061853408813 , global_step: 1109
- AI-Rank-log  1618958271.3487058  eval_accuracy: 0.42452144622802734 , global_step: 1110
- AI-Rank-log  1618958315.287653  eval_accuracy: 0.4248705208301544 , global_step: 1111
- AI-Rank-log  1618958359.288101  eval_accuracy: 0.42424651980400085 , global_step: 1112
- AI-Rank-log  1618958403.229383  eval_accuracy: 0.42424091696739197 , global_step: 1113
- AI-Rank-log  1618958447.2505457  eval_accuracy: 0.4269590675830841 , global_step: 1114
- AI-Rank-log  1618958491.1903033  eval_accuracy: 0.4287252724170685 , global_step: 1115
- AI-Rank-log  1618958535.143156  eval_accuracy: 0.42805618047714233 , global_step: 1116
- AI-Rank-log  1618958579.1741245  eval_accuracy: 0.4267518222332001 , global_step: 1117
- AI-Rank-log  1618958623.11438  eval_accuracy: 0.4284723401069641 , global_step: 1118
- AI-Rank-log  1618958667.063113  eval_accuracy: 0.4291224479675293 , global_step: 1119
- AI-Rank-log  1618958711.0333388  eval_accuracy: 0.4301774799823761 , global_step: 1120
- AI-Rank-log  1618958754.9604285  eval_accuracy: 0.42885443568229675 , global_step: 1121
- AI-Rank-log  1618958799.023814  eval_accuracy: 0.42709842324256897 , global_step: 1122
- AI-Rank-log  1618958842.9565797  eval_accuracy: 0.4291509985923767 , global_step: 1123
- AI-Rank-log  1618958886.869825  eval_accuracy: 0.4284139573574066 , global_step: 1124
- AI-Rank-log  1618958930.8435864  eval_accuracy: 0.42852312326431274 , global_step: 1125
- AI-Rank-log  1618958974.7851906  eval_accuracy: 0.43117162585258484 , global_step: 1126
- AI-Rank-log  1618959018.7111707  eval_accuracy: 0.4295593798160553 , global_step: 1127
- AI-Rank-log  1618959062.719199  eval_accuracy: 0.43027883768081665 , global_step: 1128
- AI-Rank-log  1618959106.6712592  eval_accuracy: 0.4304203987121582 , global_step: 1129
- AI-Rank-log  1618959150.6101542  eval_accuracy: 0.4334145486354828 , global_step: 1130
- AI-Rank-log  1618959194.6332042  eval_accuracy: 0.4332197308540344 , global_step: 1131
- AI-Rank-log  1618959238.5384507  eval_accuracy: 0.43487244844436646 , global_step: 1132
- AI-Rank-log  1618959282.499256  eval_accuracy: 0.4339190423488617 , global_step: 1133
- AI-Rank-log  1618959326.508049  eval_accuracy: 0.4341878294944763 , global_step: 1134
- AI-Rank-log  1618959370.4231527  eval_accuracy: 0.43665796518325806 , global_step: 1135
- AI-Rank-log  1618959414.4174404  eval_accuracy: 0.4355909824371338 , global_step: 1136
- AI-Rank-log  1618959458.3345392  eval_accuracy: 0.4341510832309723 , global_step: 1137
- AI-Rank-log  1618959502.2339966  eval_accuracy: 0.4327121078968048 , global_step: 1138
- AI-Rank-log  1618959546.2756658  eval_accuracy: 0.4336729347705841 , global_step: 1139
- AI-Rank-log  1618959590.192538  eval_accuracy: 0.4343901574611664 , global_step: 1140
- AI-Rank-log  1618959634.2109985  eval_accuracy: 0.43581733107566833 , global_step: 1141
- AI-Rank-log  1618959678.1625905  eval_accuracy: 0.437695175409317 , global_step: 1142
- AI-Rank-log  1618959722.131387  eval_accuracy: 0.4363898038864136 , global_step: 1143
- AI-Rank-log  1618959766.1263175  eval_accuracy: 0.4387185573577881 , global_step: 1144
- AI-Rank-log  1618959810.0990715  eval_accuracy: 0.44049960374832153 , global_step: 1145
- AI-Rank-log  1618959854.0096128  eval_accuracy: 0.440197229385376 , global_step: 1146
- AI-Rank-log  1618959898.0073118  eval_accuracy: 0.44077709317207336 , global_step: 1147
- AI-Rank-log  1618959941.9901464  eval_accuracy: 0.4395318925380707 , global_step: 1148
- AI-Rank-log  1618959985.9047043  eval_accuracy: 0.4388287365436554 , global_step: 1149
- AI-Rank-log  1618960029.857408  eval_accuracy: 0.4370533525943756 , global_step: 1150
- AI-Rank-log  1618960073.8759928  eval_accuracy: 0.4415084719657898 , global_step: 1151
- AI-Rank-log  1618960118.1202447  eval_accuracy: 0.43999746441841125 , global_step: 1152
- AI-Rank-log  1618960162.5747056  eval_accuracy: 0.4383179545402527 , global_step: 1153
- AI-Rank-log  1618960207.4464557  eval_accuracy: 0.441995769739151 , global_step: 1154
- AI-Rank-log  1618960252.259799  eval_accuracy: 0.44119471311569214 , global_step: 1155
- AI-Rank-log  1618960297.3066916  eval_accuracy: 0.4411627948284149 , global_step: 1156
- AI-Rank-log  1618960341.2448382  eval_accuracy: 0.4414352774620056 , global_step: 1157
- AI-Rank-log  1618960385.2260027  eval_accuracy: 0.4435805678367615 , global_step: 1158
- AI-Rank-log  1618960429.178697  eval_accuracy: 0.4429779648780823 , global_step: 1159
- AI-Rank-log  1618960473.1698182  eval_accuracy: 0.4428612291812897 , global_step: 1160
- AI-Rank-log  1618960517.1856284  eval_accuracy: 0.4438685178756714 , global_step: 1161
- AI-Rank-log  1618960561.159961  eval_accuracy: 0.44279417395591736 , global_step: 1162
- AI-Rank-log  1618960605.228343  eval_accuracy: 0.4435393512248993 , global_step: 1163
- AI-Rank-log  1618960649.1021223  eval_accuracy: 0.447307825088501 , global_step: 1164
- AI-Rank-log  1618960693.0627909  eval_accuracy: 0.4457991123199463 , global_step: 1165
- AI-Rank-log  1618960737.1050603  eval_accuracy: 0.4471197724342346 , global_step: 1166
- AI-Rank-log  1618960781.0265067  eval_accuracy: 0.44666963815689087 , global_step: 1167
- AI-Rank-log  1618960824.998521  eval_accuracy: 0.4474444091320038 , global_step: 1168
- AI-Rank-log  1618960869.0693839  eval_accuracy: 0.44519367814064026 , global_step: 1169
- AI-Rank-log  1618960912.9810064  eval_accuracy: 0.44692787528038025 , global_step: 1170
- AI-Rank-log  1618960956.9921002  eval_accuracy: 0.4478369355201721 , global_step: 1171
- AI-Rank-log  1618961001.0041673  eval_accuracy: 0.4464641213417053 , global_step: 1172
- AI-Rank-log  1618961044.9343424  eval_accuracy: 0.4474201202392578 , global_step: 1173
- AI-Rank-log  1618961088.974021  eval_accuracy: 0.44836798310279846 , global_step: 1174
- AI-Rank-log  1618961132.9240963  eval_accuracy: 0.44977888464927673 , global_step: 1175
- AI-Rank-log  1618961176.8793259  eval_accuracy: 0.4497361183166504 , global_step: 1176
- AI-Rank-log  1618961220.980517  eval_accuracy: 0.4494570791721344 , global_step: 1177
- AI-Rank-log  1618961264.9134982  eval_accuracy: 0.4502154290676117 , global_step: 1178
- AI-Rank-log  1618961308.833659  eval_accuracy: 0.45014169812202454 , global_step: 1179
- AI-Rank-log  1618961352.851387  eval_accuracy: 0.4505214989185333 , global_step: 1180
- AI-Rank-log  1618961396.7755158  eval_accuracy: 0.4514548182487488 , global_step: 1181
- AI-Rank-log  1618961440.8204613  eval_accuracy: 0.4513808786869049 , global_step: 1182
- AI-Rank-log  1618961484.8102133  eval_accuracy: 0.452825129032135 , global_step: 1183
- AI-Rank-log  1618961528.743299  eval_accuracy: 0.4528294801712036 , global_step: 1184
- AI-Rank-log  1618961572.7018783  eval_accuracy: 0.4534715414047241 , global_step: 1185
- AI-Rank-log  1618961616.6193118  eval_accuracy: 0.45120832324028015 , global_step: 1186
- AI-Rank-log  1618961660.5462868  eval_accuracy: 0.4538477063179016 , global_step: 1187
- AI-Rank-log  1618961704.6134717  eval_accuracy: 0.45479556918144226 , global_step: 1188
- AI-Rank-log  1618961748.562307  eval_accuracy: 0.4544256031513214 , global_step: 1189
- AI-Rank-log  1618961792.4759743  eval_accuracy: 0.45569053292274475 , global_step: 1190
- AI-Rank-log  1618961836.4608183  eval_accuracy: 0.452594131231308 , global_step: 1191
- AI-Rank-log  1618961880.4521594  eval_accuracy: 0.4551545977592468 , global_step: 1192
- AI-Rank-log  1618961933.7286298  eval_accuracy: 0.4532306492328644 , global_step: 1193
- AI-Rank-log  1618961977.6564264  eval_accuracy: 0.4537893235683441 , global_step: 1194
- AI-Rank-log  1618962021.6147852  eval_accuracy: 0.4561060070991516 , global_step: 1195
- AI-Rank-log  1618962065.5687644  eval_accuracy: 0.45597970485687256 , global_step: 1196
- AI-Rank-log  1618962109.4996486  eval_accuracy: 0.4552686810493469 , global_step: 1197
- AI-Rank-log  1618962153.4921257  eval_accuracy: 0.45835310220718384 , global_step: 1198
- AI-Rank-log  1618962197.506359  eval_accuracy: 0.4560835361480713 , global_step: 1199
- AI-Rank-log  1618962241.494456  eval_accuracy: 0.4571077823638916 , global_step: 1200
- AI-Rank-log  1618962285.3895848  eval_accuracy: 0.4585832953453064 , global_step: 1201
- AI-Rank-log  1618962329.3972516  eval_accuracy: 0.4563961625099182 , global_step: 1202
- AI-Rank-log  1618962373.4026132  eval_accuracy: 0.45952531695365906 , global_step: 1203
- AI-Rank-log  1618962417.4557023  eval_accuracy: 0.45952650904655457 , global_step: 1204
- AI-Rank-log  1618962461.3453772  eval_accuracy: 0.4615713059902191 , global_step: 1205
- AI-Rank-log  1618962505.3067918  eval_accuracy: 0.4613959789276123 , global_step: 1206
- AI-Rank-log  1618962549.312813  eval_accuracy: 0.46259260177612305 , global_step: 1207
- AI-Rank-log  1618962593.222989  eval_accuracy: 0.46080589294433594 , global_step: 1208
- AI-Rank-log  1618962637.1610947  eval_accuracy: 0.4622635841369629 , global_step: 1209
- AI-Rank-log  1618962681.130568  eval_accuracy: 0.46000418066978455 , global_step: 1210
- AI-Rank-log  1618962725.0365744  eval_accuracy: 0.46310320496559143 , global_step: 1211
- AI-Rank-log  1618962769.024447  eval_accuracy: 0.46015501022338867 , global_step: 1212
- AI-Rank-log  1618962813.032122  eval_accuracy: 0.46358421444892883 , global_step: 1213
- AI-Rank-log  1618962856.993622  eval_accuracy: 0.46323445439338684 , global_step: 1214
- AI-Rank-log  1618962901.001176  eval_accuracy: 0.4621655344963074 , global_step: 1215
- AI-Rank-log  1618962944.9299169  eval_accuracy: 0.4614294767379761 , global_step: 1216
- AI-Rank-log  1618962988.8594973  eval_accuracy: 0.46418365836143494 , global_step: 1217
- AI-Rank-log  1618963032.8629365  eval_accuracy: 0.4631432592868805 , global_step: 1218
- AI-Rank-log  1618963076.7760525  eval_accuracy: 0.46381253004074097 , global_step: 1219
- AI-Rank-log  1618963120.7397223  eval_accuracy: 0.46468156576156616 , global_step: 1220

yq01-sys-hic-k8s-v100-box-a225-0804:34466:34532 [0] misc/ibvwrap.cc:220 NCCL WARN Call to ibv_get_async_event failed
- AI-Rank-log  1618963164.737109  eval_accuracy: 0.4641493260860443 , global_step: 1221
- AI-Rank-log  1618963208.6434915  eval_accuracy: 0.46289461851119995 , global_step: 1222
- AI-Rank-log  1618963252.6130548  eval_accuracy: 0.4660641849040985 , global_step: 1223
- AI-Rank-log  1618963296.688433  eval_accuracy: 0.4649333655834198 , global_step: 1224
- AI-Rank-log  1618963340.645003  eval_accuracy: 0.46574485301971436 , global_step: 1225
- AI-Rank-log  1618963384.687524  eval_accuracy: 0.4658185541629791 , global_step: 1226
- AI-Rank-log  1618963428.6116526  eval_accuracy: 0.4671880304813385 , global_step: 1227
- AI-Rank-log  1618963472.5032563  eval_accuracy: 0.4672158360481262 , global_step: 1228
- AI-Rank-log  1618963516.533807  eval_accuracy: 0.4666200578212738 , global_step: 1229
- AI-Rank-log  1618963561.2503746  eval_accuracy: 0.465925008058548 , global_step: 1230
- AI-Rank-log  1618963605.8150692  eval_accuracy: 0.46893417835235596 , global_step: 1231
- AI-Rank-log  1618963650.601116  eval_accuracy: 0.46723347902297974 , global_step: 1232
- AI-Rank-log  1618963695.6847556  eval_accuracy: 0.4668751358985901 , global_step: 1233
- AI-Rank-log  1618963740.0475974  eval_accuracy: 0.46907687187194824 , global_step: 1234
- AI-Rank-log  1618963784.0223322  eval_accuracy: 0.4688270688056946 , global_step: 1235
- AI-Rank-log  1618963827.9680731  eval_accuracy: 0.4694657325744629 , global_step: 1236
- AI-Rank-log  1618963871.9475563  eval_accuracy: 0.4698364734649658 , global_step: 1237
- AI-Rank-log  1618963915.8999941  eval_accuracy: 0.4694359600543976 , global_step: 1238
- AI-Rank-log  1618963959.8560352  eval_accuracy: 0.46960315108299255 , global_step: 1239
- AI-Rank-log  1618964003.836597  eval_accuracy: 0.47037920355796814 , global_step: 1240
- AI-Rank-log  1618964047.8132617  eval_accuracy: 0.47087687253952026 , global_step: 1241
- AI-Rank-log  1618964091.7200747  eval_accuracy: 0.4718257486820221 , global_step: 1242
- AI-Rank-log  1618964135.6855922  eval_accuracy: 0.47228699922561646 , global_step: 1243
- AI-Rank-log  1618964179.6454349  eval_accuracy: 0.4737689793109894 , global_step: 1244
- AI-Rank-log  1618964223.5763247  eval_accuracy: 0.4732823967933655 , global_step: 1245
- AI-Rank-log  1618964267.5967321  eval_accuracy: 0.4736146628856659 , global_step: 1246
- AI-Rank-log  1618964311.4933279  eval_accuracy: 0.4757407307624817 , global_step: 1247
- AI-Rank-log  1618964355.384324  eval_accuracy: 0.47581747174263 , global_step: 1248
- AI-Rank-log  1618964399.2988715  eval_accuracy: 0.47399333119392395 , global_step: 1249
- AI-Rank-log  1618964443.20643  eval_accuracy: 0.4700741767883301 , global_step: 1250
- AI-Rank-log  1618964487.1324918  eval_accuracy: 0.4722025692462921 , global_step: 1251
- AI-Rank-log  1618964531.0908203  eval_accuracy: 0.4766447842121124 , global_step: 1252
- AI-Rank-log  1618964575.0336976  eval_accuracy: 0.47622954845428467 , global_step: 1253
- AI-Rank-log  1618964618.9577544  eval_accuracy: 0.4747488498687744 , global_step: 1254
- AI-Rank-log  1618964662.878116  eval_accuracy: 0.4770348370075226 , global_step: 1255
- AI-Rank-log  1618964706.8041248  eval_accuracy: 0.4735116958618164 , global_step: 1256
- AI-Rank-log  1618964750.7166984  eval_accuracy: 0.4740228056907654 , global_step: 1257
- AI-Rank-log  1618964794.7137208  eval_accuracy: 0.4774959683418274 , global_step: 1258
- AI-Rank-log  1618964838.6407666  eval_accuracy: 0.47560593485832214 , global_step: 1259
- AI-Rank-log  1618964882.5977843  eval_accuracy: 0.47758910059928894 , global_step: 1260
- AI-Rank-log  1618964926.5312827  eval_accuracy: 0.4771786332130432 , global_step: 1261
- AI-Rank-log  1618964970.4941053  eval_accuracy: 0.47840794920921326 , global_step: 1262
- AI-Rank-log  1618965014.4128175  eval_accuracy: 0.4778899848461151 , global_step: 1263
- AI-Rank-log  1618965058.3318896  eval_accuracy: 0.47892236709594727 , global_step: 1264
- AI-Rank-log  1618965102.300675  eval_accuracy: 0.4770830571651459 , global_step: 1265
- AI-Rank-log  1618965146.2241552  eval_accuracy: 0.47878772020339966 , global_step: 1266
- AI-Rank-log  1618965190.1612341  eval_accuracy: 0.4777609407901764 , global_step: 1267
- AI-Rank-log  1618965234.1487832  eval_accuracy: 0.48060423135757446 , global_step: 1268
- AI-Rank-log  1618965278.021884  eval_accuracy: 0.4799532890319824 , global_step: 1269
- AI-Rank-log  1618965321.9755142  eval_accuracy: 0.47980180382728577 , global_step: 1270
- AI-Rank-log  1618965365.9396684  eval_accuracy: 0.48174911737442017 , global_step: 1271
- AI-Rank-log  1618965409.8775058  eval_accuracy: 0.4811584949493408 , global_step: 1272
- AI-Rank-log  1618965453.838256  eval_accuracy: 0.4803673028945923 , global_step: 1273
- AI-Rank-log  1618965497.7220974  eval_accuracy: 0.4802691638469696 , global_step: 1274
- AI-Rank-log  1618965541.6806166  eval_accuracy: 0.4801837205886841 , global_step: 1275
- AI-Rank-log  1618965585.6504133  eval_accuracy: 0.4820918142795563 , global_step: 1276
- AI-Rank-log  1618965629.5964751  eval_accuracy: 0.47986140847206116 , global_step: 1277
- AI-Rank-log  1618965673.4696245  eval_accuracy: 0.48243626952171326 , global_step: 1278
- AI-Rank-log  1618965717.280519  eval_accuracy: 0.4828885793685913 , global_step: 1279
- AI-Rank-log  1618965761.1420012  eval_accuracy: 0.48466724157333374 , global_step: 1280
- AI-Rank-log  1618965805.0742931  eval_accuracy: 0.4831225574016571 , global_step: 1281
- AI-Rank-log  1618965849.0630505  eval_accuracy: 0.4785021245479584 , global_step: 1282
- AI-Rank-log  1618965892.9851065  eval_accuracy: 0.4849095344543457 , global_step: 1283
- AI-Rank-log  1618965936.9176407  eval_accuracy: 0.4844130575656891 , global_step: 1284
- AI-Rank-log  1618965980.8418455  eval_accuracy: 0.4811432361602783 , global_step: 1285
- AI-Rank-log  1618966024.7505968  eval_accuracy: 0.4840214252471924 , global_step: 1286
- AI-Rank-log  1618966068.716657  eval_accuracy: 0.48308271169662476 , global_step: 1287
- AI-Rank-log  1618966112.6525857  eval_accuracy: 0.48452553153038025 , global_step: 1288
- AI-Rank-log  1618966156.5628004  eval_accuracy: 0.4845612049102783 , global_step: 1289
- AI-Rank-log  1618966200.5777547  eval_accuracy: 0.48518046736717224 , global_step: 1290
- AI-Rank-log  1618966244.483131  eval_accuracy: 0.48447170853614807 , global_step: 1291
- AI-Rank-log  1618966288.4251053  eval_accuracy: 0.4856606125831604 , global_step: 1292
- AI-Rank-log  1618966332.4177234  eval_accuracy: 0.4862636923789978 , global_step: 1293
- AI-Rank-log  1618966376.336384  eval_accuracy: 0.4872848689556122 , global_step: 1294
- AI-Rank-log  1618966420.2631288  eval_accuracy: 0.48496702313423157 , global_step: 1295
- AI-Rank-log  1618966464.291113  eval_accuracy: 0.48649489879608154 , global_step: 1296
- AI-Rank-log  1618966508.1719005  eval_accuracy: 0.4884626269340515 , global_step: 1297
- AI-Rank-log  1618966552.159312  eval_accuracy: 0.48865917325019836 , global_step: 1298
- AI-Rank-log  1618966596.1157227  eval_accuracy: 0.48777520656585693 , global_step: 1299
- AI-Rank-log  1618966640.0146303  eval_accuracy: 0.487800657749176 , global_step: 1300
- AI-Rank-log  1618966684.0011933  eval_accuracy: 0.4882209897041321 , global_step: 1301
- AI-Rank-log  1618966727.9553256  eval_accuracy: 0.4905114769935608 , global_step: 1302
- AI-Rank-log  1618966771.8537865  eval_accuracy: 0.48944053053855896 , global_step: 1303
- AI-Rank-log  1618966815.836677  eval_accuracy: 0.4891878664493561 , global_step: 1304
- AI-Rank-log  1618966859.7649515  eval_accuracy: 0.490134060382843 , global_step: 1305
- AI-Rank-log  1618966903.7587562  eval_accuracy: 0.4894544780254364 , global_step: 1306
- AI-Rank-log  1618966948.9750264  eval_accuracy: 0.48902514576911926 , global_step: 1307
- AI-Rank-log  1618966993.3664045  eval_accuracy: 0.4913308024406433 , global_step: 1308
- AI-Rank-log  1618967038.1488228  eval_accuracy: 0.4907388687133789 , global_step: 1309
- AI-Rank-log  1618967083.1296778  eval_accuracy: 0.49230822920799255 , global_step: 1310
- AI-Rank-log  1618967127.1348836  eval_accuracy: 0.4899822175502777 , global_step: 1311
- AI-Rank-log  1618967171.107961  eval_accuracy: 0.4925509989261627 , global_step: 1312
- AI-Rank-log  1618967215.0563579  eval_accuracy: 0.49055570363998413 , global_step: 1313
- AI-Rank-log  1618967258.9752908  eval_accuracy: 0.4895501732826233 , global_step: 1314
- AI-Rank-log  1618967302.9318717  eval_accuracy: 0.4915539026260376 , global_step: 1315
- AI-Rank-log  1618967346.822037  eval_accuracy: 0.49221280217170715 , global_step: 1316
- AI-Rank-log  1618967390.776832  eval_accuracy: 0.4923701286315918 , global_step: 1317
- AI-Rank-log  1618967434.7450984  eval_accuracy: 0.49394747614860535 , global_step: 1318
- AI-Rank-log  1618967478.6986701  eval_accuracy: 0.4930107593536377 , global_step: 1319
- AI-Rank-log  1618967522.770225  eval_accuracy: 0.49267032742500305 , global_step: 1320
- AI-Rank-log  1618967566.656807  eval_accuracy: 0.4928523898124695 , global_step: 1321
- AI-Rank-log  1618967610.6124759  eval_accuracy: 0.49544692039489746 , global_step: 1322
- AI-Rank-log  1618967654.5719435  eval_accuracy: 0.4936099052429199 , global_step: 1323
- AI-Rank-log  1618967698.5159066  eval_accuracy: 0.49497950077056885 , global_step: 1324
- AI-Rank-log  1618967742.462037  eval_accuracy: 0.49254709482192993 , global_step: 1325
- AI-Rank-log  1618967786.3958297  eval_accuracy: 0.496405690908432 , global_step: 1326
- AI-Rank-log  1618967830.3543155  eval_accuracy: 0.4957897961139679 , global_step: 1327
- AI-Rank-log  1618967874.3317587  eval_accuracy: 0.49549663066864014 , global_step: 1328
- AI-Rank-log  1618967918.2282362  eval_accuracy: 0.49620407819747925 , global_step: 1329
- AI-Rank-log  1618967962.175464  eval_accuracy: 0.4970536231994629 , global_step: 1330
- AI-Rank-log  1618968006.2375083  eval_accuracy: 0.4951336085796356 , global_step: 1331
- AI-Rank-log  1618968050.1475832  eval_accuracy: 0.4936436712741852 , global_step: 1332
- AI-Rank-log  1618968094.0743499  eval_accuracy: 0.4940737187862396 , global_step: 1333
- AI-Rank-log  1618968138.0508733  eval_accuracy: 0.49490171670913696 , global_step: 1334
- AI-Rank-log  1618968181.9800296  eval_accuracy: 0.4976111054420471 , global_step: 1335
- AI-Rank-log  1618968225.905239  eval_accuracy: 0.4975355565547943 , global_step: 1336
- AI-Rank-log  1618968269.8957753  eval_accuracy: 0.4982745945453644 , global_step: 1337
- AI-Rank-log  1618968313.809676  eval_accuracy: 0.49767738580703735 , global_step: 1338
- AI-Rank-log  1618968357.799854  eval_accuracy: 0.49807167053222656 , global_step: 1339
- AI-Rank-log  1618968401.7290726  eval_accuracy: 0.4957542419433594 , global_step: 1340
- AI-Rank-log  1618968445.6258368  eval_accuracy: 0.49953845143318176 , global_step: 1341
- AI-Rank-log  1618968489.607528  eval_accuracy: 0.4983624219894409 , global_step: 1342
- AI-Rank-log  1618968533.5304008  eval_accuracy: 0.4979152977466583 , global_step: 1343
- AI-Rank-log  1618968577.4522126  eval_accuracy: 0.5000197291374207 , global_step: 1344
- AI-Rank-log  1618968621.4282012  eval_accuracy: 0.5013306736946106 , global_step: 1345
- AI-Rank-log  1618968665.3619356  eval_accuracy: 0.5017074346542358 , global_step: 1346
- AI-Rank-log  1618968709.2556438  eval_accuracy: 0.5016075968742371 , global_step: 1347
- AI-Rank-log  1618968753.2276194  eval_accuracy: 0.5002906918525696 , global_step: 1348
- AI-Rank-log  1618968797.1088972  eval_accuracy: 0.5013449192047119 , global_step: 1349
- AI-Rank-log  1618968841.037009  eval_accuracy: 0.49971720576286316 , global_step: 1350
- AI-Rank-log  1618968885.041499  eval_accuracy: 0.5011749267578125 , global_step: 1351
- AI-Rank-log  1618968928.975398  eval_accuracy: 0.5028762221336365 , global_step: 1352
- AI-Rank-log  1618968972.962876  eval_accuracy: 0.5015960335731506 , global_step: 1353
- AI-Rank-log  1618969016.880063  eval_accuracy: 0.5029071569442749 , global_step: 1354
- AI-Rank-log  1618969060.796432  eval_accuracy: 0.4998840093612671 , global_step: 1355
- AI-Rank-log  1618969104.8179479  eval_accuracy: 0.5034781098365784 , global_step: 1356
- AI-Rank-log  1618969148.7236724  eval_accuracy: 0.4995196759700775 , global_step: 1357
- AI-Rank-log  1618969192.6313152  eval_accuracy: 0.4986785054206848 , global_step: 1358
- AI-Rank-log  1618969236.6549501  eval_accuracy: 0.501602053642273 , global_step: 1359
- AI-Rank-log  1618969280.5433335  eval_accuracy: 0.4995015561580658 , global_step: 1360
- AI-Rank-log  1618969324.500598  eval_accuracy: 0.5033725500106812 , global_step: 1361
- AI-Rank-log  1618969368.4338984  eval_accuracy: 0.5020307898521423 , global_step: 1362
- AI-Rank-log  1618969412.330972  eval_accuracy: 0.5037837028503418 , global_step: 1363
- AI-Rank-log  1618969456.3207145  eval_accuracy: 0.5026291012763977 , global_step: 1364
- AI-Rank-log  1618969500.2324734  eval_accuracy: 0.5049246549606323 , global_step: 1365
- AI-Rank-log  1618969544.1257467  eval_accuracy: 0.5060596466064453 , global_step: 1366
- AI-Rank-log  1618969588.1188843  eval_accuracy: 0.5047505497932434 , global_step: 1367
- AI-Rank-log  1618969632.0599675  eval_accuracy: 0.5058098435401917 , global_step: 1368
- AI-Rank-log  1618969675.915263  eval_accuracy: 0.5040289759635925 , global_step: 1369
- AI-Rank-log  1618969719.8625479  eval_accuracy: 0.5066215991973877 , global_step: 1370
- AI-Rank-log  1618969763.7558339  eval_accuracy: 0.5049091577529907 , global_step: 1371
- AI-Rank-log  1618969807.7506685  eval_accuracy: 0.5067675709724426 , global_step: 1372
- AI-Rank-log  1618969851.650951  eval_accuracy: 0.504888653755188 , global_step: 1373
- AI-Rank-log  1618969895.6028779  eval_accuracy: 0.5073136687278748 , global_step: 1374
- AI-Rank-log  1618969939.5829313  eval_accuracy: 0.5071836113929749 , global_step: 1375
- AI-Rank-log  1618969983.496863  eval_accuracy: 0.5077800154685974 , global_step: 1376
- AI-Rank-log  1618970027.3651774  eval_accuracy: 0.5077167749404907 , global_step: 1377
- AI-Rank-log  1618970071.2824352  eval_accuracy: 0.5084103941917419 , global_step: 1378
- AI-Rank-log  1618970115.1865659  eval_accuracy: 0.507652759552002 , global_step: 1379
- AI-Rank-log  1618970158.904384  eval_accuracy: 0.5085617303848267 , global_step: 1380
- AI-Rank-log  1618970202.8186753  eval_accuracy: 0.507729709148407 , global_step: 1381
- AI-Rank-log  1618970246.6934648  eval_accuracy: 0.5086253881454468 , global_step: 1382
- AI-Rank-log  1618970290.6319816  eval_accuracy: 0.5067861676216125 , global_step: 1383
- AI-Rank-log  1618970334.5472448  eval_accuracy: 0.5089002251625061 , global_step: 1384
- AI-Rank-log  1618970380.1822248  eval_accuracy: 0.5091589689254761 , global_step: 1385
- AI-Rank-log  1618970424.8449125  eval_accuracy: 0.5100542306900024 , global_step: 1386
- AI-Rank-log  1618970469.305266  eval_accuracy: 0.5102283954620361 , global_step: 1387
- AI-Rank-log  1618970514.3337438  eval_accuracy: 0.5099637508392334 , global_step: 1388
- AI-Rank-log  1618970558.3581786  eval_accuracy: 0.5081236958503723 , global_step: 1389
- AI-Rank-log  1618970602.1732068  eval_accuracy: 0.5107656717300415 , global_step: 1390
- AI-Rank-log  1618970646.097477  eval_accuracy: 0.5098729729652405 , global_step: 1391
- AI-Rank-log  1618970690.0382197  eval_accuracy: 0.5113765001296997 , global_step: 1392
- AI-Rank-log  1618970742.7482872  eval_accuracy: 0.5111761093139648 , global_step: 1393
- AI-Rank-log  1618970786.6530151  eval_accuracy: 0.5114043354988098 , global_step: 1394
- AI-Rank-log  1618970830.5742643  eval_accuracy: 0.5106064081192017 , global_step: 1395
- AI-Rank-log  1618970874.4031293  eval_accuracy: 0.51307612657547 , global_step: 1396
- AI-Rank-log  1618970918.4029884  eval_accuracy: 0.5122873783111572 , global_step: 1397
- AI-Rank-log  1618970962.2234185  eval_accuracy: 0.5126458406448364 , global_step: 1398
- AI-Rank-log  1618971006.0929003  eval_accuracy: 0.512249231338501 , global_step: 1399
- AI-Rank-log  1618971050.0974793  eval_accuracy: 0.5115525722503662 , global_step: 1400
- AI-Rank-log  1618971093.965156  eval_accuracy: 0.5122289657592773 , global_step: 1401
- AI-Rank-log  1618971137.8046556  eval_accuracy: 0.5147303938865662 , global_step: 1402
- AI-Rank-log  1618971181.759318  eval_accuracy: 0.5100693106651306 , global_step: 1403
- AI-Rank-log  1618971225.6079679  eval_accuracy: 0.5134429335594177 , global_step: 1404
- AI-Rank-log  1618971269.4890606  eval_accuracy: 0.512933075428009 , global_step: 1405
- AI-Rank-log  1618971313.4148898  eval_accuracy: 0.5129776000976562 , global_step: 1406
- AI-Rank-log  1618971357.2739258  eval_accuracy: 0.5117341876029968 , global_step: 1407
- AI-Rank-log  1618971401.2490327  eval_accuracy: 0.5123890042304993 , global_step: 1408
- AI-Rank-log  1618971445.1304755  eval_accuracy: 0.5131893157958984 , global_step: 1409
- AI-Rank-log  1618971488.9547698  eval_accuracy: 0.5153025984764099 , global_step: 1410
- AI-Rank-log  1618971532.9438674  eval_accuracy: 0.5156516432762146 , global_step: 1411
- AI-Rank-log  1618971576.821668  eval_accuracy: 0.5133291482925415 , global_step: 1412
- AI-Rank-log  1618971620.6539183  eval_accuracy: 0.5144948363304138 , global_step: 1413
- AI-Rank-log  1618971664.59893  eval_accuracy: 0.5147127509117126 , global_step: 1414
- AI-Rank-log  1618971708.4891827  eval_accuracy: 0.5140268802642822 , global_step: 1415
- AI-Rank-log  1618971752.3844857  eval_accuracy: 0.5165607929229736 , global_step: 1416
- AI-Rank-log  1618971796.2653747  eval_accuracy: 0.5170297026634216 , global_step: 1417
- AI-Rank-log  1618971840.1301844  eval_accuracy: 0.5156235098838806 , global_step: 1418
- AI-Rank-log  1618971884.0318966  eval_accuracy: 0.5148620009422302 , global_step: 1419
- AI-Rank-log  1618971927.9400332  eval_accuracy: 0.5179418921470642 , global_step: 1420
- AI-Rank-log  1618971971.8363054  eval_accuracy: 0.5164743661880493 , global_step: 1421
- AI-Rank-log  1618972015.7605882  eval_accuracy: 0.5178982615470886 , global_step: 1422
- AI-Rank-log  1618972059.6546798  eval_accuracy: 0.5168287754058838 , global_step: 1423
- AI-Rank-log  1618972103.4843829  eval_accuracy: 0.5188772082328796 , global_step: 1424
- AI-Rank-log  1618972147.4245448  eval_accuracy: 0.5175324082374573 , global_step: 1425
- AI-Rank-log  1618972191.2941506  eval_accuracy: 0.5173558592796326 , global_step: 1426
- AI-Rank-log  1618972235.1486862  eval_accuracy: 0.5170401334762573 , global_step: 1427
- AI-Rank-log  1618972279.105453  eval_accuracy: 0.5197785496711731 , global_step: 1428
- AI-Rank-log  1618972322.9728906  eval_accuracy: 0.5175572633743286 , global_step: 1429
- AI-Rank-log  1618972366.85628  eval_accuracy: 0.5193055272102356 , global_step: 1430
- AI-Rank-log  1618972410.6797242  eval_accuracy: 0.5186207294464111 , global_step: 1431
- AI-Rank-log  1618972454.5661967  eval_accuracy: 0.5208911299705505 , global_step: 1432
- AI-Rank-log  1618972498.4901805  eval_accuracy: 0.5205206871032715 , global_step: 1433
- AI-Rank-log  1618972542.3766065  eval_accuracy: 0.5206607580184937 , global_step: 1434
- AI-Rank-log  1618972586.273189  eval_accuracy: 0.5209246277809143 , global_step: 1435
- AI-Rank-log  1618972630.1942008  eval_accuracy: 0.5209029316902161 , global_step: 1436
- AI-Rank-log  1618972674.0922704  eval_accuracy: 0.522121012210846 , global_step: 1437
- AI-Rank-log  1618972717.965368  eval_accuracy: 0.52272629737854 , global_step: 1438
- AI-Rank-log  1618972761.9031963  eval_accuracy: 0.5218736529350281 , global_step: 1439
- AI-Rank-log  1618972805.8078175  eval_accuracy: 0.5234102010726929 , global_step: 1440
- AI-Rank-log  1618972849.7598703  eval_accuracy: 0.5212376117706299 , global_step: 1441
- AI-Rank-log  1618972893.6311831  eval_accuracy: 0.523601233959198 , global_step: 1442
- AI-Rank-log  1618972937.5498998  eval_accuracy: 0.5192649364471436 , global_step: 1443
- AI-Rank-log  1618972981.4640043  eval_accuracy: 0.5225486159324646 , global_step: 1444
- AI-Rank-log  1618973025.3701603  eval_accuracy: 0.5218097567558289 , global_step: 1445
- AI-Rank-log  1618973069.230026  eval_accuracy: 0.5214489698410034 , global_step: 1446
- AI-Rank-log  1618973113.2087455  eval_accuracy: 0.5234565734863281 , global_step: 1447
- AI-Rank-log  1618973157.0953429  eval_accuracy: 0.5247657299041748 , global_step: 1448
- AI-Rank-log  1618973201.0451784  eval_accuracy: 0.5234437584877014 , global_step: 1449
- AI-Rank-log  1618973244.9193077  eval_accuracy: 0.5232225656509399 , global_step: 1450
- AI-Rank-log  1618973288.795892  eval_accuracy: 0.5242946147918701 , global_step: 1451
- AI-Rank-log  1618973332.7612755  eval_accuracy: 0.5243886709213257 , global_step: 1452
- AI-Rank-log  1618973376.6395395  eval_accuracy: 0.5244236588478088 , global_step: 1453
- AI-Rank-log  1618973420.5113187  eval_accuracy: 0.5240610241889954 , global_step: 1454
- AI-Rank-log  1618973464.4713497  eval_accuracy: 0.5257622599601746 , global_step: 1455
- AI-Rank-log  1618973508.3823726  eval_accuracy: 0.5251839756965637 , global_step: 1456
- AI-Rank-log  1618973552.2737105  eval_accuracy: 0.5244414806365967 , global_step: 1457
- AI-Rank-log  1618973596.2426124  eval_accuracy: 0.5245879292488098 , global_step: 1458
- AI-Rank-log  1618973640.143939  eval_accuracy: 0.5252220034599304 , global_step: 1459
- AI-Rank-log  1618973684.1153316  eval_accuracy: 0.5224583745002747 , global_step: 1460
- AI-Rank-log  1618973727.984633  eval_accuracy: 0.5262824892997742 , global_step: 1461
- AI-Rank-log  1618973772.8730252  eval_accuracy: 0.5250237584114075 , global_step: 1462
- AI-Rank-log  1618973818.271156  eval_accuracy: 0.526287317276001 , global_step: 1463
- AI-Rank-log  1618973863.503977  eval_accuracy: 0.5265452265739441 , global_step: 1464
- AI-Rank-log  1618973908.382183  eval_accuracy: 0.5268462300300598 , global_step: 1465
- AI-Rank-log  1618973953.1943593  eval_accuracy: 0.5281638503074646 , global_step: 1466
- AI-Rank-log  1618973997.0852156  eval_accuracy: 0.5271644592285156 , global_step: 1467
- AI-Rank-log  1618974040.986509  eval_accuracy: 0.5265430212020874 , global_step: 1468
- AI-Rank-log  1618974084.9477868  eval_accuracy: 0.5267003774642944 , global_step: 1469
- AI-Rank-log  1618974128.8502023  eval_accuracy: 0.5262976884841919 , global_step: 1470
- AI-Rank-log  1618974172.8623753  eval_accuracy: 0.5278705954551697 , global_step: 1471
- AI-Rank-log  1618974216.7852147  eval_accuracy: 0.5277636647224426 , global_step: 1472
- AI-Rank-log  1618974260.728796  eval_accuracy: 0.528063178062439 , global_step: 1473
- AI-Rank-log  1618974304.740402  eval_accuracy: 0.5274471044540405 , global_step: 1474
- AI-Rank-log  1618974348.6571224  eval_accuracy: 0.52747642993927 , global_step: 1475
- AI-Rank-log  1618974392.5845957  eval_accuracy: 0.5289307832717896 , global_step: 1476
- AI-Rank-log  1618974436.6165483  eval_accuracy: 0.5300126075744629 , global_step: 1477
- AI-Rank-log  1618974480.4975724  eval_accuracy: 0.52943354845047 , global_step: 1478
- AI-Rank-log  1618974524.3797574  eval_accuracy: 0.5307701826095581 , global_step: 1479
- AI-Rank-log  1618974568.3396251  eval_accuracy: 0.5293211340904236 , global_step: 1480
- AI-Rank-log  1618974612.318572  eval_accuracy: 0.5314598679542542 , global_step: 1481
- AI-Rank-log  1618974656.274303  eval_accuracy: 0.5291953682899475 , global_step: 1482
- AI-Rank-log  1618974700.1828957  eval_accuracy: 0.5309910774230957 , global_step: 1483
- AI-Rank-log  1618974744.1102073  eval_accuracy: 0.5300235748291016 , global_step: 1484
- AI-Rank-log  1618974788.096479  eval_accuracy: 0.529561460018158 , global_step: 1485
- AI-Rank-log  1618974832.0458658  eval_accuracy: 0.5317311882972717 , global_step: 1486
- AI-Rank-log  1618974875.978404  eval_accuracy: 0.5317942500114441 , global_step: 1487
- AI-Rank-log  1618974919.9116817  eval_accuracy: 0.5299109220504761 , global_step: 1488

yq01-sys-hic-k8s-v100-box-a225-0804:34471:34528 [0] misc/ibvwrap.cc:220 NCCL WARN Call to ibv_get_async_event failed
- AI-Rank-log  1618974963.8403716  eval_accuracy: 0.5328121781349182 , global_step: 1489
- AI-Rank-log  1618975007.8197968  eval_accuracy: 0.531484067440033 , global_step: 1490
- AI-Rank-log  1618975051.7281525  eval_accuracy: 0.5321899652481079 , global_step: 1491
- AI-Rank-log  1618975095.6475363  eval_accuracy: 0.53068608045578 , global_step: 1492
- AI-Rank-log  1618975139.6532364  eval_accuracy: 0.5325876474380493 , global_step: 1493
- AI-Rank-log  1618975183.55179  eval_accuracy: 0.5331289768218994 , global_step: 1494
- AI-Rank-log  1618975227.4904907  eval_accuracy: 0.5326818227767944 , global_step: 1495
- AI-Rank-log  1618975271.466527  eval_accuracy: 0.5328320264816284 , global_step: 1496
- AI-Rank-log  1618975315.37775  eval_accuracy: 0.5347086191177368 , global_step: 1497
- AI-Rank-log  1618975359.2902458  eval_accuracy: 0.5316339731216431 , global_step: 1498
- AI-Rank-log  1618975403.2680738  eval_accuracy: 0.5329654812812805 , global_step: 1499
- AI-Rank-log  1618975446.9985094  eval_accuracy: 0.5327060222625732 , global_step: 1500
- AI-Rank-log  1618975490.9289792  eval_accuracy: 0.5326679348945618 , global_step: 1501
- AI-Rank-log  1618975534.8694184  eval_accuracy: 0.5314844250679016 , global_step: 1502
- AI-Rank-log  1618975578.8525043  eval_accuracy: 0.5352604985237122 , global_step: 1503
- AI-Rank-log  1618975622.8650672  eval_accuracy: 0.5350521802902222 , global_step: 1504
- AI-Rank-log  1618975666.7833307  eval_accuracy: 0.5352850556373596 , global_step: 1505
- AI-Rank-log  1618975710.7098076  eval_accuracy: 0.5341358184814453 , global_step: 1506
- AI-Rank-log  1618975754.7144728  eval_accuracy: 0.535240650177002 , global_step: 1507
- AI-Rank-log  1618975798.5926936  eval_accuracy: 0.5333665013313293 , global_step: 1508
- AI-Rank-log  1618975842.5531094  eval_accuracy: 0.5339226126670837 , global_step: 1509
- AI-Rank-log  1618975886.5276537  eval_accuracy: 0.5321552753448486 , global_step: 1510
- AI-Rank-log  1618975930.4382963  eval_accuracy: 0.5333679914474487 , global_step: 1511
- AI-Rank-log  1618975974.3559465  eval_accuracy: 0.535590410232544 , global_step: 1512
- AI-Rank-log  1618976018.3461578  eval_accuracy: 0.5353461503982544 , global_step: 1513
- AI-Rank-log  1618976062.221989  eval_accuracy: 0.5346359610557556 , global_step: 1514
- AI-Rank-log  1618976106.238243  eval_accuracy: 0.5357666611671448 , global_step: 1515
- AI-Rank-log  1618976150.1660101  eval_accuracy: 0.5331788659095764 , global_step: 1516
- AI-Rank-log  1618976194.0626128  eval_accuracy: 0.5358663201332092 , global_step: 1517
- AI-Rank-log  1618976238.0023205  eval_accuracy: 0.5355807542800903 , global_step: 1518
- AI-Rank-log  1618976281.9368784  eval_accuracy: 0.5372490882873535 , global_step: 1519
- AI-Rank-log  1618976325.8479571  eval_accuracy: 0.5365962386131287 , global_step: 1520
- AI-Rank-log  1618976369.8124354  eval_accuracy: 0.5391888618469238 , global_step: 1521
- AI-Rank-log  1618976413.746882  eval_accuracy: 0.5374720096588135 , global_step: 1522
- AI-Rank-log  1618976457.7168305  eval_accuracy: 0.5393826961517334 , global_step: 1523
- AI-Rank-log  1618976501.6254559  eval_accuracy: 0.5372401475906372 , global_step: 1524
- AI-Rank-log  1618976545.5012753  eval_accuracy: 0.5383352637290955 , global_step: 1525
- AI-Rank-log  1618976589.504017  eval_accuracy: 0.5380830764770508 , global_step: 1526
- AI-Rank-log  1618976633.46431  eval_accuracy: 0.5375874042510986 , global_step: 1527
- AI-Rank-log  1618976677.416109  eval_accuracy: 0.5368899703025818 , global_step: 1528
- AI-Rank-log  1618976721.3350391  eval_accuracy: 0.5375959277153015 , global_step: 1529
- AI-Rank-log  1618976765.245158  eval_accuracy: 0.5378988981246948 , global_step: 1530
- AI-Rank-log  1618976809.1350932  eval_accuracy: 0.537729799747467 , global_step: 1531
- AI-Rank-log  1618976853.1610649  eval_accuracy: 0.5386809706687927 , global_step: 1532
- AI-Rank-log  1618976897.0663342  eval_accuracy: 0.5390088558197021 , global_step: 1533
- AI-Rank-log  1618976940.9885616  eval_accuracy: 0.5391600728034973 , global_step: 1534
- AI-Rank-log  1618976984.9860353  eval_accuracy: 0.5390470623970032 , global_step: 1535
- AI-Rank-log  1618977028.9186502  eval_accuracy: 0.5389682054519653 , global_step: 1536
- AI-Rank-log  1618977072.8915038  eval_accuracy: 0.5405741930007935 , global_step: 1537
- AI-Rank-log  1618977116.814839  eval_accuracy: 0.5387973189353943 , global_step: 1538
- AI-Rank-log  1618977161.6482234  eval_accuracy: 0.5410028696060181 , global_step: 1539
- AI-Rank-log  1618977206.023864  eval_accuracy: 0.5400699377059937 , global_step: 1540
- AI-Rank-log  1618977250.786595  eval_accuracy: 0.5417683124542236 , global_step: 1541
- AI-Rank-log  1618977295.2916603  eval_accuracy: 0.5409793853759766 , global_step: 1542
- AI-Rank-log  1618977340.355472  eval_accuracy: 0.540962815284729 , global_step: 1543
- AI-Rank-log  1618977384.4118774  eval_accuracy: 0.5417722463607788 , global_step: 1544
- AI-Rank-log  1618977428.454703  eval_accuracy: 0.5425578951835632 , global_step: 1545
- AI-Rank-log  1618977472.4604936  eval_accuracy: 0.5414572358131409 , global_step: 1546
- AI-Rank-log  1618977516.3972266  eval_accuracy: 0.5415627956390381 , global_step: 1547
- AI-Rank-log  1618977560.417101  eval_accuracy: 0.5406188368797302 , global_step: 1548
- AI-Rank-log  1618977604.3393493  eval_accuracy: 0.5421544909477234 , global_step: 1549
- AI-Rank-log  1618977648.3659918  eval_accuracy: 0.541685938835144 , global_step: 1550
- AI-Rank-log  1618977692.3874402  eval_accuracy: 0.5427322387695312 , global_step: 1551
- AI-Rank-log  1618977736.3258474  eval_accuracy: 0.5396285653114319 , global_step: 1552
- AI-Rank-log  1618977780.3574383  eval_accuracy: 0.5430150032043457 , global_step: 1553
- AI-Rank-log  1618977824.3130925  eval_accuracy: 0.5427630543708801 , global_step: 1554
- AI-Rank-log  1618977868.212418  eval_accuracy: 0.5427467823028564 , global_step: 1555
- AI-Rank-log  1618977912.2266037  eval_accuracy: 0.541482150554657 , global_step: 1556
- AI-Rank-log  1618977956.1647367  eval_accuracy: 0.544029951095581 , global_step: 1557
- AI-Rank-log  1618978000.0854986  eval_accuracy: 0.5419800877571106 , global_step: 1558
- AI-Rank-log  1618978044.0830476  eval_accuracy: 0.5445190668106079 , global_step: 1559
- AI-Rank-log  1618978087.9931471  eval_accuracy: 0.5426933765411377 , global_step: 1560
- AI-Rank-log  1618978131.8971791  eval_accuracy: 0.5445861220359802 , global_step: 1561
- AI-Rank-log  1618978175.881862  eval_accuracy: 0.5432894229888916 , global_step: 1562
- AI-Rank-log  1618978219.7626367  eval_accuracy: 0.5442477464675903 , global_step: 1563
- AI-Rank-log  1618978263.8015347  eval_accuracy: 0.5454397201538086 , global_step: 1564
- AI-Rank-log  1618978307.7604597  eval_accuracy: 0.5449138283729553 , global_step: 1565
- AI-Rank-log  1618978351.6703348  eval_accuracy: 0.5442711710929871 , global_step: 1566
- AI-Rank-log  1618978395.6586084  eval_accuracy: 0.5452228784561157 , global_step: 1567
- AI-Rank-log  1618978439.5809739  eval_accuracy: 0.5455516576766968 , global_step: 1568
- AI-Rank-log  1618978483.4843416  eval_accuracy: 0.5449342727661133 , global_step: 1569
- AI-Rank-log  1618978527.4610837  eval_accuracy: 0.5455895066261292 , global_step: 1570
- AI-Rank-log  1618978571.394218  eval_accuracy: 0.5451166033744812 , global_step: 1571
- AI-Rank-log  1618978615.310091  eval_accuracy: 0.5477637052536011 , global_step: 1572
- AI-Rank-log  1618978659.3137863  eval_accuracy: 0.5469189882278442 , global_step: 1573
- AI-Rank-log  1618978703.2400959  eval_accuracy: 0.5467795729637146 , global_step: 1574
- AI-Rank-log  1618978747.2111166  eval_accuracy: 0.5472569465637207 , global_step: 1575
- AI-Rank-log  1618978791.1438997  eval_accuracy: 0.5472381711006165 , global_step: 1576
- AI-Rank-log  1618978835.1047816  eval_accuracy: 0.5478705167770386 , global_step: 1577
- AI-Rank-log  1618978879.0807152  eval_accuracy: 0.5478377938270569 , global_step: 1578
- AI-Rank-log  1618978923.0539474  eval_accuracy: 0.5472267270088196 , global_step: 1579
- AI-Rank-log  1618978967.0379462  eval_accuracy: 0.5468927025794983 , global_step: 1580
- AI-Rank-log  1618979010.9936342  eval_accuracy: 0.5471412539482117 , global_step: 1581
- AI-Rank-log  1618979054.9154825  eval_accuracy: 0.5466657876968384 , global_step: 1582
- AI-Rank-log  1618979098.901002  eval_accuracy: 0.547249972820282 , global_step: 1583
- AI-Rank-log  1618979142.869315  eval_accuracy: 0.5476105213165283 , global_step: 1584
- AI-Rank-log  1618979186.7993853  eval_accuracy: 0.5482684373855591 , global_step: 1585
- AI-Rank-log  1618979230.757808  eval_accuracy: 0.5483064651489258 , global_step: 1586
- AI-Rank-log  1618979274.6649046  eval_accuracy: 0.5460771918296814 , global_step: 1587
- AI-Rank-log  1618979318.6048326  eval_accuracy: 0.5487298369407654 , global_step: 1588
- AI-Rank-log  1618979362.5635238  eval_accuracy: 0.5492967367172241 , global_step: 1589
- AI-Rank-log  1618979406.502092  eval_accuracy: 0.5490313768386841 , global_step: 1590
- AI-Rank-log  1618979450.4936085  eval_accuracy: 0.5489203333854675 , global_step: 1591
- AI-Rank-log  1618979494.4320667  eval_accuracy: 0.5495006442070007 , global_step: 1592
- AI-Rank-log  1618979547.5727072  eval_accuracy: 0.5497297644615173 , global_step: 1593
- AI-Rank-log  1618979591.5587263  eval_accuracy: 0.5497226715087891 , global_step: 1594
- AI-Rank-log  1618979635.5404673  eval_accuracy: 0.548541784286499 , global_step: 1595
- AI-Rank-log  1618979679.4203923  eval_accuracy: 0.5496419668197632 , global_step: 1596
- AI-Rank-log  1618979723.4444017  eval_accuracy: 0.549239456653595 , global_step: 1597
- AI-Rank-log  1618979767.347225  eval_accuracy: 0.549830973148346 , global_step: 1598
- AI-Rank-log  1618979811.2779846  eval_accuracy: 0.5506285429000854 , global_step: 1599
- AI-Rank-log  1618979855.2383387  eval_accuracy: 0.5520097017288208 , global_step: 1600
- AI-Rank-log  1618979899.1309128  eval_accuracy: 0.5511259436607361 , global_step: 1601
- AI-Rank-log  1618979943.1659641  eval_accuracy: 0.5509623885154724 , global_step: 1602
- AI-Rank-log  1618979987.1210847  eval_accuracy: 0.5509978532791138 , global_step: 1603
- AI-Rank-log  1618980031.0239494  eval_accuracy: 0.5493162870407104 , global_step: 1604
- AI-Rank-log  1618980075.0043118  eval_accuracy: 0.5520347356796265 , global_step: 1605
- AI-Rank-log  1618980118.9692657  eval_accuracy: 0.5497389435768127 , global_step: 1606
- AI-Rank-log  1618980162.880106  eval_accuracy: 0.5513212084770203 , global_step: 1607
- AI-Rank-log  1618980206.8982759  eval_accuracy: 0.5491609573364258 , global_step: 1608
- AI-Rank-log  1618980250.8229005  eval_accuracy: 0.5523926615715027 , global_step: 1609
- AI-Rank-log  1618980294.7419455  eval_accuracy: 0.5518922209739685 , global_step: 1610
- AI-Rank-log  1618980338.7843044  eval_accuracy: 0.5531150698661804 , global_step: 1611
- AI-Rank-log  1618980382.7520514  eval_accuracy: 0.5497062802314758 , global_step: 1612
- AI-Rank-log  1618980426.7419755  eval_accuracy: 0.55290687084198 , global_step: 1613
- AI-Rank-log  1618980470.6366506  eval_accuracy: 0.5541765689849854 , global_step: 1614
- AI-Rank-log  1618980514.5452347  eval_accuracy: 0.5538030862808228 , global_step: 1615
- AI-Rank-log  1618980559.3194892  eval_accuracy: 0.5535634160041809 , global_step: 1616
- AI-Rank-log  1618980604.7661858  eval_accuracy: 0.5525932908058167 , global_step: 1617
- AI-Rank-log  1618980649.8015845  eval_accuracy: 0.5526497960090637 , global_step: 1618
- AI-Rank-log  1618980693.8258111  eval_accuracy: 0.5528240203857422 , global_step: 1619
- AI-Rank-log  1618980738.4644053  eval_accuracy: 0.5537646412849426 , global_step: 1620
- AI-Rank-log  1618980783.209411  eval_accuracy: 0.5530230402946472 , global_step: 1621
- AI-Rank-log  1618980827.4924018  eval_accuracy: 0.5545443296432495 , global_step: 1622
- AI-Rank-log  1618980871.449982  eval_accuracy: 0.5528191924095154 , global_step: 1623
- AI-Rank-log  1618980915.4262195  eval_accuracy: 0.5533127784729004 , global_step: 1624
- AI-Rank-log  1618980959.4856303  eval_accuracy: 0.5523124933242798 , global_step: 1625
- AI-Rank-log  1618981003.4355073  eval_accuracy: 0.553659200668335 , global_step: 1626
- AI-Rank-log  1618981047.4131844  eval_accuracy: 0.5541465878486633 , global_step: 1627
- AI-Rank-log  1618981091.351068  eval_accuracy: 0.5535120964050293 , global_step: 1628
- AI-Rank-log  1618981135.2982779  eval_accuracy: 0.5537372827529907 , global_step: 1629
- AI-Rank-log  1618981179.2772162  eval_accuracy: 0.5541461706161499 , global_step: 1630
- AI-Rank-log  1618981223.2886596  eval_accuracy: 0.5549082159996033 , global_step: 1631
- AI-Rank-log  1618981267.2819705  eval_accuracy: 0.5546785593032837 , global_step: 1632
- AI-Rank-log  1618981311.2244878  eval_accuracy: 0.5545126795768738 , global_step: 1633
- AI-Rank-log  1618981355.1809645  eval_accuracy: 0.556067705154419 , global_step: 1634
- AI-Rank-log  1618981399.2214596  eval_accuracy: 0.5559645295143127 , global_step: 1635
- AI-Rank-log  1618981443.153498  eval_accuracy: 0.5560755133628845 , global_step: 1636
- AI-Rank-log  1618981487.0683  eval_accuracy: 0.5557757019996643 , global_step: 1637
- AI-Rank-log  1618981531.0568213  eval_accuracy: 0.554259181022644 , global_step: 1638
- AI-Rank-log  1618981574.9523983  eval_accuracy: 0.5556790232658386 , global_step: 1639
- AI-Rank-log  1618981618.8577876  eval_accuracy: 0.5564293265342712 , global_step: 1640
- AI-Rank-log  1618981662.913358  eval_accuracy: 0.5581130385398865 , global_step: 1641
- AI-Rank-log  1618981706.8123856  eval_accuracy: 0.5558274388313293 , global_step: 1642
- AI-Rank-log  1618981750.770429  eval_accuracy: 0.5554934144020081 , global_step: 1643
- AI-Rank-log  1618981794.7127573  eval_accuracy: 0.5552546977996826 , global_step: 1644
- AI-Rank-log  1618981838.6339521  eval_accuracy: 0.5568526387214661 , global_step: 1645
- AI-Rank-log  1618981882.6860912  eval_accuracy: 0.5555850863456726 , global_step: 1646
- AI-Rank-log  1618981926.6177065  eval_accuracy: 0.5583849549293518 , global_step: 1647
- AI-Rank-log  1618981970.5774267  eval_accuracy: 0.5571777820587158 , global_step: 1648
- AI-Rank-log  1618982014.5751817  eval_accuracy: 0.5579892992973328 , global_step: 1649
- AI-Rank-log  1618982058.5120645  eval_accuracy: 0.5578221082687378 , global_step: 1650
- AI-Rank-log  1618982102.627261  eval_accuracy: 0.5580979585647583 , global_step: 1651
- AI-Rank-log  1618982146.643323  eval_accuracy: 0.5579820871353149 , global_step: 1652
- AI-Rank-log  1618982190.6164384  eval_accuracy: 0.5588868856430054 , global_step: 1653
- AI-Rank-log  1618982234.6119673  eval_accuracy: 0.5589849948883057 , global_step: 1654
- AI-Rank-log  1618982278.55799  eval_accuracy: 0.5586525797843933 , global_step: 1655
- AI-Rank-log  1618982322.4604788  eval_accuracy: 0.5573353171348572 , global_step: 1656
- AI-Rank-log  1618982366.4697287  eval_accuracy: 0.5586882829666138 , global_step: 1657
- AI-Rank-log  1618982410.435747  eval_accuracy: 0.5567171573638916 , global_step: 1658
- AI-Rank-log  1618982454.342879  eval_accuracy: 0.5593073964118958 , global_step: 1659
- AI-Rank-log  1618982498.3082418  eval_accuracy: 0.559617280960083 , global_step: 1660
- AI-Rank-log  1618982542.2460291  eval_accuracy: 0.5608421564102173 , global_step: 1661
- AI-Rank-log  1618982586.2057292  eval_accuracy: 0.5595393776893616 , global_step: 1662
- AI-Rank-log  1618982630.1131842  eval_accuracy: 0.5604541301727295 , global_step: 1663
- AI-Rank-log  1618982674.0355365  eval_accuracy: 0.5599610209465027 , global_step: 1664
- AI-Rank-log  1618982717.95414  eval_accuracy: 0.5604998469352722 , global_step: 1665
- AI-Rank-log  1618982761.9110363  eval_accuracy: 0.5595732927322388 , global_step: 1666
- AI-Rank-log  1618982805.8585331  eval_accuracy: 0.5614050030708313 , global_step: 1667
- AI-Rank-log  1618982849.8836122  eval_accuracy: 0.559951663017273 , global_step: 1668
- AI-Rank-log  1618982893.833473  eval_accuracy: 0.5612643361091614 , global_step: 1669
- AI-Rank-log  1618982937.7245216  eval_accuracy: 0.5586916208267212 , global_step: 1670
- AI-Rank-log  1618982981.7065725  eval_accuracy: 0.5615706443786621 , global_step: 1671
- AI-Rank-log  1618983025.638092  eval_accuracy: 0.5614402294158936 , global_step: 1672
- AI-Rank-log  1618983069.56214  eval_accuracy: 0.5617873668670654 , global_step: 1673
- AI-Rank-log  1618983113.5677245  eval_accuracy: 0.5600680112838745 , global_step: 1674
- AI-Rank-log  1618983157.483018  eval_accuracy: 0.5593639612197876 , global_step: 1675
- AI-Rank-log  1618983201.4363945  eval_accuracy: 0.5612589716911316 , global_step: 1676
- AI-Rank-log  1618983245.3290312  eval_accuracy: 0.5605903267860413 , global_step: 1677
- AI-Rank-log  1618983289.2613688  eval_accuracy: 0.5601566433906555 , global_step: 1678
- AI-Rank-log  1618983333.2538884  eval_accuracy: 0.5600305199623108 , global_step: 1679
- AI-Rank-log  1618983377.219154  eval_accuracy: 0.5619118809700012 , global_step: 1680
- AI-Rank-log  1618983421.137621  eval_accuracy: 0.5618875026702881 , global_step: 1681
- AI-Rank-log  1618983465.1084669  eval_accuracy: 0.5628153085708618 , global_step: 1682
- AI-Rank-log  1618983509.0006769  eval_accuracy: 0.5627030730247498 , global_step: 1683
- AI-Rank-log  1618983553.0137756  eval_accuracy: 0.5626866221427917 , global_step: 1684
- AI-Rank-log  1618983596.887959  eval_accuracy: 0.5645492076873779 , global_step: 1685
- AI-Rank-log  1618983640.845251  eval_accuracy: 0.5632334351539612 , global_step: 1686
- AI-Rank-log  1618983684.8592532  eval_accuracy: 0.5633518695831299 , global_step: 1687
- AI-Rank-log  1618983728.8214505  eval_accuracy: 0.5642678141593933 , global_step: 1688
- AI-Rank-log  1618983772.7478902  eval_accuracy: 0.5639448761940002 , global_step: 1689
- AI-Rank-log  1618983816.7155232  eval_accuracy: 0.5636225342750549 , global_step: 1690
- AI-Rank-log  1618983860.6188035  eval_accuracy: 0.5633014440536499 , global_step: 1691
- AI-Rank-log  1618983904.5442588  eval_accuracy: 0.5637521147727966 , global_step: 1692
- AI-Rank-log  1618983948.6810575  eval_accuracy: 0.5633944272994995 , global_step: 1693
- AI-Rank-log  1618983993.2383716  eval_accuracy: 0.5646568536758423 , global_step: 1694
- AI-Rank-log  1618984037.7519066  eval_accuracy: 0.564434826374054 , global_step: 1695
- AI-Rank-log  1618984083.2038202  eval_accuracy: 0.5639522671699524 , global_step: 1696
- AI-Rank-log  1618984127.3980896  eval_accuracy: 0.5650964379310608 , global_step: 1697
- AI-Rank-log  1618984172.6566794  eval_accuracy: 0.5653361678123474 , global_step: 1698
- AI-Rank-log  1618984216.60281  eval_accuracy: 0.5660049915313721 , global_step: 1699
- AI-Rank-log  1618984260.790309  eval_accuracy: 0.5651267170906067 , global_step: 1700
- AI-Rank-log  1618984304.802458  eval_accuracy: 0.5657629370689392 , global_step: 1701
- AI-Rank-log  1618984348.7479296  eval_accuracy: 0.5647932887077332 , global_step: 1702
- AI-Rank-log  1618984392.6622102  eval_accuracy: 0.5664774179458618 , global_step: 1703
- AI-Rank-log  1618984436.6596632  eval_accuracy: 0.5661509037017822 , global_step: 1704
- AI-Rank-log  1618984480.5539408  eval_accuracy: 0.5662001967430115 , global_step: 1705
- AI-Rank-log  1618984524.562752  eval_accuracy: 0.5639081597328186 , global_step: 1706
- AI-Rank-log  1618984568.5240774  eval_accuracy: 0.5666916370391846 , global_step: 1707
- AI-Rank-log  1618984612.4358494  eval_accuracy: 0.5642837882041931 , global_step: 1708
- AI-Rank-log  1618984656.4603748  eval_accuracy: 0.5658918619155884 , global_step: 1709
- AI-Rank-log  1618984700.364449  eval_accuracy: 0.5644987225532532 , global_step: 1710
- AI-Rank-log  1618984744.2452521  eval_accuracy: 0.5671209096908569 , global_step: 1711
- AI-Rank-log  1618984788.2254338  eval_accuracy: 0.5660443902015686 , global_step: 1712
- AI-Rank-log  1618984832.1890333  eval_accuracy: 0.5669502019882202 , global_step: 1713
- AI-Rank-log  1618984876.119702  eval_accuracy: 0.5678251385688782 , global_step: 1714
- AI-Rank-log  1618984920.058784  eval_accuracy: 0.5666931867599487 , global_step: 1715
- AI-Rank-log  1618984963.9582767  eval_accuracy: 0.56769859790802 , global_step: 1716
- AI-Rank-log  1618985007.9464223  eval_accuracy: 0.5677015781402588 , global_step: 1717
- AI-Rank-log  1618985051.8728259  eval_accuracy: 0.5688288807868958 , global_step: 1718
- AI-Rank-log  1618985095.7672212  eval_accuracy: 0.5678698420524597 , global_step: 1719
- AI-Rank-log  1618985139.7416642  eval_accuracy: 0.5683274865150452 , global_step: 1720
- AI-Rank-log  1618985183.7149394  eval_accuracy: 0.5692564845085144 , global_step: 1721
- AI-Rank-log  1618985227.6762214  eval_accuracy: 0.5690742135047913 , global_step: 1722
- AI-Rank-log  1618985271.6484396  eval_accuracy: 0.5674911737442017 , global_step: 1723
- AI-Rank-log  1618985315.5953772  eval_accuracy: 0.5687322020530701 , global_step: 1724
- AI-Rank-log  1618985359.4913025  eval_accuracy: 0.5685310363769531 , global_step: 1725
- AI-Rank-log  1618985403.4466624  eval_accuracy: 0.5676835775375366 , global_step: 1726
- AI-Rank-log  1618985447.3807726  eval_accuracy: 0.5662637948989868 , global_step: 1727
- AI-Rank-log  1618985491.3389878  eval_accuracy: 0.5676653981208801 , global_step: 1728
- AI-Rank-log  1618985535.2419295  eval_accuracy: 0.5690670609474182 , global_step: 1729
- AI-Rank-log  1618985579.182258  eval_accuracy: 0.5687034726142883 , global_step: 1730
- AI-Rank-log  1618985623.1359541  eval_accuracy: 0.5696664452552795 , global_step: 1731
- AI-Rank-log  1618985667.017989  eval_accuracy: 0.5677787661552429 , global_step: 1732
- AI-Rank-log  1618985710.9741585  eval_accuracy: 0.5705708861351013 , global_step: 1733
- AI-Rank-log  1618985754.9335175  eval_accuracy: 0.570968508720398 , global_step: 1734
- AI-Rank-log  1618985798.8243742  eval_accuracy: 0.5698116421699524 , global_step: 1735
- AI-Rank-log  1618985842.7912292  eval_accuracy: 0.56982421875 , global_step: 1736
- AI-Rank-log  1618985886.7030547  eval_accuracy: 0.569624125957489 , global_step: 1737
- AI-Rank-log  1618985930.5889323  eval_accuracy: 0.5694426894187927 , global_step: 1738
- AI-Rank-log  1618985974.4995716  eval_accuracy: 0.5705512762069702 , global_step: 1739
- AI-Rank-log  1618986018.3620222  eval_accuracy: 0.5700551867485046 , global_step: 1740
- AI-Rank-log  1618986062.250342  eval_accuracy: 0.570592999458313 , global_step: 1741

yq01-sys-hic-k8s-v100-box-a225-0804:34470:34523 [0] misc/ibvwrap.cc:220 NCCL WARN Call to ibv_get_async_event failed
- AI-Rank-log  1618986106.2427032  eval_accuracy: 0.5694034099578857 , global_step: 1742
- AI-Rank-log  1618986150.1112  eval_accuracy: 0.5682127475738525 , global_step: 1743
- AI-Rank-log  1618986194.0314317  eval_accuracy: 0.5698736906051636 , global_step: 1744
- AI-Rank-log  1618986237.978418  eval_accuracy: 0.5686171650886536 , global_step: 1745
- AI-Rank-log  1618986281.836798  eval_accuracy: 0.570544421672821 , global_step: 1746
- AI-Rank-log  1618986325.799966  eval_accuracy: 0.5711861252784729 , global_step: 1747
- AI-Rank-log  1618986369.677546  eval_accuracy: 0.5693935751914978 , global_step: 1748
- AI-Rank-log  1618986413.563124  eval_accuracy: 0.5691494941711426 , global_step: 1749
- AI-Rank-log  1618986457.5938046  eval_accuracy: 0.5716018080711365 , global_step: 1750
- AI-Rank-log  1618986501.458182  eval_accuracy: 0.5727898478507996 , global_step: 1751
- AI-Rank-log  1618986545.350831  eval_accuracy: 0.5708164572715759 , global_step: 1752
- AI-Rank-log  1618986589.3589957  eval_accuracy: 0.5698984861373901 , global_step: 1753
- AI-Rank-log  1618986633.225133  eval_accuracy: 0.5719361901283264 , global_step: 1754
- AI-Rank-log  1618986677.207898  eval_accuracy: 0.5698775053024292 , global_step: 1755
- AI-Rank-log  1618986721.127061  eval_accuracy: 0.572543203830719 , global_step: 1756
- AI-Rank-log  1618986764.9951978  eval_accuracy: 0.5719913244247437 , global_step: 1757
- AI-Rank-log  1618986808.9896142  eval_accuracy: 0.5723364353179932 , global_step: 1758
- AI-Rank-log  1618986852.9386923  eval_accuracy: 0.5711686015129089 , global_step: 1759
- AI-Rank-log  1618986896.803422  eval_accuracy: 0.5737046599388123 , global_step: 1760
- AI-Rank-log  1618986940.7511775  eval_accuracy: 0.5706493854522705 , global_step: 1761
- AI-Rank-log  1618986984.68627  eval_accuracy: 0.5729735493659973 , global_step: 1762
- AI-Rank-log  1618987028.5180616  eval_accuracy: 0.5722926259040833 , global_step: 1763
- AI-Rank-log  1618987072.4704463  eval_accuracy: 0.5733654499053955 , global_step: 1764
- AI-Rank-log  1618987116.3351183  eval_accuracy: 0.5702601671218872 , global_step: 1765
- AI-Rank-log  1618987160.1994488  eval_accuracy: 0.5721626281738281 , global_step: 1766
- AI-Rank-log  1618987204.1897755  eval_accuracy: 0.5719918012619019 , global_step: 1767
- AI-Rank-log  1618987248.051218  eval_accuracy: 0.5739607214927673 , global_step: 1768
- AI-Rank-log  1618987291.9852061  eval_accuracy: 0.5736744999885559 , global_step: 1769
- AI-Rank-log  1618987335.8863535  eval_accuracy: 0.5733994245529175 , global_step: 1770
- AI-Rank-log  1618987381.2994883  eval_accuracy: 0.5738230347633362 , global_step: 1771
- AI-Rank-log  1618987426.5259361  eval_accuracy: 0.5732929110527039 , global_step: 1772
- AI-Rank-log  1618987470.9033482  eval_accuracy: 0.5706005096435547 , global_step: 1773
- AI-Rank-log  1618987515.276067  eval_accuracy: 0.5735214352607727 , global_step: 1774
- AI-Rank-log  1618987560.0179286  eval_accuracy: 0.5746329426765442 , global_step: 1775
- AI-Rank-log  1618987604.9799268  eval_accuracy: 0.5732346773147583 , global_step: 1776
- AI-Rank-log  1618987649.1853516  eval_accuracy: 0.5731881260871887 , global_step: 1777
- AI-Rank-log  1618987693.0297334  eval_accuracy: 0.5746029615402222 , global_step: 1778
- AI-Rank-log  1618987736.902891  eval_accuracy: 0.574607253074646 , global_step: 1779
- AI-Rank-log  1618987780.8366568  eval_accuracy: 0.5746995806694031 , global_step: 1780
- AI-Rank-log  1618987824.7842655  eval_accuracy: 0.5739686489105225 , global_step: 1781
- AI-Rank-log  1618987868.713442  eval_accuracy: 0.5740794539451599 , global_step: 1782
- AI-Rank-log  1618987912.6182442  eval_accuracy: 0.5739263892173767 , global_step: 1783
- AI-Rank-log  1618987956.5147054  eval_accuracy: 0.5735335350036621 , global_step: 1784
- AI-Rank-log  1618988000.372048  eval_accuracy: 0.574566125869751 , global_step: 1785
- AI-Rank-log  1618988044.2825954  eval_accuracy: 0.5751263499259949 , global_step: 1786
- AI-Rank-log  1618988088.1888742  eval_accuracy: 0.5761561989784241 , global_step: 1787
- AI-Rank-log  1618988132.1573236  eval_accuracy: 0.5758539438247681 , global_step: 1788
- AI-Rank-log  1618988175.9849055  eval_accuracy: 0.5760249495506287 , global_step: 1789
- AI-Rank-log  1618988219.8666606  eval_accuracy: 0.5766162872314453 , global_step: 1790
- AI-Rank-log  1618988263.789502  eval_accuracy: 0.5766687989234924 , global_step: 1791
- AI-Rank-log  1618988307.63641  eval_accuracy: 0.574004590511322 , global_step: 1792
- AI-Rank-log  1618988360.3371096  eval_accuracy: 0.5773674249649048 , global_step: 1793
- AI-Rank-log  1618988404.2792244  eval_accuracy: 0.5763993263244629 , global_step: 1794
- AI-Rank-log  1618988448.143553  eval_accuracy: 0.5757791996002197 , global_step: 1795
- AI-Rank-log  1618988492.0103917  eval_accuracy: 0.5773781538009644 , global_step: 1796
- AI-Rank-log  1618988535.9789534  eval_accuracy: 0.5770098567008972 , global_step: 1797
- AI-Rank-log  1618988579.79913  eval_accuracy: 0.576866626739502 , global_step: 1798
- AI-Rank-log  1618988623.7641795  eval_accuracy: 0.5778194069862366 , global_step: 1799
- AI-Rank-log  1618988667.6555  eval_accuracy: 0.576097846031189 , global_step: 1800
- AI-Rank-log  1618988711.4881349  eval_accuracy: 0.5761170983314514 , global_step: 1801
- AI-Rank-log  1618988755.4080563  eval_accuracy: 0.5770118832588196 , global_step: 1802
- AI-Rank-log  1618988799.2855878  eval_accuracy: 0.5745607018470764 , global_step: 1803
- AI-Rank-log  1618988843.1367702  eval_accuracy: 0.5758160948753357 , global_step: 1804
- AI-Rank-log  1618988887.022542  eval_accuracy: 0.5765855312347412 , global_step: 1805
- AI-Rank-log  1618988930.8834412  eval_accuracy: 0.5788719654083252 , global_step: 1806
- AI-Rank-log  1618988974.7073162  eval_accuracy: 0.5786557793617249 , global_step: 1807
- AI-Rank-log  1618989018.6808553  eval_accuracy: 0.5784361958503723 , global_step: 1808
- AI-Rank-log  1618989062.5170095  eval_accuracy: 0.5776047706604004 , global_step: 1809
- AI-Rank-log  1618989106.45754  eval_accuracy: 0.5794450640678406 , global_step: 1810
- AI-Rank-log  1618989150.3009818  eval_accuracy: 0.5757638812065125 , global_step: 1811
- AI-Rank-log  1618989194.1985252  eval_accuracy: 0.5786288380622864 , global_step: 1812
- AI-Rank-log  1618989238.121836  eval_accuracy: 0.5784868001937866 , global_step: 1813
- AI-Rank-log  1618989282.0253704  eval_accuracy: 0.5787680149078369 , global_step: 1814
- AI-Rank-log  1618989325.8813858  eval_accuracy: 0.577880322933197 , global_step: 1815
- AI-Rank-log  1618989369.848644  eval_accuracy: 0.5801738500595093 , global_step: 1816
- AI-Rank-log  1618989413.7020025  eval_accuracy: 0.5798118114471436 , global_step: 1817
- AI-Rank-log  1618989457.5164707  eval_accuracy: 0.5781100988388062 , global_step: 1818
- AI-Rank-log  1618989501.4605346  eval_accuracy: 0.5795280933380127 , global_step: 1819
- AI-Rank-log  1618989545.337854  eval_accuracy: 0.5806468725204468 , global_step: 1820
- AI-Rank-log  1618989589.251793  eval_accuracy: 0.5795749425888062 , global_step: 1821
- AI-Rank-log  1618989633.153199  eval_accuracy: 0.5778713822364807 , global_step: 1822
- AI-Rank-log  1618989677.0599575  eval_accuracy: 0.5796363353729248 , global_step: 1823
- AI-Rank-log  1618989720.99819  eval_accuracy: 0.5803946852684021 , global_step: 1824
- AI-Rank-log  1618989764.8412004  eval_accuracy: 0.5806449055671692 , global_step: 1825
- AI-Rank-log  1618989808.696939  eval_accuracy: 0.5803731083869934 , global_step: 1826
- AI-Rank-log  1618989852.6627116  eval_accuracy: 0.580941915512085 , global_step: 1827
- AI-Rank-log  1618989896.5312333  eval_accuracy: 0.5792839527130127 , global_step: 1828
- AI-Rank-log  1618989940.4112265  eval_accuracy: 0.580895721912384 , global_step: 1829
- AI-Rank-log  1618989984.307332  eval_accuracy: 0.5793944001197815 , global_step: 1830
- AI-Rank-log  1618990028.1728761  eval_accuracy: 0.5801495909690857 , global_step: 1831
- AI-Rank-log  1618990072.1198852  eval_accuracy: 0.580001950263977 , global_step: 1832
- AI-Rank-log  1618990115.9621918  eval_accuracy: 0.5806606411933899 , global_step: 1833
- AI-Rank-log  1618990159.850304  eval_accuracy: 0.5798816680908203 , global_step: 1834
- AI-Rank-log  1618990203.78954  eval_accuracy: 0.5802967548370361 , global_step: 1835
- AI-Rank-log  1618990247.6556623  eval_accuracy: 0.5805438756942749 , global_step: 1836
- AI-Rank-log  1618990291.5141945  eval_accuracy: 0.5806272625923157 , global_step: 1837
- AI-Rank-log  1618990335.4708884  eval_accuracy: 0.5809967517852783 , global_step: 1838
- AI-Rank-log  1618990379.3653524  eval_accuracy: 0.581824779510498 , global_step: 1839
- AI-Rank-log  1618990423.255246  eval_accuracy: 0.5806220769882202 , global_step: 1840
- AI-Rank-log  1618990467.122865  eval_accuracy: 0.581404447555542 , global_step: 1841
- AI-Rank-log  1618990510.981397  eval_accuracy: 0.5832399129867554 , global_step: 1842
- AI-Rank-log  1618990554.930262  eval_accuracy: 0.5812541246414185 , global_step: 1843
- AI-Rank-log  1618990598.7527711  eval_accuracy: 0.5817427635192871 , global_step: 1844
- AI-Rank-log  1618990642.6304505  eval_accuracy: 0.5798705816268921 , global_step: 1845
- AI-Rank-log  1618990686.569011  eval_accuracy: 0.5810070633888245 , global_step: 1846
- AI-Rank-log  1618990730.3959696  eval_accuracy: 0.5821000337600708 , global_step: 1847
- AI-Rank-log  1618990775.1175961  eval_accuracy: 0.5809704065322876 , global_step: 1848
- AI-Rank-log  1618990819.2473104  eval_accuracy: 0.5780462622642517 , global_step: 1849
- AI-Rank-log  1618990863.6606262  eval_accuracy: 0.5819811820983887 , global_step: 1850
- AI-Rank-log  1618990909.2477717  eval_accuracy: 0.5803320407867432 , global_step: 1851
- AI-Rank-log  1618990954.1299858  eval_accuracy: 0.582815945148468 , global_step: 1852
- AI-Rank-log  1618990999.1754014  eval_accuracy: 0.58238285779953 , global_step: 1853
- AI-Rank-log  1618991043.080019  eval_accuracy: 0.5837284326553345 , global_step: 1854
- AI-Rank-log  1618991087.2591093  eval_accuracy: 0.5839828252792358 , global_step: 1855
- AI-Rank-log  1618991131.1196895  eval_accuracy: 0.5827798843383789 , global_step: 1856
- AI-Rank-log  1618991175.0929098  eval_accuracy: 0.5828610062599182 , global_step: 1857
- AI-Rank-log  1618991218.9501  eval_accuracy: 0.5841195583343506 , global_step: 1858
- AI-Rank-log  1618991262.761917  eval_accuracy: 0.5829851627349854 , global_step: 1859
- AI-Rank-log  1618991306.701441  eval_accuracy: 0.5844485759735107 , global_step: 1860
- AI-Rank-log  1618991350.5439422  eval_accuracy: 0.5837627053260803 , global_step: 1861
- AI-Rank-log  1618991394.5005229  eval_accuracy: 0.5842916369438171 , global_step: 1862
- AI-Rank-log  1618991438.416961  eval_accuracy: 0.5824711918830872 , global_step: 1863
- AI-Rank-log  1618991482.2426157  eval_accuracy: 0.5847125053405762 , global_step: 1864
- AI-Rank-log  1618991526.1947584  eval_accuracy: 0.5835737586021423 , global_step: 1865
- AI-Rank-log  1618991570.0992434  eval_accuracy: 0.5842682719230652 , global_step: 1866
- AI-Rank-log  1618991613.939592  eval_accuracy: 0.5833437442779541 , global_step: 1867
- AI-Rank-log  1618991657.914255  eval_accuracy: 0.583078920841217 , global_step: 1868
- AI-Rank-log  1618991701.7494075  eval_accuracy: 0.5853747129440308 , global_step: 1869
- AI-Rank-log  1618991745.5619774  eval_accuracy: 0.5857060551643372 , global_step: 1870
- AI-Rank-log  1618991789.5161192  eval_accuracy: 0.5841741561889648 , global_step: 1871
- AI-Rank-log  1618991833.44927  eval_accuracy: 0.5846930146217346 , global_step: 1872
- AI-Rank-log  1618991877.388737  eval_accuracy: 0.5847571492195129 , global_step: 1873
- AI-Rank-log  1618991921.2545655  eval_accuracy: 0.5833320021629333 , global_step: 1874
- AI-Rank-log  1618991965.0950625  eval_accuracy: 0.5847290754318237 , global_step: 1875
- AI-Rank-log  1618992009.0151582  eval_accuracy: 0.584529459476471 , global_step: 1876
- AI-Rank-log  1618992052.9042504  eval_accuracy: 0.5851256251335144 , global_step: 1877
- AI-Rank-log  1618992096.78225  eval_accuracy: 0.5859584212303162 , global_step: 1878
- AI-Rank-log  1618992140.6621547  eval_accuracy: 0.5861068367958069 , global_step: 1879
- AI-Rank-log  1618992184.6060703  eval_accuracy: 0.5863726735115051 , global_step: 1880
- AI-Rank-log  1618992228.5325334  eval_accuracy: 0.5870829820632935 , global_step: 1881
- AI-Rank-log  1618992272.4187102  eval_accuracy: 0.5880163311958313 , global_step: 1882
- AI-Rank-log  1618992316.276417  eval_accuracy: 0.5874316692352295 , global_step: 1883
- AI-Rank-log  1618992360.2020414  eval_accuracy: 0.5862371921539307 , global_step: 1884
- AI-Rank-log  1618992404.0702813  eval_accuracy: 0.5871346592903137 , global_step: 1885
- AI-Rank-log  1618992447.9253793  eval_accuracy: 0.5864490866661072 , global_step: 1886
- AI-Rank-log  1618992491.855448  eval_accuracy: 0.5852363109588623 , global_step: 1887
- AI-Rank-log  1618992535.6675344  eval_accuracy: 0.5856779217720032 , global_step: 1888
- AI-Rank-log  1618992579.5377429  eval_accuracy: 0.5861296653747559 , global_step: 1889
- AI-Rank-log  1618992623.4529135  eval_accuracy: 0.5862221121788025 , global_step: 1890
- AI-Rank-log  1618992667.3111675  eval_accuracy: 0.5853431820869446 , global_step: 1891
- AI-Rank-log  1618992711.2614923  eval_accuracy: 0.5865813493728638 , global_step: 1892
- AI-Rank-log  1618992755.0771103  eval_accuracy: 0.5852823257446289 , global_step: 1893
- AI-Rank-log  1618992798.9582946  eval_accuracy: 0.5862997174263 , global_step: 1894
- AI-Rank-log  1618992842.897173  eval_accuracy: 0.5856404900550842 , global_step: 1895
- AI-Rank-log  1618992886.76835  eval_accuracy: 0.5886517763137817 , global_step: 1896
- AI-Rank-log  1618992930.6589496  eval_accuracy: 0.5873433947563171 , global_step: 1897
- AI-Rank-log  1618992974.608445  eval_accuracy: 0.5881824493408203 , global_step: 1898
- AI-Rank-log  1618993018.3932006  eval_accuracy: 0.5885140299797058 , global_step: 1899
- AI-Rank-log  1618993062.3252268  eval_accuracy: 0.5878648161888123 , global_step: 1900
- AI-Rank-log  1618993106.177772  eval_accuracy: 0.5874027013778687 , global_step: 1901
- AI-Rank-log  1618993150.0276608  eval_accuracy: 0.5893818736076355 , global_step: 1902
- AI-Rank-log  1618993193.8063369  eval_accuracy: 0.5890479683876038 , global_step: 1903
- AI-Rank-log  1618993237.6662908  eval_accuracy: 0.5893151164054871 , global_step: 1904
- AI-Rank-log  1618993281.517223  eval_accuracy: 0.587071418762207 , global_step: 1905
- AI-Rank-log  1618993325.4645138  eval_accuracy: 0.5884737968444824 , global_step: 1906
- AI-Rank-log  1618993369.2763069  eval_accuracy: 0.5851455926895142 , global_step: 1907
- AI-Rank-log  1618993413.1326294  eval_accuracy: 0.5891310572624207 , global_step: 1908
- AI-Rank-log  1618993457.1007574  eval_accuracy: 0.58863365650177 , global_step: 1909
- AI-Rank-log  1618993500.914982  eval_accuracy: 0.5870890617370605 , global_step: 1910
- AI-Rank-log  1618993544.7890072  eval_accuracy: 0.5878761410713196 , global_step: 1911
- AI-Rank-log  1618993588.7053359  eval_accuracy: 0.5886414647102356 , global_step: 1912
- AI-Rank-log  1618993632.5283868  eval_accuracy: 0.5886553525924683 , global_step: 1913
- AI-Rank-log  1618993676.4540043  eval_accuracy: 0.5893881320953369 , global_step: 1914
- AI-Rank-log  1618993720.3347573  eval_accuracy: 0.5873833298683167 , global_step: 1915
- AI-Rank-log  1618993764.1472094  eval_accuracy: 0.5897111892700195 , global_step: 1916
- AI-Rank-log  1618993808.1068997  eval_accuracy: 0.5893277525901794 , global_step: 1917
- AI-Rank-log  1618993851.957668  eval_accuracy: 0.5883883237838745 , global_step: 1918
- AI-Rank-log  1618993895.756411  eval_accuracy: 0.5869002938270569 , global_step: 1919
- AI-Rank-log  1618993939.6640093  eval_accuracy: 0.5884611010551453 , global_step: 1920
- AI-Rank-log  1618993983.5430253  eval_accuracy: 0.5884169936180115 , global_step: 1921
- AI-Rank-log  1618994027.4410203  eval_accuracy: 0.5897048711776733 , global_step: 1922
- AI-Rank-log  1618994071.3464816  eval_accuracy: 0.5910641551017761 , global_step: 1923
- AI-Rank-log  1618994115.207677  eval_accuracy: 0.5895659923553467 , global_step: 1924
- AI-Rank-log  1618994159.1286364  eval_accuracy: 0.5896732807159424 , global_step: 1925
- AI-Rank-log  1618994203.8087778  eval_accuracy: 0.5902959108352661 , global_step: 1926
- AI-Rank-log  1618994249.0374904  eval_accuracy: 0.591525673866272 , global_step: 1927
- AI-Rank-log  1618994293.190573  eval_accuracy: 0.5895727872848511 , global_step: 1928
- AI-Rank-log  1618994338.0711195  eval_accuracy: 0.5911957025527954 , global_step: 1929
- AI-Rank-log  1618994382.753832  eval_accuracy: 0.5883162021636963 , global_step: 1930
- AI-Rank-log  1618994427.5015585  eval_accuracy: 0.5911313891410828 , global_step: 1931
- AI-Rank-log  1618994471.6691337  eval_accuracy: 0.5908619165420532 , global_step: 1932
- AI-Rank-log  1618994515.5924885  eval_accuracy: 0.5902772545814514 , global_step: 1933
- AI-Rank-log  1618994559.447735  eval_accuracy: 0.5907817482948303 , global_step: 1934
- AI-Rank-log  1618994603.294508  eval_accuracy: 0.5915944576263428 , global_step: 1935
- AI-Rank-log  1618994647.2045238  eval_accuracy: 0.5919795036315918 , global_step: 1936
- AI-Rank-log  1618994691.066772  eval_accuracy: 0.590681791305542 , global_step: 1937
- AI-Rank-log  1618994734.965059  eval_accuracy: 0.590417742729187 , global_step: 1938
- AI-Rank-log  1618994778.8587894  eval_accuracy: 0.5923646688461304 , global_step: 1939
- AI-Rank-log  1618994822.696751  eval_accuracy: 0.5906001329421997 , global_step: 1940
- AI-Rank-log  1618994866.5954626  eval_accuracy: 0.5922389030456543 , global_step: 1941
- AI-Rank-log  1618994910.5144646  eval_accuracy: 0.5914770364761353 , global_step: 1942
- AI-Rank-log  1618994954.4040875  eval_accuracy: 0.5923751592636108 , global_step: 1943
- AI-Rank-log  1618994998.345646  eval_accuracy: 0.5921365022659302 , global_step: 1944
- AI-Rank-log  1618995042.2120373  eval_accuracy: 0.5919864773750305 , global_step: 1945
- AI-Rank-log  1618995086.0920796  eval_accuracy: 0.5918603539466858 , global_step: 1946
- AI-Rank-log  1618995130.0216486  eval_accuracy: 0.5915088057518005 , global_step: 1947
- AI-Rank-log  1618995173.8758898  eval_accuracy: 0.5927881598472595 , global_step: 1948
- AI-Rank-log  1618995217.7385712  eval_accuracy: 0.5925862193107605 , global_step: 1949
- AI-Rank-log  1618995261.69441  eval_accuracy: 0.5919641256332397 , global_step: 1950
- AI-Rank-log  1618995305.5333998  eval_accuracy: 0.5922895669937134 , global_step: 1951
- AI-Rank-log  1618995349.4731216  eval_accuracy: 0.592339277267456 , global_step: 1952
- AI-Rank-log  1618995393.3694572  eval_accuracy: 0.5916470885276794 , global_step: 1953
- AI-Rank-log  1618995437.2463024  eval_accuracy: 0.592948853969574 , global_step: 1954
- AI-Rank-log  1618995481.2004905  eval_accuracy: 0.5899491906166077 , global_step: 1955
- AI-Rank-log  1618995525.0451047  eval_accuracy: 0.5918726921081543 , global_step: 1956
- AI-Rank-log  1618995568.88626  eval_accuracy: 0.5933107137680054 , global_step: 1957
- AI-Rank-log  1618995612.8781996  eval_accuracy: 0.5921933650970459 , global_step: 1958
- AI-Rank-log  1618995656.7470167  eval_accuracy: 0.5935020446777344 , global_step: 1959
- AI-Rank-log  1618995700.6469996  eval_accuracy: 0.5933157801628113 , global_step: 1960
- AI-Rank-log  1618995744.6021967  eval_accuracy: 0.5940393805503845 , global_step: 1961
- AI-Rank-log  1618995788.4348385  eval_accuracy: 0.5946731567382812 , global_step: 1962
- AI-Rank-log  1618995832.3534508  eval_accuracy: 0.5946435928344727 , global_step: 1963
- AI-Rank-log  1618995876.2322354  eval_accuracy: 0.5942973494529724 , global_step: 1964
- AI-Rank-log  1618995920.0928335  eval_accuracy: 0.5945451855659485 , global_step: 1965
- AI-Rank-log  1618995964.0414126  eval_accuracy: 0.5944895148277283 , global_step: 1966
- AI-Rank-log  1618996007.943177  eval_accuracy: 0.5940107107162476 , global_step: 1967
- AI-Rank-log  1618996051.7986116  eval_accuracy: 0.5927522778511047 , global_step: 1968
- AI-Rank-log  1618996095.7887383  eval_accuracy: 0.5924216508865356 , global_step: 1969
- AI-Rank-log  1618996139.6282578  eval_accuracy: 0.5927510857582092 , global_step: 1970
- AI-Rank-log  1618996183.5438068  eval_accuracy: 0.5929868221282959 , global_step: 1971
- AI-Rank-log  1618996227.427594  eval_accuracy: 0.5937730669975281 , global_step: 1972
- AI-Rank-log  1618996271.2969995  eval_accuracy: 0.5946246981620789 , global_step: 1973
- AI-Rank-log  1618996315.241111  eval_accuracy: 0.5934654474258423 , global_step: 1974
- AI-Rank-log  1618996359.1230671  eval_accuracy: 0.5945325493812561 , global_step: 1975
- AI-Rank-log  1618996403.0048177  eval_accuracy: 0.5954656600952148 , global_step: 1976
- AI-Rank-log  1618996446.954248  eval_accuracy: 0.5951772928237915 , global_step: 1977
- AI-Rank-log  1618996490.8282716  eval_accuracy: 0.5953447222709656 , global_step: 1978
- AI-Rank-log  1618996534.6809611  eval_accuracy: 0.5954833626747131 , global_step: 1979
- AI-Rank-log  1618996578.5939012  eval_accuracy: 0.5969974994659424 , global_step: 1980
- AI-Rank-log  1618996622.4342844  eval_accuracy: 0.5964127779006958 , global_step: 1981
- AI-Rank-log  1618996666.353765  eval_accuracy: 0.5964921712875366 , global_step: 1982
- AI-Rank-log  1618996710.2049198  eval_accuracy: 0.5938350558280945 , global_step: 1983
- AI-Rank-log  1618996754.072285  eval_accuracy: 0.5968943238258362 , global_step: 1984
- AI-Rank-log  1618996797.959194  eval_accuracy: 0.594281017780304 , global_step: 1985
- AI-Rank-log  1618996841.8218226  eval_accuracy: 0.5970723032951355 , global_step: 1986
- AI-Rank-log  1618996885.6761916  eval_accuracy: 0.5939502120018005 , global_step: 1987
- AI-Rank-log  1618996929.612416  eval_accuracy: 0.5964498519897461 , global_step: 1988
- AI-Rank-log  1618996973.5584357  eval_accuracy: 0.5952125191688538 , global_step: 1989
- AI-Rank-log  1618997017.478208  eval_accuracy: 0.597751259803772 , global_step: 1990
- AI-Rank-log  1618997061.3474264  eval_accuracy: 0.5961971282958984 , global_step: 1991
- AI-Rank-log  1618997105.1978261  eval_accuracy: 0.5973975658416748 , global_step: 1992
- AI-Rank-log  1618997157.833928  eval_accuracy: 0.5962945222854614 , global_step: 1993
- AI-Rank-log  1618997201.6799464  eval_accuracy: 0.5966706871986389 , global_step: 1994
- AI-Rank-log  1618997245.5164561  eval_accuracy: 0.5956900715827942 , global_step: 1995
- AI-Rank-log  1618997289.4125116  eval_accuracy: 0.5964199304580688 , global_step: 1996
- AI-Rank-log  1618997333.26837  eval_accuracy: 0.5964858531951904 , global_step: 1997
- AI-Rank-log  1618997377.111991  eval_accuracy: 0.5967090129852295 , global_step: 1998
- AI-Rank-log  1618997421.0426853  eval_accuracy: 0.596015989780426 , global_step: 1999
- AI-Rank-log  1618997464.9087205  eval_accuracy: 0.5968391299247742 , global_step: 2000
- AI-Rank-log  1618997508.8853502  eval_accuracy: 0.5972890257835388 , global_step: 2001
- AI-Rank-log  1618997552.7707918  eval_accuracy: 0.5968458652496338 , global_step: 2002
- AI-Rank-log  1618997597.3693585  eval_accuracy: 0.5976739525794983 , global_step: 2003
- AI-Rank-log  1618997642.507579  eval_accuracy: 0.5950828790664673 , global_step: 2004
- AI-Rank-log  1618997686.8134966  eval_accuracy: 0.5985934734344482 , global_step: 2005
- AI-Rank-log  1618997731.5032637  eval_accuracy: 0.5970879197120667 , global_step: 2006
- AI-Rank-log  1618997776.0073135  eval_accuracy: 0.5980719327926636 , global_step: 2007
- AI-Rank-log  1618997821.0179253  eval_accuracy: 0.5972205400466919 , global_step: 2008
- AI-Rank-log  1618997865.6972022  eval_accuracy: 0.5985917448997498 , global_step: 2009
- AI-Rank-log  1618997909.5825958  eval_accuracy: 0.5977901816368103 , global_step: 2010
- AI-Rank-log  1618997953.426116  eval_accuracy: 0.5981871485710144 , global_step: 2011
- AI-Rank-log  1618997997.3316684  eval_accuracy: 0.5984617471694946 , global_step: 2012
- AI-Rank-log  1618998041.2452772  eval_accuracy: 0.5980587601661682 , global_step: 2013
- AI-Rank-log  1618998085.0688484  eval_accuracy: 0.5982103943824768 , global_step: 2014
- AI-Rank-log  1618998128.9475582  eval_accuracy: 0.5984808206558228 , global_step: 2015
- AI-Rank-log  1618998172.7997112  eval_accuracy: 0.5988555550575256 , global_step: 2016
- AI-Rank-log  1618998216.640237  eval_accuracy: 0.5976737141609192 , global_step: 2017
- AI-Rank-log  1618998260.5739648  eval_accuracy: 0.5981109738349915 , global_step: 2018
- AI-Rank-log  1618998304.4342785  eval_accuracy: 0.5990641117095947 , global_step: 2019
- AI-Rank-log  1618998348.3439202  eval_accuracy: 0.5982686877250671 , global_step: 2020
- AI-Rank-log  1618998392.205924  eval_accuracy: 0.5989687442779541 , global_step: 2021
- AI-Rank-log  1618998436.072433  eval_accuracy: 0.5988302826881409 , global_step: 2022
- AI-Rank-log  1618998479.9914005  eval_accuracy: 0.5975543260574341 , global_step: 2023
- AI-Rank-log  1618998523.85466  eval_accuracy: 0.5972260236740112 , global_step: 2024
- AI-Rank-log  1618998567.7067375  eval_accuracy: 0.5992618799209595 , global_step: 2025
- AI-Rank-log  1618998611.625522  eval_accuracy: 0.5985553860664368 , global_step: 2026
- AI-Rank-log  1618998655.4578207  eval_accuracy: 0.60052090883255 , global_step: 2027
- AI-Rank-log  1618998699.3728323  eval_accuracy: 0.5991070866584778 , global_step: 2028
- AI-Rank-log  1618998743.2074103  eval_accuracy: 0.6000161170959473 , global_step: 2029
- AI-Rank-log  1618998786.8813674  eval_accuracy: 0.599141001701355 , global_step: 2030
- AI-Rank-log  1618998830.8540635  eval_accuracy: 0.6002932190895081 , global_step: 2031
- AI-Rank-log  1618998874.6476645  eval_accuracy: 0.5977910161018372 , global_step: 2032
- AI-Rank-log  1618998918.5242639  eval_accuracy: 0.6001840829849243 , global_step: 2033
- AI-Rank-log  1618998962.4525049  eval_accuracy: 0.5997280478477478 , global_step: 2034
- AI-Rank-log  1618999006.2732098  eval_accuracy: 0.60041743516922 , global_step: 2035
- AI-Rank-log  1618999050.128455  eval_accuracy: 0.5980319380760193 , global_step: 2036
- AI-Rank-log  1618999094.0353196  eval_accuracy: 0.6007938385009766 , global_step: 2037
- AI-Rank-log  1618999137.8990211  eval_accuracy: 0.6006103754043579 , global_step: 2038
- AI-Rank-log  1618999181.8202329  eval_accuracy: 0.6013825535774231 , global_step: 2039
- AI-Rank-log  1618999225.7074308  eval_accuracy: 0.5996890068054199 , global_step: 2040
- AI-Rank-log  1618999269.5677507  eval_accuracy: 0.6008324027061462 , global_step: 2041
- AI-Rank-log  1618999313.4660187  eval_accuracy: 0.6007624864578247 , global_step: 2042
- AI-Rank-log  1618999357.3128226  eval_accuracy: 0.6021522879600525 , global_step: 2043
- AI-Rank-log  1618999401.2041984  eval_accuracy: 0.6011527180671692 , global_step: 2044
- AI-Rank-log  1618999445.1693773  eval_accuracy: 0.6007790565490723 , global_step: 2045
- AI-Rank-log  1618999489.0117662  eval_accuracy: 0.6008918881416321 , global_step: 2046
- AI-Rank-log  1618999532.8599193  eval_accuracy: 0.6014338135719299 , global_step: 2047
- AI-Rank-log  1618999576.7921681  eval_accuracy: 0.6003356575965881 , global_step: 2048
- AI-Rank-log  1618999620.5929859  eval_accuracy: 0.6004994511604309 , global_step: 2049
- AI-Rank-log  1618999664.550396  eval_accuracy: 0.6020769476890564 , global_step: 2050
- AI-Rank-log  1618999708.4122992  eval_accuracy: 0.6016172170639038 , global_step: 2051
- AI-Rank-log  1618999752.2268717  eval_accuracy: 0.6024662852287292 , global_step: 2052
- AI-Rank-log  1618999796.1440027  eval_accuracy: 0.6026406288146973 , global_step: 2053
- AI-Rank-log  1618999839.990099  eval_accuracy: 0.6016793847084045 , global_step: 2054
- AI-Rank-log  1618999883.8385363  eval_accuracy: 0.6023035645484924 , global_step: 2055
- AI-Rank-log  1618999927.7658875  eval_accuracy: 0.6006523370742798 , global_step: 2056
- AI-Rank-log  1618999971.6242428  eval_accuracy: 0.6019381880760193 , global_step: 2057
- AI-Rank-log  1619000015.4650865  eval_accuracy: 0.6007608771324158 , global_step: 2058
- AI-Rank-log  1619000059.3572068  eval_accuracy: 0.6023547053337097 , global_step: 2059
- AI-Rank-log  1619000103.1857212  eval_accuracy: 0.6019337177276611 , global_step: 2060
- AI-Rank-log  1619000147.0954576  eval_accuracy: 0.6021654009819031 , global_step: 2061
- AI-Rank-log  1619000190.9599662  eval_accuracy: 0.6025153994560242 , global_step: 2062
- AI-Rank-log  1619000234.7755153  eval_accuracy: 0.6014193892478943 , global_step: 2063
- AI-Rank-log  1619000278.667058  eval_accuracy: 0.602451741695404 , global_step: 2064
- AI-Rank-log  1619000322.5509567  eval_accuracy: 0.6019072532653809 , global_step: 2065
- AI-Rank-log  1619000366.39309  eval_accuracy: 0.6032883524894714 , global_step: 2066
- AI-Rank-log  1619000410.340434  eval_accuracy: 0.6014610528945923 , global_step: 2067
- AI-Rank-log  1619000454.1747472  eval_accuracy: 0.603063702583313 , global_step: 2068
- AI-Rank-log  1619000497.9842968  eval_accuracy: 0.6025434136390686 , global_step: 2069
- AI-Rank-log  1619000541.9578476  eval_accuracy: 0.6040496230125427 , global_step: 2070
- AI-Rank-log  1619000585.8439062  eval_accuracy: 0.6035922765731812 , global_step: 2071
- AI-Rank-log  1619000629.748517  eval_accuracy: 0.603750467300415 , global_step: 2072
- AI-Rank-log  1619000673.5900607  eval_accuracy: 0.6038480401039124 , global_step: 2073
- AI-Rank-log  1619000717.4420319  eval_accuracy: 0.6034931540489197 , global_step: 2074
- AI-Rank-log  1619000761.3682477  eval_accuracy: 0.60308438539505 , global_step: 2075
- AI-Rank-log  1619000805.2295222  eval_accuracy: 0.6029439568519592 , global_step: 2076
- AI-Rank-log  1619000849.1579397  eval_accuracy: 0.6026120185852051 , global_step: 2077
- AI-Rank-log  1619000893.0759885  eval_accuracy: 0.6015596389770508 , global_step: 2078
- AI-Rank-log  1619000936.9454045  eval_accuracy: 0.6043164730072021 , global_step: 2079
- AI-Rank-log  1619000981.6516442  eval_accuracy: 0.6041861772537231 , global_step: 2080
- AI-Rank-log  1619001025.9891837  eval_accuracy: 0.6034311652183533 , global_step: 2081
- AI-Rank-log  1619001071.2636013  eval_accuracy: 0.6040502190589905 , global_step: 2082
- AI-Rank-log  1619001115.908164  eval_accuracy: 0.6039466261863708 , global_step: 2083
- AI-Rank-log  1619001160.5640738  eval_accuracy: 0.6037096381187439 , global_step: 2084
- AI-Rank-log  1619001205.3149712  eval_accuracy: 0.6041021347045898 , global_step: 2085
- AI-Rank-log  1619001250.381695  eval_accuracy: 0.6047593951225281 , global_step: 2086
- AI-Rank-log  1619001294.3570828  eval_accuracy: 0.6051419377326965 , global_step: 2087
- AI-Rank-log  1619001338.2227523  eval_accuracy: 0.6066391468048096 , global_step: 2088
- AI-Rank-log  1619001382.1764934  eval_accuracy: 0.6057244539260864 , global_step: 2089
- AI-Rank-log  1619001425.9967945  eval_accuracy: 0.60560142993927 , global_step: 2090
- AI-Rank-log  1619001469.8620818  eval_accuracy: 0.6060430407524109 , global_step: 2091
- AI-Rank-log  1619001513.7663028  eval_accuracy: 0.6043394207954407 , global_step: 2092
- AI-Rank-log  1619001557.6319711  eval_accuracy: 0.6055092811584473 , global_step: 2093
- AI-Rank-log  1619001601.5543945  eval_accuracy: 0.6064327955245972 , global_step: 2094
- AI-Rank-log  1619001645.393592  eval_accuracy: 0.6053718328475952 , global_step: 2095
- AI-Rank-log  1619001689.2342513  eval_accuracy: 0.6059232354164124 , global_step: 2096
- AI-Rank-log  1619001733.1209872  eval_accuracy: 0.6059645414352417 , global_step: 2097
- AI-Rank-log  1619001776.9477026  eval_accuracy: 0.6060985326766968 , global_step: 2098
- AI-Rank-log  1619001820.8500032  eval_accuracy: 0.6049066185951233 , global_step: 2099
- AI-Rank-log  1619001864.7907996  eval_accuracy: 0.6063773036003113 , global_step: 2100
- AI-Rank-log  1619001908.612092  eval_accuracy: 0.6049081683158875 , global_step: 2101
- AI-Rank-log  1619001952.5412073  eval_accuracy: 0.6051291823387146 , global_step: 2102
- AI-Rank-log  1619001996.4155061  eval_accuracy: 0.6040022969245911 , global_step: 2103
- AI-Rank-log  1619002040.2177556  eval_accuracy: 0.6040173172950745 , global_step: 2104
- AI-Rank-log  1619002084.1701345  eval_accuracy: 0.6044684052467346 , global_step: 2105
- AI-Rank-log  1619002128.0210621  eval_accuracy: 0.6057960987091064 , global_step: 2106
- AI-Rank-log  1619002171.8825095  eval_accuracy: 0.6045478582382202 , global_step: 2107
- AI-Rank-log  1619002215.8204086  eval_accuracy: 0.6061690449714661 , global_step: 2108
- AI-Rank-log  1619002259.6424317  eval_accuracy: 0.6050284504890442 , global_step: 2109
- AI-Rank-log  1619002303.4831064  eval_accuracy: 0.6060448288917542 , global_step: 2110
- AI-Rank-log  1619002347.4366288  eval_accuracy: 0.6038181185722351 , global_step: 2111
- AI-Rank-log  1619002391.2787457  eval_accuracy: 0.6064797639846802 , global_step: 2112
- AI-Rank-log  1619002435.0999868  eval_accuracy: 0.6042173504829407 , global_step: 2113
- AI-Rank-log  1619002479.0004137  eval_accuracy: 0.6068438291549683 , global_step: 2114
- AI-Rank-log  1619002522.8480296  eval_accuracy: 0.6062620282173157 , global_step: 2115
- AI-Rank-log  1619002566.7098014  eval_accuracy: 0.6068131327629089 , global_step: 2116
- AI-Rank-log  1619002610.570604  eval_accuracy: 0.6068892478942871 , global_step: 2117
- AI-Rank-log  1619002654.429964  eval_accuracy: 0.607150673866272 , global_step: 2118
- AI-Rank-log  1619002698.3491356  eval_accuracy: 0.6068453788757324 , global_step: 2119
- AI-Rank-log  1619002742.2254066  eval_accuracy: 0.606069803237915 , global_step: 2120
- AI-Rank-log  1619002786.0087974  eval_accuracy: 0.6061633825302124 , global_step: 2121
- AI-Rank-log  1619002829.9095266  eval_accuracy: 0.6069469451904297 , global_step: 2122
- AI-Rank-log  1619002873.7737832  eval_accuracy: 0.6060310006141663 , global_step: 2123
- AI-Rank-log  1619002917.5728204  eval_accuracy: 0.6057415008544922 , global_step: 2124
- AI-Rank-log  1619002961.4925625  eval_accuracy: 0.6068331599235535 , global_step: 2125
- AI-Rank-log  1619003005.315809  eval_accuracy: 0.6073962450027466 , global_step: 2126
- AI-Rank-log  1619003049.2403378  eval_accuracy: 0.6062538027763367 , global_step: 2127
- AI-Rank-log  1619003093.0845175  eval_accuracy: 0.606904923915863 , global_step: 2128
- AI-Rank-log  1619003136.9135149  eval_accuracy: 0.606748640537262 , global_step: 2129
- AI-Rank-log  1619003180.7904284  eval_accuracy: 0.6064541339874268 , global_step: 2130
- AI-Rank-log  1619003224.6279957  eval_accuracy: 0.6064326763153076 , global_step: 2131
- AI-Rank-log  1619003268.452967  eval_accuracy: 0.6081996560096741 , global_step: 2132
- AI-Rank-log  1619003312.3197763  eval_accuracy: 0.6065664887428284 , global_step: 2133
- AI-Rank-log  1619003356.1201203  eval_accuracy: 0.608876645565033 , global_step: 2134
- AI-Rank-log  1619003399.9966404  eval_accuracy: 0.6055000424385071 , global_step: 2135
- AI-Rank-log  1619003443.8235884  eval_accuracy: 0.6078460216522217 , global_step: 2136
- AI-Rank-log  1619003487.7024677  eval_accuracy: 0.6080191135406494 , global_step: 2137
- AI-Rank-log  1619003531.570001  eval_accuracy: 0.6087036728858948 , global_step: 2138
- AI-Rank-log  1619003575.3605022  eval_accuracy: 0.6084569692611694 , global_step: 2139
- AI-Rank-log  1619003619.189466  eval_accuracy: 0.6082612872123718 , global_step: 2140
- AI-Rank-log  1619003663.061819  eval_accuracy: 0.60760897397995 , global_step: 2141
- AI-Rank-log  1619003706.8989713  eval_accuracy: 0.6079699397087097 , global_step: 2142
- AI-Rank-log  1619003750.7675312  eval_accuracy: 0.6088005304336548 , global_step: 2143
- AI-Rank-log  1619003794.6132822  eval_accuracy: 0.6093552112579346 , global_step: 2144
- AI-Rank-log  1619003838.4277794  eval_accuracy: 0.6096686124801636 , global_step: 2145
- AI-Rank-log  1619003882.3165016  eval_accuracy: 0.6082378029823303 , global_step: 2146
- AI-Rank-log  1619003926.11158  eval_accuracy: 0.6092525124549866 , global_step: 2147
- AI-Rank-log  1619003969.9632456  eval_accuracy: 0.6076715588569641 , global_step: 2148
- AI-Rank-log  1619004013.8856382  eval_accuracy: 0.6072179079055786 , global_step: 2149
- AI-Rank-log  1619004057.708641  eval_accuracy: 0.6069013476371765 , global_step: 2150
- AI-Rank-log  1619004101.567978  eval_accuracy: 0.6080389618873596 , global_step: 2151
- AI-Rank-log  1619004145.4640546  eval_accuracy: 0.6079531311988831 , global_step: 2152
- AI-Rank-log  1619004189.2517154  eval_accuracy: 0.6101230978965759 , global_step: 2153
- AI-Rank-log  1619004233.0859692  eval_accuracy: 0.6090666055679321 , global_step: 2154
- AI-Rank-log  1619004276.9412866  eval_accuracy: 0.6107532382011414 , global_step: 2155
- AI-Rank-log  1619004320.754892  eval_accuracy: 0.6091749668121338 , global_step: 2156
- AI-Rank-log  1619004365.5812232  eval_accuracy: 0.6091452240943909 , global_step: 2157
- AI-Rank-log  1619004410.0007765  eval_accuracy: 0.6086850762367249 , global_step: 2158
- AI-Rank-log  1619004454.3049126  eval_accuracy: 0.6101493239402771 , global_step: 2159
- AI-Rank-log  1619004499.0198095  eval_accuracy: 0.6093948483467102 , global_step: 2160
- AI-Rank-log  1619004542.923727  eval_accuracy: 0.6098354458808899 , global_step: 2161
- AI-Rank-log  1619004587.4825811  eval_accuracy: 0.6091870665550232 , global_step: 2162
- AI-Rank-log  1619004632.4629548  eval_accuracy: 0.609706699848175 , global_step: 2163
- AI-Rank-log  1619004676.2733877  eval_accuracy: 0.6106396317481995 , global_step: 2164
- AI-Rank-log  1619004720.3201234  eval_accuracy: 0.6112964749336243 , global_step: 2165
- AI-Rank-log  1619004764.214243  eval_accuracy: 0.6094754934310913 , global_step: 2166
- AI-Rank-log  1619004808.0384994  eval_accuracy: 0.6094663739204407 , global_step: 2167
- AI-Rank-log  1619004851.9628785  eval_accuracy: 0.6098927855491638 , global_step: 2168
- AI-Rank-log  1619004895.7690895  eval_accuracy: 0.6096619367599487 , global_step: 2169
- AI-Rank-log  1619004939.5821722  eval_accuracy: 0.6096619963645935 , global_step: 2170
- AI-Rank-log  1619004983.49444  eval_accuracy: 0.6095221638679504 , global_step: 2171
- AI-Rank-log  1619005027.3667307  eval_accuracy: 0.6104880571365356 , global_step: 2172
- AI-Rank-log  1619005071.2201676  eval_accuracy: 0.6091982126235962 , global_step: 2173
- AI-Rank-log  1619005115.1544974  eval_accuracy: 0.6111621856689453 , global_step: 2174
- AI-Rank-log  1619005159.0077178  eval_accuracy: 0.6109717488288879 , global_step: 2175
- AI-Rank-log  1619005202.8229535  eval_accuracy: 0.6113916039466858 , global_step: 2176
- AI-Rank-log  1619005246.747638  eval_accuracy: 0.6099080443382263 , global_step: 2177
- AI-Rank-log  1619005290.6188443  eval_accuracy: 0.610933244228363 , global_step: 2178
- AI-Rank-log  1619005334.425669  eval_accuracy: 0.6093736290931702 , global_step: 2179
- AI-Rank-log  1619005378.321546  eval_accuracy: 0.6120832562446594 , global_step: 2180
- AI-Rank-log  1619005422.1952207  eval_accuracy: 0.611652672290802 , global_step: 2181
- AI-Rank-log  1619005466.0210736  eval_accuracy: 0.6110620498657227 , global_step: 2182
- AI-Rank-log  1619005509.9007552  eval_accuracy: 0.611114501953125 , global_step: 2183
- AI-Rank-log  1619005553.7234957  eval_accuracy: 0.6100836396217346 , global_step: 2184
- AI-Rank-log  1619005597.614131  eval_accuracy: 0.6083029508590698 , global_step: 2185
- AI-Rank-log  1619005641.4765787  eval_accuracy: 0.6121169328689575 , global_step: 2186
- AI-Rank-log  1619005685.3025932  eval_accuracy: 0.6101911067962646 , global_step: 2187
- AI-Rank-log  1619005729.1921866  eval_accuracy: 0.6110957264900208 , global_step: 2188
- AI-Rank-log  1619005773.0781991  eval_accuracy: 0.6101877689361572 , global_step: 2189
- AI-Rank-log  1619005816.8607805  eval_accuracy: 0.6118480563163757 , global_step: 2190
- AI-Rank-log  1619005860.8127716  eval_accuracy: 0.6112201809883118 , global_step: 2191
- AI-Rank-log  1619005904.6535153  eval_accuracy: 0.6122857928276062 , global_step: 2192
- AI-Rank-log  1619005957.4646258  eval_accuracy: 0.6118072271347046 , global_step: 2193
- AI-Rank-log  1619006001.2718537  eval_accuracy: 0.6125568747520447 , global_step: 2194
- AI-Rank-log  1619006045.1405087  eval_accuracy: 0.6102422475814819 , global_step: 2195
- AI-Rank-log  1619006089.0032191  eval_accuracy: 0.6126639246940613 , global_step: 2196
- AI-Rank-log  1619006132.8375554  eval_accuracy: 0.6128464937210083 , global_step: 2197
- AI-Rank-log  1619006176.7093325  eval_accuracy: 0.6119148135185242 , global_step: 2198
- AI-Rank-log  1619006220.5689578  eval_accuracy: 0.6126224398612976 , global_step: 2199
- AI-Rank-log  1619006264.392262  eval_accuracy: 0.611133873462677 , global_step: 2200
- AI-Rank-log  1619006308.2948537  eval_accuracy: 0.6114720702171326 , global_step: 2201
- AI-Rank-log  1619006352.1099799  eval_accuracy: 0.6112440824508667 , global_step: 2202
- AI-Rank-log  1619006395.959086  eval_accuracy: 0.6120611429214478 , global_step: 2203
- AI-Rank-log  1619006439.8853002  eval_accuracy: 0.6122307181358337 , global_step: 2204
- AI-Rank-log  1619006483.6916668  eval_accuracy: 0.6126249432563782 , global_step: 2205
- AI-Rank-log  1619006527.5253613  eval_accuracy: 0.6113678216934204 , global_step: 2206
- AI-Rank-log  1619006571.5137854  eval_accuracy: 0.6123474836349487 , global_step: 2207
- AI-Rank-log  1619006615.3125348  eval_accuracy: 0.6107538938522339 , global_step: 2208
- AI-Rank-log  1619006659.1781442  eval_accuracy: 0.6130059361457825 , global_step: 2209
- AI-Rank-log  1619006703.027914  eval_accuracy: 0.6121767163276672 , global_step: 2210
- AI-Rank-log  1619006746.8458967  eval_accuracy: 0.6134597063064575 , global_step: 2211
- AI-Rank-log  1619006790.7752392  eval_accuracy: 0.6139776110649109 , global_step: 2212
- AI-Rank-log  1619006834.6229887  eval_accuracy: 0.6142536997795105 , global_step: 2213
- AI-Rank-log  1619006878.4534292  eval_accuracy: 0.6138034462928772 , global_step: 2214
- AI-Rank-log  1619006922.3680427  eval_accuracy: 0.6142804622650146 , global_step: 2215
- AI-Rank-log  1619006966.1831663  eval_accuracy: 0.6140205264091492 , global_step: 2216
- AI-Rank-log  1619007010.0253937  eval_accuracy: 0.6140263676643372 , global_step: 2217
- AI-Rank-log  1619007053.9390457  eval_accuracy: 0.6138734817504883 , global_step: 2218
- AI-Rank-log  1619007097.7460315  eval_accuracy: 0.6134166121482849 , global_step: 2219
- AI-Rank-log  1619007141.5534801  eval_accuracy: 0.6134580969810486 , global_step: 2220
- AI-Rank-log  1619007185.4473972  eval_accuracy: 0.6143324971199036 , global_step: 2221
- AI-Rank-log  1619007229.2782917  eval_accuracy: 0.6143186092376709 , global_step: 2222
- AI-Rank-log  1619007273.2104461  eval_accuracy: 0.6143760681152344 , global_step: 2223
- AI-Rank-log  1619007317.0542617  eval_accuracy: 0.6140953898429871 , global_step: 2224
- AI-Rank-log  1619007360.8904169  eval_accuracy: 0.6151074171066284 , global_step: 2225
- AI-Rank-log  1619007404.743099  eval_accuracy: 0.6150518655776978 , global_step: 2226
- AI-Rank-log  1619007448.61507  eval_accuracy: 0.6134334206581116 , global_step: 2227
- AI-Rank-log  1619007492.4581964  eval_accuracy: 0.6144447326660156 , global_step: 2228
- AI-Rank-log  1619007536.3391078  eval_accuracy: 0.6137939691543579 , global_step: 2229
- AI-Rank-log  1619007580.1699917  eval_accuracy: 0.612852156162262 , global_step: 2230
- AI-Rank-log  1619007624.0574079  eval_accuracy: 0.6142235398292542 , global_step: 2231
- AI-Rank-log  1619007667.9650419  eval_accuracy: 0.6146538257598877 , global_step: 2232
- AI-Rank-log  1619007711.7550733  eval_accuracy: 0.6143350005149841 , global_step: 2233
- AI-Rank-log  1619007755.58425  eval_accuracy: 0.6147529482841492 , global_step: 2234
- AI-Rank-log  1619007800.2201934  eval_accuracy: 0.6135855913162231 , global_step: 2235
- AI-Rank-log  1619007844.7272017  eval_accuracy: 0.616237461566925 , global_step: 2236
- AI-Rank-log  1619007889.2253501  eval_accuracy: 0.6143014430999756 , global_step: 2237
- AI-Rank-log  1619007934.6885242  eval_accuracy: 0.6154718399047852 , global_step: 2238
- AI-Rank-log  1619007978.6046472  eval_accuracy: 0.614506721496582 , global_step: 2239
- AI-Rank-log  1619008023.0699232  eval_accuracy: 0.6164700388908386 , global_step: 2240
- AI-Rank-log  1619008068.1912682  eval_accuracy: 0.6149930357933044 , global_step: 2241
- AI-Rank-log  1619008112.2777848  eval_accuracy: 0.6163758039474487 , global_step: 2242
- AI-Rank-log  1619008156.2043507  eval_accuracy: 0.6154980659484863 , global_step: 2243
- AI-Rank-log  1619008200.0699923  eval_accuracy: 0.6161546111106873 , global_step: 2244
- AI-Rank-log  1619008244.0039492  eval_accuracy: 0.6157434582710266 , global_step: 2245
- AI-Rank-log  1619008287.8498254  eval_accuracy: 0.6147758364677429 , global_step: 2246
- AI-Rank-log  1619008331.7166529  eval_accuracy: 0.6141654253005981 , global_step: 2247
- AI-Rank-log  1619008375.6006281  eval_accuracy: 0.6162360310554504 , global_step: 2248
- AI-Rank-log  1619008419.4701478  eval_accuracy: 0.6169478893280029 , global_step: 2249
- AI-Rank-log  1619008463.3142185  eval_accuracy: 0.6151650547981262 , global_step: 2250
- AI-Rank-log  1619008507.2427216  eval_accuracy: 0.6157510876655579 , global_step: 2251
- AI-Rank-log  1619008551.108783  eval_accuracy: 0.615821897983551 , global_step: 2252
- AI-Rank-log  1619008595.002846  eval_accuracy: 0.6166448593139648 , global_step: 2253
- AI-Rank-log  1619008638.9181948  eval_accuracy: 0.6157715320587158 , global_step: 2254
- AI-Rank-log  1619008682.7699032  eval_accuracy: 0.616555392742157 , global_step: 2255
- AI-Rank-log  1619008726.6757143  eval_accuracy: 0.6138520836830139 , global_step: 2256
- AI-Rank-log  1619008770.4911633  eval_accuracy: 0.6162967085838318 , global_step: 2257
- AI-Rank-log  1619008814.3595428  eval_accuracy: 0.6165910959243774 , global_step: 2258
- AI-Rank-log  1619008858.281215  eval_accuracy: 0.6154788732528687 , global_step: 2259
- AI-Rank-log  1619008902.085306  eval_accuracy: 0.6161192059516907 , global_step: 2260
- AI-Rank-log  1619008945.938134  eval_accuracy: 0.6170881390571594 , global_step: 2261
- AI-Rank-log  1619008989.8212934  eval_accuracy: 0.6151638627052307 , global_step: 2262
- AI-Rank-log  1619009033.6231678  eval_accuracy: 0.6160698533058167 , global_step: 2263
- AI-Rank-log  1619009077.4825544  eval_accuracy: 0.6165757775306702 , global_step: 2264
- AI-Rank-log  1619009121.3932168  eval_accuracy: 0.6164937019348145 , global_step: 2265
- AI-Rank-log  1619009165.2051969  eval_accuracy: 0.6172512769699097 , global_step: 2266
- AI-Rank-log  1619009209.0927613  eval_accuracy: 0.6164575219154358 , global_step: 2267
- AI-Rank-log  1619009252.906914  eval_accuracy: 0.6170218586921692 , global_step: 2268
- AI-Rank-log  1619009296.7674258  eval_accuracy: 0.61604243516922 , global_step: 2269
- AI-Rank-log  1619009340.7568858  eval_accuracy: 0.615256667137146 , global_step: 2270
- AI-Rank-log  1619009384.548471  eval_accuracy: 0.6152377724647522 , global_step: 2271
- AI-Rank-log  1619009428.4310532  eval_accuracy: 0.6168873906135559 , global_step: 2272
- AI-Rank-log  1619009472.277511  eval_accuracy: 0.6167773604393005 , global_step: 2273
- AI-Rank-log  1619009516.107466  eval_accuracy: 0.6164461970329285 , global_step: 2274
- AI-Rank-log  1619009559.954372  eval_accuracy: 0.6164017915725708 , global_step: 2275
- AI-Rank-log  1619009603.8768868  eval_accuracy: 0.6169450879096985 , global_step: 2276
- AI-Rank-log  1619009647.7083364  eval_accuracy: 0.6169177889823914 , global_step: 2277
- AI-Rank-log  1619009691.6484342  eval_accuracy: 0.6178713440895081 , global_step: 2278
- AI-Rank-log  1619009735.541708  eval_accuracy: 0.6176944375038147 , global_step: 2279
- AI-Rank-log  1619009779.351594  eval_accuracy: 0.6180882453918457 , global_step: 2280
- AI-Rank-log  1619009823.2967892  eval_accuracy: 0.6191011071205139 , global_step: 2281
- AI-Rank-log  1619009867.1368346  eval_accuracy: 0.618227481842041 , global_step: 2282
- AI-Rank-log  1619009910.9663684  eval_accuracy: 0.619019091129303 , global_step: 2283
- AI-Rank-log  1619009954.912647  eval_accuracy: 0.6171847581863403 , global_step: 2284
- AI-Rank-log  1619009998.7673564  eval_accuracy: 0.6186710000038147 , global_step: 2285
- AI-Rank-log  1619010042.6051784  eval_accuracy: 0.6159614324569702 , global_step: 2286
- AI-Rank-log  1619010086.5510466  eval_accuracy: 0.6187540292739868 , global_step: 2287
- AI-Rank-log  1619010130.3466544  eval_accuracy: 0.6160803437232971 , global_step: 2288
- AI-Rank-log  1619010174.1989393  eval_accuracy: 0.617379367351532 , global_step: 2289
- AI-Rank-log  1619010218.1243825  eval_accuracy: 0.6166630983352661 , global_step: 2290
- AI-Rank-log  1619010261.96545  eval_accuracy: 0.617861807346344 , global_step: 2291
- AI-Rank-log  1619010305.8479638  eval_accuracy: 0.6187645792961121 , global_step: 2292
- AI-Rank-log  1619010349.7268872  eval_accuracy: 0.6177324652671814 , global_step: 2293
- AI-Rank-log  1619010393.5129359  eval_accuracy: 0.6178378462791443 , global_step: 2294
- AI-Rank-log  1619010437.4347503  eval_accuracy: 0.6180463433265686 , global_step: 2295
- AI-Rank-log  1619010481.2760468  eval_accuracy: 0.6186431646347046 , global_step: 2296
- AI-Rank-log  1619010525.0586166  eval_accuracy: 0.6190775632858276 , global_step: 2297
- AI-Rank-log  1619010568.976496  eval_accuracy: 0.6202921867370605 , global_step: 2298
- AI-Rank-log  1619010612.8233523  eval_accuracy: 0.6189201474189758 , global_step: 2299
- AI-Rank-log  1619010656.7204278  eval_accuracy: 0.6202227473258972 , global_step: 2300
- AI-Rank-log  1619010700.583162  eval_accuracy: 0.6202189326286316 , global_step: 2301
- AI-Rank-log  1619010744.4416711  eval_accuracy: 0.6193728446960449 , global_step: 2302
- AI-Rank-log  1619010788.3395503  eval_accuracy: 0.6198156476020813 , global_step: 2303
- AI-Rank-log  1619010832.1536276  eval_accuracy: 0.6203567385673523 , global_step: 2304
- AI-Rank-log  1619010876.0042462  eval_accuracy: 0.6187624335289001 , global_step: 2305
- AI-Rank-log  1619010919.8834016  eval_accuracy: 0.6194846034049988 , global_step: 2306
- AI-Rank-log  1619010963.7254696  eval_accuracy: 0.6190963983535767 , global_step: 2307
- AI-Rank-log  1619011007.6143324  eval_accuracy: 0.6189596056938171 , global_step: 2308
- AI-Rank-log  1619011052.46109  eval_accuracy: 0.6187763810157776 , global_step: 2309
- AI-Rank-log  1619011096.3381872  eval_accuracy: 0.6190159320831299 , global_step: 2310
- AI-Rank-log  1619011140.2530372  eval_accuracy: 0.6193370819091797 , global_step: 2311
- AI-Rank-log  1619011185.0113435  eval_accuracy: 0.6185738444328308 , global_step: 2312
- AI-Rank-log  1619011228.8578362  eval_accuracy: 0.6206580400466919 , global_step: 2313
- AI-Rank-log  1619011273.334596  eval_accuracy: 0.6195669770240784 , global_step: 2314
- AI-Rank-log  1619011317.3442576  eval_accuracy: 0.6207363605499268 , global_step: 2315
- AI-Rank-log  1619011361.7512953  eval_accuracy: 0.6181023716926575 , global_step: 2316
- AI-Rank-log  1619011406.8925786  eval_accuracy: 0.620772123336792 , global_step: 2317
- AI-Rank-log  1619011451.9123106  eval_accuracy: 0.6201369166374207 , global_step: 2318
- AI-Rank-log  1619011495.8559625  eval_accuracy: 0.6191758513450623 , global_step: 2319
- AI-Rank-log  1619011539.9301243  eval_accuracy: 0.6180794835090637 , global_step: 2320
- AI-Rank-log  1619011583.8120065  eval_accuracy: 0.6197471618652344 , global_step: 2321
- AI-Rank-log  1619011627.7248967  eval_accuracy: 0.6192877292633057 , global_step: 2322
- AI-Rank-log  1619011671.552556  eval_accuracy: 0.6200571060180664 , global_step: 2323
- AI-Rank-log  1619011715.417787  eval_accuracy: 0.6204062700271606 , global_step: 2324
- AI-Rank-log  1619011759.3003788  eval_accuracy: 0.6196027398109436 , global_step: 2325
- AI-Rank-log  1619011803.1122088  eval_accuracy: 0.619109034538269 , global_step: 2326
- AI-Rank-log  1619011846.9473088  eval_accuracy: 0.6177526712417603 , global_step: 2327
- AI-Rank-log  1619011890.8802836  eval_accuracy: 0.6205353140830994 , global_step: 2328
- AI-Rank-log  1619011934.7105064  eval_accuracy: 0.61919766664505 , global_step: 2329
- AI-Rank-log  1619011978.656124  eval_accuracy: 0.620637834072113 , global_step: 2330
- AI-Rank-log  1619012022.526749  eval_accuracy: 0.6206137537956238 , global_step: 2331
- AI-Rank-log  1619012066.323114  eval_accuracy: 0.6216591000556946 , global_step: 2332
- AI-Rank-log  1619012110.2196653  eval_accuracy: 0.6204711198806763 , global_step: 2333
- AI-Rank-log  1619012154.0285695  eval_accuracy: 0.6207321286201477 , global_step: 2334
- AI-Rank-log  1619012197.8591437  eval_accuracy: 0.6216965317726135 , global_step: 2335
- AI-Rank-log  1619012241.7827382  eval_accuracy: 0.6195062398910522 , global_step: 2336
- AI-Rank-log  1619012285.6282892  eval_accuracy: 0.6207634806632996 , global_step: 2337
- AI-Rank-log  1619012329.4473143  eval_accuracy: 0.620598554611206 , global_step: 2338
- AI-Rank-log  1619012373.3389897  eval_accuracy: 0.6211717128753662 , global_step: 2339
- AI-Rank-log  1619012417.1421847  eval_accuracy: 0.6191515326499939 , global_step: 2340
- AI-Rank-log  1619012461.0481393  eval_accuracy: 0.6204589009284973 , global_step: 2341
- AI-Rank-log  1619012504.9211543  eval_accuracy: 0.6192024350166321 , global_step: 2342
- AI-Rank-log  1619012548.712967  eval_accuracy: 0.6203224658966064 , global_step: 2343
- AI-Rank-log  1619012592.639612  eval_accuracy: 0.6213547587394714 , global_step: 2344
- AI-Rank-log  1619012636.3253562  eval_accuracy: 0.6212530732154846 , global_step: 2345
- AI-Rank-log  1619012680.1598852  eval_accuracy: 0.6205521821975708 , global_step: 2346
- AI-Rank-log  1619012724.029316  eval_accuracy: 0.6207761764526367 , global_step: 2347
- AI-Rank-log  1619012767.9733438  eval_accuracy: 0.6221171021461487 , global_step: 2348
- AI-Rank-log  1619012811.8735564  eval_accuracy: 0.6211054921150208 , global_step: 2349
- AI-Rank-log  1619012855.6864333  eval_accuracy: 0.6213011145591736 , global_step: 2350
- AI-Rank-log  1619012899.531533  eval_accuracy: 0.62020343542099 , global_step: 2351
- AI-Rank-log  1619012943.4153588  eval_accuracy: 0.6214342713356018 , global_step: 2352
- AI-Rank-log  1619012987.2735965  eval_accuracy: 0.621371865272522 , global_step: 2353
- AI-Rank-log  1619013031.137731  eval_accuracy: 0.6216092705726624 , global_step: 2354
- AI-Rank-log  1619013075.0473754  eval_accuracy: 0.6210278272628784 , global_step: 2355
- AI-Rank-log  1619013118.900085  eval_accuracy: 0.6213974356651306 , global_step: 2356
- AI-Rank-log  1619013162.7305474  eval_accuracy: 0.6216471195220947 , global_step: 2357
- AI-Rank-log  1619013206.6277213  eval_accuracy: 0.6219571232795715 , global_step: 2358
- AI-Rank-log  1619013250.5062883  eval_accuracy: 0.621960461139679 , global_step: 2359
- AI-Rank-log  1619013294.4267352  eval_accuracy: 0.6231440305709839 , global_step: 2360
- AI-Rank-log  1619013338.2622707  eval_accuracy: 0.6214298009872437 , global_step: 2361
- AI-Rank-log  1619013382.1384091  eval_accuracy: 0.6222826242446899 , global_step: 2362
- AI-Rank-log  1619013426.0445116  eval_accuracy: 0.6223995089530945 , global_step: 2363
- AI-Rank-log  1619013469.8935533  eval_accuracy: 0.6233420372009277 , global_step: 2364
- AI-Rank-log  1619013513.743858  eval_accuracy: 0.6222708225250244 , global_step: 2365
- AI-Rank-log  1619013557.6140435  eval_accuracy: 0.622748851776123 , global_step: 2366
- AI-Rank-log  1619013601.4837742  eval_accuracy: 0.6200964450836182 , global_step: 2367
- AI-Rank-log  1619013645.405535  eval_accuracy: 0.6227473616600037 , global_step: 2368
- AI-Rank-log  1619013689.1853023  eval_accuracy: 0.6216176748275757 , global_step: 2369
- AI-Rank-log  1619013733.057049  eval_accuracy: 0.6226423382759094 , global_step: 2370
- AI-Rank-log  1619013776.9892812  eval_accuracy: 0.6224199533462524 , global_step: 2371
- AI-Rank-log  1619013820.7990518  eval_accuracy: 0.62294602394104 , global_step: 2372
- AI-Rank-log  1619013864.6384358  eval_accuracy: 0.6212976574897766 , global_step: 2373
- AI-Rank-log  1619013908.5544302  eval_accuracy: 0.6237753629684448 , global_step: 2374
- AI-Rank-log  1619013952.4064379  eval_accuracy: 0.622623085975647 , global_step: 2375
- AI-Rank-log  1619013996.2372084  eval_accuracy: 0.6236722469329834 , global_step: 2376
- AI-Rank-log  1619014040.247628  eval_accuracy: 0.6226866841316223 , global_step: 2377
- AI-Rank-log  1619014084.0749314  eval_accuracy: 0.6241475343704224 , global_step: 2378
- AI-Rank-log  1619014127.954157  eval_accuracy: 0.622963547706604 , global_step: 2379
- AI-Rank-log  1619014171.7934368  eval_accuracy: 0.6234602332115173 , global_step: 2380
- AI-Rank-log  1619014215.6313167  eval_accuracy: 0.6219413876533508 , global_step: 2381
- AI-Rank-log  1619014259.5473986  eval_accuracy: 0.6208012104034424 , global_step: 2382
- AI-Rank-log  1619014303.3974938  eval_accuracy: 0.6222960352897644 , global_step: 2383
- AI-Rank-log  1619014347.2270591  eval_accuracy: 0.6229009032249451 , global_step: 2384
- AI-Rank-log  1619014391.1213543  eval_accuracy: 0.6232083439826965 , global_step: 2385
- AI-Rank-log  1619014434.9384873  eval_accuracy: 0.6221882700920105 , global_step: 2386
- AI-Rank-log  1619014478.8761613  eval_accuracy: 0.6216487884521484 , global_step: 2387
- AI-Rank-log  1619014522.6984441  eval_accuracy: 0.6221555471420288 , global_step: 2388
- AI-Rank-log  1619014566.284608  eval_accuracy: 0.6234083771705627 , global_step: 2389
- AI-Rank-log  1619014611.0675008  eval_accuracy: 0.6218354105949402 , global_step: 2390
- AI-Rank-log  1619014656.3637214  eval_accuracy: 0.6226707696914673 , global_step: 2391
- AI-Rank-log  1619014701.548412  eval_accuracy: 0.6225491762161255 , global_step: 2392
- AI-Rank-log  1619014754.350733  eval_accuracy: 0.6231918931007385 , global_step: 2393
- AI-Rank-log  1619014799.4593265  eval_accuracy: 0.6232810616493225 , global_step: 2394
- AI-Rank-log  1619014844.1722965  eval_accuracy: 0.6219882369041443 , global_step: 2395
- AI-Rank-log  1619014889.275763  eval_accuracy: 0.6236514449119568 , global_step: 2396
- AI-Rank-log  1619014933.1027358  eval_accuracy: 0.6237667202949524 , global_step: 2397
- AI-Rank-log  1619014977.2026935  eval_accuracy: 0.6213479042053223 , global_step: 2398
- AI-Rank-log  1619015021.018816  eval_accuracy: 0.623757541179657 , global_step: 2399
- AI-Rank-log  1619015064.861426  eval_accuracy: 0.6241266131401062 , global_step: 2400
- AI-Rank-log  1619015108.772292  eval_accuracy: 0.6244741678237915 , global_step: 2401
- AI-Rank-log  1619015152.6075206  eval_accuracy: 0.6247058510780334 , global_step: 2402
- AI-Rank-log  1619015196.451015  eval_accuracy: 0.623615026473999 , global_step: 2403
- AI-Rank-log  1619015240.328614  eval_accuracy: 0.6239172220230103 , global_step: 2404
- AI-Rank-log  1619015284.1885443  eval_accuracy: 0.623589038848877 , global_step: 2405
- AI-Rank-log  1619015328.0289836  eval_accuracy: 0.6230469942092896 , global_step: 2406
- AI-Rank-log  1619015371.9369633  eval_accuracy: 0.6248215436935425 , global_step: 2407
- AI-Rank-log  1619015415.8212688  eval_accuracy: 0.624509871006012 , global_step: 2408
- AI-Rank-log  1619015459.6697974  eval_accuracy: 0.6243798136711121 , global_step: 2409
- AI-Rank-log  1619015503.5763679  eval_accuracy: 0.6252344846725464 , global_step: 2410
- AI-Rank-log  1619015547.4381483  eval_accuracy: 0.6258555054664612 , global_step: 2411
- AI-Rank-log  1619015591.3203106  eval_accuracy: 0.6259008049964905 , global_step: 2412
- AI-Rank-log  1619015635.1392734  eval_accuracy: 0.625248908996582 , global_step: 2413
- AI-Rank-log  1619015678.9814677  eval_accuracy: 0.6252765655517578 , global_step: 2414
- AI-Rank-log  1619015722.8994226  eval_accuracy: 0.6254895329475403 , global_step: 2415
- AI-Rank-log  1619015766.7352014  eval_accuracy: 0.6248512864112854 , global_step: 2416
- AI-Rank-log  1619015810.591031  eval_accuracy: 0.6245576739311218 , global_step: 2417
- AI-Rank-log  1619015854.5256467  eval_accuracy: 0.6237761378288269 , global_step: 2418
- AI-Rank-log  1619015898.3385456  eval_accuracy: 0.6251675486564636 , global_step: 2419
- AI-Rank-log  1619015942.232757  eval_accuracy: 0.6252129673957825 , global_step: 2420
- AI-Rank-log  1619015986.051972  eval_accuracy: 0.6266108155250549 , global_step: 2421
- AI-Rank-log  1619016029.942322  eval_accuracy: 0.6263376474380493 , global_step: 2422
- AI-Rank-log  1619016073.866722  eval_accuracy: 0.626190185546875 , global_step: 2423
- AI-Rank-log  1619016117.7102413  eval_accuracy: 0.6260386109352112 , global_step: 2424
- AI-Rank-log  1619016161.5476787  eval_accuracy: 0.6245926022529602 , global_step: 2425
- AI-Rank-log  1619016205.4409728  eval_accuracy: 0.6268213987350464 , global_step: 2426
- AI-Rank-log  1619016249.3028884  eval_accuracy: 0.6233870387077332 , global_step: 2427
- AI-Rank-log  1619016293.130531  eval_accuracy: 0.6262545585632324 , global_step: 2428
- AI-Rank-log  1619016337.029494  eval_accuracy: 0.6231330633163452 , global_step: 2429
- AI-Rank-log  1619016380.8806956  eval_accuracy: 0.6256146430969238 , global_step: 2430
- AI-Rank-log  1619016424.8070893  eval_accuracy: 0.6252065300941467 , global_step: 2431
- AI-Rank-log  1619016468.6495545  eval_accuracy: 0.6258843541145325 , global_step: 2432
- AI-Rank-log  1619016512.5000038  eval_accuracy: 0.6259057521820068 , global_step: 2433
- AI-Rank-log  1619016556.427199  eval_accuracy: 0.626422107219696 , global_step: 2434
- AI-Rank-log  1619016600.257032  eval_accuracy: 0.6268457174301147 , global_step: 2435
- AI-Rank-log  1619016644.038706  eval_accuracy: 0.6262118816375732 , global_step: 2436
- AI-Rank-log  1619016687.946324  eval_accuracy: 0.6260617971420288 , global_step: 2437
- AI-Rank-log  1619016731.7946227  eval_accuracy: 0.6258890628814697 , global_step: 2438
- AI-Rank-log  1619016775.5983517  eval_accuracy: 0.6251336932182312 , global_step: 2439
- AI-Rank-log  1619016819.4992633  eval_accuracy: 0.6265469193458557 , global_step: 2440
- AI-Rank-log  1619016863.3281467  eval_accuracy: 0.6264558434486389 , global_step: 2441
- AI-Rank-log  1619016907.1765566  eval_accuracy: 0.6267356872558594 , global_step: 2442
- AI-Rank-log  1619016951.0308976  eval_accuracy: 0.6250734925270081 , global_step: 2443
- AI-Rank-log  1619016994.8759797  eval_accuracy: 0.6267898678779602 , global_step: 2444
- AI-Rank-log  1619017038.872323  eval_accuracy: 0.625523030757904 , global_step: 2445
- AI-Rank-log  1619017082.710171  eval_accuracy: 0.6261325478553772 , global_step: 2446
- AI-Rank-log  1619017126.5313838  eval_accuracy: 0.6271798610687256 , global_step: 2447
- AI-Rank-log  1619017170.4653385  eval_accuracy: 0.6254571080207825 , global_step: 2448
- AI-Rank-log  1619017214.3086534  eval_accuracy: 0.6264941096305847 , global_step: 2449
- AI-Rank-log  1619017258.119763  eval_accuracy: 0.6264883279800415 , global_step: 2450
- AI-Rank-log  1619017302.000867  eval_accuracy: 0.6271796822547913 , global_step: 2451
- AI-Rank-log  1619017345.8383543  eval_accuracy: 0.6274276971817017 , global_step: 2452
- AI-Rank-log  1619017389.7079735  eval_accuracy: 0.6278806924819946 , global_step: 2453
- AI-Rank-log  1619017433.5341797  eval_accuracy: 0.6274663805961609 , global_step: 2454
- AI-Rank-log  1619017477.3947184  eval_accuracy: 0.6272104382514954 , global_step: 2455
- AI-Rank-log  1619017521.2544584  eval_accuracy: 0.6273580193519592 , global_step: 2456
- AI-Rank-log  1619017565.1058095  eval_accuracy: 0.6262670755386353 , global_step: 2457
- AI-Rank-log  1619017608.9452083  eval_accuracy: 0.6279557943344116 , global_step: 2458
- AI-Rank-log  1619017652.8775554  eval_accuracy: 0.6265686750411987 , global_step: 2459
- AI-Rank-log  1619017696.7338626  eval_accuracy: 0.6276648640632629 , global_step: 2460
- AI-Rank-log  1619017740.6413352  eval_accuracy: 0.6277331709861755 , global_step: 2461
- AI-Rank-log  1619017784.540328  eval_accuracy: 0.6278815865516663 , global_step: 2462
- AI-Rank-log  1619017828.3955083  eval_accuracy: 0.626724898815155 , global_step: 2463
- AI-Rank-log  1619017872.3009942  eval_accuracy: 0.6276333928108215 , global_step: 2464
- AI-Rank-log  1619017916.124354  eval_accuracy: 0.6253297328948975 , global_step: 2465
- AI-Rank-log  1619017959.9736714  eval_accuracy: 0.6272370219230652 , global_step: 2466
- AI-Rank-log  1619018004.652207  eval_accuracy: 0.6265513896942139 , global_step: 2467
- AI-Rank-log  1619018048.5066414  eval_accuracy: 0.6272863149642944 , global_step: 2468
- AI-Rank-log  1619018092.965459  eval_accuracy: 0.6289514303207397 , global_step: 2469
- AI-Rank-log  1619018138.0923522  eval_accuracy: 0.6279724836349487 , global_step: 2470
- AI-Rank-log  1619018182.798794  eval_accuracy: 0.6284104585647583 , global_step: 2471
- AI-Rank-log  1619018227.5728316  eval_accuracy: 0.6278166770935059 , global_step: 2472
- AI-Rank-log  1619018272.5440085  eval_accuracy: 0.6276288032531738 , global_step: 2473
- AI-Rank-log  1619018316.369789  eval_accuracy: 0.6291357278823853 , global_step: 2474
- AI-Rank-log  1619018360.4805624  eval_accuracy: 0.6280423998832703 , global_step: 2475
- AI-Rank-log  1619018404.3522472  eval_accuracy: 0.6282942295074463 , global_step: 2476
- AI-Rank-log  1619018448.173083  eval_accuracy: 0.6272082328796387 , global_step: 2477
- AI-Rank-log  1619018492.0612493  eval_accuracy: 0.6287204623222351 , global_step: 2478
- AI-Rank-log  1619018535.8878016  eval_accuracy: 0.6269425749778748 , global_step: 2479
- AI-Rank-log  1619018579.7170138  eval_accuracy: 0.629123866558075 , global_step: 2480
- AI-Rank-log  1619018623.597524  eval_accuracy: 0.6271427869796753 , global_step: 2481
- AI-Rank-log  1619018667.405  eval_accuracy: 0.6288664937019348 , global_step: 2482
- AI-Rank-log  1619018711.356462  eval_accuracy: 0.6284521222114563 , global_step: 2483
- AI-Rank-log  1619018755.2354126  eval_accuracy: 0.629423201084137 , global_step: 2484
- AI-Rank-log  1619018799.0847113  eval_accuracy: 0.6273249387741089 , global_step: 2485
- AI-Rank-log  1619018842.9950697  eval_accuracy: 0.6270164251327515 , global_step: 2486
- AI-Rank-log  1619018886.8359892  eval_accuracy: 0.6271125674247742 , global_step: 2487
- AI-Rank-log  1619018930.6369963  eval_accuracy: 0.6283945441246033 , global_step: 2488
- AI-Rank-log  1619018974.540652  eval_accuracy: 0.6275357007980347 , global_step: 2489
- AI-Rank-log  1619019018.3644185  eval_accuracy: 0.6285869479179382 , global_step: 2490
- AI-Rank-log  1619019062.2435372  eval_accuracy: 0.6285867094993591 , global_step: 2491
- AI-Rank-log  1619019106.0982537  eval_accuracy: 0.629177987575531 , global_step: 2492
- AI-Rank-log  1619019149.9082673  eval_accuracy: 0.6293237209320068 , global_step: 2493
- AI-Rank-log  1619019193.8037605  eval_accuracy: 0.6277981400489807 , global_step: 2494
- AI-Rank-log  1619019237.652899  eval_accuracy: 0.6289012432098389 , global_step: 2495
- AI-Rank-log  1619019281.5170684  eval_accuracy: 0.6288096904754639 , global_step: 2496
- AI-Rank-log  1619019325.428346  eval_accuracy: 0.6300655007362366 , global_step: 2497
- AI-Rank-log  1619019369.2910774  eval_accuracy: 0.6287100911140442 , global_step: 2498
- AI-Rank-log  1619019413.1555321  eval_accuracy: 0.6290537714958191 , global_step: 2499
- AI-Rank-log  1619019456.9876068  eval_accuracy: 0.6269456744194031 , global_step: 2500
- AI-Rank-log  1619019500.8411582  eval_accuracy: 0.6268148422241211 , global_step: 2501
- AI-Rank-log  1619019544.6767821  eval_accuracy: 0.627991795539856 , global_step: 2502
- AI-Rank-log  1619019588.509322  eval_accuracy: 0.6292726993560791 , global_step: 2503
- AI-Rank-log  1619019632.378605  eval_accuracy: 0.6282357573509216 , global_step: 2504
- AI-Rank-log  1619019676.2172935  eval_accuracy: 0.6299158334732056 , global_step: 2505
- AI-Rank-log  1619019720.0609748  eval_accuracy: 0.6309189200401306 , global_step: 2506
- AI-Rank-log  1619019763.9452686  eval_accuracy: 0.6299340128898621 , global_step: 2507
- AI-Rank-log  1619019807.831128  eval_accuracy: 0.6295561194419861 , global_step: 2508
- AI-Rank-log  1619019851.6916852  eval_accuracy: 0.6296274662017822 , global_step: 2509
- AI-Rank-log  1619019895.54011  eval_accuracy: 0.63031005859375 , global_step: 2510
- AI-Rank-log  1619019939.4262233  eval_accuracy: 0.6281928420066833 , global_step: 2511
- AI-Rank-log  1619019983.2954972  eval_accuracy: 0.6278857588768005 , global_step: 2512
- AI-Rank-log  1619020027.2178736  eval_accuracy: 0.6258912682533264 , global_step: 2513
- AI-Rank-log  1619020071.0345068  eval_accuracy: 0.6292768120765686 , global_step: 2514
- AI-Rank-log  1619020114.8709722  eval_accuracy: 0.6268445253372192 , global_step: 2515
- AI-Rank-log  1619020158.7607937  eval_accuracy: 0.6292725801467896 , global_step: 2516
- AI-Rank-log  1619020202.6214857  eval_accuracy: 0.6292200088500977 , global_step: 2517
- AI-Rank-log  1619020246.5024843  eval_accuracy: 0.6303240656852722 , global_step: 2518
- AI-Rank-log  1619020290.4141843  eval_accuracy: 0.6290230751037598 , global_step: 2519
- AI-Rank-log  1619020334.2552655  eval_accuracy: 0.6305000185966492 , global_step: 2520
- AI-Rank-log  1619020378.0918574  eval_accuracy: 0.630005419254303 , global_step: 2521
- AI-Rank-log  1619020421.9410148  eval_accuracy: 0.6306323409080505 , global_step: 2522
- AI-Rank-log  1619020465.797541  eval_accuracy: 0.6299970149993896 , global_step: 2523
- AI-Rank-log  1619020509.7175744  eval_accuracy: 0.6306051015853882 , global_step: 2524
- AI-Rank-log  1619020553.5230935  eval_accuracy: 0.6303253173828125 , global_step: 2525
- AI-Rank-log  1619020597.3857343  eval_accuracy: 0.6308957934379578 , global_step: 2526
- AI-Rank-log  1619020641.3491004  eval_accuracy: 0.6300953030586243 , global_step: 2527
- AI-Rank-log  1619020685.3076541  eval_accuracy: 0.6306331157684326 , global_step: 2528
- AI-Rank-log  1619020729.1673827  eval_accuracy: 0.6280149817466736 , global_step: 2529
- AI-Rank-log  1619020773.1124496  eval_accuracy: 0.6322723627090454 , global_step: 2530
- AI-Rank-log  1619020816.9363196  eval_accuracy: 0.6296876072883606 , global_step: 2531
- AI-Rank-log  1619020860.7711685  eval_accuracy: 0.6295792460441589 , global_step: 2532
- AI-Rank-log  1619020904.5485675  eval_accuracy: 0.6290034651756287 , global_step: 2533
- AI-Rank-log  1619020948.3597925  eval_accuracy: 0.6308444142341614 , global_step: 2534
- AI-Rank-log  1619020992.2453988  eval_accuracy: 0.6300157904624939 , global_step: 2535
- AI-Rank-log  1619021036.0784242  eval_accuracy: 0.6304193735122681 , global_step: 2536
- AI-Rank-log  1619021079.9372969  eval_accuracy: 0.6288503408432007 , global_step: 2537
- AI-Rank-log  1619021123.885027  eval_accuracy: 0.6292185187339783 , global_step: 2538
- AI-Rank-log  1619021167.7408981  eval_accuracy: 0.6292157769203186 , global_step: 2539
- AI-Rank-log  1619021211.5494635  eval_accuracy: 0.6292203664779663 , global_step: 2540
- AI-Rank-log  1619021255.4851255  eval_accuracy: 0.6294952034950256 , global_step: 2541
- AI-Rank-log  1619021299.3180997  eval_accuracy: 0.6308344602584839 , global_step: 2542
- AI-Rank-log  1619021343.152703  eval_accuracy: 0.6308310627937317 , global_step: 2543
- AI-Rank-log  1619021388.1165955  eval_accuracy: 0.6310581564903259 , global_step: 2544
- AI-Rank-log  1619021432.029824  eval_accuracy: 0.6300288438796997 , global_step: 2545
- AI-Rank-log  1619021476.563879  eval_accuracy: 0.6310148239135742 , global_step: 2546
- AI-Rank-log  1619021520.5958056  eval_accuracy: 0.629806399345398 , global_step: 2547
- AI-Rank-log  1619021565.334753  eval_accuracy: 0.6314385533332825 , global_step: 2548
- AI-Rank-log  1619021609.9983814  eval_accuracy: 0.6310968995094299 , global_step: 2549
- AI-Rank-log  1619021654.6919074  eval_accuracy: 0.6322085857391357 , global_step: 2550
- AI-Rank-log  1619021699.5213406  eval_accuracy: 0.6310779452323914 , global_step: 2551
- AI-Rank-log  1619021743.4732916  eval_accuracy: 0.6307138204574585 , global_step: 2552
- AI-Rank-log  1619021787.5227227  eval_accuracy: 0.6313180327415466 , global_step: 2553
- AI-Rank-log  1619021831.3815305  eval_accuracy: 0.631583571434021 , global_step: 2554
- AI-Rank-log  1619021875.3712637  eval_accuracy: 0.6296082735061646 , global_step: 2555
- AI-Rank-log  1619021919.2641525  eval_accuracy: 0.6290768384933472 , global_step: 2556
- AI-Rank-log  1619021963.2393243  eval_accuracy: 0.6318116188049316 , global_step: 2557
- AI-Rank-log  1619022007.1359148  eval_accuracy: 0.6322174072265625 , global_step: 2558
- AI-Rank-log  1619022051.0166092  eval_accuracy: 0.6306563019752502 , global_step: 2559
- AI-Rank-log  1619022095.008115  eval_accuracy: 0.6318535804748535 , global_step: 2560
- AI-Rank-log  1619022138.9363546  eval_accuracy: 0.6310515999794006 , global_step: 2561
- AI-Rank-log  1619022182.8125215  eval_accuracy: 0.6324588656425476 , global_step: 2562
- AI-Rank-log  1619022226.7427037  eval_accuracy: 0.6310255527496338 , global_step: 2563
- AI-Rank-log  1619022270.6186316  eval_accuracy: 0.6313169002532959 , global_step: 2564
- AI-Rank-log  1619022314.5898166  eval_accuracy: 0.6310386657714844 , global_step: 2565
- AI-Rank-log  1619022358.4591315  eval_accuracy: 0.6312922835350037 , global_step: 2566
- AI-Rank-log  1619022402.3527126  eval_accuracy: 0.6300122737884521 , global_step: 2567
- AI-Rank-log  1619022446.3026597  eval_accuracy: 0.6322128176689148 , global_step: 2568
- AI-Rank-log  1619022490.1561034  eval_accuracy: 0.6297872066497803 , global_step: 2569
- AI-Rank-log  1619022534.0344167  eval_accuracy: 0.6315838694572449 , global_step: 2570
- AI-Rank-log  1619022578.01025  eval_accuracy: 0.6298383474349976 , global_step: 2571
- AI-Rank-log  1619022621.898577  eval_accuracy: 0.6315233707427979 , global_step: 2572
- AI-Rank-log  1619022665.7658885  eval_accuracy: 0.6299954056739807 , global_step: 2573
- AI-Rank-log  1619022709.7232206  eval_accuracy: 0.6312467455863953 , global_step: 2574
- AI-Rank-log  1619022753.597254  eval_accuracy: 0.631145179271698 , global_step: 2575
- AI-Rank-log  1619022797.5123737  eval_accuracy: 0.6328870058059692 , global_step: 2576
- AI-Rank-log  1619022841.379417  eval_accuracy: 0.6320854425430298 , global_step: 2577
- AI-Rank-log  1619022885.2622797  eval_accuracy: 0.6324599981307983 , global_step: 2578
- AI-Rank-log  1619022929.189808  eval_accuracy: 0.6313762068748474 , global_step: 2579
- AI-Rank-log  1619022973.0530548  eval_accuracy: 0.6318135261535645 , global_step: 2580
- AI-Rank-log  1619023016.9448664  eval_accuracy: 0.6327877640724182 , global_step: 2581
- AI-Rank-log  1619023060.965855  eval_accuracy: 0.6325749754905701 , global_step: 2582
- AI-Rank-log  1619023104.8158283  eval_accuracy: 0.6328868269920349 , global_step: 2583
- AI-Rank-log  1619023148.699482  eval_accuracy: 0.6318279504776001 , global_step: 2584
- AI-Rank-log  1619023192.6565828  eval_accuracy: 0.632802426815033 , global_step: 2585
- AI-Rank-log  1619023236.5437994  eval_accuracy: 0.6306778788566589 , global_step: 2586
- AI-Rank-log  1619023280.4843695  eval_accuracy: 0.6321719884872437 , global_step: 2587
- AI-Rank-log  1619023324.3643641  eval_accuracy: 0.6320488452911377 , global_step: 2588
- AI-Rank-log  1619023368.221057  eval_accuracy: 0.6320886611938477 , global_step: 2589
- AI-Rank-log  1619023412.2086272  eval_accuracy: 0.6320456266403198 , global_step: 2590
- AI-Rank-log  1619023456.0411808  eval_accuracy: 0.6324900388717651 , global_step: 2591
- AI-Rank-log  1619023499.9384592  eval_accuracy: 0.6323962211608887 , global_step: 2592
- AI-Rank-log  1619023552.6536946  eval_accuracy: 0.6329872012138367 , global_step: 2593
- AI-Rank-log  1619023596.5042315  eval_accuracy: 0.6332955956459045 , global_step: 2594
- AI-Rank-log  1619023640.3744874  eval_accuracy: 0.6324738264083862 , global_step: 2595
- AI-Rank-log  1619023684.2925525  eval_accuracy: 0.632627546787262 , global_step: 2596
- AI-Rank-log  1619023728.1321414  eval_accuracy: 0.6322793960571289 , global_step: 2597
- AI-Rank-log  1619023772.0621266  eval_accuracy: 0.6325997710227966 , global_step: 2598
- AI-Rank-log  1619023815.9621568  eval_accuracy: 0.6325436234474182 , global_step: 2599
- AI-Rank-log  1619023859.8398848  eval_accuracy: 0.6327490210533142 , global_step: 2600
- AI-Rank-log  1619023903.7863667  eval_accuracy: 0.6319552659988403 , global_step: 2601
- AI-Rank-log  1619023947.6857328  eval_accuracy: 0.6323351263999939 , global_step: 2602
- AI-Rank-log  1619023991.555661  eval_accuracy: 0.6325224041938782 , global_step: 2603
- AI-Rank-log  1619024035.4801526  eval_accuracy: 0.6311866044998169 , global_step: 2604
- AI-Rank-log  1619024079.3737543  eval_accuracy: 0.6309568285942078 , global_step: 2605
- AI-Rank-log  1619024123.2263558  eval_accuracy: 0.630437970161438 , global_step: 2606
- AI-Rank-log  1619024167.1895382  eval_accuracy: 0.6322152614593506 , global_step: 2607
- AI-Rank-log  1619024211.0741265  eval_accuracy: 0.6319071054458618 , global_step: 2608
- AI-Rank-log  1619024254.9957728  eval_accuracy: 0.6339432001113892 , global_step: 2609
- AI-Rank-log  1619024298.871104  eval_accuracy: 0.6322495937347412 , global_step: 2610
- AI-Rank-log  1619024342.7480843  eval_accuracy: 0.6334493160247803 , global_step: 2611
- AI-Rank-log  1619024386.6366835  eval_accuracy: 0.6322978734970093 , global_step: 2612
- AI-Rank-log  1619024430.5234907  eval_accuracy: 0.6341019868850708 , global_step: 2613
- AI-Rank-log  1619024474.4060986  eval_accuracy: 0.6319794058799744 , global_step: 2614
- AI-Rank-log  1619024518.3616529  eval_accuracy: 0.6347376704216003 , global_step: 2615
- AI-Rank-log  1619024562.2361972  eval_accuracy: 0.6328657865524292 , global_step: 2616
- AI-Rank-log  1619024606.111992  eval_accuracy: 0.6335407495498657 , global_step: 2617
- AI-Rank-log  1619024650.0773942  eval_accuracy: 0.6323295831680298 , global_step: 2618
- AI-Rank-log  1619024693.9516168  eval_accuracy: 0.6335076689720154 , global_step: 2619
- AI-Rank-log  1619024737.9000509  eval_accuracy: 0.6317867040634155 , global_step: 2620
- AI-Rank-log  1619024781.7653787  eval_accuracy: 0.6322004795074463 , global_step: 2621
- AI-Rank-log  1619024826.7374163  eval_accuracy: 0.633684515953064 , global_step: 2622
- AI-Rank-log  1619024871.1428165  eval_accuracy: 0.6328235268592834 , global_step: 2623
- AI-Rank-log  1619024915.4619474  eval_accuracy: 0.6335324048995972 , global_step: 2624
- AI-Rank-log  1619024959.618936  eval_accuracy: 0.6336691975593567 , global_step: 2625
- AI-Rank-log  1619025004.4997532  eval_accuracy: 0.6329997777938843 , global_step: 2626
- AI-Rank-log  1619025049.1043775  eval_accuracy: 0.634236752986908 , global_step: 2627
- AI-Rank-log  1619025094.1063123  eval_accuracy: 0.6331075429916382 , global_step: 2628
- AI-Rank-log  1619025138.0055428  eval_accuracy: 0.633773148059845 , global_step: 2629
- AI-Rank-log  1619025182.2205062  eval_accuracy: 0.633104681968689 , global_step: 2630
- AI-Rank-log  1619025226.1457298  eval_accuracy: 0.6345967054367065 , global_step: 2631
- AI-Rank-log  1619025270.0400438  eval_accuracy: 0.6335596442222595 , global_step: 2632
- AI-Rank-log  1619025313.943641  eval_accuracy: 0.6345460414886475 , global_step: 2633
- AI-Rank-log  1619025357.899777  eval_accuracy: 0.6331168413162231 , global_step: 2634
- AI-Rank-log  1619025401.7702353  eval_accuracy: 0.6336783766746521 , global_step: 2635
- AI-Rank-log  1619025445.6421835  eval_accuracy: 0.6329139471054077 , global_step: 2636
- AI-Rank-log  1619025489.6126478  eval_accuracy: 0.6336767673492432 , global_step: 2637
- AI-Rank-log  1619025533.485913  eval_accuracy: 0.6342183351516724 , global_step: 2638
- AI-Rank-log  1619025577.4060614  eval_accuracy: 0.6342051029205322 , global_step: 2639
- AI-Rank-log  1619025621.3791692  eval_accuracy: 0.6344319581985474 , global_step: 2640
- AI-Rank-log  1619025665.246353  eval_accuracy: 0.6338974833488464 , global_step: 2641
- AI-Rank-log  1619025709.1705852  eval_accuracy: 0.6331254839897156 , global_step: 2642
- AI-Rank-log  1619025753.0542717  eval_accuracy: 0.6336646676063538 , global_step: 2643
- AI-Rank-log  1619025796.8413365  eval_accuracy: 0.6341573596000671 , global_step: 2644
- AI-Rank-log  1619025840.78381  eval_accuracy: 0.634708046913147 , global_step: 2645
- AI-Rank-log  1619025884.64672  eval_accuracy: 0.634846568107605 , global_step: 2646
- AI-Rank-log  1619025928.5499358  eval_accuracy: 0.6345127820968628 , global_step: 2647
- AI-Rank-log  1619025972.448298  eval_accuracy: 0.634793221950531 , global_step: 2648
- AI-Rank-log  1619026016.3077433  eval_accuracy: 0.6355492472648621 , global_step: 2649
- AI-Rank-log  1619026060.2320354  eval_accuracy: 0.6347458362579346 , global_step: 2650
- AI-Rank-log  1619026104.1119006  eval_accuracy: 0.6351733803749084 , global_step: 2651
- AI-Rank-log  1619026147.9913697  eval_accuracy: 0.6342176795005798 , global_step: 2652
- AI-Rank-log  1619026191.9619496  eval_accuracy: 0.6362093091011047 , global_step: 2653
- AI-Rank-log  1619026235.8500981  eval_accuracy: 0.6349297165870667 , global_step: 2654
- AI-Rank-log  1619026279.6977205  eval_accuracy: 0.636189341545105 , global_step: 2655
- AI-Rank-log  1619026323.6194913  eval_accuracy: 0.6335550546646118 , global_step: 2656
- AI-Rank-log  1619026367.4825723  eval_accuracy: 0.634416401386261 , global_step: 2657
- AI-Rank-log  1619026411.3167012  eval_accuracy: 0.6331132650375366 , global_step: 2658
- AI-Rank-log  1619026455.2451718  eval_accuracy: 0.6351197957992554 , global_step: 2659
- AI-Rank-log  1619026499.1503823  eval_accuracy: 0.6335866451263428 , global_step: 2660
- AI-Rank-log  1619026543.0603402  eval_accuracy: 0.634766697883606 , global_step: 2661
- AI-Rank-log  1619026586.9415252  eval_accuracy: 0.6343458890914917 , global_step: 2662
- AI-Rank-log  1619026630.8690557  eval_accuracy: 0.6349558234214783 , global_step: 2663
- AI-Rank-log  1619026674.8056676  eval_accuracy: 0.6344183683395386 , global_step: 2664
- AI-Rank-log  1619026718.6729214  eval_accuracy: 0.6354144215583801 , global_step: 2665
- AI-Rank-log  1619026762.528981  eval_accuracy: 0.6352507472038269 , global_step: 2666
- AI-Rank-log  1619026806.4739  eval_accuracy: 0.6347731947898865 , global_step: 2667
- AI-Rank-log  1619026850.3948967  eval_accuracy: 0.6355910301208496 , global_step: 2668
- AI-Rank-log  1619026894.2603354  eval_accuracy: 0.6350743174552917 , global_step: 2669
- AI-Rank-log  1619026938.1769004  eval_accuracy: 0.6361385583877563 , global_step: 2670
- AI-Rank-log  1619026982.0555634  eval_accuracy: 0.6342248916625977 , global_step: 2671
- AI-Rank-log  1619027025.9950068  eval_accuracy: 0.6359159350395203 , global_step: 2672
- AI-Rank-log  1619027069.8601017  eval_accuracy: 0.6345440745353699 , global_step: 2673
- AI-Rank-log  1619027113.7980576  eval_accuracy: 0.6349830627441406 , global_step: 2674
- AI-Rank-log  1619027157.7072945  eval_accuracy: 0.6351680159568787 , global_step: 2675
- AI-Rank-log  1619027201.5792623  eval_accuracy: 0.6363281011581421 , global_step: 2676
- AI-Rank-log  1619027245.4957497  eval_accuracy: 0.6355395317077637 , global_step: 2677
- AI-Rank-log  1619027289.442989  eval_accuracy: 0.6362084746360779 , global_step: 2678
- AI-Rank-log  1619027333.3156235  eval_accuracy: 0.6338645815849304 , global_step: 2679
- AI-Rank-log  1619027377.2133482  eval_accuracy: 0.6363449096679688 , global_step: 2680
- AI-Rank-log  1619027421.1619697  eval_accuracy: 0.6343549489974976 , global_step: 2681
- AI-Rank-log  1619027465.0660248  eval_accuracy: 0.6346039772033691 , global_step: 2682
- AI-Rank-log  1619027509.0004766  eval_accuracy: 0.6348435878753662 , global_step: 2683
- AI-Rank-log  1619027552.8735952  eval_accuracy: 0.6345415115356445 , global_step: 2684
- AI-Rank-log  1619027596.7724404  eval_accuracy: 0.6341476440429688 , global_step: 2685
- AI-Rank-log  1619027640.6925793  eval_accuracy: 0.6355608105659485 , global_step: 2686
- AI-Rank-log  1619027684.529938  eval_accuracy: 0.6355887651443481 , global_step: 2687
- AI-Rank-log  1619027728.416554  eval_accuracy: 0.6361467838287354 , global_step: 2688
- AI-Rank-log  1619027772.3458629  eval_accuracy: 0.6348385214805603 , global_step: 2689
- AI-Rank-log  1619027816.2088842  eval_accuracy: 0.6347110271453857 , global_step: 2690
- AI-Rank-log  1619027860.1564336  eval_accuracy: 0.635553777217865 , global_step: 2691
- AI-Rank-log  1619027904.0691204  eval_accuracy: 0.6352699995040894 , global_step: 2692
- AI-Rank-log  1619027947.935062  eval_accuracy: 0.6365561485290527 , global_step: 2693
- AI-Rank-log  1619027991.9157827  eval_accuracy: 0.634438693523407 , global_step: 2694
- AI-Rank-log  1619028035.8150265  eval_accuracy: 0.6342548727989197 , global_step: 2695
- AI-Rank-log  1619028079.668846  eval_accuracy: 0.6360388994216919 , global_step: 2696
- AI-Rank-log  1619028123.6541553  eval_accuracy: 0.6362045407295227 , global_step: 2697
- AI-Rank-log  1619028167.5570598  eval_accuracy: 0.6358274817466736 , global_step: 2698
- AI-Rank-log  1619028212.3617058  eval_accuracy: 0.637190580368042 , global_step: 2699
- AI-Rank-log  1619028256.698744  eval_accuracy: 0.6351123452186584 , global_step: 2700
- AI-Rank-log  1619028301.376603  eval_accuracy: 0.6365010142326355 , global_step: 2701
- AI-Rank-log  1619028345.6817715  eval_accuracy: 0.6361771821975708 , global_step: 2702
- AI-Rank-log  1619028390.458408  eval_accuracy: 0.6363243460655212 , global_step: 2703
- AI-Rank-log  1619028434.858437  eval_accuracy: 0.6374166011810303 , global_step: 2704
- AI-Rank-log  1619028479.732556  eval_accuracy: 0.6379774808883667 , global_step: 2705
- AI-Rank-log  1619028524.75932  eval_accuracy: 0.6372774839401245 , global_step: 2706
- AI-Rank-log  1619028568.6006  eval_accuracy: 0.6381527781486511 , global_step: 2707
- AI-Rank-log  1619028612.5868852  eval_accuracy: 0.6363071799278259 , global_step: 2708
- AI-Rank-log  1619028656.455192  eval_accuracy: 0.6357872486114502 , global_step: 2709
- AI-Rank-log  1619028700.2970233  eval_accuracy: 0.635625422000885 , global_step: 2710
- AI-Rank-log  1619028744.2920306  eval_accuracy: 0.6366249918937683 , global_step: 2711
- AI-Rank-log  1619028788.1813333  eval_accuracy: 0.6357710361480713 , global_step: 2712
- AI-Rank-log  1619028832.1133137  eval_accuracy: 0.6365876197814941 , global_step: 2713
- AI-Rank-log  1619028875.9893253  eval_accuracy: 0.6358891129493713 , global_step: 2714
- AI-Rank-log  1619028919.906388  eval_accuracy: 0.636644721031189 , global_step: 2715
- AI-Rank-log  1619028963.8212082  eval_accuracy: 0.6371428966522217 , global_step: 2716
- AI-Rank-log  1619029007.6992989  eval_accuracy: 0.6350248456001282 , global_step: 2717
- AI-Rank-log  1619029051.601505  eval_accuracy: 0.636591374874115 , global_step: 2718
- AI-Rank-log  1619029095.5302591  eval_accuracy: 0.6344384551048279 , global_step: 2719
- AI-Rank-log  1619029139.4380662  eval_accuracy: 0.636340856552124 , global_step: 2720
- AI-Rank-log  1619029183.4019477  eval_accuracy: 0.6361081004142761 , global_step: 2721
- AI-Rank-log  1619029227.2912326  eval_accuracy: 0.6376661062240601 , global_step: 2722
- AI-Rank-log  1619029271.1812215  eval_accuracy: 0.6371458768844604 , global_step: 2723
- AI-Rank-log  1619029315.1060467  eval_accuracy: 0.6379224061965942 , global_step: 2724
- AI-Rank-log  1619029358.9632943  eval_accuracy: 0.6374061107635498 , global_step: 2725
- AI-Rank-log  1619029402.858309  eval_accuracy: 0.6359323859214783 , global_step: 2726
- AI-Rank-log  1619029446.7692883  eval_accuracy: 0.638126790523529 , global_step: 2727
- AI-Rank-log  1619029490.643899  eval_accuracy: 0.636946976184845 , global_step: 2728
- AI-Rank-log  1619029534.5263715  eval_accuracy: 0.6373782157897949 , global_step: 2729
- AI-Rank-log  1619029578.4722903  eval_accuracy: 0.6374520659446716 , global_step: 2730
- AI-Rank-log  1619029622.364022  eval_accuracy: 0.6371015906333923 , global_step: 2731
- AI-Rank-log  1619029666.2805936  eval_accuracy: 0.6362725496292114 , global_step: 2732
- AI-Rank-log  1619029710.154101  eval_accuracy: 0.6389304995536804 , global_step: 2733
- AI-Rank-log  1619029754.0374067  eval_accuracy: 0.6371454000473022 , global_step: 2734
- AI-Rank-log  1619029798.023485  eval_accuracy: 0.6381405591964722 , global_step: 2735
- AI-Rank-log  1619029841.927063  eval_accuracy: 0.636674165725708 , global_step: 2736
- AI-Rank-log  1619029885.8368127  eval_accuracy: 0.6371884942054749 , global_step: 2737
- AI-Rank-log  1619029929.8033235  eval_accuracy: 0.6368942260742188 , global_step: 2738
- AI-Rank-log  1619029973.6437883  eval_accuracy: 0.6376208066940308 , global_step: 2739
- AI-Rank-log  1619030017.586914  eval_accuracy: 0.6373807787895203 , global_step: 2740
- AI-Rank-log  1619030061.4468386  eval_accuracy: 0.6378905773162842 , global_step: 2741
- AI-Rank-log  1619030105.3193595  eval_accuracy: 0.637589156627655 , global_step: 2742
- AI-Rank-log  1619030149.269773  eval_accuracy: 0.6382922530174255 , global_step: 2743
- AI-Rank-log  1619030193.147289  eval_accuracy: 0.6379082202911377 , global_step: 2744
- AI-Rank-log  1619030236.99274  eval_accuracy: 0.6390773057937622 , global_step: 2745
- AI-Rank-log  1619030281.038434  eval_accuracy: 0.6371654272079468 , global_step: 2746
- AI-Rank-log  1619030324.866504  eval_accuracy: 0.6379778385162354 , global_step: 2747
- AI-Rank-log  1619030368.7060025  eval_accuracy: 0.6385414600372314 , global_step: 2748
- AI-Rank-log  1619030412.6550436  eval_accuracy: 0.6372278928756714 , global_step: 2749
- AI-Rank-log  1619030456.4940734  eval_accuracy: 0.6379784345626831 , global_step: 2750
- AI-Rank-log  1619030500.3508496  eval_accuracy: 0.6382753849029541 , global_step: 2751
- AI-Rank-log  1619030544.2893388  eval_accuracy: 0.6387567520141602 , global_step: 2752
- AI-Rank-log  1619030588.123927  eval_accuracy: 0.6373101472854614 , global_step: 2753
- AI-Rank-log  1619030632.0549471  eval_accuracy: 0.6386662125587463 , global_step: 2754
- AI-Rank-log  1619030675.943038  eval_accuracy: 0.6360921263694763 , global_step: 2755
- AI-Rank-log  1619030719.7894526  eval_accuracy: 0.639021098613739 , global_step: 2756
- AI-Rank-log  1619030763.7317574  eval_accuracy: 0.6380149126052856 , global_step: 2757
- AI-Rank-log  1619030807.6027555  eval_accuracy: 0.6381146311759949 , global_step: 2758
- AI-Rank-log  1619030851.4361515  eval_accuracy: 0.6373360753059387 , global_step: 2759
- AI-Rank-log  1619030895.1728144  eval_accuracy: 0.6386463046073914 , global_step: 2760
- AI-Rank-log  1619030939.0706334  eval_accuracy: 0.6374127864837646 , global_step: 2761
- AI-Rank-log  1619030982.9144423  eval_accuracy: 0.638644278049469 , global_step: 2762
- AI-Rank-log  1619031026.8132584  eval_accuracy: 0.6368518471717834 , global_step: 2763
- AI-Rank-log  1619031070.715352  eval_accuracy: 0.6384339928627014 , global_step: 2764
- AI-Rank-log  1619031114.661677  eval_accuracy: 0.6381509304046631 , global_step: 2765
- AI-Rank-log  1619031158.5501237  eval_accuracy: 0.6391404867172241 , global_step: 2766
- AI-Rank-log  1619031202.4363446  eval_accuracy: 0.6394232511520386 , global_step: 2767
- AI-Rank-log  1619031246.3893147  eval_accuracy: 0.6391971111297607 , global_step: 2768
- AI-Rank-log  1619031290.2486465  eval_accuracy: 0.6398980617523193 , global_step: 2769
- AI-Rank-log  1619031334.086764  eval_accuracy: 0.6403989195823669 , global_step: 2770
- AI-Rank-log  1619031378.0088534  eval_accuracy: 0.6397255063056946 , global_step: 2771
- AI-Rank-log  1619031421.8949966  eval_accuracy: 0.6386755108833313 , global_step: 2772
- AI-Rank-log  1619031465.8452249  eval_accuracy: 0.6390173435211182 , global_step: 2773
- AI-Rank-log  1619031509.743331  eval_accuracy: 0.6385207176208496 , global_step: 2774
- AI-Rank-log  1619031553.6281428  eval_accuracy: 0.638367772102356 , global_step: 2775
- AI-Rank-log  1619031598.4167168  eval_accuracy: 0.6389986872673035 , global_step: 2776
- AI-Rank-log  1619031642.8083959  eval_accuracy: 0.6383592486381531 , global_step: 2777
- AI-Rank-log  1619031686.6971605  eval_accuracy: 0.6379178762435913 , global_step: 2778
- AI-Rank-log  1619031731.0176678  eval_accuracy: 0.63818359375 , global_step: 2779
- AI-Rank-log  1619031775.855275  eval_accuracy: 0.6380732655525208 , global_step: 2780
- AI-Rank-log  1619031820.696662  eval_accuracy: 0.6382037401199341 , global_step: 2781
- AI-Rank-log  1619031865.3735833  eval_accuracy: 0.6397450566291809 , global_step: 2782
- AI-Rank-log  1619031909.5076294  eval_accuracy: 0.6388232111930847 , global_step: 2783
- AI-Rank-log  1619031954.3034868  eval_accuracy: 0.6397144198417664 , global_step: 2784
- AI-Rank-log  1619031998.3526802  eval_accuracy: 0.6392259001731873 , global_step: 2785
- AI-Rank-log  1619032042.2026422  eval_accuracy: 0.6394786238670349 , global_step: 2786
- AI-Rank-log  1619032086.1586084  eval_accuracy: 0.6397904753684998 , global_step: 2787
- AI-Rank-log  1619032130.0145304  eval_accuracy: 0.639563262462616 , global_step: 2788
- AI-Rank-log  1619032173.9614515  eval_accuracy: 0.6391649842262268 , global_step: 2789
- AI-Rank-log  1619032217.9480023  eval_accuracy: 0.6409328579902649 , global_step: 2790
- AI-Rank-log  1619032261.8168344  eval_accuracy: 0.639013409614563 , global_step: 2791
- AI-Rank-log  1619032305.752508  eval_accuracy: 0.63948655128479 , global_step: 2792
- AI-Rank-log  1619032358.469639  eval_accuracy: 0.6393567323684692 , global_step: 2793
- AI-Rank-log  1619032402.3465815  eval_accuracy: 0.6392350792884827 , global_step: 2794
- AI-Rank-log  1619032446.2994807  eval_accuracy: 0.6381295323371887 , global_step: 2795
- AI-Rank-log  1619032490.2069833  eval_accuracy: 0.6387890577316284 , global_step: 2796
- AI-Rank-log  1619032534.0270782  eval_accuracy: 0.639752209186554 , global_step: 2797
- AI-Rank-log  1619032578.0470235  eval_accuracy: 0.639958918094635 , global_step: 2798
- AI-Rank-log  1619032621.9743652  eval_accuracy: 0.6379512548446655 , global_step: 2799
- AI-Rank-log  1619032665.798113  eval_accuracy: 0.6401547789573669 , global_step: 2800
- AI-Rank-log  1619032709.8106651  eval_accuracy: 0.6374393105506897 , global_step: 2801
- AI-Rank-log  1619032753.7259479  eval_accuracy: 0.6400423645973206 , global_step: 2802
- AI-Rank-log  1619032797.6843097  eval_accuracy: 0.639637291431427 , global_step: 2803
- AI-Rank-log  1619032841.5930796  eval_accuracy: 0.6388079524040222 , global_step: 2804
- AI-Rank-log  1619032885.4441812  eval_accuracy: 0.6401733756065369 , global_step: 2805
- AI-Rank-log  1619032929.3781497  eval_accuracy: 0.6398070454597473 , global_step: 2806
- AI-Rank-log  1619032973.2792544  eval_accuracy: 0.6408094763755798 , global_step: 2807
- AI-Rank-log  1619033017.1471992  eval_accuracy: 0.6398733854293823 , global_step: 2808
- AI-Rank-log  1619033061.1287665  eval_accuracy: 0.6396351456642151 , global_step: 2809
- AI-Rank-log  1619033104.9810064  eval_accuracy: 0.6399529576301575 , global_step: 2810
- AI-Rank-log  1619033148.9487383  eval_accuracy: 0.6399542689323425 , global_step: 2811
- AI-Rank-log  1619033192.8073015  eval_accuracy: 0.6408262848854065 , global_step: 2812
- AI-Rank-log  1619033236.697756  eval_accuracy: 0.6401744484901428 , global_step: 2813
- AI-Rank-log  1619033280.6382203  eval_accuracy: 0.6405035853385925 , global_step: 2814
- AI-Rank-log  1619033324.5049155  eval_accuracy: 0.6381081342697144 , global_step: 2815
- AI-Rank-log  1619033368.4208105  eval_accuracy: 0.6388440132141113 , global_step: 2816
- AI-Rank-log  1619033412.4057226  eval_accuracy: 0.64080411195755 , global_step: 2817
- AI-Rank-log  1619033456.3574402  eval_accuracy: 0.6407631039619446 , global_step: 2818
- AI-Rank-log  1619033500.2441916  eval_accuracy: 0.6408630609512329 , global_step: 2819
- AI-Rank-log  1619033544.25337  eval_accuracy: 0.6408008933067322 , global_step: 2820
- AI-Rank-log  1619033587.9414182  eval_accuracy: 0.6389782428741455 , global_step: 2821
- AI-Rank-log  1619033631.8328261  eval_accuracy: 0.6408061385154724 , global_step: 2822
- AI-Rank-log  1619033675.7464979  eval_accuracy: 0.6393140554428101 , global_step: 2823
- AI-Rank-log  1619033719.6394901  eval_accuracy: 0.6402722597122192 , global_step: 2824
- AI-Rank-log  1619033763.576846  eval_accuracy: 0.6389845013618469 , global_step: 2825
- AI-Rank-log  1619033807.435584  eval_accuracy: 0.6407537460327148 , global_step: 2826
- AI-Rank-log  1619033851.3223925  eval_accuracy: 0.6402096152305603 , global_step: 2827
- AI-Rank-log  1619033895.2659764  eval_accuracy: 0.6413077116012573 , global_step: 2828
- AI-Rank-log  1619033939.159675  eval_accuracy: 0.6411232948303223 , global_step: 2829
- AI-Rank-log  1619033983.0891416  eval_accuracy: 0.640094518661499 , global_step: 2830
- AI-Rank-log  1619034027.14652  eval_accuracy: 0.639405369758606 , global_step: 2831
- AI-Rank-log  1619034071.0293202  eval_accuracy: 0.641139805316925 , global_step: 2832
- AI-Rank-log  1619034114.9803843  eval_accuracy: 0.6407890319824219 , global_step: 2833
- AI-Rank-log  1619034158.9014344  eval_accuracy: 0.6411275863647461 , global_step: 2834
- AI-Rank-log  1619034202.7752464  eval_accuracy: 0.639986515045166 , global_step: 2835
- AI-Rank-log  1619034246.725166  eval_accuracy: 0.6411216855049133 , global_step: 2836
- AI-Rank-log  1619034290.60365  eval_accuracy: 0.6409820914268494 , global_step: 2837
- AI-Rank-log  1619034334.5071702  eval_accuracy: 0.6394082307815552 , global_step: 2838
- AI-Rank-log  1619034378.4538357  eval_accuracy: 0.6417489051818848 , global_step: 2839
- AI-Rank-log  1619034422.2923787  eval_accuracy: 0.6411822438240051 , global_step: 2840
- AI-Rank-log  1619034466.137147  eval_accuracy: 0.640299916267395 , global_step: 2841
- AI-Rank-log  1619034510.119685  eval_accuracy: 0.6407363414764404 , global_step: 2842
- AI-Rank-log  1619034553.9556713  eval_accuracy: 0.6424202919006348 , global_step: 2843
- AI-Rank-log  1619034597.9538677  eval_accuracy: 0.6434270739555359 , global_step: 2844
- AI-Rank-log  1619034641.8709002  eval_accuracy: 0.6438228487968445 , global_step: 2845
- AI-Rank-log  1619034685.7281077  eval_accuracy: 0.6440424919128418 , global_step: 2846
- AI-Rank-log  1619034729.6835558  eval_accuracy: 0.6444317102432251 , global_step: 2847
- AI-Rank-log  1619034773.618029  eval_accuracy: 0.6443443894386292 , global_step: 2848
- AI-Rank-log  1619034817.4651706  eval_accuracy: 0.6446264386177063 , global_step: 2849
- AI-Rank-log  1619034861.4388072  eval_accuracy: 0.6440597772598267 , global_step: 2850
- AI-Rank-log  1619034905.3927805  eval_accuracy: 0.6448635458946228 , global_step: 2851
- AI-Rank-log  1619034949.330368  eval_accuracy: 0.6447649598121643 , global_step: 2852
- AI-Rank-log  1619034994.1310894  eval_accuracy: 0.6460726261138916 , global_step: 2853
- AI-Rank-log  1619035038.0512679  eval_accuracy: 0.6446537971496582 , global_step: 2854
- AI-Rank-log  1619035082.4631798  eval_accuracy: 0.646780788898468 , global_step: 2855
- AI-Rank-log  1619035127.9281943  eval_accuracy: 0.6457447409629822 , global_step: 2856
- AI-Rank-log  1619035172.7638054  eval_accuracy: 0.6460755467414856 , global_step: 2857
- AI-Rank-log  1619035216.8122845  eval_accuracy: 0.6455024480819702 , global_step: 2858
- AI-Rank-log  1619035261.1581826  eval_accuracy: 0.6462485790252686 , global_step: 2859
- AI-Rank-log  1619035305.8597534  eval_accuracy: 0.6455932855606079 , global_step: 2860
- AI-Rank-log  1619035351.0415528  eval_accuracy: 0.6459978222846985 , global_step: 2861
- AI-Rank-log  1619035395.0021513  eval_accuracy: 0.6458343863487244 , global_step: 2862
- AI-Rank-log  1619035439.2863586  eval_accuracy: 0.6458569169044495 , global_step: 2863
- AI-Rank-log  1619035483.1947076  eval_accuracy: 0.6458635926246643 , global_step: 2864
- AI-Rank-log  1619035527.1509023  eval_accuracy: 0.6456236243247986 , global_step: 2865
- AI-Rank-log  1619035571.0848951  eval_accuracy: 0.6455564498901367 , global_step: 2866
- AI-Rank-log  1619035614.9544985  eval_accuracy: 0.6460524201393127 , global_step: 2867
- AI-Rank-log  1619035658.8344436  eval_accuracy: 0.6457522511482239 , global_step: 2868
- AI-Rank-log  1619035702.7682717  eval_accuracy: 0.6450594663619995 , global_step: 2869
- AI-Rank-log  1619035746.753144  eval_accuracy: 0.6460700035095215 , global_step: 2870
- AI-Rank-log  1619035790.7041905  eval_accuracy: 0.6467006802558899 , global_step: 2871
- AI-Rank-log  1619035834.6353784  eval_accuracy: 0.646283745765686 , global_step: 2872
- AI-Rank-log  1619035878.5333834  eval_accuracy: 0.646526038646698 , global_step: 2873
- AI-Rank-log  1619035922.493308  eval_accuracy: 0.6467321515083313 , global_step: 2874
- AI-Rank-log  1619035966.3497107  eval_accuracy: 0.6471003890037537 , global_step: 2875
- AI-Rank-log  1619036010.264208  eval_accuracy: 0.6478825211524963 , global_step: 2876
- AI-Rank-log  1619036054.2569559  eval_accuracy: 0.6473240852355957 , global_step: 2877
- AI-Rank-log  1619036098.094222  eval_accuracy: 0.6477363705635071 , global_step: 2878
- AI-Rank-log  1619036142.065044  eval_accuracy: 0.6469076871871948 , global_step: 2879
- AI-Rank-log  1619036186.023614  eval_accuracy: 0.647045373916626 , global_step: 2880
- AI-Rank-log  1619036229.8725722  eval_accuracy: 0.6459508538246155 , global_step: 2881
- AI-Rank-log  1619036273.782152  eval_accuracy: 0.6471999883651733 , global_step: 2882
- AI-Rank-log  1619036317.7332373  eval_accuracy: 0.646874725818634 , global_step: 2883
- AI-Rank-log  1619036361.6089098  eval_accuracy: 0.6464875936508179 , global_step: 2884
- AI-Rank-log  1619036405.6134794  eval_accuracy: 0.6460339426994324 , global_step: 2885
- AI-Rank-log  1619036449.506698  eval_accuracy: 0.6468786597251892 , global_step: 2886
- AI-Rank-log  1619036493.3609617  eval_accuracy: 0.6470945477485657 , global_step: 2887
- AI-Rank-log  1619036537.2899232  eval_accuracy: 0.6471365690231323 , global_step: 2888
- AI-Rank-log  1619036581.1380043  eval_accuracy: 0.6476528644561768 , global_step: 2889
- AI-Rank-log  1619036625.012504  eval_accuracy: 0.6480261087417603 , global_step: 2890
- AI-Rank-log  1619036668.9719832  eval_accuracy: 0.6476684212684631 , global_step: 2891
- AI-Rank-log  1619036712.8310707  eval_accuracy: 0.6468338370323181 , global_step: 2892
- AI-Rank-log  1619036756.7159178  eval_accuracy: 0.6466469764709473 , global_step: 2893
- AI-Rank-log  1619036800.6526551  eval_accuracy: 0.6469107866287231 , global_step: 2894
- AI-Rank-log  1619036844.4915376  eval_accuracy: 0.6463556885719299 , global_step: 2895
- AI-Rank-log  1619036888.4639  eval_accuracy: 0.6469353437423706 , global_step: 2896
- AI-Rank-log  1619036932.3495636  eval_accuracy: 0.6467121243476868 , global_step: 2897
- AI-Rank-log  1619036976.1944587  eval_accuracy: 0.6480942368507385 , global_step: 2898
- AI-Rank-log  1619037020.1302137  eval_accuracy: 0.6477301716804504 , global_step: 2899
- AI-Rank-log  1619037064.0269616  eval_accuracy: 0.6482488512992859 , global_step: 2900
- AI-Rank-log  1619037107.8888156  eval_accuracy: 0.647680401802063 , global_step: 2901
- AI-Rank-log  1619037151.852364  eval_accuracy: 0.6487740278244019 , global_step: 2902
- AI-Rank-log  1619037195.7379136  eval_accuracy: 0.6476166248321533 , global_step: 2903
- AI-Rank-log  1619037239.6633048  eval_accuracy: 0.6488301157951355 , global_step: 2904
- AI-Rank-log  1619037283.5122786  eval_accuracy: 0.6472675204277039 , global_step: 2905
- AI-Rank-log  1619037327.3765247  eval_accuracy: 0.6483824253082275 , global_step: 2906
- AI-Rank-log  1619037371.2995405  eval_accuracy: 0.6475087404251099 , global_step: 2907
- AI-Rank-log  1619037415.1906874  eval_accuracy: 0.6472484469413757 , global_step: 2908
- AI-Rank-log  1619037459.0009573  eval_accuracy: 0.6475083827972412 , global_step: 2909
- AI-Rank-log  1619037502.9842951  eval_accuracy: 0.6480064988136292 , global_step: 2910
- AI-Rank-log  1619037546.9202862  eval_accuracy: 0.6480931043624878 , global_step: 2911
- AI-Rank-log  1619037590.7525523  eval_accuracy: 0.647256076335907 , global_step: 2912
- AI-Rank-log  1619037634.771243  eval_accuracy: 0.648770809173584 , global_step: 2913
- AI-Rank-log  1619037678.6810179  eval_accuracy: 0.6476279497146606 , global_step: 2914
- AI-Rank-log  1619037722.516539  eval_accuracy: 0.6485325694084167 , global_step: 2915
- AI-Rank-log  1619037766.462674  eval_accuracy: 0.6480349898338318 , global_step: 2916
- AI-Rank-log  1619037810.3284872  eval_accuracy: 0.6484171748161316 , global_step: 2917
- AI-Rank-log  1619037854.294793  eval_accuracy: 0.6478313207626343 , global_step: 2918
- AI-Rank-log  1619037898.1639996  eval_accuracy: 0.6496565937995911 , global_step: 2919
- AI-Rank-log  1619037942.0796762  eval_accuracy: 0.6476476788520813 , global_step: 2920
- AI-Rank-log  1619037986.0164406  eval_accuracy: 0.6486333608627319 , global_step: 2921
- AI-Rank-log  1619038029.9054787  eval_accuracy: 0.6487417221069336 , global_step: 2922
- AI-Rank-log  1619038073.8182304  eval_accuracy: 0.6491689085960388 , global_step: 2923
- AI-Rank-log  1619038117.7173924  eval_accuracy: 0.6487452387809753 , global_step: 2924
- AI-Rank-log  1619038161.6355343  eval_accuracy: 0.6488337516784668 , global_step: 2925
- AI-Rank-log  1619038205.5782435  eval_accuracy: 0.6487836241722107 , global_step: 2926
- AI-Rank-log  1619038249.4335787  eval_accuracy: 0.6473788619041443 , global_step: 2927
- AI-Rank-log  1619038293.3395846  eval_accuracy: 0.6491357088088989 , global_step: 2928
- AI-Rank-log  1619038337.3106802  eval_accuracy: 0.6482200026512146 , global_step: 2929
- AI-Rank-log  1619038381.1776469  eval_accuracy: 0.648831307888031 , global_step: 2930
- AI-Rank-log  1619038425.7089255  eval_accuracy: 0.6482070684432983 , global_step: 2931
- AI-Rank-log  1619038469.6334293  eval_accuracy: 0.6484329700469971 , global_step: 2932
- AI-Rank-log  1619038514.930338  eval_accuracy: 0.6486636996269226 , global_step: 2933
- AI-Rank-log  1619038559.712955  eval_accuracy: 0.6487050652503967 , global_step: 2934
- AI-Rank-log  1619038604.4046361  eval_accuracy: 0.6495369076728821 , global_step: 2935
- AI-Rank-log  1619038648.3170977  eval_accuracy: 0.6488174796104431 , global_step: 2936
- AI-Rank-log  1619038693.516338  eval_accuracy: 0.6490721106529236 , global_step: 2937
- AI-Rank-log  1619038737.836467  eval_accuracy: 0.6497316956520081 , global_step: 2938
- AI-Rank-log  1619038782.5526001  eval_accuracy: 0.6481483578681946 , global_step: 2939
- AI-Rank-log  1619038826.5503235  eval_accuracy: 0.6502475738525391 , global_step: 2940
- AI-Rank-log  1619038870.7466547  eval_accuracy: 0.6487334966659546 , global_step: 2941
- AI-Rank-log  1619038914.6369584  eval_accuracy: 0.6493433713912964 , global_step: 2942
- AI-Rank-log  1619038958.5617642  eval_accuracy: 0.6486296057701111 , global_step: 2943
- AI-Rank-log  1619039002.4202404  eval_accuracy: 0.6493109464645386 , global_step: 2944
- AI-Rank-log  1619039046.3810332  eval_accuracy: 0.6486708521842957 , global_step: 2945
- AI-Rank-log  1619039090.2750533  eval_accuracy: 0.6500723361968994 , global_step: 2946
- AI-Rank-log  1619039134.1315925  eval_accuracy: 0.6491663455963135 , global_step: 2947
- AI-Rank-log  1619039178.1450515  eval_accuracy: 0.6507318615913391 , global_step: 2948
- AI-Rank-log  1619039222.0321736  eval_accuracy: 0.6493259072303772 , global_step: 2949
- AI-Rank-log  1619039265.8693407  eval_accuracy: 0.650281548500061 , global_step: 2950
- AI-Rank-log  1619039309.8741908  eval_accuracy: 0.6495295763015747 , global_step: 2951
- AI-Rank-log  1619039353.8073385  eval_accuracy: 0.6497342586517334 , global_step: 2952
- AI-Rank-log  1619039397.6841798  eval_accuracy: 0.6498719453811646 , global_step: 2953
- AI-Rank-log  1619039441.6617854  eval_accuracy: 0.6498426795005798 , global_step: 2954
- AI-Rank-log  1619039485.577082  eval_accuracy: 0.6490859389305115 , global_step: 2955
- AI-Rank-log  1619039529.4834664  eval_accuracy: 0.6483330726623535 , global_step: 2956
- AI-Rank-log  1619039573.3381739  eval_accuracy: 0.6498978137969971 , global_step: 2957
- AI-Rank-log  1619039617.1904993  eval_accuracy: 0.650272786617279 , global_step: 2958
- AI-Rank-log  1619039661.0976593  eval_accuracy: 0.6499730944633484 , global_step: 2959
- AI-Rank-log  1619039704.9327204  eval_accuracy: 0.6496002674102783 , global_step: 2960
- AI-Rank-log  1619039748.8084137  eval_accuracy: 0.6500933170318604 , global_step: 2961
- AI-Rank-log  1619039792.7266257  eval_accuracy: 0.6497086882591248 , global_step: 2962
- AI-Rank-log  1619039836.6484504  eval_accuracy: 0.6502599716186523 , global_step: 2963
- AI-Rank-log  1619039880.524278  eval_accuracy: 0.6498439311981201 , global_step: 2964
- AI-Rank-log  1619039924.4911478  eval_accuracy: 0.6503454446792603 , global_step: 2965
- AI-Rank-log  1619039968.3561594  eval_accuracy: 0.6492144465446472 , global_step: 2966
- AI-Rank-log  1619040012.2992122  eval_accuracy: 0.6503325700759888 , global_step: 2967
- AI-Rank-log  1619040056.1806943  eval_accuracy: 0.6496111154556274 , global_step: 2968
- AI-Rank-log  1619040100.083668  eval_accuracy: 0.6500844955444336 , global_step: 2969
- AI-Rank-log  1619040144.0158072  eval_accuracy: 0.6505722999572754 , global_step: 2970
- AI-Rank-log  1619040187.953184  eval_accuracy: 0.6509552001953125 , global_step: 2971
- AI-Rank-log  1619040231.8459852  eval_accuracy: 0.6505092978477478 , global_step: 2972
- AI-Rank-log  1619040275.700524  eval_accuracy: 0.6512334942817688 , global_step: 2973
- AI-Rank-log  1619040319.5921624  eval_accuracy: 0.6497665047645569 , global_step: 2974
- AI-Rank-log  1619040363.5491872  eval_accuracy: 0.6512711644172668 , global_step: 2975
- AI-Rank-log  1619040407.4012234  eval_accuracy: 0.6492981314659119 , global_step: 2976
- AI-Rank-log  1619040451.2911036  eval_accuracy: 0.6505215167999268 , global_step: 2977
- AI-Rank-log  1619040495.2695801  eval_accuracy: 0.6498790979385376 , global_step: 2978
- AI-Rank-log  1619040539.1112041  eval_accuracy: 0.6500869989395142 , global_step: 2979
- AI-Rank-log  1619040583.0642643  eval_accuracy: 0.6508229374885559 , global_step: 2980
- AI-Rank-log  1619040627.0416124  eval_accuracy: 0.6511814594268799 , global_step: 2981
- AI-Rank-log  1619040670.8911004  eval_accuracy: 0.6509655714035034 , global_step: 2982
- AI-Rank-log  1619040714.773448  eval_accuracy: 0.6515786051750183 , global_step: 2983
- AI-Rank-log  1619040758.6859825  eval_accuracy: 0.6511878371238708 , global_step: 2984
- AI-Rank-log  1619040802.5635185  eval_accuracy: 0.6515809297561646 , global_step: 2985
- AI-Rank-log  1619040846.550818  eval_accuracy: 0.6515699625015259 , global_step: 2986
- AI-Rank-log  1619040890.411046  eval_accuracy: 0.6514305472373962 , global_step: 2987
- AI-Rank-log  1619040934.269482  eval_accuracy: 0.6505264639854431 , global_step: 2988
- AI-Rank-log  1619040978.2565076  eval_accuracy: 0.6509242653846741 , global_step: 2989
- AI-Rank-log  1619041022.1542962  eval_accuracy: 0.6496961712837219 , global_step: 2990
- AI-Rank-log  1619041066.046104  eval_accuracy: 0.650599479675293 , global_step: 2991
- AI-Rank-log  1619041110.050384  eval_accuracy: 0.6501917839050293 , global_step: 2992
- AI-Rank-log  1619041162.7640684  eval_accuracy: 0.6516074538230896 , global_step: 2993
- AI-Rank-log  1619041206.6995027  eval_accuracy: 0.6498944759368896 , global_step: 2994
- AI-Rank-log  1619041250.6346056  eval_accuracy: 0.6511618494987488 , global_step: 2995
- AI-Rank-log  1619041294.486521  eval_accuracy: 0.649344801902771 , global_step: 2996
- AI-Rank-log  1619041338.4169333  eval_accuracy: 0.6515322923660278 , global_step: 2997
- AI-Rank-log  1619041382.114323  eval_accuracy: 0.6491959095001221 , global_step: 2998
- AI-Rank-log  1619041425.958297  eval_accuracy: 0.6499815583229065 , global_step: 2999
- AI-Rank-log  1619041469.9344501  eval_accuracy: 0.6501997113227844 , global_step: 3000
- AI-Rank-log  1619041513.8333406  eval_accuracy: 0.6521247625350952 , global_step: 3001
- AI-Rank-log  1619041557.7060814  eval_accuracy: 0.6503586769104004 , global_step: 3002
- AI-Rank-log  1619041601.654729  eval_accuracy: 0.6517210006713867 , global_step: 3003
- AI-Rank-log  1619041645.5325713  eval_accuracy: 0.650621235370636 , global_step: 3004
- AI-Rank-log  1619041689.4495716  eval_accuracy: 0.6511521339416504 , global_step: 3005
- AI-Rank-log  1619041733.3265297  eval_accuracy: 0.6515282988548279 , global_step: 3006
- AI-Rank-log  1619041777.2842839  eval_accuracy: 0.6512580513954163 , global_step: 3007
- AI-Rank-log  1619041822.065871  eval_accuracy: 0.650752604007721 , global_step: 3008
- AI-Rank-log  1619041865.9306295  eval_accuracy: 0.651669979095459 , global_step: 3009
- AI-Rank-log  1619041910.400085  eval_accuracy: 0.6508834958076477 , global_step: 3010
- AI-Rank-log  1619041955.4320693  eval_accuracy: 0.6514608263969421 , global_step: 3011
- AI-Rank-log  1619041999.3839705  eval_accuracy: 0.651521623134613 , global_step: 3012
- AI-Rank-log  1619042044.3069406  eval_accuracy: 0.6515225172042847 , global_step: 3013
- AI-Rank-log  1619042088.631346  eval_accuracy: 0.6525696516036987 , global_step: 3014
- AI-Rank-log  1619042133.4003205  eval_accuracy: 0.6507445573806763 , global_step: 3015
- AI-Rank-log  1619042178.503303  eval_accuracy: 0.6517742276191711 , global_step: 3016
- AI-Rank-log  1619042222.3274047  eval_accuracy: 0.6518718004226685 , global_step: 3017
- AI-Rank-log  1619042266.2378256  eval_accuracy: 0.6523159146308899 , global_step: 3018
- AI-Rank-log  1619042310.19467  eval_accuracy: 0.6504820585250854 , global_step: 3019
- AI-Rank-log  1619042354.1264944  eval_accuracy: 0.6518408060073853 , global_step: 3020
- AI-Rank-log  1619042398.0244708  eval_accuracy: 0.6501056551933289 , global_step: 3021
- AI-Rank-log  1619042442.0091808  eval_accuracy: 0.6521380543708801 , global_step: 3022
- AI-Rank-log  1619042485.9258711  eval_accuracy: 0.651391863822937 , global_step: 3023
- AI-Rank-log  1619042529.8622727  eval_accuracy: 0.6521392464637756 , global_step: 3024
- AI-Rank-log  1619042573.7626054  eval_accuracy: 0.6521881818771362 , global_step: 3025
- AI-Rank-log  1619042617.6400583  eval_accuracy: 0.6518588662147522 , global_step: 3026
- AI-Rank-log  1619042661.6557508  eval_accuracy: 0.6519333720207214 , global_step: 3027
- AI-Rank-log  1619042705.558012  eval_accuracy: 0.6514435410499573 , global_step: 3028
- AI-Rank-log  1619042749.4755716  eval_accuracy: 0.6522665619850159 , global_step: 3029
- AI-Rank-log  1619042793.4682062  eval_accuracy: 0.6524604558944702 , global_step: 3030
- AI-Rank-log  1619042837.3551323  eval_accuracy: 0.6514937281608582 , global_step: 3031
- AI-Rank-log  1619042881.2404966  eval_accuracy: 0.6529015302658081 , global_step: 3032
- AI-Rank-log  1619042925.1938765  eval_accuracy: 0.6512782573699951 , global_step: 3033
- AI-Rank-log  1619042969.0661366  eval_accuracy: 0.6527130603790283 , global_step: 3034
- AI-Rank-log  1619043013.0969427  eval_accuracy: 0.6518774032592773 , global_step: 3035
- AI-Rank-log  1619043057.055465  eval_accuracy: 0.6529973149299622 , global_step: 3036
- AI-Rank-log  1619043100.919737  eval_accuracy: 0.6516014933586121 , global_step: 3037
- AI-Rank-log  1619043144.875155  eval_accuracy: 0.6520631313323975 , global_step: 3038
- AI-Rank-log  1619043188.7872522  eval_accuracy: 0.6515143513679504 , global_step: 3039
- AI-Rank-log  1619043232.6715133  eval_accuracy: 0.6521308422088623 , global_step: 3040
- AI-Rank-log  1619043276.6247191  eval_accuracy: 0.6524737477302551 , global_step: 3041
- AI-Rank-log  1619043320.5193844  eval_accuracy: 0.6520694494247437 , global_step: 3042
- AI-Rank-log  1619043364.50404  eval_accuracy: 0.6523021459579468 , global_step: 3043
- AI-Rank-log  1619043408.379972  eval_accuracy: 0.652114748954773 , global_step: 3044
- AI-Rank-log  1619043452.3089614  eval_accuracy: 0.6508956551551819 , global_step: 3045
- AI-Rank-log  1619043496.2293966  eval_accuracy: 0.6523504853248596 , global_step: 3046
- AI-Rank-log  1619043540.132573  eval_accuracy: 0.6507409811019897 , global_step: 3047
- AI-Rank-log  1619043584.0163121  eval_accuracy: 0.6514428853988647 , global_step: 3048
- AI-Rank-log  1619043627.9923177  eval_accuracy: 0.6520188450813293 , global_step: 3049
- AI-Rank-log  1619043671.9254227  eval_accuracy: 0.6520354747772217 , global_step: 3050
- AI-Rank-log  1619043715.7687898  eval_accuracy: 0.6533874869346619 , global_step: 3051
- AI-Rank-log  1619043759.7249913  eval_accuracy: 0.6525428295135498 , global_step: 3052
- AI-Rank-log  1619043803.5970144  eval_accuracy: 0.6521688103675842 , global_step: 3053
- AI-Rank-log  1619043847.482412  eval_accuracy: 0.6521553993225098 , global_step: 3054
- AI-Rank-log  1619043891.4626446  eval_accuracy: 0.6529674530029297 , global_step: 3055
- AI-Rank-log  1619043935.38569  eval_accuracy: 0.6528964638710022 , global_step: 3056
- AI-Rank-log  1619043979.358298  eval_accuracy: 0.6530647277832031 , global_step: 3057
- AI-Rank-log  1619044023.261333  eval_accuracy: 0.6522731781005859 , global_step: 3058
- AI-Rank-log  1619044067.2029  eval_accuracy: 0.6529450416564941 , global_step: 3059
- AI-Rank-log  1619044111.1172395  eval_accuracy: 0.6526272892951965 , global_step: 3060
- AI-Rank-log  1619044155.1189663  eval_accuracy: 0.6529150605201721 , global_step: 3061
- AI-Rank-log  1619044199.034673  eval_accuracy: 0.652873158454895 , global_step: 3062
- AI-Rank-log  1619044242.9565964  eval_accuracy: 0.6529810428619385 , global_step: 3063
- AI-Rank-log  1619044286.8875346  eval_accuracy: 0.6537733674049377 , global_step: 3064
- AI-Rank-log  1619044330.795472  eval_accuracy: 0.6539977788925171 , global_step: 3065
- AI-Rank-log  1619044374.7703452  eval_accuracy: 0.6528082489967346 , global_step: 3066
- AI-Rank-log  1619044418.6950872  eval_accuracy: 0.6537694931030273 , global_step: 3067
- AI-Rank-log  1619044462.6218615  eval_accuracy: 0.6525373458862305 , global_step: 3068
- AI-Rank-log  1619044506.5023768  eval_accuracy: 0.6526862978935242 , global_step: 3069
- AI-Rank-log  1619044550.3809543  eval_accuracy: 0.653443455696106 , global_step: 3070
- AI-Rank-log  1619044594.3644762  eval_accuracy: 0.6514149308204651 , global_step: 3071
- AI-Rank-log  1619044638.2408063  eval_accuracy: 0.6543420553207397 , global_step: 3072
- AI-Rank-log  1619044682.1181314  eval_accuracy: 0.6535390615463257 , global_step: 3073
- AI-Rank-log  1619044726.0675442  eval_accuracy: 0.6535535454750061 , global_step: 3074
- AI-Rank-log  1619044769.9252672  eval_accuracy: 0.653252124786377 , global_step: 3075
- AI-Rank-log  1619044813.9408097  eval_accuracy: 0.6540040373802185 , global_step: 3076
- AI-Rank-log  1619044857.8364818  eval_accuracy: 0.6529132127761841 , global_step: 3077
- AI-Rank-log  1619044901.7383003  eval_accuracy: 0.6538376808166504 , global_step: 3078
- AI-Rank-log  1619044945.7096996  eval_accuracy: 0.6537408828735352 , global_step: 3079
- AI-Rank-log  1619044989.62375  eval_accuracy: 0.6546329259872437 , global_step: 3080
- AI-Rank-log  1619045033.554832  eval_accuracy: 0.6532910466194153 , global_step: 3081
- AI-Rank-log  1619045077.534581  eval_accuracy: 0.6541275382041931 , global_step: 3082
- AI-Rank-log  1619045121.3983753  eval_accuracy: 0.6532343029975891 , global_step: 3083
- AI-Rank-log  1619045165.3709168  eval_accuracy: 0.6538452506065369 , global_step: 3084
- AI-Rank-log  1619045209.2753294  eval_accuracy: 0.6537030935287476 , global_step: 3085
- AI-Rank-log  1619045254.1369839  eval_accuracy: 0.6541249752044678 , global_step: 3086
- AI-Rank-log  1619045298.0510173  eval_accuracy: 0.6530010104179382 , global_step: 3087
- AI-Rank-log  1619045342.525691  eval_accuracy: 0.6532080769538879 , global_step: 3088
- AI-Rank-log  1619045386.7051327  eval_accuracy: 0.6531535387039185 , global_step: 3089
- AI-Rank-log  1619045430.6548958  eval_accuracy: 0.6536234021186829 , global_step: 3090
- AI-Rank-log  1619045475.8035612  eval_accuracy: 0.6549230217933655 , global_step: 3091
- AI-Rank-log  1619045521.6201055  eval_accuracy: 0.6541726589202881 , global_step: 3092
- AI-Rank-log  1619045565.8322887  eval_accuracy: 0.6532762050628662 , global_step: 3093
- AI-Rank-log  1619045610.5732858  eval_accuracy: 0.6540038585662842 , global_step: 3094
- AI-Rank-log  1619045654.5144384  eval_accuracy: 0.6528563499450684 , global_step: 3095
- AI-Rank-log  1619045698.6229565  eval_accuracy: 0.6548024415969849 , global_step: 3096
- AI-Rank-log  1619045742.5324183  eval_accuracy: 0.6540910005569458 , global_step: 3097
- AI-Rank-log  1619045786.4938998  eval_accuracy: 0.655340313911438 , global_step: 3098
- AI-Rank-log  1619045830.3714666  eval_accuracy: 0.6537972092628479 , global_step: 3099
- AI-Rank-log  1619045874.30367  eval_accuracy: 0.6543803215026855 , global_step: 3100
- AI-Rank-log  1619045918.2335498  eval_accuracy: 0.6536348462104797 , global_step: 3101
- AI-Rank-log  1619045962.1324515  eval_accuracy: 0.6546838879585266 , global_step: 3102
- AI-Rank-log  1619046006.0451105  eval_accuracy: 0.6549999713897705 , global_step: 3103
- AI-Rank-log  1619046049.901699  eval_accuracy: 0.6547031998634338 , global_step: 3104
- AI-Rank-log  1619046093.7904887  eval_accuracy: 0.6546882390975952 , global_step: 3105
- AI-Rank-log  1619046137.7221828  eval_accuracy: 0.6547501087188721 , global_step: 3106
- AI-Rank-log  1619046181.5838127  eval_accuracy: 0.6550989151000977 , global_step: 3107
- AI-Rank-log  1619046225.4765055  eval_accuracy: 0.6547848582267761 , global_step: 3108
- AI-Rank-log  1619046269.4085548  eval_accuracy: 0.6543770432472229 , global_step: 3109
- AI-Rank-log  1619046313.3075926  eval_accuracy: 0.6537856459617615 , global_step: 3110
- AI-Rank-log  1619046357.2009206  eval_accuracy: 0.6542235016822815 , global_step: 3111
- AI-Rank-log  1619046401.122823  eval_accuracy: 0.6544955372810364 , global_step: 3112
- AI-Rank-log  1619046444.9935372  eval_accuracy: 0.6530917882919312 , global_step: 3113
- AI-Rank-log  1619046488.99834  eval_accuracy: 0.6541258692741394 , global_step: 3114
- AI-Rank-log  1619046532.8639152  eval_accuracy: 0.6545975208282471 , global_step: 3115
- AI-Rank-log  1619046576.7308462  eval_accuracy: 0.6545848846435547 , global_step: 3116
- AI-Rank-log  1619046620.640609  eval_accuracy: 0.6529549360275269 , global_step: 3117
- AI-Rank-log  1619046664.4979832  eval_accuracy: 0.654328465461731 , global_step: 3118
- AI-Rank-log  1619046708.3580277  eval_accuracy: 0.6536592245101929 , global_step: 3119
- AI-Rank-log  1619046752.3536294  eval_accuracy: 0.6554590463638306 , global_step: 3120
- AI-Rank-log  1619046796.1874475  eval_accuracy: 0.6541861891746521 , global_step: 3121
- AI-Rank-log  1619046840.096659  eval_accuracy: 0.6553866863250732 , global_step: 3122
- AI-Rank-log  1619046883.9972243  eval_accuracy: 0.6549952626228333 , global_step: 3123
- AI-Rank-log  1619046927.8751168  eval_accuracy: 0.6552176475524902 , global_step: 3124
- AI-Rank-log  1619046971.8393972  eval_accuracy: 0.6537603735923767 , global_step: 3125
- AI-Rank-log  1619047015.715066  eval_accuracy: 0.6550518870353699 , global_step: 3126
- AI-Rank-log  1619047059.615097  eval_accuracy: 0.6545407772064209 , global_step: 3127
- AI-Rank-log  1619047103.53806  eval_accuracy: 0.655360221862793 , global_step: 3128
- AI-Rank-log  1619047147.503834  eval_accuracy: 0.654544472694397 , global_step: 3129
- AI-Rank-log  1619047191.4099555  eval_accuracy: 0.6551973223686218 , global_step: 3130
- AI-Rank-log  1619047235.404422  eval_accuracy: 0.6554509997367859 , global_step: 3131
- AI-Rank-log  1619047279.2429783  eval_accuracy: 0.6552487015724182 , global_step: 3132
- AI-Rank-log  1619047323.207156  eval_accuracy: 0.6557332873344421 , global_step: 3133
- AI-Rank-log  1619047367.0858872  eval_accuracy: 0.6560491919517517 , global_step: 3134
- AI-Rank-log  1619047410.904928  eval_accuracy: 0.655630350112915 , global_step: 3135
- AI-Rank-log  1619047454.8559265  eval_accuracy: 0.6558939814567566 , global_step: 3136
- AI-Rank-log  1619047498.7410197  eval_accuracy: 0.6546126008033752 , global_step: 3137
- AI-Rank-log  1619047542.6043  eval_accuracy: 0.6553636789321899 , global_step: 3138
- AI-Rank-log  1619047586.5576525  eval_accuracy: 0.6548150777816772 , global_step: 3139
- AI-Rank-log  1619047630.4598553  eval_accuracy: 0.6553841829299927 , global_step: 3140
- AI-Rank-log  1619047674.3180676  eval_accuracy: 0.655673086643219 , global_step: 3141
- AI-Rank-log  1619047718.2770529  eval_accuracy: 0.6555228233337402 , global_step: 3142
- AI-Rank-log  1619047762.16825  eval_accuracy: 0.6561267375946045 , global_step: 3143
- AI-Rank-log  1619047806.0322723  eval_accuracy: 0.6554397940635681 , global_step: 3144
- AI-Rank-log  1619047849.9720576  eval_accuracy: 0.6558465361595154 , global_step: 3145
- AI-Rank-log  1619047893.8567703  eval_accuracy: 0.6557396650314331 , global_step: 3146
- AI-Rank-log  1619047937.7781131  eval_accuracy: 0.6556547284126282 , global_step: 3147
- AI-Rank-log  1619047981.6574328  eval_accuracy: 0.6557990908622742 , global_step: 3148
- AI-Rank-log  1619048025.549336  eval_accuracy: 0.6551737785339355 , global_step: 3149
- AI-Rank-log  1619048069.4477067  eval_accuracy: 0.6551785469055176 , global_step: 3150
- AI-Rank-log  1619048113.360971  eval_accuracy: 0.6559897661209106 , global_step: 3151
- AI-Rank-log  1619048157.2155056  eval_accuracy: 0.6554219722747803 , global_step: 3152
- AI-Rank-log  1619048201.1240246  eval_accuracy: 0.6551864147186279 , global_step: 3153
- AI-Rank-log  1619048245.0015569  eval_accuracy: 0.6554842591285706 , global_step: 3154
- AI-Rank-log  1619048288.9125643  eval_accuracy: 0.6548777222633362 , global_step: 3155
- AI-Rank-log  1619048332.7658334  eval_accuracy: 0.6557753086090088 , global_step: 3156
- AI-Rank-log  1619048376.67334  eval_accuracy: 0.6545035243034363 , global_step: 3157
- AI-Rank-log  1619048420.6239707  eval_accuracy: 0.6555857062339783 , global_step: 3158
- AI-Rank-log  1619048464.503631  eval_accuracy: 0.65534508228302 , global_step: 3159
- AI-Rank-log  1619048508.4119742  eval_accuracy: 0.6557844281196594 , global_step: 3160
- AI-Rank-log  1619048552.359502  eval_accuracy: 0.6545827984809875 , global_step: 3161
- AI-Rank-log  1619048596.2599273  eval_accuracy: 0.6568866968154907 , global_step: 3162
- AI-Rank-log  1619048641.456863  eval_accuracy: 0.6554198265075684 , global_step: 3163
- AI-Rank-log  1619048685.4271488  eval_accuracy: 0.6571687459945679 , global_step: 3164
- AI-Rank-log  1619048729.960718  eval_accuracy: 0.6561419367790222 , global_step: 3165
- AI-Rank-log  1619048773.943634  eval_accuracy: 0.6560967564582825 , global_step: 3166
- AI-Rank-log  1619048818.1084034  eval_accuracy: 0.6566931009292603 , global_step: 3167
- AI-Rank-log  1619048863.2374628  eval_accuracy: 0.6552433967590332 , global_step: 3168
- AI-Rank-log  1619048907.1794617  eval_accuracy: 0.6564368009567261 , global_step: 3169
- AI-Rank-log  1619048951.9085407  eval_accuracy: 0.656366765499115 , global_step: 3170
- AI-Rank-log  1619048996.8216627  eval_accuracy: 0.6553863286972046 , global_step: 3171
- AI-Rank-log  1619049040.8087828  eval_accuracy: 0.6564041972160339 , global_step: 3172
- AI-Rank-log  1619049084.918172  eval_accuracy: 0.6541576385498047 , global_step: 3173
- AI-Rank-log  1619049128.8143215  eval_accuracy: 0.6563906669616699 , global_step: 3174
- AI-Rank-log  1619049172.7953234  eval_accuracy: 0.6534633636474609 , global_step: 3175
- AI-Rank-log  1619049216.6877177  eval_accuracy: 0.65654456615448 , global_step: 3176
- AI-Rank-log  1619049260.6482053  eval_accuracy: 0.6564949750900269 , global_step: 3177
- AI-Rank-log  1619049304.5437114  eval_accuracy: 0.6560965180397034 , global_step: 3178
- AI-Rank-log  1619049348.4605763  eval_accuracy: 0.6559134125709534 , global_step: 3179
- AI-Rank-log  1619049392.3694937  eval_accuracy: 0.656991720199585 , global_step: 3180
- AI-Rank-log  1619049436.2335453  eval_accuracy: 0.6557927131652832 , global_step: 3181
- AI-Rank-log  1619049480.1496038  eval_accuracy: 0.6556357741355896 , global_step: 3182
- AI-Rank-log  1619049524.0650988  eval_accuracy: 0.6550809144973755 , global_step: 3183
- AI-Rank-log  1619049567.9217093  eval_accuracy: 0.6544654965400696 , global_step: 3184
- AI-Rank-log  1619049611.8263483  eval_accuracy: 0.6558467149734497 , global_step: 3185
- AI-Rank-log  1619049655.7619653  eval_accuracy: 0.6554014086723328 , global_step: 3186
- AI-Rank-log  1619049699.612244  eval_accuracy: 0.6568277478218079 , global_step: 3187
- AI-Rank-log  1619049743.5716274  eval_accuracy: 0.6550191044807434 , global_step: 3188
- AI-Rank-log  1619049787.5009227  eval_accuracy: 0.6556776762008667 , global_step: 3189
- AI-Rank-log  1619049831.3597598  eval_accuracy: 0.6551381945610046 , global_step: 3190
- AI-Rank-log  1619049875.326859  eval_accuracy: 0.6564139127731323 , global_step: 3191
- AI-Rank-log  1619049919.2381692  eval_accuracy: 0.65613853931427 , global_step: 3192
- AI-Rank-log  1619049971.9784064  eval_accuracy: 0.65619957447052 , global_step: 3193
- AI-Rank-log  1619050015.8951774  eval_accuracy: 0.6559348106384277 , global_step: 3194
- AI-Rank-log  1619050059.7623053  eval_accuracy: 0.6565356254577637 , global_step: 3195
- AI-Rank-log  1619050103.5997655  eval_accuracy: 0.6562429070472717 , global_step: 3196
- AI-Rank-log  1619050147.5633883  eval_accuracy: 0.6561247110366821 , global_step: 3197
- AI-Rank-log  1619050191.448102  eval_accuracy: 0.6565159559249878 , global_step: 3198
- AI-Rank-log  1619050235.3767395  eval_accuracy: 0.6556627750396729 , global_step: 3199
- AI-Rank-log  1619050279.267981  eval_accuracy: 0.6570128798484802 , global_step: 3200
- AI-Rank-log  1619050323.1620955  eval_accuracy: 0.6553725600242615 , global_step: 3201
- AI-Rank-log  1619050367.0939815  eval_accuracy: 0.6575205326080322 , global_step: 3202
- AI-Rank-log  1619050411.0112715  eval_accuracy: 0.6567546129226685 , global_step: 3203
- AI-Rank-log  1619050454.8744972  eval_accuracy: 0.6565621495246887 , global_step: 3204
- AI-Rank-log  1619050498.7721667  eval_accuracy: 0.656970739364624 , global_step: 3205
- AI-Rank-log  1619050542.701717  eval_accuracy: 0.6579381227493286 , global_step: 3206
- AI-Rank-log  1619050586.5849435  eval_accuracy: 0.6566855311393738 , global_step: 3207
- AI-Rank-log  1619050630.4919322  eval_accuracy: 0.656311571598053 , global_step: 3208
- AI-Rank-log  1619050674.3965027  eval_accuracy: 0.6555073857307434 , global_step: 3209
- AI-Rank-log  1619050718.3793478  eval_accuracy: 0.6572721600532532 , global_step: 3210
- AI-Rank-log  1619050762.2416883  eval_accuracy: 0.6578831076622009 , global_step: 3211
- AI-Rank-log  1619050806.131805  eval_accuracy: 0.656446099281311 , global_step: 3212
- AI-Rank-log  1619050850.0750687  eval_accuracy: 0.6577330827713013 , global_step: 3213
- AI-Rank-log  1619050894.0097198  eval_accuracy: 0.6573112607002258 , global_step: 3214
- AI-Rank-log  1619050937.9100678  eval_accuracy: 0.6580931544303894 , global_step: 3215
- AI-Rank-log  1619050981.8215978  eval_accuracy: 0.6559510231018066 , global_step: 3216
- AI-Rank-log  1619051025.694628  eval_accuracy: 0.6577301025390625 , global_step: 3217
- AI-Rank-log  1619051069.5811903  eval_accuracy: 0.6566908359527588 , global_step: 3218
- AI-Rank-log  1619051113.5317447  eval_accuracy: 0.6571527123451233 , global_step: 3219
- AI-Rank-log  1619051157.4291625  eval_accuracy: 0.6570315957069397 , global_step: 3220
- AI-Rank-log  1619051201.4179108  eval_accuracy: 0.6569003462791443 , global_step: 3221
- AI-Rank-log  1619051245.2632527  eval_accuracy: 0.6576874256134033 , global_step: 3222
- AI-Rank-log  1619051289.1725185  eval_accuracy: 0.6577520966529846 , global_step: 3223
- AI-Rank-log  1619051333.1739028  eval_accuracy: 0.6568876504898071 , global_step: 3224
- AI-Rank-log  1619051377.0210276  eval_accuracy: 0.6584213972091675 , global_step: 3225
- AI-Rank-log  1619051420.9437382  eval_accuracy: 0.656914472579956 , global_step: 3226
- AI-Rank-log  1619051464.8912866  eval_accuracy: 0.6578595042228699 , global_step: 3227
- AI-Rank-log  1619051508.740137  eval_accuracy: 0.657309353351593 , global_step: 3228
- AI-Rank-log  1619051552.69071  eval_accuracy: 0.6569753289222717 , global_step: 3229
- AI-Rank-log  1619051596.5573351  eval_accuracy: 0.6580690741539001 , global_step: 3230
- AI-Rank-log  1619051640.3977253  eval_accuracy: 0.6573411226272583 , global_step: 3231
- AI-Rank-log  1619051684.359405  eval_accuracy: 0.65690016746521 , global_step: 3232
- AI-Rank-log  1619051728.2587404  eval_accuracy: 0.6564335823059082 , global_step: 3233
- AI-Rank-log  1619051772.129762  eval_accuracy: 0.6565173864364624 , global_step: 3234
- AI-Rank-log  1619051816.1588664  eval_accuracy: 0.6563219428062439 , global_step: 3235
- AI-Rank-log  1619051860.0090518  eval_accuracy: 0.6584265828132629 , global_step: 3236
- AI-Rank-log  1619051903.8537369  eval_accuracy: 0.6570506691932678 , global_step: 3237
- AI-Rank-log  1619051947.8548193  eval_accuracy: 0.6574364304542542 , global_step: 3238
- AI-Rank-log  1619051991.7470918  eval_accuracy: 0.6568533778190613 , global_step: 3239
- AI-Rank-log  1619052036.6785352  eval_accuracy: 0.6577234864234924 , global_step: 3240
- AI-Rank-log  1619052080.6158845  eval_accuracy: 0.657849907875061 , global_step: 3241
- AI-Rank-log  1619052125.081632  eval_accuracy: 0.658356249332428 , global_step: 3242
- AI-Rank-log  1619052169.3762794  eval_accuracy: 0.6583665013313293 , global_step: 3243
- AI-Rank-log  1619052213.6037574  eval_accuracy: 0.6565978527069092 , global_step: 3244
- AI-Rank-log  1619052258.3857603  eval_accuracy: 0.6575077176094055 , global_step: 3245
- AI-Rank-log  1619052302.682444  eval_accuracy: 0.6572160720825195 , global_step: 3246
- AI-Rank-log  1619052347.968691  eval_accuracy: 0.6581177115440369 , global_step: 3247
- AI-Rank-log  1619052393.0717306  eval_accuracy: 0.656343936920166 , global_step: 3248
- AI-Rank-log  1619052437.892832  eval_accuracy: 0.6570531725883484 , global_step: 3249
- AI-Rank-log  1619052481.7904532  eval_accuracy: 0.6561815142631531 , global_step: 3250
- AI-Rank-log  1619052525.9273424  eval_accuracy: 0.6575101017951965 , global_step: 3251
- AI-Rank-log  1619052569.868287  eval_accuracy: 0.6575731635093689 , global_step: 3252
- AI-Rank-log  1619052613.8250203  eval_accuracy: 0.6573277711868286 , global_step: 3253
- AI-Rank-log  1619052657.7981393  eval_accuracy: 0.6578025221824646 , global_step: 3254
- AI-Rank-log  1619052701.709971  eval_accuracy: 0.6568788886070251 , global_step: 3255
- AI-Rank-log  1619052745.6133626  eval_accuracy: 0.6578960418701172 , global_step: 3256
- AI-Rank-log  1619052789.522584  eval_accuracy: 0.6577123403549194 , global_step: 3257
- AI-Rank-log  1619052833.4208798  eval_accuracy: 0.6579267978668213 , global_step: 3258
- AI-Rank-log  1619052877.393714  eval_accuracy: 0.6575249433517456 , global_step: 3259
- AI-Rank-log  1619052921.2728748  eval_accuracy: 0.6580119729042053 , global_step: 3260
- AI-Rank-log  1619052965.1506524  eval_accuracy: 0.6567144989967346 , global_step: 3261
- AI-Rank-log  1619053008.8683548  eval_accuracy: 0.6578065752983093 , global_step: 3262
- AI-Rank-log  1619053052.7625198  eval_accuracy: 0.6585688591003418 , global_step: 3263
- AI-Rank-log  1619053096.6755388  eval_accuracy: 0.6589628458023071 , global_step: 3264
- AI-Rank-log  1619053140.6175303  eval_accuracy: 0.6584571003913879 , global_step: 3265
- AI-Rank-log  1619053184.5045187  eval_accuracy: 0.6588230133056641 , global_step: 3266
- AI-Rank-log  1619053228.42427  eval_accuracy: 0.6578001976013184 , global_step: 3267
- AI-Rank-log  1619053272.395027  eval_accuracy: 0.6588823199272156 , global_step: 3268
- AI-Rank-log  1619053316.2961419  eval_accuracy: 0.6583136916160583 , global_step: 3269
- AI-Rank-log  1619053360.2369459  eval_accuracy: 0.6590458750724792 , global_step: 3270
- AI-Rank-log  1619053404.1237335  eval_accuracy: 0.6583969593048096 , global_step: 3271
- AI-Rank-log  1619053448.0108008  eval_accuracy: 0.6593279838562012 , global_step: 3272
- AI-Rank-log  1619053491.9913397  eval_accuracy: 0.6578049659729004 , global_step: 3273
- AI-Rank-log  1619053535.8742867  eval_accuracy: 0.6594894528388977 , global_step: 3274
- AI-Rank-log  1619053579.8000128  eval_accuracy: 0.6569008231163025 , global_step: 3275
- AI-Rank-log  1619053623.8175833  eval_accuracy: 0.6590888500213623 , global_step: 3276
- AI-Rank-log  1619053667.6830244  eval_accuracy: 0.6590882539749146 , global_step: 3277
- AI-Rank-log  1619053711.628299  eval_accuracy: 0.6583827137947083 , global_step: 3278
- AI-Rank-log  1619053755.6143477  eval_accuracy: 0.6585426330566406 , global_step: 3279
- AI-Rank-log  1619053799.5352085  eval_accuracy: 0.6588636636734009 , global_step: 3280
- AI-Rank-log  1619053843.4105585  eval_accuracy: 0.6579679250717163 , global_step: 3281
- AI-Rank-log  1619053887.3779042  eval_accuracy: 0.6588684320449829 , global_step: 3282
- AI-Rank-log  1619053931.2414968  eval_accuracy: 0.6588306427001953 , global_step: 3283
- AI-Rank-log  1619053975.2165616  eval_accuracy: 0.659642219543457 , global_step: 3284
- AI-Rank-log  1619054019.129689  eval_accuracy: 0.6589471697807312 , global_step: 3285
- AI-Rank-log  1619054063.0017114  eval_accuracy: 0.6583058834075928 , global_step: 3286
- AI-Rank-log  1619054107.0148091  eval_accuracy: 0.6594470739364624 , global_step: 3287
- AI-Rank-log  1619054150.922311  eval_accuracy: 0.6594545841217041 , global_step: 3288
- AI-Rank-log  1619054194.8080523  eval_accuracy: 0.6584999561309814 , global_step: 3289
- AI-Rank-log  1619054238.7916594  eval_accuracy: 0.6591015458106995 , global_step: 3290
- AI-Rank-log  1619054282.7045808  eval_accuracy: 0.6574917435646057 , global_step: 3291
- AI-Rank-log  1619054326.6586185  eval_accuracy: 0.6580103635787964 , global_step: 3292
- AI-Rank-log  1619054370.5603013  eval_accuracy: 0.6589947938919067 , global_step: 3293
- AI-Rank-log  1619054414.4836843  eval_accuracy: 0.6584680080413818 , global_step: 3294
- AI-Rank-log  1619054458.4365294  eval_accuracy: 0.6587336659431458 , global_step: 3295
- AI-Rank-log  1619054502.3193176  eval_accuracy: 0.6598649621009827 , global_step: 3296
- AI-Rank-log  1619054546.1981747  eval_accuracy: 0.6590300798416138 , global_step: 3297
- AI-Rank-log  1619054590.172052  eval_accuracy: 0.6603980660438538 , global_step: 3298
- AI-Rank-log  1619054634.0427787  eval_accuracy: 0.6597923636436462 , global_step: 3299
- AI-Rank-log  1619054677.8615098  eval_accuracy: 0.6601504683494568 , global_step: 3300
- AI-Rank-log  1619054721.8164349  eval_accuracy: 0.6595790982246399 , global_step: 3301
- AI-Rank-log  1619054765.6729424  eval_accuracy: 0.6592665314674377 , global_step: 3302
- AI-Rank-log  1619054809.629867  eval_accuracy: 0.6579803824424744 , global_step: 3303
- AI-Rank-log  1619054853.521361  eval_accuracy: 0.6596230864524841 , global_step: 3304
- AI-Rank-log  1619054897.451898  eval_accuracy: 0.657700777053833 , global_step: 3305
- AI-Rank-log  1619054941.361513  eval_accuracy: 0.6590532064437866 , global_step: 3306
- AI-Rank-log  1619054985.2765212  eval_accuracy: 0.6586977243423462 , global_step: 3307
- AI-Rank-log  1619055029.1856887  eval_accuracy: 0.6590628027915955 , global_step: 3308
- AI-Rank-log  1619055073.1194742  eval_accuracy: 0.6596395373344421 , global_step: 3309
- AI-Rank-log  1619055117.026006  eval_accuracy: 0.6598955392837524 , global_step: 3310
- AI-Rank-log  1619055160.9650316  eval_accuracy: 0.6591929197311401 , global_step: 3311
- AI-Rank-log  1619055204.8685658  eval_accuracy: 0.6604241132736206 , global_step: 3312
- AI-Rank-log  1619055248.7903793  eval_accuracy: 0.6588215231895447 , global_step: 3313
- AI-Rank-log  1619055292.7477806  eval_accuracy: 0.6595895290374756 , global_step: 3314
- AI-Rank-log  1619055336.6241145  eval_accuracy: 0.6589359045028687 , global_step: 3315
- AI-Rank-log  1619055380.4967554  eval_accuracy: 0.6603264808654785 , global_step: 3316
- AI-Rank-log  1619055425.446556  eval_accuracy: 0.6574543118476868 , global_step: 3317
- AI-Rank-log  1619055469.6647196  eval_accuracy: 0.6599542498588562 , global_step: 3318
- AI-Rank-log  1619055514.019254  eval_accuracy: 0.6588257551193237 , global_step: 3319
- AI-Rank-log  1619055558.5207584  eval_accuracy: 0.6594163179397583 , global_step: 3320
- AI-Rank-log  1619055602.8710985  eval_accuracy: 0.6596899032592773 , global_step: 3321
- AI-Rank-log  1619055647.647229  eval_accuracy: 0.6588001847267151 , global_step: 3322
- AI-Rank-log  1619055691.613051  eval_accuracy: 0.6593443751335144 , global_step: 3323
- AI-Rank-log  1619055736.0555933  eval_accuracy: 0.6593276858329773 , global_step: 3324
- AI-Rank-log  1619055780.8197162  eval_accuracy: 0.6591759920120239 , global_step: 3325
- AI-Rank-log  1619055826.1251075  eval_accuracy: 0.6588712930679321 , global_step: 3326
- AI-Rank-log  1619055870.0054739  eval_accuracy: 0.659454882144928 , global_step: 3327
- AI-Rank-log  1619055914.0625117  eval_accuracy: 0.658781111240387 , global_step: 3328
- AI-Rank-log  1619055957.943166  eval_accuracy: 0.6595010757446289 , global_step: 3329
- AI-Rank-log  1619056001.9077594  eval_accuracy: 0.6597092151641846 , global_step: 3330
- AI-Rank-log  1619056045.838838  eval_accuracy: 0.6588492393493652 , global_step: 3331
- AI-Rank-log  1619056089.7238197  eval_accuracy: 0.6590955853462219 , global_step: 3332
- AI-Rank-log  1619056133.6840723  eval_accuracy: 0.6596058011054993 , global_step: 3333
- AI-Rank-log  1619056177.574978  eval_accuracy: 0.6583550572395325 , global_step: 3334
- AI-Rank-log  1619056221.4743302  eval_accuracy: 0.6601395606994629 , global_step: 3335
- AI-Rank-log  1619056265.4533951  eval_accuracy: 0.6596733331680298 , global_step: 3336
- AI-Rank-log  1619056309.3418891  eval_accuracy: 0.6600342392921448 , global_step: 3337
- AI-Rank-log  1619056353.2306173  eval_accuracy: 0.6598897576332092 , global_step: 3338
- AI-Rank-log  1619056397.1777546  eval_accuracy: 0.6584821939468384 , global_step: 3339
- AI-Rank-log  1619056441.0737367  eval_accuracy: 0.6586471796035767 , global_step: 3340
- AI-Rank-log  1619056485.0319414  eval_accuracy: 0.6595133543014526 , global_step: 3341
- AI-Rank-log  1619056528.9171894  eval_accuracy: 0.6591857075691223 , global_step: 3342
- AI-Rank-log  1619056572.8292596  eval_accuracy: 0.660121500492096 , global_step: 3343
- AI-Rank-log  1619056616.7996583  eval_accuracy: 0.6595170497894287 , global_step: 3344
- AI-Rank-log  1619056660.7697902  eval_accuracy: 0.6596090197563171 , global_step: 3345
- AI-Rank-log  1619056704.6088443  eval_accuracy: 0.6595388650894165 , global_step: 3346
- AI-Rank-log  1619056748.552915  eval_accuracy: 0.6611905097961426 , global_step: 3347
- AI-Rank-log  1619056792.4615502  eval_accuracy: 0.6593358516693115 , global_step: 3348
- AI-Rank-log  1619056836.4570928  eval_accuracy: 0.660714328289032 , global_step: 3349
- AI-Rank-log  1619056880.3440382  eval_accuracy: 0.6598177552223206 , global_step: 3350
- AI-Rank-log  1619056924.2401273  eval_accuracy: 0.6612464189529419 , global_step: 3351
- AI-Rank-log  1619056968.1383128  eval_accuracy: 0.6602187156677246 , global_step: 3352
- AI-Rank-log  1619057012.0051074  eval_accuracy: 0.6617925763130188 , global_step: 3353
- AI-Rank-log  1619057055.9148457  eval_accuracy: 0.6608015894889832 , global_step: 3354
- AI-Rank-log  1619057099.845041  eval_accuracy: 0.6608498692512512 , global_step: 3355
- AI-Rank-log  1619057143.72016  eval_accuracy: 0.6608335375785828 , global_step: 3356
- AI-Rank-log  1619057187.6606123  eval_accuracy: 0.6599066853523254 , global_step: 3357
- AI-Rank-log  1619057231.4130785  eval_accuracy: 0.6603155136108398 , global_step: 3358
- AI-Rank-log  1619057275.2954452  eval_accuracy: 0.6609907150268555 , global_step: 3359
- AI-Rank-log  1619057319.1608632  eval_accuracy: 0.6600571870803833 , global_step: 3360
- AI-Rank-log  1619057363.092107  eval_accuracy: 0.6606112122535706 , global_step: 3361
- AI-Rank-log  1619057406.968614  eval_accuracy: 0.6601470112800598 , global_step: 3362
- AI-Rank-log  1619057450.9414022  eval_accuracy: 0.6611611843109131 , global_step: 3363
- AI-Rank-log  1619057494.82879  eval_accuracy: 0.6598769426345825 , global_step: 3364
- AI-Rank-log  1619057538.606891  eval_accuracy: 0.6603683829307556 , global_step: 3365
- AI-Rank-log  1619057582.578096  eval_accuracy: 0.6600461006164551 , global_step: 3366
- AI-Rank-log  1619057626.4417822  eval_accuracy: 0.6612814664840698 , global_step: 3367
- AI-Rank-log  1619057670.3157115  eval_accuracy: 0.6610709428787231 , global_step: 3368
- AI-Rank-log  1619057714.3040795  eval_accuracy: 0.6608182787895203 , global_step: 3369
- AI-Rank-log  1619057758.2148204  eval_accuracy: 0.6607251763343811 , global_step: 3370
- AI-Rank-log  1619057802.1526303  eval_accuracy: 0.6607890129089355 , global_step: 3371
- AI-Rank-log  1619057846.0129166  eval_accuracy: 0.660906970500946 , global_step: 3372
- AI-Rank-log  1619057889.9276338  eval_accuracy: 0.6602493524551392 , global_step: 3373
- AI-Rank-log  1619057933.8932514  eval_accuracy: 0.6616197824478149 , global_step: 3374
- AI-Rank-log  1619057977.7504094  eval_accuracy: 0.6607341766357422 , global_step: 3375
- AI-Rank-log  1619058021.6488876  eval_accuracy: 0.6616665720939636 , global_step: 3376
- AI-Rank-log  1619058065.6239202  eval_accuracy: 0.6616392731666565 , global_step: 3377
- AI-Rank-log  1619058109.488631  eval_accuracy: 0.6605641841888428 , global_step: 3378
- AI-Rank-log  1619058153.358965  eval_accuracy: 0.6612626314163208 , global_step: 3379
- AI-Rank-log  1619058197.3081234  eval_accuracy: 0.6613579392433167 , global_step: 3380
- AI-Rank-log  1619058241.1794665  eval_accuracy: 0.6614290475845337 , global_step: 3381
- AI-Rank-log  1619058285.1347342  eval_accuracy: 0.6612880229949951 , global_step: 3382
- AI-Rank-log  1619058329.0342505  eval_accuracy: 0.6610069870948792 , global_step: 3383
- AI-Rank-log  1619058372.944251  eval_accuracy: 0.6599889397621155 , global_step: 3384
- AI-Rank-log  1619058416.94003  eval_accuracy: 0.660245418548584 , global_step: 3385
- AI-Rank-log  1619058460.8438046  eval_accuracy: 0.6603714227676392 , global_step: 3386
- AI-Rank-log  1619058504.7255268  eval_accuracy: 0.6607815623283386 , global_step: 3387
- AI-Rank-log  1619058548.6884806  eval_accuracy: 0.6607187986373901 , global_step: 3388
- AI-Rank-log  1619058592.5847218  eval_accuracy: 0.6613953709602356 , global_step: 3389
- AI-Rank-log  1619058636.4824004  eval_accuracy: 0.6614311337471008 , global_step: 3390
- AI-Rank-log  1619058680.4084823  eval_accuracy: 0.6614044308662415 , global_step: 3391
- AI-Rank-log  1619058724.2557619  eval_accuracy: 0.6613914370536804 , global_step: 3392
- AI-Rank-log  1619058776.9882183  eval_accuracy: 0.6605150103569031 , global_step: 3393
- AI-Rank-log  1619058820.862471  eval_accuracy: 0.6616698503494263 , global_step: 3394
- AI-Rank-log  1619058865.2119489  eval_accuracy: 0.6612493991851807 , global_step: 3395
- AI-Rank-log  1619058909.5793047  eval_accuracy: 0.6628828048706055 , global_step: 3396
- AI-Rank-log  1619058953.5939133  eval_accuracy: 0.6625607013702393 , global_step: 3397
- AI-Rank-log  1619058998.2251117  eval_accuracy: 0.662375271320343 , global_step: 3398
- AI-Rank-log  1619059042.4726453  eval_accuracy: 0.6609584093093872 , global_step: 3399
- AI-Rank-log  1619059086.9242966  eval_accuracy: 0.6627953052520752 , global_step: 3400
- AI-Rank-log  1619059131.3048198  eval_accuracy: 0.6603741645812988 , global_step: 3401
- AI-Rank-log  1619059176.0493488  eval_accuracy: 0.6623609662055969 , global_step: 3402
- AI-Rank-log  1619059220.2186508  eval_accuracy: 0.660467803478241 , global_step: 3403
- AI-Rank-log  1619059265.1530197  eval_accuracy: 0.6604346632957458 , global_step: 3404
- AI-Rank-log  1619059309.02295  eval_accuracy: 0.6603081822395325 , global_step: 3405
- AI-Rank-log  1619059353.2493434  eval_accuracy: 0.6617691516876221 , global_step: 3406
- AI-Rank-log  1619059397.1964085  eval_accuracy: 0.6613612174987793 , global_step: 3407
- AI-Rank-log  1619059441.0720494  eval_accuracy: 0.6619749665260315 , global_step: 3408
- AI-Rank-log  1619059484.9752288  eval_accuracy: 0.6616255044937134 , global_step: 3409
- AI-Rank-log  1619059528.885053  eval_accuracy: 0.6619000434875488 , global_step: 3410
- AI-Rank-log  1619059572.7422519  eval_accuracy: 0.6614251732826233 , global_step: 3411
- AI-Rank-log  1619059616.6145625  eval_accuracy: 0.6624981164932251 , global_step: 3412
- AI-Rank-log  1619059660.5711021  eval_accuracy: 0.6614529490470886 , global_step: 3413
- AI-Rank-log  1619059704.4693177  eval_accuracy: 0.6620649099349976 , global_step: 3414
- AI-Rank-log  1619059748.4624667  eval_accuracy: 0.6617305874824524 , global_step: 3415
- AI-Rank-log  1619059792.3506942  eval_accuracy: 0.6627711057662964 , global_step: 3416
- AI-Rank-log  1619059836.2287302  eval_accuracy: 0.6619897484779358 , global_step: 3417
- AI-Rank-log  1619059880.1892977  eval_accuracy: 0.6620395183563232 , global_step: 3418
- AI-Rank-log  1619059924.0441852  eval_accuracy: 0.6623369455337524 , global_step: 3419
- AI-Rank-log  1619059967.955723  eval_accuracy: 0.6621796488761902 , global_step: 3420
- AI-Rank-log  1619060011.9199123  eval_accuracy: 0.6611260771751404 , global_step: 3421
- AI-Rank-log  1619060055.7956958  eval_accuracy: 0.662051260471344 , global_step: 3422
- AI-Rank-log  1619060099.7102916  eval_accuracy: 0.6608911156654358 , global_step: 3423
- AI-Rank-log  1619060143.6320732  eval_accuracy: 0.662065863609314 , global_step: 3424
- AI-Rank-log  1619060187.558958  eval_accuracy: 0.6618220210075378 , global_step: 3425
- AI-Rank-log  1619060231.5017684  eval_accuracy: 0.6626300811767578 , global_step: 3426
- AI-Rank-log  1619060275.3664994  eval_accuracy: 0.6627511382102966 , global_step: 3427
- AI-Rank-log  1619060319.2633562  eval_accuracy: 0.6635605692863464 , global_step: 3428
- AI-Rank-log  1619060363.1973767  eval_accuracy: 0.663021981716156 , global_step: 3429
- AI-Rank-log  1619060407.097074  eval_accuracy: 0.6625763773918152 , global_step: 3430
- AI-Rank-log  1619060451.0035431  eval_accuracy: 0.6620917320251465 , global_step: 3431
- AI-Rank-log  1619060494.973381  eval_accuracy: 0.662418007850647 , global_step: 3432
- AI-Rank-log  1619060538.8266633  eval_accuracy: 0.6630600094795227 , global_step: 3433
- AI-Rank-log  1619060582.6815567  eval_accuracy: 0.6628361940383911 , global_step: 3434
- AI-Rank-log  1619060626.6394067  eval_accuracy: 0.662630021572113 , global_step: 3435
- AI-Rank-log  1619060670.5095375  eval_accuracy: 0.6615564823150635 , global_step: 3436
- AI-Rank-log  1619060714.4506679  eval_accuracy: 0.6621118187904358 , global_step: 3437
- AI-Rank-log  1619060758.3594394  eval_accuracy: 0.6627059578895569 , global_step: 3438
- AI-Rank-log  1619060802.188246  eval_accuracy: 0.6622225046157837 , global_step: 3439
- AI-Rank-log  1619060846.1499867  eval_accuracy: 0.6621278524398804 , global_step: 3440
- AI-Rank-log  1619060890.0161448  eval_accuracy: 0.6632897257804871 , global_step: 3441
- AI-Rank-log  1619060933.9028163  eval_accuracy: 0.6630884408950806 , global_step: 3442
- AI-Rank-log  1619060977.841148  eval_accuracy: 0.6630791425704956 , global_step: 3443
- AI-Rank-log  1619061021.7696185  eval_accuracy: 0.6615810394287109 , global_step: 3444
- AI-Rank-log  1619061065.6198065  eval_accuracy: 0.6633775234222412 , global_step: 3445
- AI-Rank-log  1619061109.597014  eval_accuracy: 0.6620655655860901 , global_step: 3446
- AI-Rank-log  1619061153.4610703  eval_accuracy: 0.6618718504905701 , global_step: 3447
- AI-Rank-log  1619061197.2860947  eval_accuracy: 0.6625597476959229 , global_step: 3448
- AI-Rank-log  1619061241.285214  eval_accuracy: 0.6622299551963806 , global_step: 3449
- AI-Rank-log  1619061285.1709173  eval_accuracy: 0.6612256765365601 , global_step: 3450
- AI-Rank-log  1619061329.1736927  eval_accuracy: 0.663177490234375 , global_step: 3451
- AI-Rank-log  1619061373.073999  eval_accuracy: 0.6611485481262207 , global_step: 3452
- AI-Rank-log  1619061416.9194133  eval_accuracy: 0.6627042293548584 , global_step: 3453
- AI-Rank-log  1619061460.8605525  eval_accuracy: 0.661252498626709 , global_step: 3454
- AI-Rank-log  1619061504.7798536  eval_accuracy: 0.6625475287437439 , global_step: 3455
- AI-Rank-log  1619061548.5983546  eval_accuracy: 0.6621682643890381 , global_step: 3456
- AI-Rank-log  1619061592.5836525  eval_accuracy: 0.6616615056991577 , global_step: 3457
- AI-Rank-log  1619061636.50215  eval_accuracy: 0.6619071364402771 , global_step: 3458
- AI-Rank-log  1619061680.3959744  eval_accuracy: 0.663602352142334 , global_step: 3459
- AI-Rank-log  1619061724.3251266  eval_accuracy: 0.6628581881523132 , global_step: 3460
- AI-Rank-log  1619061768.209463  eval_accuracy: 0.6635932922363281 , global_step: 3461
- AI-Rank-log  1619061812.1111758  eval_accuracy: 0.6624585390090942 , global_step: 3462
- AI-Rank-log  1619061856.0155885  eval_accuracy: 0.6635565757751465 , global_step: 3463
- AI-Rank-log  1619061899.9302168  eval_accuracy: 0.6628628373146057 , global_step: 3464
- AI-Rank-log  1619061943.8909652  eval_accuracy: 0.6626303195953369 , global_step: 3465
- AI-Rank-log  1619061987.8138528  eval_accuracy: 0.6635886430740356 , global_step: 3466
- AI-Rank-log  1619062031.7624764  eval_accuracy: 0.6636233329772949 , global_step: 3467
- AI-Rank-log  1619062075.7249162  eval_accuracy: 0.6628820300102234 , global_step: 3468
- AI-Rank-log  1619062119.6701787  eval_accuracy: 0.6635669469833374 , global_step: 3469
- AI-Rank-log  1619062163.6455712  eval_accuracy: 0.6632611751556396 , global_step: 3470
- AI-Rank-log  1619062207.558114  eval_accuracy: 0.6630117297172546 , global_step: 3471
- AI-Rank-log  1619062252.4457443  eval_accuracy: 0.662979781627655 , global_step: 3472
- AI-Rank-log  1619062296.4377136  eval_accuracy: 0.6628741025924683 , global_step: 3473
- AI-Rank-log  1619062341.1303911  eval_accuracy: 0.6623926162719727 , global_step: 3474
- AI-Rank-log  1619062385.879267  eval_accuracy: 0.6628093123435974 , global_step: 3475
- AI-Rank-log  1619062430.0762541  eval_accuracy: 0.6623409390449524 , global_step: 3476
- AI-Rank-log  1619062474.8786352  eval_accuracy: 0.6634495258331299 , global_step: 3477
- AI-Rank-log  1619062519.0723572  eval_accuracy: 0.6621949076652527 , global_step: 3478
- AI-Rank-log  1619062563.3129954  eval_accuracy: 0.6636303663253784 , global_step: 3479
- AI-Rank-log  1619062608.09747  eval_accuracy: 0.663482666015625 , global_step: 3480
- AI-Rank-log  1619062653.2744186  eval_accuracy: 0.663746178150177 , global_step: 3481
- AI-Rank-log  1619062697.209124  eval_accuracy: 0.6628672480583191 , global_step: 3482
- AI-Rank-log  1619062740.8953807  eval_accuracy: 0.6633186936378479 , global_step: 3483
- AI-Rank-log  1619062785.1176918  eval_accuracy: 0.6627156138420105 , global_step: 3484
- AI-Rank-log  1619062829.0358784  eval_accuracy: 0.6642964482307434 , global_step: 3485
- AI-Rank-log  1619062872.9544818  eval_accuracy: 0.6636635661125183 , global_step: 3486
- AI-Rank-log  1619062916.979496  eval_accuracy: 0.6638291478157043 , global_step: 3487
- AI-Rank-log  1619062960.9019372  eval_accuracy: 0.6627105474472046 , global_step: 3488
- AI-Rank-log  1619063004.8471005  eval_accuracy: 0.6634381413459778 , global_step: 3489
- AI-Rank-log  1619063048.853358  eval_accuracy: 0.6623026728630066 , global_step: 3490
- AI-Rank-log  1619063092.7321024  eval_accuracy: 0.6631557941436768 , global_step: 3491
- AI-Rank-log  1619063136.7796748  eval_accuracy: 0.6616034507751465 , global_step: 3492
- AI-Rank-log  1619063180.7136834  eval_accuracy: 0.6644520163536072 , global_step: 3493
- AI-Rank-log  1619063224.6321406  eval_accuracy: 0.6637904644012451 , global_step: 3494
- AI-Rank-log  1619063268.658392  eval_accuracy: 0.6644368171691895 , global_step: 3495
- AI-Rank-log  1619063312.591146  eval_accuracy: 0.6635040044784546 , global_step: 3496
- AI-Rank-log  1619063356.5557752  eval_accuracy: 0.6639653444290161 , global_step: 3497
- AI-Rank-log  1619063400.5587683  eval_accuracy: 0.6643745303153992 , global_step: 3498
- AI-Rank-log  1619063444.5356874  eval_accuracy: 0.6640806794166565 , global_step: 3499
- AI-Rank-log  1619063488.4393563  eval_accuracy: 0.6631391644477844 , global_step: 3500
- AI-Rank-log  1619063532.4559777  eval_accuracy: 0.6638973355293274 , global_step: 3501
- AI-Rank-log  1619063576.4275131  eval_accuracy: 0.6637200117111206 , global_step: 3502
- AI-Rank-log  1619063620.504163  eval_accuracy: 0.6639133095741272 , global_step: 3503
- AI-Rank-log  1619063664.449983  eval_accuracy: 0.6638349890708923 , global_step: 3504
- AI-Rank-log  1619063708.38466  eval_accuracy: 0.6633760929107666 , global_step: 3505
- AI-Rank-log  1619063752.380359  eval_accuracy: 0.6640756726264954 , global_step: 3506
- AI-Rank-log  1619063796.3191261  eval_accuracy: 0.66251540184021 , global_step: 3507
- AI-Rank-log  1619063840.2298896  eval_accuracy: 0.6645658016204834 , global_step: 3508
- AI-Rank-log  1619063884.241608  eval_accuracy: 0.663780689239502 , global_step: 3509
- AI-Rank-log  1619063928.3127248  eval_accuracy: 0.6641455292701721 , global_step: 3510
- AI-Rank-log  1619063972.2193756  eval_accuracy: 0.6638008952140808 , global_step: 3511
- AI-Rank-log  1619064016.226007  eval_accuracy: 0.664367139339447 , global_step: 3512
- AI-Rank-log  1619064060.15845  eval_accuracy: 0.6642230749130249 , global_step: 3513
- AI-Rank-log  1619064104.1199617  eval_accuracy: 0.6643153429031372 , global_step: 3514
- AI-Rank-log  1619064148.0526175  eval_accuracy: 0.6638699769973755 , global_step: 3515
- AI-Rank-log  1619064191.9838328  eval_accuracy: 0.6653245091438293 , global_step: 3516
- AI-Rank-log  1619064235.9762788  eval_accuracy: 0.664114236831665 , global_step: 3517
- AI-Rank-log  1619064279.9108353  eval_accuracy: 0.6648444533348083 , global_step: 3518
- AI-Rank-log  1619064323.8794944  eval_accuracy: 0.6640340089797974 , global_step: 3519
- AI-Rank-log  1619064367.8618374  eval_accuracy: 0.6640776991844177 , global_step: 3520
- AI-Rank-log  1619064411.8079429  eval_accuracy: 0.6630678772926331 , global_step: 3521
- AI-Rank-log  1619064455.8026981  eval_accuracy: 0.6635053753852844 , global_step: 3522
- AI-Rank-log  1619064499.720476  eval_accuracy: 0.6627641320228577 , global_step: 3523
- AI-Rank-log  1619064543.6499152  eval_accuracy: 0.6639389395713806 , global_step: 3524
- AI-Rank-log  1619064587.7332468  eval_accuracy: 0.6640845537185669 , global_step: 3525
- AI-Rank-log  1619064631.7813063  eval_accuracy: 0.6635559797286987 , global_step: 3526
- AI-Rank-log  1619064675.725929  eval_accuracy: 0.6647295355796814 , global_step: 3527
- AI-Rank-log  1619064719.7288325  eval_accuracy: 0.6641476154327393 , global_step: 3528
- AI-Rank-log  1619064763.6552215  eval_accuracy: 0.6641374230384827 , global_step: 3529
- AI-Rank-log  1619064807.609017  eval_accuracy: 0.6654090285301208 , global_step: 3530
- AI-Rank-log  1619064851.556757  eval_accuracy: 0.6642438769340515 , global_step: 3531
- AI-Rank-log  1619064895.4609685  eval_accuracy: 0.6645912528038025 , global_step: 3532
- AI-Rank-log  1619064939.4188592  eval_accuracy: 0.6640093326568604 , global_step: 3533
- AI-Rank-log  1619064983.3454828  eval_accuracy: 0.6648389101028442 , global_step: 3534
- AI-Rank-log  1619065027.2752159  eval_accuracy: 0.6633309125900269 , global_step: 3535
- AI-Rank-log  1619065071.290957  eval_accuracy: 0.6655258536338806 , global_step: 3536
- AI-Rank-log  1619065115.187327  eval_accuracy: 0.6632298827171326 , global_step: 3537
- AI-Rank-log  1619065159.1847653  eval_accuracy: 0.664804995059967 , global_step: 3538
- AI-Rank-log  1619065203.2122974  eval_accuracy: 0.6642569899559021 , global_step: 3539
- AI-Rank-log  1619065247.099445  eval_accuracy: 0.664112389087677 , global_step: 3540
- AI-Rank-log  1619065291.0410588  eval_accuracy: 0.662661612033844 , global_step: 3541
- AI-Rank-log  1619065335.0612795  eval_accuracy: 0.6640291810035706 , global_step: 3542
- AI-Rank-log  1619065378.9070623  eval_accuracy: 0.6640470027923584 , global_step: 3543
- AI-Rank-log  1619065422.957254  eval_accuracy: 0.6645965576171875 , global_step: 3544
- AI-Rank-log  1619065466.8653016  eval_accuracy: 0.6646699905395508 , global_step: 3545
- AI-Rank-log  1619065510.8000786  eval_accuracy: 0.664637565612793 , global_step: 3546
- AI-Rank-log  1619065554.8566535  eval_accuracy: 0.6641429662704468 , global_step: 3547
- AI-Rank-log  1619065598.781105  eval_accuracy: 0.6631467938423157 , global_step: 3548
- AI-Rank-log  1619065642.8766112  eval_accuracy: 0.6638726592063904 , global_step: 3549
- AI-Rank-log  1619065687.3532221  eval_accuracy: 0.6638062000274658 , global_step: 3550
- AI-Rank-log  1619065731.6885364  eval_accuracy: 0.663263738155365 , global_step: 3551
- AI-Rank-log  1619065776.1983044  eval_accuracy: 0.6644614338874817 , global_step: 3552
- AI-Rank-log  1619065820.5651033  eval_accuracy: 0.662804365158081 , global_step: 3553
- AI-Rank-log  1619065864.5332782  eval_accuracy: 0.6646448969841003 , global_step: 3554
- AI-Rank-log  1619065909.3096716  eval_accuracy: 0.6646392941474915 , global_step: 3555
- AI-Rank-log  1619065953.568438  eval_accuracy: 0.664772093296051 , global_step: 3556
- AI-Rank-log  1619065998.4824688  eval_accuracy: 0.6640775203704834 , global_step: 3557
- AI-Rank-log  1619066042.507501  eval_accuracy: 0.6654056310653687 , global_step: 3558
- AI-Rank-log  1619066087.83378  eval_accuracy: 0.6649984121322632 , global_step: 3559
- AI-Rank-log  1619066131.7493904  eval_accuracy: 0.6650506258010864 , global_step: 3560
- AI-Rank-log  1619066175.75937  eval_accuracy: 0.6648306250572205 , global_step: 3561
- AI-Rank-log  1619066220.0510798  eval_accuracy: 0.6659521460533142 , global_step: 3562
- AI-Rank-log  1619066263.9461496  eval_accuracy: 0.6645735502243042 , global_step: 3563
- AI-Rank-log  1619066307.9225903  eval_accuracy: 0.6658458709716797 , global_step: 3564
- AI-Rank-log  1619066351.831444  eval_accuracy: 0.6649240255355835 , global_step: 3565
- AI-Rank-log  1619066395.8241546  eval_accuracy: 0.6647416949272156 , global_step: 3566
- AI-Rank-log  1619066439.7421227  eval_accuracy: 0.6659988760948181 , global_step: 3567
- AI-Rank-log  1619066483.675838  eval_accuracy: 0.665086030960083 , global_step: 3568
- AI-Rank-log  1619066527.6522489  eval_accuracy: 0.6651991605758667 , global_step: 3569
- AI-Rank-log  1619066571.62789  eval_accuracy: 0.6653570532798767 , global_step: 3570
- AI-Rank-log  1619066615.5468605  eval_accuracy: 0.6652475595474243 , global_step: 3571
- AI-Rank-log  1619066659.5101366  eval_accuracy: 0.6656169891357422 , global_step: 3572
- AI-Rank-log  1619066703.4661276  eval_accuracy: 0.6638839840888977 , global_step: 3573
- AI-Rank-log  1619066747.3911006  eval_accuracy: 0.6655441522598267 , global_step: 3574
- AI-Rank-log  1619066791.377208  eval_accuracy: 0.664940595626831 , global_step: 3575
- AI-Rank-log  1619066835.2995017  eval_accuracy: 0.6651565432548523 , global_step: 3576
- AI-Rank-log  1619066879.2906158  eval_accuracy: 0.6637566685676575 , global_step: 3577
- AI-Rank-log  1619066923.2473931  eval_accuracy: 0.6647871732711792 , global_step: 3578
- AI-Rank-log  1619066967.2035985  eval_accuracy: 0.6644798517227173 , global_step: 3579
- AI-Rank-log  1619067011.2450628  eval_accuracy: 0.6655096411705017 , global_step: 3580
- AI-Rank-log  1619067055.1713486  eval_accuracy: 0.6643907427787781 , global_step: 3581
- AI-Rank-log  1619067099.1413138  eval_accuracy: 0.6648964285850525 , global_step: 3582
- AI-Rank-log  1619067143.1243525  eval_accuracy: 0.6656699180603027 , global_step: 3583
- AI-Rank-log  1619067187.038947  eval_accuracy: 0.665001392364502 , global_step: 3584
- AI-Rank-log  1619067230.9450707  eval_accuracy: 0.6647312641143799 , global_step: 3585
- AI-Rank-log  1619067274.9310246  eval_accuracy: 0.665614664554596 , global_step: 3586
- AI-Rank-log  1619067318.8929138  eval_accuracy: 0.6637473106384277 , global_step: 3587
- AI-Rank-log  1619067362.9310126  eval_accuracy: 0.66534423828125 , global_step: 3588
- AI-Rank-log  1619067406.8355112  eval_accuracy: 0.664872944355011 , global_step: 3589
- AI-Rank-log  1619067450.7799616  eval_accuracy: 0.6640653014183044 , global_step: 3590
- AI-Rank-log  1619067494.7462504  eval_accuracy: 0.6647846698760986 , global_step: 3591
- AI-Rank-log  1619067538.6533887  eval_accuracy: 0.6656707525253296 , global_step: 3592
- AI-Rank-log  1619067591.3922958  eval_accuracy: 0.6645059585571289 , global_step: 3593
- AI-Rank-log  1619067635.3582823  eval_accuracy: 0.6658971905708313 , global_step: 3594
- AI-Rank-log  1619067679.2833605  eval_accuracy: 0.6647509932518005 , global_step: 3595
- AI-Rank-log  1619067723.2205086  eval_accuracy: 0.6651028394699097 , global_step: 3596
- AI-Rank-log  1619067767.2302864  eval_accuracy: 0.6643689274787903 , global_step: 3597
- AI-Rank-log  1619067811.1272147  eval_accuracy: 0.6658986210823059 , global_step: 3598
- AI-Rank-log  1619067855.1208777  eval_accuracy: 0.6642686724662781 , global_step: 3599
- AI-Rank-log  1619067899.0661535  eval_accuracy: 0.6655818223953247 , global_step: 3600
- AI-Rank-log  1619067942.9509847  eval_accuracy: 0.6644647121429443 , global_step: 3601
- AI-Rank-log  1619067987.0041049  eval_accuracy: 0.6654208302497864 , global_step: 3602
- AI-Rank-log  1619068030.9549797  eval_accuracy: 0.6650418043136597 , global_step: 3603
- AI-Rank-log  1619068074.835242  eval_accuracy: 0.6646947264671326 , global_step: 3604
- AI-Rank-log  1619068118.8426507  eval_accuracy: 0.6658393144607544 , global_step: 3605
- AI-Rank-log  1619068162.778974  eval_accuracy: 0.6650469899177551 , global_step: 3606
- AI-Rank-log  1619068206.735485  eval_accuracy: 0.6661608219146729 , global_step: 3607
- AI-Rank-log  1619068250.7250724  eval_accuracy: 0.6657682061195374 , global_step: 3608
- AI-Rank-log  1619068294.6658356  eval_accuracy: 0.6663626432418823 , global_step: 3609
- AI-Rank-log  1619068338.6223454  eval_accuracy: 0.6664257049560547 , global_step: 3610
- AI-Rank-log  1619068382.6416547  eval_accuracy: 0.6660730838775635 , global_step: 3611
- AI-Rank-log  1619068426.5650914  eval_accuracy: 0.6665740013122559 , global_step: 3612
- AI-Rank-log  1619068470.5225835  eval_accuracy: 0.6669383645057678 , global_step: 3613
- AI-Rank-log  1619068514.4991088  eval_accuracy: 0.6655620336532593 , global_step: 3614
- AI-Rank-log  1619068558.43427  eval_accuracy: 0.6668577790260315 , global_step: 3615
- AI-Rank-log  1619068602.3744411  eval_accuracy: 0.6664276719093323 , global_step: 3616
- AI-Rank-log  1619068646.3268023  eval_accuracy: 0.6659157872200012 , global_step: 3617
- AI-Rank-log  1619068690.2146542  eval_accuracy: 0.6649606823921204 , global_step: 3618
- AI-Rank-log  1619068734.1675906  eval_accuracy: 0.6675555109977722 , global_step: 3619
- AI-Rank-log  1619068778.141199  eval_accuracy: 0.6657790541648865 , global_step: 3620
- AI-Rank-log  1619068822.1041298  eval_accuracy: 0.6673413515090942 , global_step: 3621
- AI-Rank-log  1619068866.7429364  eval_accuracy: 0.6669774055480957 , global_step: 3622
- AI-Rank-log  1619068910.6621604  eval_accuracy: 0.6670205593109131 , global_step: 3623
- AI-Rank-log  1619068954.6448002  eval_accuracy: 0.6673912405967712 , global_step: 3624
- AI-Rank-log  1619068998.5537076  eval_accuracy: 0.6671130061149597 , global_step: 3625
- AI-Rank-log  1619069042.470503  eval_accuracy: 0.6669285893440247 , global_step: 3626
- AI-Rank-log  1619069087.3186786  eval_accuracy: 0.6672602295875549 , global_step: 3627
- AI-Rank-log  1619069131.6673253  eval_accuracy: 0.6663928031921387 , global_step: 3628
- AI-Rank-log  1619069176.1720748  eval_accuracy: 0.6659485101699829 , global_step: 3629
- AI-Rank-log  1619069220.4938667  eval_accuracy: 0.6663517355918884 , global_step: 3630
- AI-Rank-log  1619069264.6277635  eval_accuracy: 0.6658529043197632 , global_step: 3631
- AI-Rank-log  1619069309.448161  eval_accuracy: 0.6665758490562439 , global_step: 3632
- AI-Rank-log  1619069353.4353058  eval_accuracy: 0.6648097634315491 , global_step: 3633
- AI-Rank-log  1619069397.863921  eval_accuracy: 0.6657352447509766 , global_step: 3634
- AI-Rank-log  1619069442.4135509  eval_accuracy: 0.6651983261108398 , global_step: 3635
- AI-Rank-log  1619069487.557288  eval_accuracy: 0.6667154431343079 , global_step: 3636
- AI-Rank-log  1619069531.4745243  eval_accuracy: 0.6660177111625671 , global_step: 3637
- AI-Rank-log  1619069575.5172522  eval_accuracy: 0.666708767414093 , global_step: 3638
- AI-Rank-log  1619069619.8871644  eval_accuracy: 0.666357696056366 , global_step: 3639
- AI-Rank-log  1619069663.8515162  eval_accuracy: 0.6659978032112122 , global_step: 3640
- AI-Rank-log  1619069707.8571565  eval_accuracy: 0.666208803653717 , global_step: 3641
- AI-Rank-log  1619069751.7860153  eval_accuracy: 0.6663570404052734 , global_step: 3642
- AI-Rank-log  1619069795.7775714  eval_accuracy: 0.6671809554100037 , global_step: 3643
- AI-Rank-log  1619069839.7595384  eval_accuracy: 0.6654375195503235 , global_step: 3644
- AI-Rank-log  1619069883.6471462  eval_accuracy: 0.667195737361908 , global_step: 3645
- AI-Rank-log  1619069927.6639934  eval_accuracy: 0.6660951972007751 , global_step: 3646
- AI-Rank-log  1619069971.608334  eval_accuracy: 0.6676990985870361 , global_step: 3647
- AI-Rank-log  1619070015.5523083  eval_accuracy: 0.6664324998855591 , global_step: 3648
- AI-Rank-log  1619070059.5580401  eval_accuracy: 0.6670301556587219 , global_step: 3649
- AI-Rank-log  1619070103.4757266  eval_accuracy: 0.6668025851249695 , global_step: 3650
- AI-Rank-log  1619070147.417758  eval_accuracy: 0.666860818862915 , global_step: 3651
- AI-Rank-log  1619070191.4083977  eval_accuracy: 0.6673383116722107 , global_step: 3652
- AI-Rank-log  1619070235.322977  eval_accuracy: 0.6667826175689697 , global_step: 3653
- AI-Rank-log  1619070279.297  eval_accuracy: 0.6662836670875549 , global_step: 3654
- AI-Rank-log  1619070323.2229342  eval_accuracy: 0.6669537425041199 , global_step: 3655
- AI-Rank-log  1619070367.1285465  eval_accuracy: 0.6654401421546936 , global_step: 3656
- AI-Rank-log  1619070411.1208718  eval_accuracy: 0.6666341423988342 , global_step: 3657
- AI-Rank-log  1619070455.0136833  eval_accuracy: 0.667015790939331 , global_step: 3658
- AI-Rank-log  1619070498.9218903  eval_accuracy: 0.6675350069999695 , global_step: 3659
- AI-Rank-log  1619070543.0327685  eval_accuracy: 0.6670371294021606 , global_step: 3660
- AI-Rank-log  1619070586.959996  eval_accuracy: 0.668002724647522 , global_step: 3661
- AI-Rank-log  1619070630.892863  eval_accuracy: 0.6675654649734497 , global_step: 3662
- AI-Rank-log  1619070674.9521465  eval_accuracy: 0.6674491763114929 , global_step: 3663
- AI-Rank-log  1619070718.8833687  eval_accuracy: 0.6670955419540405 , global_step: 3664
- AI-Rank-log  1619070762.858187  eval_accuracy: 0.6673858761787415 , global_step: 3665
- AI-Rank-log  1619070806.8218772  eval_accuracy: 0.6666989326477051 , global_step: 3666
- AI-Rank-log  1619070850.8033283  eval_accuracy: 0.6676474213600159 , global_step: 3667
- AI-Rank-log  1619070894.7572942  eval_accuracy: 0.6672785878181458 , global_step: 3668
- AI-Rank-log  1619070938.690938  eval_accuracy: 0.6671698689460754 , global_step: 3669
- AI-Rank-log  1619070982.6367764  eval_accuracy: 0.6670503616333008 , global_step: 3670
- AI-Rank-log  1619071026.6089368  eval_accuracy: 0.6660071611404419 , global_step: 3671
- AI-Rank-log  1619071070.5630207  eval_accuracy: 0.666759729385376 , global_step: 3672
- AI-Rank-log  1619071114.45095  eval_accuracy: 0.66487717628479 , global_step: 3673
- AI-Rank-log  1619071158.4134789  eval_accuracy: 0.6665629148483276 , global_step: 3674
- AI-Rank-log  1619071202.3864937  eval_accuracy: 0.6666133999824524 , global_step: 3675
- AI-Rank-log  1619071246.3400998  eval_accuracy: 0.667529821395874 , global_step: 3676
- AI-Rank-log  1619071290.2368739  eval_accuracy: 0.6668328642845154 , global_step: 3677
- AI-Rank-log  1619071334.2373638  eval_accuracy: 0.6668700575828552 , global_step: 3678
- AI-Rank-log  1619071378.232554  eval_accuracy: 0.6665628552436829 , global_step: 3679
- AI-Rank-log  1619071422.195568  eval_accuracy: 0.6670565009117126 , global_step: 3680
- AI-Rank-log  1619071466.1355312  eval_accuracy: 0.6672495007514954 , global_step: 3681
- AI-Rank-log  1619071510.1355536  eval_accuracy: 0.6675522923469543 , global_step: 3682
- AI-Rank-log  1619071554.0848024  eval_accuracy: 0.6685139536857605 , global_step: 3683
- AI-Rank-log  1619071598.022129  eval_accuracy: 0.6672461628913879 , global_step: 3684
- AI-Rank-log  1619071641.9468813  eval_accuracy: 0.6680378317832947 , global_step: 3685
- AI-Rank-log  1619071685.890653  eval_accuracy: 0.6660756468772888 , global_step: 3686
- AI-Rank-log  1619071729.8962183  eval_accuracy: 0.6681950092315674 , global_step: 3687
- AI-Rank-log  1619071773.8456333  eval_accuracy: 0.6663106083869934 , global_step: 3688
- AI-Rank-log  1619071817.8008058  eval_accuracy: 0.6673812866210938 , global_step: 3689
- AI-Rank-log  1619071861.8372977  eval_accuracy: 0.66671222448349 , global_step: 3690
- AI-Rank-log  1619071905.7833285  eval_accuracy: 0.667461633682251 , global_step: 3691
- AI-Rank-log  1619071949.6837132  eval_accuracy: 0.6676160097122192 , global_step: 3692
- AI-Rank-log  1619071993.73028  eval_accuracy: 0.6672940254211426 , global_step: 3693
- AI-Rank-log  1619072037.6723697  eval_accuracy: 0.6671416163444519 , global_step: 3694
- AI-Rank-log  1619072081.6358867  eval_accuracy: 0.667658805847168 , global_step: 3695
- AI-Rank-log  1619072125.68066  eval_accuracy: 0.6667928695678711 , global_step: 3696
- AI-Rank-log  1619072169.5945468  eval_accuracy: 0.667151153087616 , global_step: 3697
- AI-Rank-log  1619072213.6134415  eval_accuracy: 0.6670140027999878 , global_step: 3698
- AI-Rank-log  1619072257.5354924  eval_accuracy: 0.6680859327316284 , global_step: 3699
- AI-Rank-log  1619072301.497047  eval_accuracy: 0.6665859818458557 , global_step: 3700
- AI-Rank-log  1619072345.54249  eval_accuracy: 0.6670425534248352 , global_step: 3701
- AI-Rank-log  1619072389.4425936  eval_accuracy: 0.666114091873169 , global_step: 3702
- AI-Rank-log  1619072433.3689785  eval_accuracy: 0.6675174236297607 , global_step: 3703
- AI-Rank-log  1619072478.2803354  eval_accuracy: 0.6666120290756226 , global_step: 3704
- AI-Rank-log  1619072522.2746496  eval_accuracy: 0.6668898463249207 , global_step: 3705
- AI-Rank-log  1619072566.2156878  eval_accuracy: 0.6659660339355469 , global_step: 3706
- AI-Rank-log  1619072610.7244518  eval_accuracy: 0.6668568849563599 , global_step: 3707
- AI-Rank-log  1619072655.715138  eval_accuracy: 0.6668168306350708 , global_step: 3708
- AI-Rank-log  1619072699.6915624  eval_accuracy: 0.6674929261207581 , global_step: 3709
- AI-Rank-log  1619072744.3696694  eval_accuracy: 0.6675339341163635 , global_step: 3710
- AI-Rank-log  1619072788.9720976  eval_accuracy: 0.6676209568977356 , global_step: 3711
- AI-Rank-log  1619072834.6121712  eval_accuracy: 0.6666724681854248 , global_step: 3712
- AI-Rank-log  1619072878.5824912  eval_accuracy: 0.6678924560546875 , global_step: 3713
- AI-Rank-log  1619072923.7817721  eval_accuracy: 0.6660964488983154 , global_step: 3714
- AI-Rank-log  1619072967.8303974  eval_accuracy: 0.6675848364830017 , global_step: 3715
- AI-Rank-log  1619073011.7832909  eval_accuracy: 0.6665809750556946 , global_step: 3716
- AI-Rank-log  1619073056.0711594  eval_accuracy: 0.6656016111373901 , global_step: 3717
- AI-Rank-log  1619073100.0358872  eval_accuracy: 0.6676666736602783 , global_step: 3718
- AI-Rank-log  1619073143.9530163  eval_accuracy: 0.6670452952384949 , global_step: 3719
- AI-Rank-log  1619073187.939296  eval_accuracy: 0.6675720810890198 , global_step: 3720
- AI-Rank-log  1619073231.8724132  eval_accuracy: 0.6675049066543579 , global_step: 3721
- AI-Rank-log  1619073275.8139825  eval_accuracy: 0.6679582595825195 , global_step: 3722
- AI-Rank-log  1619073319.8642843  eval_accuracy: 0.6667912006378174 , global_step: 3723
- AI-Rank-log  1619073363.8224616  eval_accuracy: 0.6686567068099976 , global_step: 3724
- AI-Rank-log  1619073407.7197895  eval_accuracy: 0.668234646320343 , global_step: 3725
- AI-Rank-log  1619073451.7233796  eval_accuracy: 0.6686795949935913 , global_step: 3726
- AI-Rank-log  1619073495.6823573  eval_accuracy: 0.6687118411064148 , global_step: 3727
- AI-Rank-log  1619073539.6457767  eval_accuracy: 0.6678407788276672 , global_step: 3728
- AI-Rank-log  1619073583.5736833  eval_accuracy: 0.6688671112060547 , global_step: 3729
- AI-Rank-log  1619073627.495658  eval_accuracy: 0.66748046875 , global_step: 3730
- AI-Rank-log  1619073671.4682496  eval_accuracy: 0.6682539582252502 , global_step: 3731
- AI-Rank-log  1619073715.3990922  eval_accuracy: 0.6678352355957031 , global_step: 3732
- AI-Rank-log  1619073759.3252718  eval_accuracy: 0.668961763381958 , global_step: 3733
- AI-Rank-log  1619073803.28699  eval_accuracy: 0.6685102581977844 , global_step: 3734
- AI-Rank-log  1619073847.21834  eval_accuracy: 0.6679255366325378 , global_step: 3735
- AI-Rank-log  1619073891.1213822  eval_accuracy: 0.6675465703010559 , global_step: 3736
- AI-Rank-log  1619073935.1293113  eval_accuracy: 0.6674801111221313 , global_step: 3737
- AI-Rank-log  1619073979.0648875  eval_accuracy: 0.6672295928001404 , global_step: 3738
- AI-Rank-log  1619074023.0211766  eval_accuracy: 0.6681602597236633 , global_step: 3739
- AI-Rank-log  1619074066.9159768  eval_accuracy: 0.6676228642463684 , global_step: 3740
- AI-Rank-log  1619074110.8407447  eval_accuracy: 0.6685323715209961 , global_step: 3741
- AI-Rank-log  1619074154.8498273  eval_accuracy: 0.6679153442382812 , global_step: 3742
- AI-Rank-log  1619074198.702985  eval_accuracy: 0.6682645082473755 , global_step: 3743
- AI-Rank-log  1619074242.673916  eval_accuracy: 0.6678518056869507 , global_step: 3744
- AI-Rank-log  1619074286.6625223  eval_accuracy: 0.6687223315238953 , global_step: 3745
- AI-Rank-log  1619074330.5769315  eval_accuracy: 0.6687583923339844 , global_step: 3746
- AI-Rank-log  1619074374.4949353  eval_accuracy: 0.6680130362510681 , global_step: 3747
- AI-Rank-log  1619074418.5204058  eval_accuracy: 0.6685522794723511 , global_step: 3748
- AI-Rank-log  1619074462.386127  eval_accuracy: 0.6667235493659973 , global_step: 3749
- AI-Rank-log  1619074506.3724186  eval_accuracy: 0.6688994765281677 , global_step: 3750
- AI-Rank-log  1619074550.2568827  eval_accuracy: 0.6683776378631592 , global_step: 3751
- AI-Rank-log  1619074594.1700518  eval_accuracy: 0.6681932210922241 , global_step: 3752
- AI-Rank-log  1619074638.1447163  eval_accuracy: 0.6688678860664368 , global_step: 3753
- AI-Rank-log  1619074682.0190706  eval_accuracy: 0.6682805418968201 , global_step: 3754
- AI-Rank-log  1619074725.9328911  eval_accuracy: 0.6680450439453125 , global_step: 3755
- AI-Rank-log  1619074769.9204683  eval_accuracy: 0.669344425201416 , global_step: 3756
- AI-Rank-log  1619074813.849999  eval_accuracy: 0.6696338057518005 , global_step: 3757
- AI-Rank-log  1619074857.7524016  eval_accuracy: 0.6693148612976074 , global_step: 3758
- AI-Rank-log  1619074901.7526634  eval_accuracy: 0.6690583825111389 , global_step: 3759
- AI-Rank-log  1619074945.6674402  eval_accuracy: 0.6689341068267822 , global_step: 3760
- AI-Rank-log  1619074989.6777062  eval_accuracy: 0.6695456504821777 , global_step: 3761
- AI-Rank-log  1619075033.6309972  eval_accuracy: 0.6688399910926819 , global_step: 3762
- AI-Rank-log  1619075077.49968  eval_accuracy: 0.6693799495697021 , global_step: 3763
- AI-Rank-log  1619075121.5205073  eval_accuracy: 0.6695536375045776 , global_step: 3764
- AI-Rank-log  1619075165.4739046  eval_accuracy: 0.6695713400840759 , global_step: 3765
- AI-Rank-log  1619075209.355716  eval_accuracy: 0.6701359152793884 , global_step: 3766
- AI-Rank-log  1619075253.3043833  eval_accuracy: 0.669034481048584 , global_step: 3767
- AI-Rank-log  1619075297.2350879  eval_accuracy: 0.6701029539108276 , global_step: 3768
- AI-Rank-log  1619075341.1918075  eval_accuracy: 0.6687092781066895 , global_step: 3769
- AI-Rank-log  1619075385.147521  eval_accuracy: 0.6703510284423828 , global_step: 3770
- AI-Rank-log  1619075429.083682  eval_accuracy: 0.6687605381011963 , global_step: 3771
- AI-Rank-log  1619075473.0446677  eval_accuracy: 0.6704226136207581 , global_step: 3772
- AI-Rank-log  1619075516.957217  eval_accuracy: 0.6691367626190186 , global_step: 3773
- AI-Rank-log  1619075560.8664603  eval_accuracy: 0.6690627336502075 , global_step: 3774
- AI-Rank-log  1619075604.8711467  eval_accuracy: 0.6695334911346436 , global_step: 3775
- AI-Rank-log  1619075648.8480496  eval_accuracy: 0.6691479086875916 , global_step: 3776
- AI-Rank-log  1619075692.7815368  eval_accuracy: 0.6680243015289307 , global_step: 3777
- AI-Rank-log  1619075736.7730346  eval_accuracy: 0.6693548560142517 , global_step: 3778
- AI-Rank-log  1619075780.6977963  eval_accuracy: 0.6689967513084412 , global_step: 3779
- AI-Rank-log  1619075824.7174916  eval_accuracy: 0.6684250235557556 , global_step: 3780
- AI-Rank-log  1619075869.8423674  eval_accuracy: 0.6691263914108276 , global_step: 3781
- AI-Rank-log  1619075914.069696  eval_accuracy: 0.6682500243186951 , global_step: 3782
- AI-Rank-log  1619075958.0800056  eval_accuracy: 0.6695043444633484 , global_step: 3783
- AI-Rank-log  1619076003.3637245  eval_accuracy: 0.6686811447143555 , global_step: 3784
- AI-Rank-log  1619076047.356142  eval_accuracy: 0.668820321559906 , global_step: 3785
- AI-Rank-log  1619076091.4484057  eval_accuracy: 0.6690760254859924 , global_step: 3786
- AI-Rank-log  1619076135.3897758  eval_accuracy: 0.6695436835289001 , global_step: 3787
- AI-Rank-log  1619076180.2134573  eval_accuracy: 0.66897052526474 , global_step: 3788
- AI-Rank-log  1619076224.119302  eval_accuracy: 0.670271098613739 , global_step: 3789
- AI-Rank-log  1619076268.7319906  eval_accuracy: 0.6696400046348572 , global_step: 3790
- AI-Rank-log  1619076313.9259918  eval_accuracy: 0.6697939038276672 , global_step: 3791
- AI-Rank-log  1619076357.8299701  eval_accuracy: 0.6690956354141235 , global_step: 3792
- AI-Rank-log  1619076410.7060575  eval_accuracy: 0.6692751049995422 , global_step: 3793
- AI-Rank-log  1619076455.04601  eval_accuracy: 0.6682811379432678 , global_step: 3794
- AI-Rank-log  1619076498.952018  eval_accuracy: 0.6693957448005676 , global_step: 3795
- AI-Rank-log  1619076542.933563  eval_accuracy: 0.6697975397109985 , global_step: 3796
- AI-Rank-log  1619076586.9073436  eval_accuracy: 0.6687657833099365 , global_step: 3797
- AI-Rank-log  1619076630.8508778  eval_accuracy: 0.6693147420883179 , global_step: 3798
- AI-Rank-log  1619076674.8136272  eval_accuracy: 0.6692863702774048 , global_step: 3799
- AI-Rank-log  1619076718.7389984  eval_accuracy: 0.6678616404533386 , global_step: 3800
- AI-Rank-log  1619076762.6612725  eval_accuracy: 0.6690051555633545 , global_step: 3801
- AI-Rank-log  1619076806.7561417  eval_accuracy: 0.6700417399406433 , global_step: 3802
- AI-Rank-log  1619076850.7281044  eval_accuracy: 0.669223427772522 , global_step: 3803
- AI-Rank-log  1619076894.6184926  eval_accuracy: 0.6691722273826599 , global_step: 3804
- AI-Rank-log  1619076938.6259103  eval_accuracy: 0.6697235107421875 , global_step: 3805
- AI-Rank-log  1619076982.5488718  eval_accuracy: 0.6691523194313049 , global_step: 3806
- AI-Rank-log  1619077026.4930742  eval_accuracy: 0.6695845723152161 , global_step: 3807
- AI-Rank-log  1619077070.5049336  eval_accuracy: 0.6687612533569336 , global_step: 3808
- AI-Rank-log  1619077114.4420774  eval_accuracy: 0.6698203682899475 , global_step: 3809
- AI-Rank-log  1619077158.4727564  eval_accuracy: 0.6689971089363098 , global_step: 3810
- AI-Rank-log  1619077202.459278  eval_accuracy: 0.6692624092102051 , global_step: 3811
- AI-Rank-log  1619077246.3932314  eval_accuracy: 0.6689711809158325 , global_step: 3812
- AI-Rank-log  1619077290.3925202  eval_accuracy: 0.6699525117874146 , global_step: 3813
- AI-Rank-log  1619077334.3229609  eval_accuracy: 0.6695023775100708 , global_step: 3814
- AI-Rank-log  1619077378.2831373  eval_accuracy: 0.6704455018043518 , global_step: 3815
- AI-Rank-log  1619077422.24892  eval_accuracy: 0.6697233319282532 , global_step: 3816
- AI-Rank-log  1619077466.1559582  eval_accuracy: 0.6704118251800537 , global_step: 3817
- AI-Rank-log  1619077510.1089249  eval_accuracy: 0.6697500944137573 , global_step: 3818
- AI-Rank-log  1619077553.9803073  eval_accuracy: 0.670076847076416 , global_step: 3819
- AI-Rank-log  1619077597.9582999  eval_accuracy: 0.6699339151382446 , global_step: 3820
- AI-Rank-log  1619077641.87834  eval_accuracy: 0.66973876953125 , global_step: 3821
- AI-Rank-log  1619077685.7934144  eval_accuracy: 0.6699506044387817 , global_step: 3822
- AI-Rank-log  1619077729.7216525  eval_accuracy: 0.6702518463134766 , global_step: 3823
- AI-Rank-log  1619077773.6732068  eval_accuracy: 0.6705421209335327 , global_step: 3824
- AI-Rank-log  1619077817.6464455  eval_accuracy: 0.6703239679336548 , global_step: 3825
- AI-Rank-log  1619077861.6150026  eval_accuracy: 0.6701038479804993 , global_step: 3826
- AI-Rank-log  1619077905.627262  eval_accuracy: 0.6691833734512329 , global_step: 3827
- AI-Rank-log  1619077949.5715125  eval_accuracy: 0.669474184513092 , global_step: 3828
- AI-Rank-log  1619077993.582939  eval_accuracy: 0.6703096032142639 , global_step: 3829
- AI-Rank-log  1619078037.489349  eval_accuracy: 0.6696637272834778 , global_step: 3830
- AI-Rank-log  1619078081.4436944  eval_accuracy: 0.6687084436416626 , global_step: 3831
- AI-Rank-log  1619078125.4342935  eval_accuracy: 0.6699908375740051 , global_step: 3832
- AI-Rank-log  1619078169.326513  eval_accuracy: 0.6700119376182556 , global_step: 3833
- AI-Rank-log  1619078213.2520556  eval_accuracy: 0.6699209809303284 , global_step: 3834
- AI-Rank-log  1619078257.3552852  eval_accuracy: 0.6692957282066345 , global_step: 3835
- AI-Rank-log  1619078301.242013  eval_accuracy: 0.6704418659210205 , global_step: 3836
- AI-Rank-log  1619078345.2292578  eval_accuracy: 0.6688796281814575 , global_step: 3837
- AI-Rank-log  1619078389.1569273  eval_accuracy: 0.6699586510658264 , global_step: 3838
- AI-Rank-log  1619078433.0897853  eval_accuracy: 0.669203519821167 , global_step: 3839
- AI-Rank-log  1619078477.1106794  eval_accuracy: 0.670304536819458 , global_step: 3840
- AI-Rank-log  1619078521.0373366  eval_accuracy: 0.6693384051322937 , global_step: 3841
- AI-Rank-log  1619078564.945074  eval_accuracy: 0.6698178648948669 , global_step: 3842
- AI-Rank-log  1619078608.96224  eval_accuracy: 0.6697170734405518 , global_step: 3843
- AI-Rank-log  1619078652.8844616  eval_accuracy: 0.6694962978363037 , global_step: 3844
- AI-Rank-log  1619078696.8030405  eval_accuracy: 0.670451819896698 , global_step: 3845
- AI-Rank-log  1619078740.8068914  eval_accuracy: 0.6700023412704468 , global_step: 3846
- AI-Rank-log  1619078784.7171865  eval_accuracy: 0.669826090335846 , global_step: 3847
- AI-Rank-log  1619078828.6793444  eval_accuracy: 0.6704456210136414 , global_step: 3848
- AI-Rank-log  1619078872.5948133  eval_accuracy: 0.6699044704437256 , global_step: 3849
- AI-Rank-log  1619078916.4714127  eval_accuracy: 0.6697460412979126 , global_step: 3850
- AI-Rank-log  1619078960.5060544  eval_accuracy: 0.6703976988792419 , global_step: 3851
- AI-Rank-log  1619079004.4609478  eval_accuracy: 0.669711172580719 , global_step: 3852
- AI-Rank-log  1619079048.3515618  eval_accuracy: 0.670937180519104 , global_step: 3853
- AI-Rank-log  1619079092.3103986  eval_accuracy: 0.6698679327964783 , global_step: 3854
- AI-Rank-log  1619079136.2251265  eval_accuracy: 0.6707590818405151 , global_step: 3855
- AI-Rank-log  1619079180.084716  eval_accuracy: 0.6696326732635498 , global_step: 3856
- AI-Rank-log  1619079224.0315716  eval_accuracy: 0.6705361008644104 , global_step: 3857
- AI-Rank-log  1619079267.905275  eval_accuracy: 0.6706412434577942 , global_step: 3858
- AI-Rank-log  1619079312.620498  eval_accuracy: 0.6703762412071228 , global_step: 3859
- AI-Rank-log  1619079356.5584896  eval_accuracy: 0.6705273985862732 , global_step: 3860
- AI-Rank-log  1619079401.0616531  eval_accuracy: 0.670465350151062 , global_step: 3861
- AI-Rank-log  1619079445.3437092  eval_accuracy: 0.6697160601615906 , global_step: 3862
- AI-Rank-log  1619079489.4411983  eval_accuracy: 0.6704632043838501 , global_step: 3863
- AI-Rank-log  1619079533.4117136  eval_accuracy: 0.6703256368637085 , global_step: 3864
- AI-Rank-log  1619079578.2216346  eval_accuracy: 0.6702655553817749 , global_step: 3865
- AI-Rank-log  1619079622.4788191  eval_accuracy: 0.6700177192687988 , global_step: 3866
- AI-Rank-log  1619079667.8049417  eval_accuracy: 0.6703094840049744 , global_step: 3867
- AI-Rank-log  1619079712.040808  eval_accuracy: 0.6708939671516418 , global_step: 3868
- AI-Rank-log  1619079757.305908  eval_accuracy: 0.6683577299118042 , global_step: 3869
- AI-Rank-log  1619079801.2390685  eval_accuracy: 0.6704431772232056 , global_step: 3870
- AI-Rank-log  1619079845.1216125  eval_accuracy: 0.6692594289779663 , global_step: 3871
- AI-Rank-log  1619079889.18771  eval_accuracy: 0.6690015196800232 , global_step: 3872
- AI-Rank-log  1619079933.140081  eval_accuracy: 0.6696716547012329 , global_step: 3873
- AI-Rank-log  1619079977.0776565  eval_accuracy: 0.6701342463493347 , global_step: 3874
- AI-Rank-log  1619080020.9823124  eval_accuracy: 0.6697238683700562 , global_step: 3875
- AI-Rank-log  1619080064.9276807  eval_accuracy: 0.6703290343284607 , global_step: 3876
- AI-Rank-log  1619080108.8141756  eval_accuracy: 0.6696455478668213 , global_step: 3877
- AI-Rank-log  1619080152.7457654  eval_accuracy: 0.6705617904663086 , global_step: 3878
- AI-Rank-log  1619080196.6829612  eval_accuracy: 0.6705514788627625 , global_step: 3879
- AI-Rank-log  1619080240.6219053  eval_accuracy: 0.67081618309021 , global_step: 3880
- AI-Rank-log  1619080284.544401  eval_accuracy: 0.6711196303367615 , global_step: 3881
- AI-Rank-log  1619080328.3913548  eval_accuracy: 0.6704859137535095 , global_step: 3882
- AI-Rank-log  1619080372.260763  eval_accuracy: 0.6701422333717346 , global_step: 3883
- AI-Rank-log  1619080416.2116692  eval_accuracy: 0.6703905463218689 , global_step: 3884
- AI-Rank-log  1619080460.0295339  eval_accuracy: 0.6703702211380005 , global_step: 3885
- AI-Rank-log  1619080503.901851  eval_accuracy: 0.6696847677230835 , global_step: 3886
- AI-Rank-log  1619080547.8903966  eval_accuracy: 0.6695476770401001 , global_step: 3887
- AI-Rank-log  1619080591.7280555  eval_accuracy: 0.6705373525619507 , global_step: 3888
- AI-Rank-log  1619080635.7134008  eval_accuracy: 0.6697404384613037 , global_step: 3889
- AI-Rank-log  1619080679.5889318  eval_accuracy: 0.6706215739250183 , global_step: 3890
- AI-Rank-log  1619080723.432786  eval_accuracy: 0.6700500249862671 , global_step: 3891
- AI-Rank-log  1619080767.3954365  eval_accuracy: 0.6706639528274536 , global_step: 3892
- AI-Rank-log  1619080811.2799754  eval_accuracy: 0.6697185039520264 , global_step: 3893
- AI-Rank-log  1619080855.1430657  eval_accuracy: 0.6705243587493896 , global_step: 3894
- AI-Rank-log  1619080899.084142  eval_accuracy: 0.670059084892273 , global_step: 3895
- AI-Rank-log  1619080942.9751585  eval_accuracy: 0.671488344669342 , global_step: 3896
- AI-Rank-log  1619080986.8395245  eval_accuracy: 0.6705056428909302 , global_step: 3897
- AI-Rank-log  1619081030.810648  eval_accuracy: 0.671523928642273 , global_step: 3898
- AI-Rank-log  1619081074.6492386  eval_accuracy: 0.6715146899223328 , global_step: 3899
- AI-Rank-log  1619081118.5883453  eval_accuracy: 0.671108603477478 , global_step: 3900
- AI-Rank-log  1619081162.4656951  eval_accuracy: 0.6710902452468872 , global_step: 3901
- AI-Rank-log  1619081206.3659508  eval_accuracy: 0.6708216667175293 , global_step: 3902
- AI-Rank-log  1619081250.3872328  eval_accuracy: 0.6710628867149353 , global_step: 3903
- AI-Rank-log  1619081294.2543538  eval_accuracy: 0.6700852513313293 , global_step: 3904
- AI-Rank-log  1619081338.150291  eval_accuracy: 0.6713078618049622 , global_step: 3905
- AI-Rank-log  1619081382.0491004  eval_accuracy: 0.6696956157684326 , global_step: 3906
- AI-Rank-log  1619081425.9238641  eval_accuracy: 0.6713504791259766 , global_step: 3907
- AI-Rank-log  1619081469.846663  eval_accuracy: 0.6710032820701599 , global_step: 3908
- AI-Rank-log  1619081513.7344604  eval_accuracy: 0.6717618703842163 , global_step: 3909
- AI-Rank-log  1619081557.5991042  eval_accuracy: 0.6705458164215088 , global_step: 3910
- AI-Rank-log  1619081601.5119772  eval_accuracy: 0.6711263656616211 , global_step: 3911
- AI-Rank-log  1619081645.3970747  eval_accuracy: 0.6705487370491028 , global_step: 3912
- AI-Rank-log  1619081689.2813468  eval_accuracy: 0.6716263890266418 , global_step: 3913
- AI-Rank-log  1619081733.1989555  eval_accuracy: 0.6703076958656311 , global_step: 3914
- AI-Rank-log  1619081777.1491134  eval_accuracy: 0.6715118885040283 , global_step: 3915
- AI-Rank-log  1619081821.0167022  eval_accuracy: 0.6710155010223389 , global_step: 3916
- AI-Rank-log  1619081864.9423978  eval_accuracy: 0.6712270379066467 , global_step: 3917
- AI-Rank-log  1619081908.8630974  eval_accuracy: 0.6708728671073914 , global_step: 3918
- AI-Rank-log  1619081952.8699107  eval_accuracy: 0.6707977056503296 , global_step: 3919
- AI-Rank-log  1619081996.7769203  eval_accuracy: 0.6708340048789978 , global_step: 3920
- AI-Rank-log  1619082040.648418  eval_accuracy: 0.6709294319152832 , global_step: 3921
- AI-Rank-log  1619082084.5641894  eval_accuracy: 0.6708022952079773 , global_step: 3922
- AI-Rank-log  1619082128.432035  eval_accuracy: 0.6711846590042114 , global_step: 3923
- AI-Rank-log  1619082172.3089345  eval_accuracy: 0.6700844764709473 , global_step: 3924
- AI-Rank-log  1619082216.2364004  eval_accuracy: 0.6721658706665039 , global_step: 3925
- AI-Rank-log  1619082260.1077826  eval_accuracy: 0.670331597328186 , global_step: 3926
- AI-Rank-log  1619082304.024303  eval_accuracy: 0.6716905832290649 , global_step: 3927
- AI-Rank-log  1619082347.9694223  eval_accuracy: 0.6706181168556213 , global_step: 3928
- AI-Rank-log  1619082391.830568  eval_accuracy: 0.6717132329940796 , global_step: 3929
- AI-Rank-log  1619082435.8080325  eval_accuracy: 0.671566903591156 , global_step: 3930
- AI-Rank-log  1619082479.6897979  eval_accuracy: 0.6705166101455688 , global_step: 3931
- AI-Rank-log  1619082523.625362  eval_accuracy: 0.670445442199707 , global_step: 3932
- AI-Rank-log  1619082567.6443768  eval_accuracy: 0.6711763739585876 , global_step: 3933
- AI-Rank-log  1619082611.4912074  eval_accuracy: 0.670487642288208 , global_step: 3934
- AI-Rank-log  1619082655.4168258  eval_accuracy: 0.6710699200630188 , global_step: 3935
- AI-Rank-log  1619082700.2344193  eval_accuracy: 0.6713944673538208 , global_step: 3936
- AI-Rank-log  1619082744.105419  eval_accuracy: 0.6704016923904419 , global_step: 3937
- AI-Rank-log  1619082788.6665902  eval_accuracy: 0.6720155477523804 , global_step: 3938
- AI-Rank-log  1619082833.3825326  eval_accuracy: 0.6709679961204529 , global_step: 3939
- AI-Rank-log  1619082877.4531627  eval_accuracy: 0.671052098274231 , global_step: 3940
- AI-Rank-log  1619082921.6981142  eval_accuracy: 0.6712686419487 , global_step: 3941
- AI-Rank-log  1619082966.317699  eval_accuracy: 0.6720036268234253 , global_step: 3942
- AI-Rank-log  1619083010.7700932  eval_accuracy: 0.6709241271018982 , global_step: 3943
- AI-Rank-log  1619083054.7565506  eval_accuracy: 0.6722381711006165 , global_step: 3944
- AI-Rank-log  1619083099.180205  eval_accuracy: 0.6715573072433472 , global_step: 3945
- AI-Rank-log  1619083144.128809  eval_accuracy: 0.6727080941200256 , global_step: 3946
- AI-Rank-log  1619083188.0959642  eval_accuracy: 0.6712900400161743 , global_step: 3947
- AI-Rank-log  1619083232.0248706  eval_accuracy: 0.6718316674232483 , global_step: 3948
- AI-Rank-log  1619083276.0762215  eval_accuracy: 0.6716445684432983 , global_step: 3949
- AI-Rank-log  1619083320.0418108  eval_accuracy: 0.6717502474784851 , global_step: 3950
- AI-Rank-log  1619083363.9569378  eval_accuracy: 0.6717159152030945 , global_step: 3951
- AI-Rank-log  1619083407.8985767  eval_accuracy: 0.6707755327224731 , global_step: 3952
- AI-Rank-log  1619083451.8175828  eval_accuracy: 0.6726188063621521 , global_step: 3953
- AI-Rank-log  1619083495.6868942  eval_accuracy: 0.6708378195762634 , global_step: 3954
- AI-Rank-log  1619083539.6658947  eval_accuracy: 0.6718146800994873 , global_step: 3955
- AI-Rank-log  1619083583.6032033  eval_accuracy: 0.67171710729599 , global_step: 3956
- AI-Rank-log  1619083627.475808  eval_accuracy: 0.6720920205116272 , global_step: 3957
- AI-Rank-log  1619083671.4217782  eval_accuracy: 0.6720100045204163 , global_step: 3958
- AI-Rank-log  1619083715.349074  eval_accuracy: 0.6716954708099365 , global_step: 3959
- AI-Rank-log  1619083759.213217  eval_accuracy: 0.6718935370445251 , global_step: 3960
- AI-Rank-log  1619083803.2097514  eval_accuracy: 0.6720432043075562 , global_step: 3961
- AI-Rank-log  1619083847.121197  eval_accuracy: 0.6729837656021118 , global_step: 3962
- AI-Rank-log  1619083891.0353966  eval_accuracy: 0.6727907657623291 , global_step: 3963
- AI-Rank-log  1619083934.941777  eval_accuracy: 0.6731582283973694 , global_step: 3964
- AI-Rank-log  1619083978.828568  eval_accuracy: 0.6732259392738342 , global_step: 3965
- AI-Rank-log  1619084022.7623348  eval_accuracy: 0.6724776029586792 , global_step: 3966
- AI-Rank-log  1619084066.6789694  eval_accuracy: 0.6722990870475769 , global_step: 3967
- AI-Rank-log  1619084110.5705655  eval_accuracy: 0.6721343994140625 , global_step: 3968
- AI-Rank-log  1619084154.4779887  eval_accuracy: 0.6717928051948547 , global_step: 3969
- AI-Rank-log  1619084198.3669114  eval_accuracy: 0.6709165573120117 , global_step: 3970
- AI-Rank-log  1619084242.277015  eval_accuracy: 0.6724664568901062 , global_step: 3971
- AI-Rank-log  1619084286.2595055  eval_accuracy: 0.6712906956672668 , global_step: 3972
- AI-Rank-log  1619084330.1411421  eval_accuracy: 0.6724536418914795 , global_step: 3973
- AI-Rank-log  1619084373.9072049  eval_accuracy: 0.6725141406059265 , global_step: 3974
- AI-Rank-log  1619084417.7909935  eval_accuracy: 0.6725701093673706 , global_step: 3975
- AI-Rank-log  1619084461.7345755  eval_accuracy: 0.6714556217193604 , global_step: 3976
- AI-Rank-log  1619084505.6847918  eval_accuracy: 0.6734435558319092 , global_step: 3977
- AI-Rank-log  1619084549.6337595  eval_accuracy: 0.6717450618743896 , global_step: 3978
- AI-Rank-log  1619084593.5445092  eval_accuracy: 0.6734734773635864 , global_step: 3979
- AI-Rank-log  1619084637.4893622  eval_accuracy: 0.6729176640510559 , global_step: 3980
- AI-Rank-log  1619084681.4091322  eval_accuracy: 0.673163890838623 , global_step: 3981
- AI-Rank-log  1619084725.4281452  eval_accuracy: 0.6737122535705566 , global_step: 3982
- AI-Rank-log  1619084769.3341222  eval_accuracy: 0.6731153726577759 , global_step: 3983
- AI-Rank-log  1619084813.209271  eval_accuracy: 0.673625648021698 , global_step: 3984
- AI-Rank-log  1619084857.1866927  eval_accuracy: 0.6725808382034302 , global_step: 3985
- AI-Rank-log  1619084901.0281396  eval_accuracy: 0.673200786113739 , global_step: 3986
- AI-Rank-log  1619084944.993307  eval_accuracy: 0.6724390387535095 , global_step: 3987
- AI-Rank-log  1619084988.9556527  eval_accuracy: 0.6729274392127991 , global_step: 3988
- AI-Rank-log  1619085032.850732  eval_accuracy: 0.6724299788475037 , global_step: 3989
- AI-Rank-log  1619085076.7700539  eval_accuracy: 0.6728395223617554 , global_step: 3990
- AI-Rank-log  1619085120.7064166  eval_accuracy: 0.672920286655426 , global_step: 3991
- AI-Rank-log  1619085164.5894406  eval_accuracy: 0.6723486185073853 , global_step: 3992
- AI-Rank-log  1619085217.6172729  eval_accuracy: 0.6725701689720154 , global_step: 3993
- AI-Rank-log  1619085261.4824963  eval_accuracy: 0.6727122068405151 , global_step: 3994
- AI-Rank-log  1619085305.3589802  eval_accuracy: 0.6720942258834839 , global_step: 3995
- AI-Rank-log  1619085349.3104842  eval_accuracy: 0.6720203161239624 , global_step: 3996
- AI-Rank-log  1619085393.2002037  eval_accuracy: 0.6717686057090759 , global_step: 3997
- AI-Rank-log  1619085437.0402634  eval_accuracy: 0.6719790101051331 , global_step: 3998
- AI-Rank-log  1619085481.0304813  eval_accuracy: 0.671615481376648 , global_step: 3999
- AI-Rank-log  1619085524.9314713  eval_accuracy: 0.6707112789154053 , global_step: 4000
- AI-Rank-log  1619085568.8078241  eval_accuracy: 0.6724499464035034 , global_step: 4001
- AI-Rank-log  1619085612.7922637  eval_accuracy: 0.6705876588821411 , global_step: 4002
- AI-Rank-log  1619085656.691153  eval_accuracy: 0.6715359687805176 , global_step: 4003
- AI-Rank-log  1619085700.6291804  eval_accuracy: 0.6716383099555969 , global_step: 4004
- AI-Rank-log  1619085744.5335107  eval_accuracy: 0.6726999878883362 , global_step: 4005
- AI-Rank-log  1619085788.4191134  eval_accuracy: 0.6722835898399353 , global_step: 4006
- AI-Rank-log  1619085832.4440389  eval_accuracy: 0.6726984977722168 , global_step: 4007
- AI-Rank-log  1619085876.3579316  eval_accuracy: 0.6726040244102478 , global_step: 4008
- AI-Rank-log  1619085920.211937  eval_accuracy: 0.6733769178390503 , global_step: 4009
- AI-Rank-log  1619085964.1468046  eval_accuracy: 0.671863317489624 , global_step: 4010
- AI-Rank-log  1619086008.0287304  eval_accuracy: 0.6733411550521851 , global_step: 4011
- AI-Rank-log  1619086051.9024591  eval_accuracy: 0.6723541617393494 , global_step: 4012
- AI-Rank-log  1619086096.741766  eval_accuracy: 0.6736447215080261 , global_step: 4013
- AI-Rank-log  1619086140.6583364  eval_accuracy: 0.6732895970344543 , global_step: 4014
- AI-Rank-log  1619086185.149809  eval_accuracy: 0.6736186146736145 , global_step: 4015
- AI-Rank-log  1619086229.164198  eval_accuracy: 0.6730442047119141 , global_step: 4016
- AI-Rank-log  1619086273.584676  eval_accuracy: 0.6731017827987671 , global_step: 4017
- AI-Rank-log  1619086317.9326656  eval_accuracy: 0.6715592741966248 , global_step: 4018
- AI-Rank-log  1619086362.706509  eval_accuracy: 0.6733292937278748 , global_step: 4019
- AI-Rank-log  1619086406.8339257  eval_accuracy: 0.6719174981117249 , global_step: 4020
- AI-Rank-log  1619086451.0307066  eval_accuracy: 0.6725026369094849 , global_step: 4021
- AI-Rank-log  1619086495.5724387  eval_accuracy: 0.6729896068572998 , global_step: 4022
- AI-Rank-log  1619086539.7395287  eval_accuracy: 0.6718223094940186 , global_step: 4023
- AI-Rank-log  1619086584.9632268  eval_accuracy: 0.6728293299674988 , global_step: 4024
- AI-Rank-log  1619086628.8551154  eval_accuracy: 0.6724278330802917 , global_step: 4025
- AI-Rank-log  1619086672.8163881  eval_accuracy: 0.6733884215354919 , global_step: 4026
- AI-Rank-log  1619086716.870902  eval_accuracy: 0.6718688607215881 , global_step: 4027
- AI-Rank-log  1619086760.829622  eval_accuracy: 0.6728341579437256 , global_step: 4028
- AI-Rank-log  1619086804.8245933  eval_accuracy: 0.6717000007629395 , global_step: 4029
- AI-Rank-log  1619086848.671493  eval_accuracy: 0.6726986765861511 , global_step: 4030
- AI-Rank-log  1619086892.6080031  eval_accuracy: 0.6728772521018982 , global_step: 4031
- AI-Rank-log  1619086936.638952  eval_accuracy: 0.6727096438407898 , global_step: 4032
- AI-Rank-log  1619086980.5164995  eval_accuracy: 0.6735106110572815 , global_step: 4033
- AI-Rank-log  1619087024.4162745  eval_accuracy: 0.6737558245658875 , global_step: 4034
- AI-Rank-log  1619087068.3480582  eval_accuracy: 0.6733890175819397 , global_step: 4035
- AI-Rank-log  1619087112.194683  eval_accuracy: 0.6738993525505066 , global_step: 4036
- AI-Rank-log  1619087156.134272  eval_accuracy: 0.6740170121192932 , global_step: 4037
- AI-Rank-log  1619087200.053893  eval_accuracy: 0.6734522581100464 , global_step: 4038
- AI-Rank-log  1619087243.9625733  eval_accuracy: 0.6736785769462585 , global_step: 4039
- AI-Rank-log  1619087287.9268737  eval_accuracy: 0.6733893752098083 , global_step: 4040
- AI-Rank-log  1619087331.7792544  eval_accuracy: 0.6731270551681519 , global_step: 4041
- AI-Rank-log  1619087375.6592991  eval_accuracy: 0.6740254759788513 , global_step: 4042
- AI-Rank-log  1619087419.6581945  eval_accuracy: 0.673789918422699 , global_step: 4043
- AI-Rank-log  1619087463.5379546  eval_accuracy: 0.6733328104019165 , global_step: 4044
- AI-Rank-log  1619087507.429171  eval_accuracy: 0.6734541654586792 , global_step: 4045
- AI-Rank-log  1619087551.4333212  eval_accuracy: 0.6725656986236572 , global_step: 4046
- AI-Rank-log  1619087595.3295805  eval_accuracy: 0.6741176247596741 , global_step: 4047
- AI-Rank-log  1619087639.2891095  eval_accuracy: 0.6727657318115234 , global_step: 4048
- AI-Rank-log  1619087683.202033  eval_accuracy: 0.6741333603858948 , global_step: 4049
- AI-Rank-log  1619087727.0924284  eval_accuracy: 0.673008918762207 , global_step: 4050
- AI-Rank-log  1619087771.0897794  eval_accuracy: 0.6735831499099731 , global_step: 4051
- AI-Rank-log  1619087814.9547594  eval_accuracy: 0.6731768846511841 , global_step: 4052
- AI-Rank-log  1619087858.7849174  eval_accuracy: 0.6733777523040771 , global_step: 4053
- AI-Rank-log  1619087902.7447765  eval_accuracy: 0.6730579733848572 , global_step: 4054
- AI-Rank-log  1619087946.7007594  eval_accuracy: 0.6739189624786377 , global_step: 4055
- AI-Rank-log  1619087990.563533  eval_accuracy: 0.6743139028549194 , global_step: 4056
- AI-Rank-log  1619088034.538566  eval_accuracy: 0.6744325757026672 , global_step: 4057
- AI-Rank-log  1619088078.4497085  eval_accuracy: 0.6742357611656189 , global_step: 4058
- AI-Rank-log  1619088122.3728845  eval_accuracy: 0.6742488741874695 , global_step: 4059
- AI-Rank-log  1619088166.3134513  eval_accuracy: 0.6730931401252747 , global_step: 4060
- AI-Rank-log  1619088210.1937575  eval_accuracy: 0.6735929250717163 , global_step: 4061
- AI-Rank-log  1619088254.10323  eval_accuracy: 0.6733958721160889 , global_step: 4062
- AI-Rank-log  1619088297.985308  eval_accuracy: 0.6733784675598145 , global_step: 4063
- AI-Rank-log  1619088341.8686903  eval_accuracy: 0.6737574934959412 , global_step: 4064
- AI-Rank-log  1619088385.8023655  eval_accuracy: 0.6730827689170837 , global_step: 4065
- AI-Rank-log  1619088429.7461562  eval_accuracy: 0.6731091737747192 , global_step: 4066
- AI-Rank-log  1619088473.5846589  eval_accuracy: 0.6739410758018494 , global_step: 4067
- AI-Rank-log  1619088517.5377014  eval_accuracy: 0.6741405129432678 , global_step: 4068
- AI-Rank-log  1619088561.4755034  eval_accuracy: 0.6733648777008057 , global_step: 4069
- AI-Rank-log  1619088605.3891225  eval_accuracy: 0.6739023327827454 , global_step: 4070
- AI-Rank-log  1619088649.3257039  eval_accuracy: 0.6732568144798279 , global_step: 4071
- AI-Rank-log  1619088693.241982  eval_accuracy: 0.6739401817321777 , global_step: 4072
- AI-Rank-log  1619088737.1691303  eval_accuracy: 0.673316240310669 , global_step: 4073
- AI-Rank-log  1619088781.0719693  eval_accuracy: 0.6736682057380676 , global_step: 4074
- AI-Rank-log  1619088824.9767451  eval_accuracy: 0.6725440621376038 , global_step: 4075
- AI-Rank-log  1619088868.8943222  eval_accuracy: 0.6741775274276733 , global_step: 4076
- AI-Rank-log  1619088912.7793467  eval_accuracy: 0.6726319789886475 , global_step: 4077
- AI-Rank-log  1619088956.6486368  eval_accuracy: 0.6741939783096313 , global_step: 4078
- AI-Rank-log  1619089000.5895221  eval_accuracy: 0.6734298467636108 , global_step: 4079
- AI-Rank-log  1619089044.4771001  eval_accuracy: 0.673965573310852 , global_step: 4080
- AI-Rank-log  1619089088.3195512  eval_accuracy: 0.673434317111969 , global_step: 4081
- AI-Rank-log  1619089132.3912623  eval_accuracy: 0.6735944747924805 , global_step: 4082
- AI-Rank-log  1619089176.2858582  eval_accuracy: 0.671944260597229 , global_step: 4083
- AI-Rank-log  1619089220.264222  eval_accuracy: 0.6736180782318115 , global_step: 4084
- AI-Rank-log  1619089264.1752703  eval_accuracy: 0.6731290817260742 , global_step: 4085
- AI-Rank-log  1619089308.074082  eval_accuracy: 0.6732276678085327 , global_step: 4086
- AI-Rank-log  1619089351.9816842  eval_accuracy: 0.6730964183807373 , global_step: 4087
- AI-Rank-log  1619089395.9042869  eval_accuracy: 0.6731612682342529 , global_step: 4088
- AI-Rank-log  1619089439.8208554  eval_accuracy: 0.6737395524978638 , global_step: 4089
- AI-Rank-log  1619089483.825145  eval_accuracy: 0.674196720123291 , global_step: 4090
- AI-Rank-log  1619089528.123581  eval_accuracy: 0.6715038418769836 , global_step: 4091
- AI-Rank-log  1619089572.1149814  eval_accuracy: 0.6727675199508667 , global_step: 4092
- AI-Rank-log  1619089616.6569562  eval_accuracy: 0.6718698143959045 , global_step: 4093
- AI-Rank-log  1619089661.2733586  eval_accuracy: 0.6734975576400757 , global_step: 4094
- AI-Rank-log  1619089705.3880055  eval_accuracy: 0.6738699078559875 , global_step: 4095
- AI-Rank-log  1619089749.3071308  eval_accuracy: 0.6736616492271423 , global_step: 4096
- AI-Rank-log  1619089794.0843441  eval_accuracy: 0.6740105152130127 , global_step: 4097
- AI-Rank-log  1619089838.1273108  eval_accuracy: 0.6727942824363708 , global_step: 4098
- AI-Rank-log  1619089882.4420774  eval_accuracy: 0.6740084886550903 , global_step: 4099
- AI-Rank-log  1619089927.1344988  eval_accuracy: 0.6734764575958252 , global_step: 4100
- AI-Rank-log  1619089972.4733493  eval_accuracy: 0.6745392680168152 , global_step: 4101
- AI-Rank-log  1619090016.3518543  eval_accuracy: 0.6743289828300476 , global_step: 4102
- AI-Rank-log  1619090060.2785006  eval_accuracy: 0.6737210750579834 , global_step: 4103
- AI-Rank-log  1619090105.069559  eval_accuracy: 0.6736422777175903 , global_step: 4104
- AI-Rank-log  1619090148.8935714  eval_accuracy: 0.6744596362113953 , global_step: 4105
- AI-Rank-log  1619090192.81173  eval_accuracy: 0.6741441488265991 , global_step: 4106
- AI-Rank-log  1619090236.7162669  eval_accuracy: 0.6745929718017578 , global_step: 4107
- AI-Rank-log  1619090280.5559604  eval_accuracy: 0.674392580986023 , global_step: 4108
- AI-Rank-log  1619090324.4957616  eval_accuracy: 0.6742277145385742 , global_step: 4109
- AI-Rank-log  1619090368.401654  eval_accuracy: 0.674144983291626 , global_step: 4110
- AI-Rank-log  1619090412.2677205  eval_accuracy: 0.6743788719177246 , global_step: 4111
- AI-Rank-log  1619090456.2764542  eval_accuracy: 0.674403727054596 , global_step: 4112
- AI-Rank-log  1619090500.1467671  eval_accuracy: 0.6744949817657471 , global_step: 4113
- AI-Rank-log  1619090544.09813  eval_accuracy: 0.6747397184371948 , global_step: 4114
- AI-Rank-log  1619090588.0089362  eval_accuracy: 0.6746304035186768 , global_step: 4115
- AI-Rank-log  1619090631.8941145  eval_accuracy: 0.6747673153877258 , global_step: 4116
- AI-Rank-log  1619090675.866051  eval_accuracy: 0.6754648685455322 , global_step: 4117
- AI-Rank-log  1619090719.81255  eval_accuracy: 0.6748961806297302 , global_step: 4118
- AI-Rank-log  1619090763.6975412  eval_accuracy: 0.6736046075820923 , global_step: 4119
- AI-Rank-log  1619090807.6295753  eval_accuracy: 0.674085259437561 , global_step: 4120
- AI-Rank-log  1619090851.5084887  eval_accuracy: 0.6748533844947815 , global_step: 4121
- AI-Rank-log  1619090895.432296  eval_accuracy: 0.6742743253707886 , global_step: 4122
- AI-Rank-log  1619090939.294802  eval_accuracy: 0.6750723123550415 , global_step: 4123
- AI-Rank-log  1619090983.2074165  eval_accuracy: 0.674494206905365 , global_step: 4124
- AI-Rank-log  1619091027.1684887  eval_accuracy: 0.6749373078346252 , global_step: 4125
- AI-Rank-log  1619091071.0913818  eval_accuracy: 0.674717366695404 , global_step: 4126
- AI-Rank-log  1619091114.9944773  eval_accuracy: 0.6748443841934204 , global_step: 4127
- AI-Rank-log  1619091158.9720235  eval_accuracy: 0.6747336387634277 , global_step: 4128
- AI-Rank-log  1619091202.8880477  eval_accuracy: 0.675270140171051 , global_step: 4129
- AI-Rank-log  1619091246.7830741  eval_accuracy: 0.6749798655509949 , global_step: 4130
- AI-Rank-log  1619091290.7094865  eval_accuracy: 0.6743555068969727 , global_step: 4131
- AI-Rank-log  1619091334.6000535  eval_accuracy: 0.6746301054954529 , global_step: 4132
- AI-Rank-log  1619091378.4737272  eval_accuracy: 0.674723207950592 , global_step: 4133
- AI-Rank-log  1619091422.3793485  eval_accuracy: 0.6740579009056091 , global_step: 4134
- AI-Rank-log  1619091466.2978513  eval_accuracy: 0.6741829514503479 , global_step: 4135
- AI-Rank-log  1619091510.227361  eval_accuracy: 0.6735577583312988 , global_step: 4136
- AI-Rank-log  1619091554.0982897  eval_accuracy: 0.6736024022102356 , global_step: 4137
- AI-Rank-log  1619091597.9877987  eval_accuracy: 0.673350989818573 , global_step: 4138
- AI-Rank-log  1619091641.9431777  eval_accuracy: 0.6744678616523743 , global_step: 4139
- AI-Rank-log  1619091685.8423836  eval_accuracy: 0.6744917035102844 , global_step: 4140
- AI-Rank-log  1619091729.707744  eval_accuracy: 0.6740407347679138 , global_step: 4141
- AI-Rank-log  1619091773.5889776  eval_accuracy: 0.6748203039169312 , global_step: 4142
- AI-Rank-log  1619091817.477618  eval_accuracy: 0.6744686365127563 , global_step: 4143
- AI-Rank-log  1619091861.3892102  eval_accuracy: 0.6741149425506592 , global_step: 4144
- AI-Rank-log  1619091905.2602627  eval_accuracy: 0.6752805113792419 , global_step: 4145
- AI-Rank-log  1619091949.1626534  eval_accuracy: 0.6750763058662415 , global_step: 4146
- AI-Rank-log  1619091993.127319  eval_accuracy: 0.6758487820625305 , global_step: 4147
- AI-Rank-log  1619092037.0478961  eval_accuracy: 0.6752354502677917 , global_step: 4148
- AI-Rank-log  1619092080.8975203  eval_accuracy: 0.6746407747268677 , global_step: 4149
- AI-Rank-log  1619092124.8834307  eval_accuracy: 0.6743425130844116 , global_step: 4150
- AI-Rank-log  1619092168.7292132  eval_accuracy: 0.6744809150695801 , global_step: 4151
- AI-Rank-log  1619092212.6211905  eval_accuracy: 0.6739090085029602 , global_step: 4152
- AI-Rank-log  1619092256.5419965  eval_accuracy: 0.6747269034385681 , global_step: 4153
- AI-Rank-log  1619092300.3514225  eval_accuracy: 0.6738666892051697 , global_step: 4154
- AI-Rank-log  1619092344.3404226  eval_accuracy: 0.6753543615341187 , global_step: 4155
- AI-Rank-log  1619092388.2445726  eval_accuracy: 0.6729398369789124 , global_step: 4156
- AI-Rank-log  1619092432.0670085  eval_accuracy: 0.6742523908615112 , global_step: 4157
- AI-Rank-log  1619092476.0548348  eval_accuracy: 0.6743565201759338 , global_step: 4158
- AI-Rank-log  1619092519.9312863  eval_accuracy: 0.6753033995628357 , global_step: 4159
- AI-Rank-log  1619092563.7685554  eval_accuracy: 0.674739420413971 , global_step: 4160
- AI-Rank-log  1619092607.6851249  eval_accuracy: 0.6753767132759094 , global_step: 4161
- AI-Rank-log  1619092651.53451  eval_accuracy: 0.6748968958854675 , global_step: 4162
- AI-Rank-log  1619092695.4277055  eval_accuracy: 0.6752556562423706 , global_step: 4163
- AI-Rank-log  1619092739.363743  eval_accuracy: 0.6746329665184021 , global_step: 4164
- AI-Rank-log  1619092783.2464201  eval_accuracy: 0.6752443909645081 , global_step: 4165
- AI-Rank-log  1619092827.15325  eval_accuracy: 0.6741988658905029 , global_step: 4166
- AI-Rank-log  1619092871.0212502  eval_accuracy: 0.6753871440887451 , global_step: 4167
- AI-Rank-log  1619092915.7395592  eval_accuracy: 0.6744868755340576 , global_step: 4168
- AI-Rank-log  1619092959.6896076  eval_accuracy: 0.6753207445144653 , global_step: 4169
- AI-Rank-log  1619093003.6251516  eval_accuracy: 0.6746262907981873 , global_step: 4170
- AI-Rank-log  1619093048.10549  eval_accuracy: 0.6751847863197327 , global_step: 4171
- AI-Rank-log  1619093092.6383357  eval_accuracy: 0.6746282577514648 , global_step: 4172
- AI-Rank-log  1619093136.5697827  eval_accuracy: 0.6743723154067993 , global_step: 4173
- AI-Rank-log  1619093181.275068  eval_accuracy: 0.6748025417327881 , global_step: 4174
- AI-Rank-log  1619093225.2424455  eval_accuracy: 0.6749524474143982 , global_step: 4175
- AI-Rank-log  1619093269.4506075  eval_accuracy: 0.6751699447631836 , global_step: 4176
- AI-Rank-log  1619093314.1691253  eval_accuracy: 0.6753296852111816 , global_step: 4177
- AI-Rank-log  1619093358.3665442  eval_accuracy: 0.6762335300445557 , global_step: 4178
- AI-Rank-log  1619093403.5500243  eval_accuracy: 0.675247311592102 , global_step: 4179
- AI-Rank-log  1619093447.51962  eval_accuracy: 0.6758599281311035 , global_step: 4180
- AI-Rank-log  1619093491.3494527  eval_accuracy: 0.674835741519928 , global_step: 4181
- AI-Rank-log  1619093535.5358477  eval_accuracy: 0.6752176284790039 , global_step: 4182
- AI-Rank-log  1619093579.4726994  eval_accuracy: 0.6738012433052063 , global_step: 4183
- AI-Rank-log  1619093623.3410623  eval_accuracy: 0.6754634380340576 , global_step: 4184
- AI-Rank-log  1619093667.2030218  eval_accuracy: 0.6743232607841492 , global_step: 4185
- AI-Rank-log  1619093711.1907942  eval_accuracy: 0.6758798956871033 , global_step: 4186
- AI-Rank-log  1619093755.090615  eval_accuracy: 0.6754763126373291 , global_step: 4187
- AI-Rank-log  1619093799.0120976  eval_accuracy: 0.6757520437240601 , global_step: 4188
- AI-Rank-log  1619093842.8840458  eval_accuracy: 0.6752476096153259 , global_step: 4189
- AI-Rank-log  1619093886.7581952  eval_accuracy: 0.6758123636245728 , global_step: 4190
- AI-Rank-log  1619093930.6973248  eval_accuracy: 0.6755223870277405 , global_step: 4191
- AI-Rank-log  1619093974.5563788  eval_accuracy: 0.6755043864250183 , global_step: 4192
- AI-Rank-log  1619094027.7226346  eval_accuracy: 0.6747682094573975 , global_step: 4193
- AI-Rank-log  1619094071.6867194  eval_accuracy: 0.6749914884567261 , global_step: 4194
- AI-Rank-log  1619094115.3416724  eval_accuracy: 0.6742712259292603 , global_step: 4195
- AI-Rank-log  1619094159.144189  eval_accuracy: 0.6755416393280029 , global_step: 4196
- AI-Rank-log  1619094203.0676663  eval_accuracy: 0.6746306419372559 , global_step: 4197
- AI-Rank-log  1619094246.9069355  eval_accuracy: 0.676419198513031 , global_step: 4198
- AI-Rank-log  1619094290.8147492  eval_accuracy: 0.6749793887138367 , global_step: 4199
- AI-Rank-log  1619094334.6611757  eval_accuracy: 0.6760302782058716 , global_step: 4200
- AI-Rank-log  1619094378.504218  eval_accuracy: 0.6756141185760498 , global_step: 4201
- AI-Rank-log  1619094422.4391155  eval_accuracy: 0.676311194896698 , global_step: 4202
- AI-Rank-log  1619094466.293586  eval_accuracy: 0.6760079860687256 , global_step: 4203
- AI-Rank-log  1619094510.1554272  eval_accuracy: 0.6755884885787964 , global_step: 4204
- AI-Rank-log  1619094554.13475  eval_accuracy: 0.6760426163673401 , global_step: 4205
- AI-Rank-log  1619094597.9805863  eval_accuracy: 0.6744677424430847 , global_step: 4206
- AI-Rank-log  1619094641.9454486  eval_accuracy: 0.6745808124542236 , global_step: 4207
- AI-Rank-log  1619094685.8275979  eval_accuracy: 0.6759072542190552 , global_step: 4208
- AI-Rank-log  1619094729.6902773  eval_accuracy: 0.6762664318084717 , global_step: 4209
- AI-Rank-log  1619094773.6460414  eval_accuracy: 0.6759144067764282 , global_step: 4210
- AI-Rank-log  1619094817.4907448  eval_accuracy: 0.6767617464065552 , global_step: 4211
- AI-Rank-log  1619094861.3396995  eval_accuracy: 0.6764285564422607 , global_step: 4212
- AI-Rank-log  1619094905.2974367  eval_accuracy: 0.6769891977310181 , global_step: 4213
- AI-Rank-log  1619094949.138734  eval_accuracy: 0.6772138476371765 , global_step: 4214
- AI-Rank-log  1619094992.9943304  eval_accuracy: 0.6762296557426453 , global_step: 4215
- AI-Rank-log  1619095036.9362173  eval_accuracy: 0.6763032078742981 , global_step: 4216
- AI-Rank-log  1619095080.7816846  eval_accuracy: 0.6748740077018738 , global_step: 4217
- AI-Rank-log  1619095124.6655166  eval_accuracy: 0.6759250164031982 , global_step: 4218
- AI-Rank-log  1619095168.5401757  eval_accuracy: 0.6759415864944458 , global_step: 4219
- AI-Rank-log  1619095212.4110274  eval_accuracy: 0.6758994460105896 , global_step: 4220
- AI-Rank-log  1619095256.3327975  eval_accuracy: 0.6763561367988586 , global_step: 4221
- AI-Rank-log  1619095300.222837  eval_accuracy: 0.6754453182220459 , global_step: 4222
- AI-Rank-log  1619095344.0874426  eval_accuracy: 0.6753888726234436 , global_step: 4223
- AI-Rank-log  1619095388.0327322  eval_accuracy: 0.675658106803894 , global_step: 4224
- AI-Rank-log  1619095431.9124134  eval_accuracy: 0.6761999130249023 , global_step: 4225
- AI-Rank-log  1619095475.83602  eval_accuracy: 0.6761190891265869 , global_step: 4226
- AI-Rank-log  1619095519.7290766  eval_accuracy: 0.6760720610618591 , global_step: 4227
- AI-Rank-log  1619095563.6010156  eval_accuracy: 0.676326334476471 , global_step: 4228
- AI-Rank-log  1619095607.5951066  eval_accuracy: 0.6761147379875183 , global_step: 4229
- AI-Rank-log  1619095651.472564  eval_accuracy: 0.6760003566741943 , global_step: 4230
- AI-Rank-log  1619095695.3661332  eval_accuracy: 0.6746386885643005 , global_step: 4231
- AI-Rank-log  1619095739.2615867  eval_accuracy: 0.6760584712028503 , global_step: 4232
- AI-Rank-log  1619095783.1190984  eval_accuracy: 0.6753140687942505 , global_step: 4233
- AI-Rank-log  1619095827.0387785  eval_accuracy: 0.6761981248855591 , global_step: 4234
- AI-Rank-log  1619095870.932116  eval_accuracy: 0.6765210032463074 , global_step: 4235
- AI-Rank-log  1619095914.8510144  eval_accuracy: 0.6761226058006287 , global_step: 4236
- AI-Rank-log  1619095958.7028875  eval_accuracy: 0.6758268475532532 , global_step: 4237
- AI-Rank-log  1619096002.6165748  eval_accuracy: 0.676101565361023 , global_step: 4238
- AI-Rank-log  1619096046.4845064  eval_accuracy: 0.6767808794975281 , global_step: 4239
- AI-Rank-log  1619096090.232322  eval_accuracy: 0.6757208704948425 , global_step: 4240
- AI-Rank-log  1619096134.0721822  eval_accuracy: 0.6771308183670044 , global_step: 4241
- AI-Rank-log  1619096177.9033585  eval_accuracy: 0.6758195757865906 , global_step: 4242
- AI-Rank-log  1619096221.8190084  eval_accuracy: 0.6769633889198303 , global_step: 4243
- AI-Rank-log  1619096265.6475067  eval_accuracy: 0.6758033633232117 , global_step: 4244
- AI-Rank-log  1619096309.5888295  eval_accuracy: 0.6770848631858826 , global_step: 4245
- AI-Rank-log  1619096353.9669993  eval_accuracy: 0.6751261353492737 , global_step: 4246
- AI-Rank-log  1619096397.9559255  eval_accuracy: 0.676669180393219 , global_step: 4247
- AI-Rank-log  1619096442.462456  eval_accuracy: 0.6756500005722046 , global_step: 4248
- AI-Rank-log  1619096487.164264  eval_accuracy: 0.6761742234230042 , global_step: 4249
- AI-Rank-log  1619096531.2638738  eval_accuracy: 0.6760843992233276 , global_step: 4250
- AI-Rank-log  1619096575.2172391  eval_accuracy: 0.6768025159835815 , global_step: 4251
- AI-Rank-log  1619096620.0644662  eval_accuracy: 0.6759722828865051 , global_step: 4252
- AI-Rank-log  1619096664.1374161  eval_accuracy: 0.6771509051322937 , global_step: 4253
- AI-Rank-log  1619096708.2966042  eval_accuracy: 0.6754612326622009 , global_step: 4254
- AI-Rank-log  1619096752.9424314  eval_accuracy: 0.6771653294563293 , global_step: 4255
- AI-Rank-log  1619096796.8169267  eval_accuracy: 0.6745425462722778 , global_step: 4256
- AI-Rank-log  1619096841.945167  eval_accuracy: 0.6767677068710327 , global_step: 4257
- AI-Rank-log  1619096885.7812943  eval_accuracy: 0.675930917263031 , global_step: 4258
- AI-Rank-log  1619096929.7425113  eval_accuracy: 0.6755988001823425 , global_step: 4259
- AI-Rank-log  1619096974.058382  eval_accuracy: 0.6755932569503784 , global_step: 4260
- AI-Rank-log  1619097017.8792555  eval_accuracy: 0.6757331490516663 , global_step: 4261
- AI-Rank-log  1619097061.8678215  eval_accuracy: 0.6761303544044495 , global_step: 4262
- AI-Rank-log  1619097105.7312248  eval_accuracy: 0.6764084100723267 , global_step: 4263
- AI-Rank-log  1619097149.6047065  eval_accuracy: 0.6762638092041016 , global_step: 4264
- AI-Rank-log  1619097193.5681567  eval_accuracy: 0.6765801310539246 , global_step: 4265
- AI-Rank-log  1619097237.4475284  eval_accuracy: 0.6766060590744019 , global_step: 4266
- AI-Rank-log  1619097281.2835643  eval_accuracy: 0.6767520904541016 , global_step: 4267
- AI-Rank-log  1619097325.2461474  eval_accuracy: 0.6759151220321655 , global_step: 4268
- AI-Rank-log  1619097369.1013093  eval_accuracy: 0.676741898059845 , global_step: 4269
- AI-Rank-log  1619097413.0019023  eval_accuracy: 0.6766203045845032 , global_step: 4270
- AI-Rank-log  1619097456.864272  eval_accuracy: 0.6767470240592957 , global_step: 4271
- AI-Rank-log  1619097500.71339  eval_accuracy: 0.6762310266494751 , global_step: 4272
- AI-Rank-log  1619097544.599971  eval_accuracy: 0.676899790763855 , global_step: 4273
- AI-Rank-log  1619097588.471604  eval_accuracy: 0.6765645742416382 , global_step: 4274
- AI-Rank-log  1619097632.3497746  eval_accuracy: 0.6770421862602234 , global_step: 4275
- AI-Rank-log  1619097676.2443802  eval_accuracy: 0.6768733263015747 , global_step: 4276
- AI-Rank-log  1619097720.0939994  eval_accuracy: 0.6763932108879089 , global_step: 4277
- AI-Rank-log  1619097763.989974  eval_accuracy: 0.6764979362487793 , global_step: 4278
- AI-Rank-log  1619097807.8574085  eval_accuracy: 0.6757970452308655 , global_step: 4279
- AI-Rank-log  1619097851.7335713  eval_accuracy: 0.6770331859588623 , global_step: 4280
- AI-Rank-log  1619097895.6542385  eval_accuracy: 0.6760064363479614 , global_step: 4281
- AI-Rank-log  1619097939.549053  eval_accuracy: 0.6767483353614807 , global_step: 4282
- AI-Rank-log  1619097983.4165692  eval_accuracy: 0.6762906908988953 , global_step: 4283
- AI-Rank-log  1619098027.3674717  eval_accuracy: 0.6769842505455017 , global_step: 4284
- AI-Rank-log  1619098071.1987288  eval_accuracy: 0.6760095953941345 , global_step: 4285
- AI-Rank-log  1619098115.0672724  eval_accuracy: 0.6766357421875 , global_step: 4286
- AI-Rank-log  1619098158.953883  eval_accuracy: 0.6757556796073914 , global_step: 4287
- AI-Rank-log  1619098202.7752988  eval_accuracy: 0.6766182780265808 , global_step: 4288
- AI-Rank-log  1619098246.6825583  eval_accuracy: 0.6765857338905334 , global_step: 4289
- AI-Rank-log  1619098290.486181  eval_accuracy: 0.6771065592765808 , global_step: 4290
- AI-Rank-log  1619098334.3538375  eval_accuracy: 0.6775012016296387 , global_step: 4291
- AI-Rank-log  1619098378.2791882  eval_accuracy: 0.6760213971138 , global_step: 4292
- AI-Rank-log  1619098422.096086  eval_accuracy: 0.6768332123756409 , global_step: 4293
- AI-Rank-log  1619098465.975583  eval_accuracy: 0.6762864589691162 , global_step: 4294
- AI-Rank-log  1619098509.8928216  eval_accuracy: 0.6769651770591736 , global_step: 4295
- AI-Rank-log  1619098553.719947  eval_accuracy: 0.6772331595420837 , global_step: 4296
- AI-Rank-log  1619098597.5964763  eval_accuracy: 0.6767535209655762 , global_step: 4297
- AI-Rank-log  1619098641.4982076  eval_accuracy: 0.6770457625389099 , global_step: 4298
- AI-Rank-log  1619098685.340157  eval_accuracy: 0.6773018836975098 , global_step: 4299
- AI-Rank-log  1619098729.319375  eval_accuracy: 0.6767123937606812 , global_step: 4300
- AI-Rank-log  1619098773.150351  eval_accuracy: 0.6782892942428589 , global_step: 4301
- AI-Rank-log  1619098816.9901586  eval_accuracy: 0.6770259737968445 , global_step: 4302
- AI-Rank-log  1619098860.963039  eval_accuracy: 0.6781648397445679 , global_step: 4303
- AI-Rank-log  1619098904.8146687  eval_accuracy: 0.6761635541915894 , global_step: 4304
- AI-Rank-log  1619098948.7018268  eval_accuracy: 0.6780848503112793 , global_step: 4305
- AI-Rank-log  1619098992.6489644  eval_accuracy: 0.6762258410453796 , global_step: 4306
- AI-Rank-log  1619099036.4742098  eval_accuracy: 0.6779781579971313 , global_step: 4307
- AI-Rank-log  1619099080.33851  eval_accuracy: 0.6774431467056274 , global_step: 4308
- AI-Rank-log  1619099124.3019342  eval_accuracy: 0.6775009632110596 , global_step: 4309
- AI-Rank-log  1619099168.134103  eval_accuracy: 0.6768507361412048 , global_step: 4310
- AI-Rank-log  1619099212.0753782  eval_accuracy: 0.6770140528678894 , global_step: 4311
- AI-Rank-log  1619099255.9407806  eval_accuracy: 0.6765788197517395 , global_step: 4312
- AI-Rank-log  1619099299.804296  eval_accuracy: 0.6777625679969788 , global_step: 4313
- AI-Rank-log  1619099343.7569418  eval_accuracy: 0.6770793199539185 , global_step: 4314
- AI-Rank-log  1619099387.602324  eval_accuracy: 0.6768671274185181 , global_step: 4315
- AI-Rank-log  1619099431.4610755  eval_accuracy: 0.6765843629837036 , global_step: 4316
- AI-Rank-log  1619099475.3781164  eval_accuracy: 0.6774223446846008 , global_step: 4317
- AI-Rank-log  1619099519.197632  eval_accuracy: 0.6769392490386963 , global_step: 4318
- AI-Rank-log  1619099563.1013684  eval_accuracy: 0.6768679022789001 , global_step: 4319
- AI-Rank-log  1619099606.9943104  eval_accuracy: 0.6766298413276672 , global_step: 4320
- AI-Rank-log  1619099650.8309271  eval_accuracy: 0.6764370203018188 , global_step: 4321
- AI-Rank-log  1619099694.7425723  eval_accuracy: 0.6772131323814392 , global_step: 4322
- AI-Rank-log  1619099739.372771  eval_accuracy: 0.6769762635231018 , global_step: 4323
- AI-Rank-log  1619099783.2319527  eval_accuracy: 0.6765381693840027 , global_step: 4324
- AI-Rank-log  1619099827.1644137  eval_accuracy: 0.6774102449417114 , global_step: 4325
- AI-Rank-log  1619099872.2386088  eval_accuracy: 0.6758792400360107 , global_step: 4326
- AI-Rank-log  1619099916.0795202  eval_accuracy: 0.6775059700012207 , global_step: 4327
- AI-Rank-log  1619099960.175939  eval_accuracy: 0.6764445304870605 , global_step: 4328
- AI-Rank-log  1619100004.0598757  eval_accuracy: 0.6775472164154053 , global_step: 4329
- AI-Rank-log  1619100048.6336942  eval_accuracy: 0.676982581615448 , global_step: 4330
- AI-Rank-log  1619100093.0634525  eval_accuracy: 0.6772459149360657 , global_step: 4331
- AI-Rank-log  1619100138.202875  eval_accuracy: 0.6769982576370239 , global_step: 4332
- AI-Rank-log  1619100182.1771367  eval_accuracy: 0.6763939261436462 , global_step: 4333
- AI-Rank-log  1619100227.61626  eval_accuracy: 0.676933228969574 , global_step: 4334
- AI-Rank-log  1619100271.490411  eval_accuracy: 0.6770489811897278 , global_step: 4335
- AI-Rank-log  1619100315.3818262  eval_accuracy: 0.677265465259552 , global_step: 4336
- AI-Rank-log  1619100359.7457619  eval_accuracy: 0.6771515607833862 , global_step: 4337
- AI-Rank-log  1619100403.5835013  eval_accuracy: 0.676437258720398 , global_step: 4338
- AI-Rank-log  1619100447.4806187  eval_accuracy: 0.677750825881958 , global_step: 4339
- AI-Rank-log  1619100491.3712096  eval_accuracy: 0.6773601770401001 , global_step: 4340
- AI-Rank-log  1619100535.3406103  eval_accuracy: 0.6772014498710632 , global_step: 4341
- AI-Rank-log  1619100579.2049873  eval_accuracy: 0.6771613955497742 , global_step: 4342
- AI-Rank-log  1619100623.081449  eval_accuracy: 0.6774166822433472 , global_step: 4343
- AI-Rank-log  1619100667.0293941  eval_accuracy: 0.6760367751121521 , global_step: 4344
- AI-Rank-log  1619100710.950162  eval_accuracy: 0.6772748231887817 , global_step: 4345
- AI-Rank-log  1619100754.799763  eval_accuracy: 0.6769130825996399 , global_step: 4346
- AI-Rank-log  1619100798.7195368  eval_accuracy: 0.6783972978591919 , global_step: 4347
- AI-Rank-log  1619100842.5559664  eval_accuracy: 0.6777681112289429 , global_step: 4348
- AI-Rank-log  1619100886.444393  eval_accuracy: 0.6777780055999756 , global_step: 4349
- AI-Rank-log  1619100930.2892811  eval_accuracy: 0.6785812377929688 , global_step: 4350
- AI-Rank-log  1619100974.1117885  eval_accuracy: 0.6782099604606628 , global_step: 4351
- AI-Rank-log  1619101018.0374205  eval_accuracy: 0.6780573129653931 , global_step: 4352
- AI-Rank-log  1619101061.8495471  eval_accuracy: 0.6772685050964355 , global_step: 4353
- AI-Rank-log  1619101105.7442825  eval_accuracy: 0.6783227920532227 , global_step: 4354
- AI-Rank-log  1619101149.6618285  eval_accuracy: 0.678054928779602 , global_step: 4355
- AI-Rank-log  1619101193.4956665  eval_accuracy: 0.6783215403556824 , global_step: 4356
- AI-Rank-log  1619101237.381898  eval_accuracy: 0.6787924766540527 , global_step: 4357
- AI-Rank-log  1619101281.2890654  eval_accuracy: 0.6776221990585327 , global_step: 4358
- AI-Rank-log  1619101325.138218  eval_accuracy: 0.6781885623931885 , global_step: 4359
- AI-Rank-log  1619101369.047504  eval_accuracy: 0.6779921650886536 , global_step: 4360
- AI-Rank-log  1619101412.900467  eval_accuracy: 0.6768279671669006 , global_step: 4361
- AI-Rank-log  1619101456.7416143  eval_accuracy: 0.67725670337677 , global_step: 4362
- AI-Rank-log  1619101500.628005  eval_accuracy: 0.67800372838974 , global_step: 4363
- AI-Rank-log  1619101544.4661684  eval_accuracy: 0.6778857111930847 , global_step: 4364
- AI-Rank-log  1619101588.286466  eval_accuracy: 0.6786110997200012 , global_step: 4365
- AI-Rank-log  1619101632.2251124  eval_accuracy: 0.6780968308448792 , global_step: 4366
- AI-Rank-log  1619101676.0612981  eval_accuracy: 0.679238498210907 , global_step: 4367
- AI-Rank-log  1619101719.8984644  eval_accuracy: 0.6783154010772705 , global_step: 4368
- AI-Rank-log  1619101763.838939  eval_accuracy: 0.6786446571350098 , global_step: 4369
- AI-Rank-log  1619101807.65058  eval_accuracy: 0.6788650751113892 , global_step: 4370
- AI-Rank-log  1619101851.5199134  eval_accuracy: 0.6784223914146423 , global_step: 4371
- AI-Rank-log  1619101895.494664  eval_accuracy: 0.6788558959960938 , global_step: 4372
- AI-Rank-log  1619101939.338833  eval_accuracy: 0.6776873469352722 , global_step: 4373
- AI-Rank-log  1619101983.2552824  eval_accuracy: 0.6785247921943665 , global_step: 4374
- AI-Rank-log  1619102026.9197352  eval_accuracy: 0.677510678768158 , global_step: 4375
- AI-Rank-log  1619102070.7542317  eval_accuracy: 0.6778134107589722 , global_step: 4376
- AI-Rank-log  1619102114.6983774  eval_accuracy: 0.6764358282089233 , global_step: 4377
- AI-Rank-log  1619102158.555548  eval_accuracy: 0.6775081157684326 , global_step: 4378
- AI-Rank-log  1619102202.4278133  eval_accuracy: 0.6765122413635254 , global_step: 4379
- AI-Rank-log  1619102246.373532  eval_accuracy: 0.6778539419174194 , global_step: 4380
- AI-Rank-log  1619102290.2256567  eval_accuracy: 0.6770272254943848 , global_step: 4381
- AI-Rank-log  1619102334.0385442  eval_accuracy: 0.6774379014968872 , global_step: 4382
- AI-Rank-log  1619102378.0068944  eval_accuracy: 0.677869975566864 , global_step: 4383
- AI-Rank-log  1619102421.8858232  eval_accuracy: 0.6778553128242493 , global_step: 4384
- AI-Rank-log  1619102465.7654397  eval_accuracy: 0.6779663562774658 , global_step: 4385
- AI-Rank-log  1619102509.6082864  eval_accuracy: 0.6786759495735168 , global_step: 4386
- AI-Rank-log  1619102553.45502  eval_accuracy: 0.6779418587684631 , global_step: 4387
- AI-Rank-log  1619102597.3635278  eval_accuracy: 0.6779523491859436 , global_step: 4388
- AI-Rank-log  1619102641.240403  eval_accuracy: 0.6774678230285645 , global_step: 4389
- AI-Rank-log  1619102685.1173844  eval_accuracy: 0.6773437857627869 , global_step: 4390
- AI-Rank-log  1619102729.0616698  eval_accuracy: 0.6776778101921082 , global_step: 4391
- AI-Rank-log  1619102772.9167275  eval_accuracy: 0.6782631278038025 , global_step: 4392
- AI-Rank-log  1619102825.6587472  eval_accuracy: 0.6785628795623779 , global_step: 4393
- AI-Rank-log  1619102869.6201396  eval_accuracy: 0.678675651550293 , global_step: 4394
- AI-Rank-log  1619102913.4724844  eval_accuracy: 0.6782309412956238 , global_step: 4395
- AI-Rank-log  1619102957.7907917  eval_accuracy: 0.6792660355567932 , global_step: 4396
- AI-Rank-log  1619103001.6140728  eval_accuracy: 0.6783134937286377 , global_step: 4397
- AI-Rank-log  1619103045.44998  eval_accuracy: 0.6790345311164856 , global_step: 4398
- AI-Rank-log  1619103089.4052503  eval_accuracy: 0.6780667901039124 , global_step: 4399
- AI-Rank-log  1619103134.2662647  eval_accuracy: 0.6784003973007202 , global_step: 4400
- AI-Rank-log  1619103178.1039999  eval_accuracy: 0.6772777438163757 , global_step: 4401
- AI-Rank-log  1619103221.9657984  eval_accuracy: 0.6784509420394897 , global_step: 4402
- AI-Rank-log  1619103266.269556  eval_accuracy: 0.6784493923187256 , global_step: 4403
- AI-Rank-log  1619103310.4606318  eval_accuracy: 0.6787143349647522 , global_step: 4404
- AI-Rank-log  1619103355.3933158  eval_accuracy: 0.6784431338310242 , global_step: 4405
- AI-Rank-log  1619103399.2484217  eval_accuracy: 0.6778535842895508 , global_step: 4406
- AI-Rank-log  1619103444.0436485  eval_accuracy: 0.6788290143013 , global_step: 4407
- AI-Rank-log  1619103488.539465  eval_accuracy: 0.6789105534553528 , global_step: 4408
- AI-Rank-log  1619103532.3780468  eval_accuracy: 0.6785107254981995 , global_step: 4409
- AI-Rank-log  1619103577.0498335  eval_accuracy: 0.678909420967102 , global_step: 4410
- AI-Rank-log  1619103622.1371539  eval_accuracy: 0.6783245801925659 , global_step: 4411
- AI-Rank-log  1619103665.9786031  eval_accuracy: 0.6792745590209961 , global_step: 4412
- AI-Rank-log  1619103709.9331737  eval_accuracy: 0.6781501173973083 , global_step: 4413
- AI-Rank-log  1619103753.7695057  eval_accuracy: 0.678734302520752 , global_step: 4414
- AI-Rank-log  1619103797.874689  eval_accuracy: 0.6781131029129028 , global_step: 4415
- AI-Rank-log  1619103841.7760344  eval_accuracy: 0.6787903308868408 , global_step: 4416
- AI-Rank-log  1619103885.6174455  eval_accuracy: 0.6780104637145996 , global_step: 4417
- AI-Rank-log  1619103929.6297035  eval_accuracy: 0.6791625618934631 , global_step: 4418
- AI-Rank-log  1619103973.5028293  eval_accuracy: 0.6787568926811218 , global_step: 4419
- AI-Rank-log  1619104017.330821  eval_accuracy: 0.6789765954017639 , global_step: 4420
- AI-Rank-log  1619104061.2417378  eval_accuracy: 0.6788367629051208 , global_step: 4421
- AI-Rank-log  1619104105.1325922  eval_accuracy: 0.6788995862007141 , global_step: 4422
- AI-Rank-log  1619104148.9667108  eval_accuracy: 0.6788057088851929 , global_step: 4423
- AI-Rank-log  1619104192.8968828  eval_accuracy: 0.6793010830879211 , global_step: 4424
- AI-Rank-log  1619104236.7738547  eval_accuracy: 0.6787771582603455 , global_step: 4425
- AI-Rank-log  1619104280.6845272  eval_accuracy: 0.6784644722938538 , global_step: 4426
- AI-Rank-log  1619104324.5071757  eval_accuracy: 0.6790291666984558 , global_step: 4427
- AI-Rank-log  1619104368.3793979  eval_accuracy: 0.6778380274772644 , global_step: 4428
- AI-Rank-log  1619104412.3462615  eval_accuracy: 0.6793066263198853 , global_step: 4429
- AI-Rank-log  1619104455.9774828  eval_accuracy: 0.678989052772522 , global_step: 4430
- AI-Rank-log  1619104499.8518884  eval_accuracy: 0.6791447401046753 , global_step: 4431
- AI-Rank-log  1619104543.7970269  eval_accuracy: 0.6786057353019714 , global_step: 4432
- AI-Rank-log  1619104587.6405709  eval_accuracy: 0.6793385148048401 , global_step: 4433
- AI-Rank-log  1619104631.4781063  eval_accuracy: 0.6786918640136719 , global_step: 4434
- AI-Rank-log  1619104675.4062567  eval_accuracy: 0.6792389154434204 , global_step: 4435
- AI-Rank-log  1619104719.3025153  eval_accuracy: 0.6782277822494507 , global_step: 4436
- AI-Rank-log  1619104763.1480865  eval_accuracy: 0.6793630123138428 , global_step: 4437
- AI-Rank-log  1619104807.1093223  eval_accuracy: 0.6785823106765747 , global_step: 4438
- AI-Rank-log  1619104850.970571  eval_accuracy: 0.6789710521697998 , global_step: 4439
- AI-Rank-log  1619104894.8466585  eval_accuracy: 0.677823543548584 , global_step: 4440
- AI-Rank-log  1619104938.691219  eval_accuracy: 0.679966926574707 , global_step: 4441
- AI-Rank-log  1619104982.5569224  eval_accuracy: 0.6794970631599426 , global_step: 4442
- AI-Rank-log  1619105026.483903  eval_accuracy: 0.6799359917640686 , global_step: 4443
- AI-Rank-log  1619105070.3837404  eval_accuracy: 0.6785690188407898 , global_step: 4444
- AI-Rank-log  1619105114.2088044  eval_accuracy: 0.6797611713409424 , global_step: 4445
- AI-Rank-log  1619105158.1116228  eval_accuracy: 0.678926408290863 , global_step: 4446
- AI-Rank-log  1619105201.9708571  eval_accuracy: 0.6799962520599365 , global_step: 4447
- AI-Rank-log  1619105245.9166296  eval_accuracy: 0.6789765954017639 , global_step: 4448
- AI-Rank-log  1619105289.7395513  eval_accuracy: 0.6788137555122375 , global_step: 4449
- AI-Rank-log  1619105333.5876217  eval_accuracy: 0.6789831519126892 , global_step: 4450
- AI-Rank-log  1619105377.4543605  eval_accuracy: 0.6789515018463135 , global_step: 4451
- AI-Rank-log  1619105421.3462584  eval_accuracy: 0.679157555103302 , global_step: 4452
- AI-Rank-log  1619105465.1842217  eval_accuracy: 0.6801016926765442 , global_step: 4453
- AI-Rank-log  1619105509.1042025  eval_accuracy: 0.6797133684158325 , global_step: 4454
- AI-Rank-log  1619105552.9551709  eval_accuracy: 0.6789045333862305 , global_step: 4455
- AI-Rank-log  1619105596.8399591  eval_accuracy: 0.678183376789093 , global_step: 4456
- AI-Rank-log  1619105640.667442  eval_accuracy: 0.6784522533416748 , global_step: 4457
- AI-Rank-log  1619105684.5577366  eval_accuracy: 0.6778920292854309 , global_step: 4458
- AI-Rank-log  1619105728.451217  eval_accuracy: 0.67830890417099 , global_step: 4459
- AI-Rank-log  1619105772.294194  eval_accuracy: 0.6779137253761292 , global_step: 4460
- AI-Rank-log  1619105816.1756136  eval_accuracy: 0.6783162951469421 , global_step: 4461
- AI-Rank-log  1619105860.0955665  eval_accuracy: 0.6782686710357666 , global_step: 4462
- AI-Rank-log  1619105903.901711  eval_accuracy: 0.6792407035827637 , global_step: 4463
- AI-Rank-log  1619105947.7290592  eval_accuracy: 0.6792105436325073 , global_step: 4464
- AI-Rank-log  1619105991.662473  eval_accuracy: 0.6791381239891052 , global_step: 4465
- AI-Rank-log  1619106035.476354  eval_accuracy: 0.6785683631896973 , global_step: 4466
- AI-Rank-log  1619106079.4112186  eval_accuracy: 0.6789067387580872 , global_step: 4467
- AI-Rank-log  1619106123.2454462  eval_accuracy: 0.6791789531707764 , global_step: 4468
- AI-Rank-log  1619106167.0294123  eval_accuracy: 0.6795064806938171 , global_step: 4469
- AI-Rank-log  1619106210.9897783  eval_accuracy: 0.6789686679840088 , global_step: 4470
- AI-Rank-log  1619106254.7821698  eval_accuracy: 0.6788730621337891 , global_step: 4471
- AI-Rank-log  1619106298.6333103  eval_accuracy: 0.6784636378288269 , global_step: 4472
- AI-Rank-log  1619106342.5553014  eval_accuracy: 0.6779673099517822 , global_step: 4473
- AI-Rank-log  1619106386.3696077  eval_accuracy: 0.6778985261917114 , global_step: 4474
- AI-Rank-log  1619106430.1867163  eval_accuracy: 0.6790277361869812 , global_step: 4475
- AI-Rank-log  1619106474.1839023  eval_accuracy: 0.6780401468276978 , global_step: 4476
- AI-Rank-log  1619106517.990358  eval_accuracy: 0.6792150735855103 , global_step: 4477
- AI-Rank-log  1619106563.1984491  eval_accuracy: 0.67829430103302 , global_step: 4478
- AI-Rank-log  1619106607.0646002  eval_accuracy: 0.6787570118904114 , global_step: 4479
- AI-Rank-log  1619106651.4569204  eval_accuracy: 0.678560733795166 , global_step: 4480
- AI-Rank-log  1619106695.6827908  eval_accuracy: 0.6796504259109497 , global_step: 4481
- AI-Rank-log  1619106739.5659666  eval_accuracy: 0.6781716346740723 , global_step: 4482
- AI-Rank-log  1619106784.4819303  eval_accuracy: 0.6789353489875793 , global_step: 4483
- AI-Rank-log  1619106829.2382393  eval_accuracy: 0.6780697107315063 , global_step: 4484
- AI-Rank-log  1619106873.0969381  eval_accuracy: 0.678956151008606 , global_step: 4485
- AI-Rank-log  1619106917.4460053  eval_accuracy: 0.6789303421974182 , global_step: 4486
- AI-Rank-log  1619106962.119326  eval_accuracy: 0.6787636876106262 , global_step: 4487
- AI-Rank-log  1619107007.0495744  eval_accuracy: 0.6787672638893127 , global_step: 4488
- AI-Rank-log  1619107052.1686041  eval_accuracy: 0.6780790686607361 , global_step: 4489
- AI-Rank-log  1619107096.0038924  eval_accuracy: 0.6792150139808655 , global_step: 4490
- AI-Rank-log  1619107139.862537  eval_accuracy: 0.6783870458602905 , global_step: 4491
- AI-Rank-log  1619107184.0139146  eval_accuracy: 0.6802482008934021 , global_step: 4492
- AI-Rank-log  1619107227.9302986  eval_accuracy: 0.679829478263855 , global_step: 4493
- AI-Rank-log  1619107271.8661876  eval_accuracy: 0.6799280047416687 , global_step: 4494
- AI-Rank-log  1619107315.7331703  eval_accuracy: 0.6798356175422668 , global_step: 4495
- AI-Rank-log  1619107359.5783684  eval_accuracy: 0.6791865825653076 , global_step: 4496
- AI-Rank-log  1619107403.490172  eval_accuracy: 0.6792795658111572 , global_step: 4497
- AI-Rank-log  1619107447.2805338  eval_accuracy: 0.6794797778129578 , global_step: 4498
- AI-Rank-log  1619107491.1386209  eval_accuracy: 0.6784666776657104 , global_step: 4499
- AI-Rank-log  1619107535.0400615  eval_accuracy: 0.6795023083686829 , global_step: 4500
- AI-Rank-log  1619107578.9180179  eval_accuracy: 0.6795374155044556 , global_step: 4501
- AI-Rank-log  1619107622.7912483  eval_accuracy: 0.6794248819351196 , global_step: 4502
- AI-Rank-log  1619107666.7288818  eval_accuracy: 0.6792032122612 , global_step: 4503
- AI-Rank-log  1619107710.609973  eval_accuracy: 0.679512619972229 , global_step: 4504
- AI-Rank-log  1619107754.5149868  eval_accuracy: 0.6794054508209229 , global_step: 4505
- AI-Rank-log  1619107798.4402077  eval_accuracy: 0.6795622110366821 , global_step: 4506
- AI-Rank-log  1619107842.2961118  eval_accuracy: 0.6787756085395813 , global_step: 4507
- AI-Rank-log  1619107886.1778903  eval_accuracy: 0.6789079904556274 , global_step: 4508
- AI-Rank-log  1619107930.012461  eval_accuracy: 0.6787398457527161 , global_step: 4509
- AI-Rank-log  1619107973.8461006  eval_accuracy: 0.6788366436958313 , global_step: 4510
- AI-Rank-log  1619108017.767926  eval_accuracy: 0.6786899566650391 , global_step: 4511
- AI-Rank-log  1619108061.589344  eval_accuracy: 0.678949236869812 , global_step: 4512
- AI-Rank-log  1619108105.4221098  eval_accuracy: 0.6791992783546448 , global_step: 4513
- AI-Rank-log  1619108149.3535583  eval_accuracy: 0.6797646284103394 , global_step: 4514
- AI-Rank-log  1619108193.182442  eval_accuracy: 0.6789284944534302 , global_step: 4515
- AI-Rank-log  1619108237.0997546  eval_accuracy: 0.6794015765190125 , global_step: 4516
- AI-Rank-log  1619108280.9540362  eval_accuracy: 0.6780133247375488 , global_step: 4517
- AI-Rank-log  1619108324.7828782  eval_accuracy: 0.6794500350952148 , global_step: 4518
- AI-Rank-log  1619108368.7024722  eval_accuracy: 0.6786412000656128 , global_step: 4519
- AI-Rank-log  1619108412.5836577  eval_accuracy: 0.6790391802787781 , global_step: 4520
- AI-Rank-log  1619108456.4116693  eval_accuracy: 0.6797224283218384 , global_step: 4521
- AI-Rank-log  1619108500.3493838  eval_accuracy: 0.6790307760238647 , global_step: 4522
- AI-Rank-log  1619108544.1953404  eval_accuracy: 0.6782899498939514 , global_step: 4523
- AI-Rank-log  1619108587.9939637  eval_accuracy: 0.6789491176605225 , global_step: 4524
- AI-Rank-log  1619108631.9263997  eval_accuracy: 0.6787382364273071 , global_step: 4525
- AI-Rank-log  1619108675.8003566  eval_accuracy: 0.6792964935302734 , global_step: 4526
- AI-Rank-log  1619108719.748382  eval_accuracy: 0.6795940399169922 , global_step: 4527
- AI-Rank-log  1619108763.6023893  eval_accuracy: 0.6790687441825867 , global_step: 4528
- AI-Rank-log  1619108807.4365995  eval_accuracy: 0.6794320344924927 , global_step: 4529
- AI-Rank-log  1619108851.3655136  eval_accuracy: 0.6786943674087524 , global_step: 4530
- AI-Rank-log  1619108895.2377622  eval_accuracy: 0.6797656416893005 , global_step: 4531
- AI-Rank-log  1619108939.0539355  eval_accuracy: 0.6784029603004456 , global_step: 4532
- AI-Rank-log  1619108983.0215495  eval_accuracy: 0.6795765161514282 , global_step: 4533
- AI-Rank-log  1619109026.8793433  eval_accuracy: 0.6799578070640564 , global_step: 4534
- AI-Rank-log  1619109070.7793536  eval_accuracy: 0.6795215606689453 , global_step: 4535
- AI-Rank-log  1619109114.5914075  eval_accuracy: 0.6794755458831787 , global_step: 4536
- AI-Rank-log  1619109158.4456482  eval_accuracy: 0.6802703142166138 , global_step: 4537
- AI-Rank-log  1619109202.3282568  eval_accuracy: 0.680351972579956 , global_step: 4538
- AI-Rank-log  1619109246.19173  eval_accuracy: 0.679797887802124 , global_step: 4539
- AI-Rank-log  1619109290.0365918  eval_accuracy: 0.6801299452781677 , global_step: 4540
- AI-Rank-log  1619109333.9249623  eval_accuracy: 0.680427610874176 , global_step: 4541
- AI-Rank-log  1619109377.753132  eval_accuracy: 0.6796991229057312 , global_step: 4542
- AI-Rank-log  1619109421.604171  eval_accuracy: 0.6797726154327393 , global_step: 4543
- AI-Rank-log  1619109465.5123458  eval_accuracy: 0.6792654991149902 , global_step: 4544
- AI-Rank-log  1619109509.3621843  eval_accuracy: 0.6792252063751221 , global_step: 4545
- AI-Rank-log  1619109553.2529943  eval_accuracy: 0.6802089810371399 , global_step: 4546
- AI-Rank-log  1619109597.0768998  eval_accuracy: 0.6795892119407654 , global_step: 4547
- AI-Rank-log  1619109640.7330437  eval_accuracy: 0.6803928017616272 , global_step: 4548
- AI-Rank-log  1619109684.6282878  eval_accuracy: 0.6801455020904541 , global_step: 4549
- AI-Rank-log  1619109728.4438064  eval_accuracy: 0.6802276968955994 , global_step: 4550
- AI-Rank-log  1619109772.2831452  eval_accuracy: 0.6802992224693298 , global_step: 4551
- AI-Rank-log  1619109816.1551926  eval_accuracy: 0.680310070514679 , global_step: 4552
- AI-Rank-log  1619109859.9503195  eval_accuracy: 0.6806367039680481 , global_step: 4553
- AI-Rank-log  1619109903.7858744  eval_accuracy: 0.67979896068573 , global_step: 4554
- AI-Rank-log  1619109948.653771  eval_accuracy: 0.6801018714904785 , global_step: 4555
- AI-Rank-log  1619109992.4449275  eval_accuracy: 0.6793505549430847 , global_step: 4556
- AI-Rank-log  1619110036.6527257  eval_accuracy: 0.6795469522476196 , global_step: 4557
- AI-Rank-log  1619110080.68977  eval_accuracy: 0.6801361441612244 , global_step: 4558
- AI-Rank-log  1619110125.2286382  eval_accuracy: 0.6800307035446167 , global_step: 4559
- AI-Rank-log  1619110169.415687  eval_accuracy: 0.6795744895935059 , global_step: 4560
- AI-Rank-log  1619110214.0517669  eval_accuracy: 0.6799298524856567 , global_step: 4561
- AI-Rank-log  1619110257.8812487  eval_accuracy: 0.6792578101158142 , global_step: 4562
- AI-Rank-log  1619110302.2811525  eval_accuracy: 0.680461049079895 , global_step: 4563
- AI-Rank-log  1619110346.8348818  eval_accuracy: 0.6796000003814697 , global_step: 4564
- AI-Rank-log  1619110390.7959108  eval_accuracy: 0.6802406311035156 , global_step: 4565
- AI-Rank-log  1619110435.0098255  eval_accuracy: 0.6794646382331848 , global_step: 4566
- AI-Rank-log  1619110479.685704  eval_accuracy: 0.6799585819244385 , global_step: 4567
- AI-Rank-log  1619110523.6812265  eval_accuracy: 0.6803944110870361 , global_step: 4568
- AI-Rank-log  1619110567.5335293  eval_accuracy: 0.6798075437545776 , global_step: 4569
- AI-Rank-log  1619110611.705881  eval_accuracy: 0.6808714866638184 , global_step: 4570
- AI-Rank-log  1619110655.6249542  eval_accuracy: 0.6793696284294128 , global_step: 4571
- AI-Rank-log  1619110699.4580119  eval_accuracy: 0.6800759434700012 , global_step: 4572
- AI-Rank-log  1619110743.294465  eval_accuracy: 0.679025411605835 , global_step: 4573
- AI-Rank-log  1619110787.2000496  eval_accuracy: 0.680186927318573 , global_step: 4574
- AI-Rank-log  1619110831.028502  eval_accuracy: 0.6794018745422363 , global_step: 4575
- AI-Rank-log  1619110874.8204002  eval_accuracy: 0.6805362105369568 , global_step: 4576
- AI-Rank-log  1619110918.6929975  eval_accuracy: 0.6801151037216187 , global_step: 4577
- AI-Rank-log  1619110962.482225  eval_accuracy: 0.6805216670036316 , global_step: 4578
- AI-Rank-log  1619111006.3648043  eval_accuracy: 0.6792405843734741 , global_step: 4579
- AI-Rank-log  1619111050.2055197  eval_accuracy: 0.6803977489471436 , global_step: 4580
- AI-Rank-log  1619111093.9842486  eval_accuracy: 0.6791453957557678 , global_step: 4581
- AI-Rank-log  1619111137.8572674  eval_accuracy: 0.6806209087371826 , global_step: 4582
- AI-Rank-log  1619111181.7117507  eval_accuracy: 0.6802641153335571 , global_step: 4583
- AI-Rank-log  1619111225.4912295  eval_accuracy: 0.6809579133987427 , global_step: 4584
- AI-Rank-log  1619111269.3358958  eval_accuracy: 0.6802328824996948 , global_step: 4585
- AI-Rank-log  1619111313.1307285  eval_accuracy: 0.6806658506393433 , global_step: 4586
- AI-Rank-log  1619111356.9801664  eval_accuracy: 0.6802749037742615 , global_step: 4587
- AI-Rank-log  1619111400.8890245  eval_accuracy: 0.6800643801689148 , global_step: 4588
- AI-Rank-log  1619111444.7355647  eval_accuracy: 0.6791844964027405 , global_step: 4589
- AI-Rank-log  1619111488.5944672  eval_accuracy: 0.6796391010284424 , global_step: 4590
- AI-Rank-log  1619111532.43037  eval_accuracy: 0.6791484951972961 , global_step: 4591
- AI-Rank-log  1619111576.2758226  eval_accuracy: 0.6748538017272949 , global_step: 4592
- AI-Rank-log  1619111629.1777484  eval_accuracy: 0.674771785736084 , global_step: 4593
- AI-Rank-log  1619111672.961222  eval_accuracy: 0.6755531430244446 , global_step: 4594
- AI-Rank-log  1619111716.7886586  eval_accuracy: 0.6766437888145447 , global_step: 4595
- AI-Rank-log  1619111760.7252247  eval_accuracy: 0.67405104637146 , global_step: 4596
- AI-Rank-log  1619111804.5697944  eval_accuracy: 0.6745217442512512 , global_step: 4597
- AI-Rank-log  1619111848.4117858  eval_accuracy: 0.6744168400764465 , global_step: 4598
- AI-Rank-log  1619111892.3047352  eval_accuracy: 0.6667386293411255 , global_step: 4599
- AI-Rank-log  1619111936.1303356  eval_accuracy: 0.6706676483154297 , global_step: 4600
- AI-Rank-log  1619111979.9877238  eval_accuracy: 0.6608864665031433 , global_step: 4601
- AI-Rank-log  1619112023.8199623  eval_accuracy: 0.6608864665031433 , global_step: 4601
- AI-Rank-log  1619112067.6416233  eval_accuracy: 0.6608864665031433 , global_step: 4601
- AI-Rank-log  1619112111.533366  eval_accuracy: 0.6620105504989624 , global_step: 4602
- AI-Rank-log  1619112155.3741112  eval_accuracy: 0.6653012037277222 , global_step: 4603
- AI-Rank-log  1619112199.2001975  eval_accuracy: 0.6646851897239685 , global_step: 4604
- AI-Rank-log  1619112243.090233  eval_accuracy: 0.6658210158348083 , global_step: 4605
- AI-Rank-log  1619112286.9048388  eval_accuracy: 0.6678468585014343 , global_step: 4606
- AI-Rank-log  1619112330.7073693  eval_accuracy: 0.6703198552131653 , global_step: 4607
- AI-Rank-log  1619112374.555419  eval_accuracy: 0.6720634698867798 , global_step: 4608
- AI-Rank-log  1619112418.3786752  eval_accuracy: 0.6723765730857849 , global_step: 4609
- AI-Rank-log  1619112462.2581146  eval_accuracy: 0.672349750995636 , global_step: 4610
- AI-Rank-log  1619112506.059672  eval_accuracy: 0.6734864711761475 , global_step: 4611
- AI-Rank-log  1619112549.8643045  eval_accuracy: 0.6735719442367554 , global_step: 4612
- AI-Rank-log  1619112593.7554297  eval_accuracy: 0.6740634441375732 , global_step: 4613
- AI-Rank-log  1619112637.541103  eval_accuracy: 0.674465000629425 , global_step: 4614
- AI-Rank-log  1619112681.3664818  eval_accuracy: 0.6745764017105103 , global_step: 4615
- AI-Rank-log  1619112725.2365813  eval_accuracy: 0.6750918030738831 , global_step: 4616
- AI-Rank-log  1619112769.0200474  eval_accuracy: 0.6752215623855591 , global_step: 4617
- AI-Rank-log  1619112812.9081416  eval_accuracy: 0.6737996339797974 , global_step: 4618
- AI-Rank-log  1619112856.7124424  eval_accuracy: 0.6741151213645935 , global_step: 4619
- AI-Rank-log  1619112900.530831  eval_accuracy: 0.6751108169555664 , global_step: 4620
- AI-Rank-log  1619112944.4035919  eval_accuracy: 0.6760730147361755 , global_step: 4621
- AI-Rank-log  1619112988.1900194  eval_accuracy: 0.6754031777381897 , global_step: 4622
- AI-Rank-log  1619113031.988293  eval_accuracy: 0.675291895866394 , global_step: 4623
- AI-Rank-log  1619113075.8914635  eval_accuracy: 0.6763902306556702 , global_step: 4624
- AI-Rank-log  1619113119.7442553  eval_accuracy: 0.6768166422843933 , global_step: 4625
- AI-Rank-log  1619113163.5626369  eval_accuracy: 0.6781213879585266 , global_step: 4626
- AI-Rank-log  1619113207.4476037  eval_accuracy: 0.6780829429626465 , global_step: 4627
- AI-Rank-log  1619113251.2917814  eval_accuracy: 0.6782437562942505 , global_step: 4628
- AI-Rank-log  1619113295.0963876  eval_accuracy: 0.6781529784202576 , global_step: 4629
- AI-Rank-log  1619113339.8576849  eval_accuracy: 0.6782248616218567 , global_step: 4630
- AI-Rank-log  1619113383.7938256  eval_accuracy: 0.6779119372367859 , global_step: 4631
- AI-Rank-log  1619113428.1686592  eval_accuracy: 0.6782756447792053 , global_step: 4632
- AI-Rank-log  1619113472.0272336  eval_accuracy: 0.6765152215957642 , global_step: 4633
- AI-Rank-log  1619113516.4184277  eval_accuracy: 0.6749343276023865 , global_step: 4634
- AI-Rank-log  1619113560.678259  eval_accuracy: 0.6743457913398743 , global_step: 4635
- AI-Rank-log  1619113604.5016036  eval_accuracy: 0.6750790476799011 , global_step: 4636
- AI-Rank-log  1619113649.188583  eval_accuracy: 0.6755880117416382 , global_step: 4637
- AI-Rank-log  1619113693.1191308  eval_accuracy: 0.6747949123382568 , global_step: 4638
- AI-Rank-log  1619113737.3648503  eval_accuracy: 0.6750414967536926 , global_step: 4639
- AI-Rank-log  1619113781.8139844  eval_accuracy: 0.6758843660354614 , global_step: 4640
- AI-Rank-log  1619113825.8907123  eval_accuracy: 0.6760772466659546 , global_step: 4641
- AI-Rank-log  1619113870.9841485  eval_accuracy: 0.6752764582633972 , global_step: 4642
- AI-Rank-log  1619113914.9008949  eval_accuracy: 0.6761197447776794 , global_step: 4643
- AI-Rank-log  1619113958.726542  eval_accuracy: 0.6760849356651306 , global_step: 4644
- AI-Rank-log  1619114002.7837687  eval_accuracy: 0.6769446134567261 , global_step: 4645
- AI-Rank-log  1619114046.6717496  eval_accuracy: 0.6771408915519714 , global_step: 4646
- AI-Rank-log  1619114090.5340548  eval_accuracy: 0.6779415011405945 , global_step: 4647
- AI-Rank-log  1619114134.3840191  eval_accuracy: 0.677821159362793 , global_step: 4648
- AI-Rank-log  1619114178.2390583  eval_accuracy: 0.6781201362609863 , global_step: 4649
- AI-Rank-log  1619114222.054289  eval_accuracy: 0.6779876947402954 , global_step: 4650
- AI-Rank-log  1619114266.0004802  eval_accuracy: 0.6785354018211365 , global_step: 4651
- AI-Rank-log  1619114309.7982244  eval_accuracy: 0.677906334400177 , global_step: 4652
- AI-Rank-log  1619114353.6373293  eval_accuracy: 0.6773703694343567 , global_step: 4653
- AI-Rank-log  1619114397.5405214  eval_accuracy: 0.6781163811683655 , global_step: 4654
- AI-Rank-log  1619114441.3996553  eval_accuracy: 0.6781448721885681 , global_step: 4655
- AI-Rank-log  1619114485.2536242  eval_accuracy: 0.6776801347732544 , global_step: 4656
- AI-Rank-log  1619114529.18409  eval_accuracy: 0.6781377792358398 , global_step: 4657
- AI-Rank-log  1619114573.0537498  eval_accuracy: 0.6784884929656982 , global_step: 4658
- AI-Rank-log  1619114616.9636815  eval_accuracy: 0.6781112551689148 , global_step: 4659
- AI-Rank-log  1619114660.7734244  eval_accuracy: 0.6781774759292603 , global_step: 4660
- AI-Rank-log  1619114704.5871606  eval_accuracy: 0.6786513328552246 , global_step: 4661
- AI-Rank-log  1619114748.4709425  eval_accuracy: 0.6786395311355591 , global_step: 4662
- AI-Rank-log  1619114792.2980733  eval_accuracy: 0.6789672374725342 , global_step: 4663
- AI-Rank-log  1619114836.0950115  eval_accuracy: 0.6778863668441772 , global_step: 4664
- AI-Rank-log  1619114880.0431054  eval_accuracy: 0.6790619492530823 , global_step: 4665
- AI-Rank-log  1619114923.8088064  eval_accuracy: 0.6790146827697754 , global_step: 4666
- AI-Rank-log  1619114967.659678  eval_accuracy: 0.6793900728225708 , global_step: 4667
- AI-Rank-log  1619115011.5367281  eval_accuracy: 0.679282546043396 , global_step: 4668
- AI-Rank-log  1619115055.3921022  eval_accuracy: 0.6791516542434692 , global_step: 4669
- AI-Rank-log  1619115099.2912726  eval_accuracy: 0.6785596609115601 , global_step: 4670
- AI-Rank-log  1619115143.1385477  eval_accuracy: 0.6788556575775146 , global_step: 4671
- AI-Rank-log  1619115186.958926  eval_accuracy: 0.6778486371040344 , global_step: 4672
- AI-Rank-log  1619115230.8512714  eval_accuracy: 0.679132342338562 , global_step: 4673
- AI-Rank-log  1619115274.6798987  eval_accuracy: 0.6794033050537109 , global_step: 4674
- AI-Rank-log  1619115318.4873369  eval_accuracy: 0.6802523732185364 , global_step: 4675
- AI-Rank-log  1619115362.3870876  eval_accuracy: 0.6804596185684204 , global_step: 4676
- AI-Rank-log  1619115406.2127833  eval_accuracy: 0.6795641779899597 , global_step: 4677
- AI-Rank-log  1619115450.1524432  eval_accuracy: 0.6807308793067932 , global_step: 4678
- AI-Rank-log  1619115493.967881  eval_accuracy: 0.6808743476867676 , global_step: 4679
- AI-Rank-log  1619115537.7873237  eval_accuracy: 0.6799564361572266 , global_step: 4680
- AI-Rank-log  1619115581.6679928  eval_accuracy: 0.6804187297821045 , global_step: 4681
- AI-Rank-log  1619115625.5167656  eval_accuracy: 0.6801239848136902 , global_step: 4682
- AI-Rank-log  1619115669.306302  eval_accuracy: 0.680446982383728 , global_step: 4683
- AI-Rank-log  1619115713.170312  eval_accuracy: 0.6799406409263611 , global_step: 4684
- AI-Rank-log  1619115757.008187  eval_accuracy: 0.6802818775177002 , global_step: 4685
- AI-Rank-log  1619115800.8175092  eval_accuracy: 0.6806540489196777 , global_step: 4686
- AI-Rank-log  1619115844.723963  eval_accuracy: 0.6795598268508911 , global_step: 4687
- AI-Rank-log  1619115888.5391617  eval_accuracy: 0.6784672141075134 , global_step: 4688
- AI-Rank-log  1619115932.4116197  eval_accuracy: 0.6805862188339233 , global_step: 4689
- AI-Rank-log  1619115976.255033  eval_accuracy: 0.6786435842514038 , global_step: 4690
- AI-Rank-log  1619116020.066071  eval_accuracy: 0.6806156039237976 , global_step: 4691
- AI-Rank-log  1619116063.9116912  eval_accuracy: 0.6788070797920227 , global_step: 4692
- AI-Rank-log  1619116107.753364  eval_accuracy: 0.6797848343849182 , global_step: 4693
- AI-Rank-log  1619116151.5944176  eval_accuracy: 0.6799330115318298 , global_step: 4694
- AI-Rank-log  1619116195.4409971  eval_accuracy: 0.6808026432991028 , global_step: 4695
- AI-Rank-log  1619116239.2828753  eval_accuracy: 0.6802606582641602 , global_step: 4696
- AI-Rank-log  1619116283.0930166  eval_accuracy: 0.6801034212112427 , global_step: 4697
- AI-Rank-log  1619116326.9717133  eval_accuracy: 0.6800775527954102 , global_step: 4698
- AI-Rank-log  1619116370.8099895  eval_accuracy: 0.6808991432189941 , global_step: 4699
- AI-Rank-log  1619116414.6817675  eval_accuracy: 0.6798846125602722 , global_step: 4700
- AI-Rank-log  1619116458.4945211  eval_accuracy: 0.6806273460388184 , global_step: 4701
- AI-Rank-log  1619116502.33121  eval_accuracy: 0.6807937026023865 , global_step: 4702
- AI-Rank-log  1619116546.1880026  eval_accuracy: 0.6809636950492859 , global_step: 4703
- AI-Rank-log  1619116590.0190072  eval_accuracy: 0.6806699633598328 , global_step: 4704
- AI-Rank-log  1619116633.8318198  eval_accuracy: 0.6795345544815063 , global_step: 4705
- AI-Rank-log  1619116677.7010124  eval_accuracy: 0.6793325543403625 , global_step: 4706
- AI-Rank-log  1619116722.4324336  eval_accuracy: 0.6807020902633667 , global_step: 4707
- AI-Rank-log  1619116766.5664783  eval_accuracy: 0.6803691387176514 , global_step: 4708
- AI-Rank-log  1619116810.4407556  eval_accuracy: 0.6811086535453796 , global_step: 4709
- AI-Rank-log  1619116854.9435241  eval_accuracy: 0.6806896924972534 , global_step: 4710
- AI-Rank-log  1619116899.423888  eval_accuracy: 0.680804431438446 , global_step: 4711
- AI-Rank-log  1619116943.4336028  eval_accuracy: 0.6807087063789368 , global_step: 4712
- AI-Rank-log  1619116987.5327713  eval_accuracy: 0.680647075176239 , global_step: 4713
- AI-Rank-log  1619117032.1939  eval_accuracy: 0.6801387071609497 , global_step: 4714
- AI-Rank-log  1619117076.520688  eval_accuracy: 0.6809437870979309 , global_step: 4715
- AI-Rank-log  1619117121.1265938  eval_accuracy: 0.6795093417167664 , global_step: 4716
- AI-Rank-log  1619117165.0171373  eval_accuracy: 0.6813580393791199 , global_step: 4717
- AI-Rank-log  1619117209.7120228  eval_accuracy: 0.6794541478157043 , global_step: 4718
- AI-Rank-log  1619117254.0458088  eval_accuracy: 0.6801049709320068 , global_step: 4719
- AI-Rank-log  1619117298.7747881  eval_accuracy: 0.6797265410423279 , global_step: 4720
- AI-Rank-log  1619117342.6322856  eval_accuracy: 0.679850161075592 , global_step: 4721
- AI-Rank-log  1619117386.5326076  eval_accuracy: 0.6806706786155701 , global_step: 4722
- AI-Rank-log  1619117430.5719619  eval_accuracy: 0.6800585389137268 , global_step: 4723
- AI-Rank-log  1619117474.3726265  eval_accuracy: 0.680367648601532 , global_step: 4724
- AI-Rank-log  1619117518.2414248  eval_accuracy: 0.6803068518638611 , global_step: 4725
- AI-Rank-log  1619117562.058104  eval_accuracy: 0.6804636716842651 , global_step: 4726
- AI-Rank-log  1619117605.8877897  eval_accuracy: 0.6810461282730103 , global_step: 4727
- AI-Rank-log  1619117649.8193614  eval_accuracy: 0.679902970790863 , global_step: 4728
- AI-Rank-log  1619117693.6265583  eval_accuracy: 0.6807975769042969 , global_step: 4729
- AI-Rank-log  1619117737.4698105  eval_accuracy: 0.6798436045646667 , global_step: 4730
- AI-Rank-log  1619117781.2822316  eval_accuracy: 0.6811873912811279 , global_step: 4731
- AI-Rank-log  1619117825.0827253  eval_accuracy: 0.681111752986908 , global_step: 4732
- AI-Rank-log  1619117868.9622848  eval_accuracy: 0.6806554794311523 , global_step: 4733
- AI-Rank-log  1619117912.8179376  eval_accuracy: 0.6808598041534424 , global_step: 4734
- AI-Rank-log  1619117956.596286  eval_accuracy: 0.6807019710540771 , global_step: 4735
- AI-Rank-log  1619118000.6843522  eval_accuracy: 0.6800591349601746 , global_step: 4736
- AI-Rank-log  1619118044.5182667  eval_accuracy: 0.6798597574234009 , global_step: 4737
- AI-Rank-log  1619118088.319174  eval_accuracy: 0.6806386709213257 , global_step: 4738
- AI-Rank-log  1619118132.2007637  eval_accuracy: 0.6806828379631042 , global_step: 4739
- AI-Rank-log  1619118176.0774379  eval_accuracy: 0.6810206770896912 , global_step: 4740
- AI-Rank-log  1619118219.952126  eval_accuracy: 0.6806691884994507 , global_step: 4741
- AI-Rank-log  1619118263.8013198  eval_accuracy: 0.6814231276512146 , global_step: 4742
- AI-Rank-log  1619118307.629475  eval_accuracy: 0.6807293891906738 , global_step: 4743
- AI-Rank-log  1619118351.517547  eval_accuracy: 0.6815438270568848 , global_step: 4744
- AI-Rank-log  1619118395.3905156  eval_accuracy: 0.680707573890686 , global_step: 4745
- AI-Rank-log  1619118439.200395  eval_accuracy: 0.681683361530304 , global_step: 4746
- AI-Rank-log  1619118483.0684135  eval_accuracy: 0.6810235977172852 , global_step: 4747
- AI-Rank-log  1619118526.9346533  eval_accuracy: 0.6812458038330078 , global_step: 4748
- AI-Rank-log  1619118570.7812731  eval_accuracy: 0.6812447905540466 , global_step: 4749
- AI-Rank-log  1619118614.6945322  eval_accuracy: 0.6818186640739441 , global_step: 4750
- AI-Rank-log  1619118658.5197592  eval_accuracy: 0.6807799339294434 , global_step: 4751
- AI-Rank-log  1619118702.3865747  eval_accuracy: 0.6813097596168518 , global_step: 4752
- AI-Rank-log  1619118746.2009125  eval_accuracy: 0.6801856756210327 , global_step: 4753
- AI-Rank-log  1619118790.0169642  eval_accuracy: 0.6811239123344421 , global_step: 4754
- AI-Rank-log  1619118833.9014719  eval_accuracy: 0.6804680228233337 , global_step: 4755
- AI-Rank-log  1619118877.750327  eval_accuracy: 0.6809173822402954 , global_step: 4756
- AI-Rank-log  1619118921.5644736  eval_accuracy: 0.6804183125495911 , global_step: 4757
- AI-Rank-log  1619118965.4112027  eval_accuracy: 0.6814272403717041 , global_step: 4758
- AI-Rank-log  1619119009.246783  eval_accuracy: 0.6809387803077698 , global_step: 4759
- AI-Rank-log  1619119053.214334  eval_accuracy: 0.6816026568412781 , global_step: 4760
- AI-Rank-log  1619119097.0793295  eval_accuracy: 0.6807785034179688 , global_step: 4761
- AI-Rank-log  1619119140.9366124  eval_accuracy: 0.6804576516151428 , global_step: 4762
- AI-Rank-log  1619119184.8383298  eval_accuracy: 0.6810853481292725 , global_step: 4763
- AI-Rank-log  1619119228.6477058  eval_accuracy: 0.680590808391571 , global_step: 4764
- AI-Rank-log  1619119272.4737527  eval_accuracy: 0.6821348071098328 , global_step: 4765
- AI-Rank-log  1619119316.4292493  eval_accuracy: 0.6807292103767395 , global_step: 4766
- AI-Rank-log  1619119360.0480585  eval_accuracy: 0.6815579533576965 , global_step: 4767
- AI-Rank-log  1619119403.8854916  eval_accuracy: 0.6810300350189209 , global_step: 4768
- AI-Rank-log  1619119447.7841842  eval_accuracy: 0.6803932189941406 , global_step: 4769
- AI-Rank-log  1619119491.581454  eval_accuracy: 0.6811801195144653 , global_step: 4770
- AI-Rank-log  1619119535.4126477  eval_accuracy: 0.681178629398346 , global_step: 4771
- AI-Rank-log  1619119579.3090007  eval_accuracy: 0.6809366345405579 , global_step: 4772
- AI-Rank-log  1619119623.150707  eval_accuracy: 0.6809563040733337 , global_step: 4773
- AI-Rank-log  1619119667.0351114  eval_accuracy: 0.6815674901008606 , global_step: 4774
- AI-Rank-log  1619119710.8819065  eval_accuracy: 0.6818650960922241 , global_step: 4775
- AI-Rank-log  1619119754.6893508  eval_accuracy: 0.6817674040794373 , global_step: 4776
- AI-Rank-log  1619119798.613358  eval_accuracy: 0.6812281608581543 , global_step: 4777
- AI-Rank-log  1619119842.461976  eval_accuracy: 0.6813315153121948 , global_step: 4778
- AI-Rank-log  1619119886.2810624  eval_accuracy: 0.6808655858039856 , global_step: 4779
- AI-Rank-log  1619119930.2097652  eval_accuracy: 0.6811062097549438 , global_step: 4780
- AI-Rank-log  1619119974.0184782  eval_accuracy: 0.681379497051239 , global_step: 4781
- AI-Rank-log  1619120017.9038017  eval_accuracy: 0.6809178590774536 , global_step: 4782
- AI-Rank-log  1619120061.7608635  eval_accuracy: 0.6810439825057983 , global_step: 4783
- AI-Rank-log  1619120105.5530522  eval_accuracy: 0.6813880801200867 , global_step: 4784
- AI-Rank-log  1619120150.1875904  eval_accuracy: 0.6809788942337036 , global_step: 4785
- AI-Rank-log  1619120194.0118713  eval_accuracy: 0.6812610626220703 , global_step: 4786
- AI-Rank-log  1619120237.8176155  eval_accuracy: 0.6819647550582886 , global_step: 4787
- AI-Rank-log  1619120282.359289  eval_accuracy: 0.681279718875885 , global_step: 4788
- AI-Rank-log  1619120326.637283  eval_accuracy: 0.6815294027328491 , global_step: 4789
- AI-Rank-log  1619120370.700625  eval_accuracy: 0.6817458868026733 , global_step: 4790
- AI-Rank-log  1619120423.6881127  eval_accuracy: 0.6821413040161133 , global_step: 4791
- AI-Rank-log  1619120468.3154733  eval_accuracy: 0.6817355155944824 , global_step: 4792
- AI-Rank-log  1619120512.1975732  eval_accuracy: 0.6818358898162842 , global_step: 4793
- AI-Rank-log  1619120556.2304456  eval_accuracy: 0.6820328831672668 , global_step: 4794
- AI-Rank-log  1619120601.0822701  eval_accuracy: 0.6813305616378784 , global_step: 4795
- AI-Rank-log  1619120645.0548465  eval_accuracy: 0.6816130876541138 , global_step: 4796
- AI-Rank-log  1619120690.1299138  eval_accuracy: 0.6816807985305786 , global_step: 4797
- AI-Rank-log  1619120734.0084999  eval_accuracy: 0.6808886528015137 , global_step: 4798
- AI-Rank-log  1619120777.9324398  eval_accuracy: 0.6822323799133301 , global_step: 4799
- AI-Rank-log  1619120821.7686732  eval_accuracy: 0.680740475654602 , global_step: 4800
- AI-Rank-log  1619120865.9944198  eval_accuracy: 0.6822744607925415 , global_step: 4801
- AI-Rank-log  1619120909.8508584  eval_accuracy: 0.681237518787384 , global_step: 4802
- AI-Rank-log  1619120953.6861854  eval_accuracy: 0.6816638112068176 , global_step: 4803
- AI-Rank-log  1619120997.6926346  eval_accuracy: 0.6812867522239685 , global_step: 4804
- AI-Rank-log  1619121041.523011  eval_accuracy: 0.6825143098831177 , global_step: 4805
- AI-Rank-log  1619121085.3832583  eval_accuracy: 0.6813322901725769 , global_step: 4806
- AI-Rank-log  1619121129.2848728  eval_accuracy: 0.681369423866272 , global_step: 4807
- AI-Rank-log  1619121173.1488621  eval_accuracy: 0.6816641688346863 , global_step: 4808
- AI-Rank-log  1619121216.9822454  eval_accuracy: 0.681880533695221 , global_step: 4809
- AI-Rank-log  1619121260.8612964  eval_accuracy: 0.6819171905517578 , global_step: 4810
- AI-Rank-log  1619121304.6769314  eval_accuracy: 0.6816526651382446 , global_step: 4811
- AI-Rank-log  1619121348.5155258  eval_accuracy: 0.6818189024925232 , global_step: 4812
- AI-Rank-log  1619121392.445737  eval_accuracy: 0.682250440120697 , global_step: 4813
- AI-Rank-log  1619121436.2714634  eval_accuracy: 0.6826223134994507 , global_step: 4814
- AI-Rank-log  1619121480.1620815  eval_accuracy: 0.6812814474105835 , global_step: 4815
- AI-Rank-log  1619121523.9309118  eval_accuracy: 0.6826283931732178 , global_step: 4816
- AI-Rank-log  1619121567.7163246  eval_accuracy: 0.6805175542831421 , global_step: 4817
- AI-Rank-log  1619121611.6032958  eval_accuracy: 0.6821422576904297 , global_step: 4818
- AI-Rank-log  1619121655.401374  eval_accuracy: 0.6814926266670227 , global_step: 4819
- AI-Rank-log  1619121699.2740078  eval_accuracy: 0.682060182094574 , global_step: 4820
- AI-Rank-log  1619121743.1899793  eval_accuracy: 0.682234525680542 , global_step: 4821
- AI-Rank-log  1619121786.9800355  eval_accuracy: 0.6819136142730713 , global_step: 4822
- AI-Rank-log  1619121830.8972075  eval_accuracy: 0.6819718480110168 , global_step: 4823
- AI-Rank-log  1619121874.7251298  eval_accuracy: 0.6834229230880737 , global_step: 4824
- AI-Rank-log  1619121918.521666  eval_accuracy: 0.6816954016685486 , global_step: 4825
- AI-Rank-log  1619121962.4294994  eval_accuracy: 0.6832613348960876 , global_step: 4826
- AI-Rank-log  1619122006.2320719  eval_accuracy: 0.6815341711044312 , global_step: 4827
- AI-Rank-log  1619122050.0376503  eval_accuracy: 0.6824726462364197 , global_step: 4828
- AI-Rank-log  1619122093.9815812  eval_accuracy: 0.6820212006568909 , global_step: 4829
- AI-Rank-log  1619122137.7899325  eval_accuracy: 0.6822040677070618 , global_step: 4830
- AI-Rank-log  1619122181.5898163  eval_accuracy: 0.6818438172340393 , global_step: 4831
- AI-Rank-log  1619122225.495476  eval_accuracy: 0.6825670599937439 , global_step: 4832
- AI-Rank-log  1619122269.2875116  eval_accuracy: 0.6831876039505005 , global_step: 4833
- AI-Rank-log  1619122313.2098818  eval_accuracy: 0.6818883419036865 , global_step: 4834
- AI-Rank-log  1619122357.0400293  eval_accuracy: 0.682277262210846 , global_step: 4835
- AI-Rank-log  1619122400.9057968  eval_accuracy: 0.6822865605354309 , global_step: 4836
- AI-Rank-log  1619122444.809175  eval_accuracy: 0.6823235154151917 , global_step: 4837
- AI-Rank-log  1619122488.6924944  eval_accuracy: 0.6816285252571106 , global_step: 4838
- AI-Rank-log  1619122532.5064507  eval_accuracy: 0.6828153133392334 , global_step: 4839
- AI-Rank-log  1619122576.3953676  eval_accuracy: 0.6823204159736633 , global_step: 4840
- AI-Rank-log  1619122620.239314  eval_accuracy: 0.682515561580658 , global_step: 4841
- AI-Rank-log  1619122664.041024  eval_accuracy: 0.6819853186607361 , global_step: 4842
- AI-Rank-log  1619122707.9689853  eval_accuracy: 0.6830553412437439 , global_step: 4843
- AI-Rank-log  1619122751.8041728  eval_accuracy: 0.682222306728363 , global_step: 4844
- AI-Rank-log  1619122795.6651268  eval_accuracy: 0.6837230920791626 , global_step: 4845
- AI-Rank-log  1619122839.5301507  eval_accuracy: 0.6832155585289001 , global_step: 4846
- AI-Rank-log  1619122883.354439  eval_accuracy: 0.6834568381309509 , global_step: 4847
- AI-Rank-log  1619122927.2107623  eval_accuracy: 0.6823685765266418 , global_step: 4848
- AI-Rank-log  1619122971.0445292  eval_accuracy: 0.6830288171768188 , global_step: 4849
- AI-Rank-log  1619123014.856122  eval_accuracy: 0.6817642450332642 , global_step: 4850
- AI-Rank-log  1619123058.751327  eval_accuracy: 0.6824572086334229 , global_step: 4851
- AI-Rank-log  1619123102.5785294  eval_accuracy: 0.6817746758460999 , global_step: 4852
- AI-Rank-log  1619123146.4740005  eval_accuracy: 0.6821054220199585 , global_step: 4853
- AI-Rank-log  1619123190.2897239  eval_accuracy: 0.6822056770324707 , global_step: 4854
- AI-Rank-log  1619123234.1286175  eval_accuracy: 0.6816866397857666 , global_step: 4855
- AI-Rank-log  1619123277.993549  eval_accuracy: 0.682059645652771 , global_step: 4856
- AI-Rank-log  1619123321.8115704  eval_accuracy: 0.6819851398468018 , global_step: 4857
- AI-Rank-log  1619123365.663742  eval_accuracy: 0.6809736490249634 , global_step: 4858
- AI-Rank-log  1619123409.519527  eval_accuracy: 0.6822193264961243 , global_step: 4859
- AI-Rank-log  1619123453.3441608  eval_accuracy: 0.6809878945350647 , global_step: 4860
- AI-Rank-log  1619123497.1822152  eval_accuracy: 0.6816267371177673 , global_step: 4861
- AI-Rank-log  1619123542.4770105  eval_accuracy: 0.6816776990890503 , global_step: 4862
- AI-Rank-log  1619123586.29522  eval_accuracy: 0.6814643740653992 , global_step: 4863
- AI-Rank-log  1619123630.1028702  eval_accuracy: 0.6818824410438538 , global_step: 4864
- AI-Rank-log  1619123674.5193062  eval_accuracy: 0.6823366284370422 , global_step: 4865
- AI-Rank-log  1619123718.8792884  eval_accuracy: 0.6823210716247559 , global_step: 4866
- AI-Rank-log  1619123762.9527404  eval_accuracy: 0.6816609501838684 , global_step: 4867
- AI-Rank-log  1619123806.79556  eval_accuracy: 0.6820704936981201 , global_step: 4868
- AI-Rank-log  1619123851.568459  eval_accuracy: 0.6814209818840027 , global_step: 4869
- AI-Rank-log  1619123895.498005  eval_accuracy: 0.6820148825645447 , global_step: 4870
- AI-Rank-log  1619123939.9901752  eval_accuracy: 0.6821696162223816 , global_step: 4871
- AI-Rank-log  1619123983.861225  eval_accuracy: 0.6819790601730347 , global_step: 4872
- AI-Rank-log  1619124028.4473915  eval_accuracy: 0.6816893815994263 , global_step: 4873
- AI-Rank-log  1619124072.2676158  eval_accuracy: 0.6828211545944214 , global_step: 4874
- AI-Rank-log  1619124117.5314617  eval_accuracy: 0.6817302703857422 , global_step: 4875
- AI-Rank-log  1619124161.3821995  eval_accuracy: 0.6821962594985962 , global_step: 4876
- AI-Rank-log  1619124205.183505  eval_accuracy: 0.6825618743896484 , global_step: 4877
- AI-Rank-log  1619124249.1334615  eval_accuracy: 0.6824991106987 , global_step: 4878
- AI-Rank-log  1619124293.3260117  eval_accuracy: 0.6829244494438171 , global_step: 4879
- AI-Rank-log  1619124337.1415877  eval_accuracy: 0.6826878786087036 , global_step: 4880
- AI-Rank-log  1619124381.0788221  eval_accuracy: 0.6830353736877441 , global_step: 4881
- AI-Rank-log  1619124424.9251802  eval_accuracy: 0.6824929118156433 , global_step: 4882
- AI-Rank-log  1619124468.8398764  eval_accuracy: 0.6828624606132507 , global_step: 4883
- AI-Rank-log  1619124512.723959  eval_accuracy: 0.6823354959487915 , global_step: 4884
- AI-Rank-log  1619124556.5564828  eval_accuracy: 0.6831014752388 , global_step: 4885
- AI-Rank-log  1619124600.491613  eval_accuracy: 0.6826279163360596 , global_step: 4886
- AI-Rank-log  1619124644.3801122  eval_accuracy: 0.682666003704071 , global_step: 4887
- AI-Rank-log  1619124688.172861  eval_accuracy: 0.6831488013267517 , global_step: 4888
- AI-Rank-log  1619124732.1583226  eval_accuracy: 0.6827613115310669 , global_step: 4889
- AI-Rank-log  1619124776.011778  eval_accuracy: 0.6833502054214478 , global_step: 4890
- AI-Rank-log  1619124819.8176198  eval_accuracy: 0.6822142004966736 , global_step: 4891
- AI-Rank-log  1619124863.748302  eval_accuracy: 0.6826741099357605 , global_step: 4892
- AI-Rank-log  1619124907.6032925  eval_accuracy: 0.681631863117218 , global_step: 4893
- AI-Rank-log  1619124951.4923046  eval_accuracy: 0.6828621029853821 , global_step: 4894
- AI-Rank-log  1619124995.3635278  eval_accuracy: 0.683535099029541 , global_step: 4895
- AI-Rank-log  1619125039.2751236  eval_accuracy: 0.6830657124519348 , global_step: 4896
- AI-Rank-log  1619125083.1524146  eval_accuracy: 0.6833169460296631 , global_step: 4897
- AI-Rank-log  1619125126.9895084  eval_accuracy: 0.6827279925346375 , global_step: 4898
- AI-Rank-log  1619125170.8334022  eval_accuracy: 0.6833315491676331 , global_step: 4899
- AI-Rank-log  1619125214.6983192  eval_accuracy: 0.6839052438735962 , global_step: 4900
- AI-Rank-log  1619125258.6001732  eval_accuracy: 0.6841181516647339 , global_step: 4901
- AI-Rank-log  1619125302.449469  eval_accuracy: 0.6835089325904846 , global_step: 4902
- AI-Rank-log  1619125346.3298118  eval_accuracy: 0.6845512390136719 , global_step: 4903
- AI-Rank-log  1619125390.1555808  eval_accuracy: 0.6831679344177246 , global_step: 4904
- AI-Rank-log  1619125434.0321856  eval_accuracy: 0.6843820810317993 , global_step: 4905
- AI-Rank-log  1619125477.849208  eval_accuracy: 0.6829085350036621 , global_step: 4906
- AI-Rank-log  1619125521.7415528  eval_accuracy: 0.6843485832214355 , global_step: 4907
- AI-Rank-log  1619125565.6283212  eval_accuracy: 0.6838773488998413 , global_step: 4908
- AI-Rank-log  1619125609.4670799  eval_accuracy: 0.6832237243652344 , global_step: 4909
- AI-Rank-log  1619125653.325572  eval_accuracy: 0.6833293437957764 , global_step: 4910
- AI-Rank-log  1619125697.2230754  eval_accuracy: 0.6835432052612305 , global_step: 4911
- AI-Rank-log  1619125741.060155  eval_accuracy: 0.6835092306137085 , global_step: 4912
- AI-Rank-log  1619125784.9049377  eval_accuracy: 0.6832928657531738 , global_step: 4913
- AI-Rank-log  1619125828.8298326  eval_accuracy: 0.6829883456230164 , global_step: 4914
- AI-Rank-log  1619125872.7323604  eval_accuracy: 0.6826658844947815 , global_step: 4915
- AI-Rank-log  1619125916.6422496  eval_accuracy: 0.6826387047767639 , global_step: 4916
- AI-Rank-log  1619125960.467143  eval_accuracy: 0.6833974123001099 , global_step: 4917
- AI-Rank-log  1619126004.371327  eval_accuracy: 0.6836230754852295 , global_step: 4918
- AI-Rank-log  1619126048.337482  eval_accuracy: 0.6833077669143677 , global_step: 4919
- AI-Rank-log  1619126092.1495042  eval_accuracy: 0.683779239654541 , global_step: 4920
- AI-Rank-log  1619126136.0172493  eval_accuracy: 0.6834718585014343 , global_step: 4921
- AI-Rank-log  1619126179.9616485  eval_accuracy: 0.683211088180542 , global_step: 4922
- AI-Rank-log  1619126223.785348  eval_accuracy: 0.6830310225486755 , global_step: 4923
- AI-Rank-log  1619126267.7266371  eval_accuracy: 0.6836329698562622 , global_step: 4924
- AI-Rank-log  1619126311.5880184  eval_accuracy: 0.6832505464553833 , global_step: 4925
- AI-Rank-log  1619126355.403201  eval_accuracy: 0.6832231879234314 , global_step: 4926
- AI-Rank-log  1619126399.3316627  eval_accuracy: 0.6825501322746277 , global_step: 4927
- AI-Rank-log  1619126443.1262708  eval_accuracy: 0.6826134324073792 , global_step: 4928
- AI-Rank-log  1619126486.9812386  eval_accuracy: 0.6824108362197876 , global_step: 4929
- AI-Rank-log  1619126530.8963735  eval_accuracy: 0.6826973557472229 , global_step: 4930
- AI-Rank-log  1619126574.6910026  eval_accuracy: 0.6829557418823242 , global_step: 4931
- AI-Rank-log  1619126618.529346  eval_accuracy: 0.6816452741622925 , global_step: 4932
- AI-Rank-log  1619126662.427215  eval_accuracy: 0.68226557970047 , global_step: 4933
- AI-Rank-log  1619126706.298967  eval_accuracy: 0.6830688118934631 , global_step: 4934
- AI-Rank-log  1619126750.1512954  eval_accuracy: 0.6825110912322998 , global_step: 4935
- AI-Rank-log  1619126794.060191  eval_accuracy: 0.6830772161483765 , global_step: 4936
- AI-Rank-log  1619126837.8842406  eval_accuracy: 0.6832522749900818 , global_step: 4937
- AI-Rank-log  1619126881.8243213  eval_accuracy: 0.6824100613594055 , global_step: 4938
- AI-Rank-log  1619126926.7124715  eval_accuracy: 0.6834011077880859 , global_step: 4939
- AI-Rank-log  1619126970.6926665  eval_accuracy: 0.6824782490730286 , global_step: 4940
- AI-Rank-log  1619127015.2964334  eval_accuracy: 0.6831290125846863 , global_step: 4941
- AI-Rank-log  1619127059.139396  eval_accuracy: 0.6824697256088257 , global_step: 4942
- AI-Rank-log  1619127103.2753088  eval_accuracy: 0.6826099157333374 , global_step: 4943
- AI-Rank-log  1619127147.7594097  eval_accuracy: 0.682630717754364 , global_step: 4944
- AI-Rank-log  1619127191.994886  eval_accuracy: 0.6829890608787537 , global_step: 4945
- AI-Rank-log  1619127235.850828  eval_accuracy: 0.6820996999740601 , global_step: 4946
- AI-Rank-log  1619127280.540571  eval_accuracy: 0.6826376914978027 , global_step: 4947
- AI-Rank-log  1619127324.3787737  eval_accuracy: 0.681952178478241 , global_step: 4948
- AI-Rank-log  1619127368.450587  eval_accuracy: 0.6826165914535522 , global_step: 4949
- AI-Rank-log  1619127413.130052  eval_accuracy: 0.6818661689758301 , global_step: 4950
- AI-Rank-log  1619127456.9573073  eval_accuracy: 0.6825391054153442 , global_step: 4951
- AI-Rank-log  1619127501.9442542  eval_accuracy: 0.6818188428878784 , global_step: 4952
- AI-Rank-log  1619127545.7884905  eval_accuracy: 0.682946503162384 , global_step: 4953
- AI-Rank-log  1619127589.6029701  eval_accuracy: 0.6831102967262268 , global_step: 4954
- AI-Rank-log  1619127633.4867823  eval_accuracy: 0.6837937831878662 , global_step: 4955
- AI-Rank-log  1619127677.7941735  eval_accuracy: 0.6833431720733643 , global_step: 4956
- AI-Rank-log  1619127721.7446322  eval_accuracy: 0.6834701299667358 , global_step: 4957
- AI-Rank-log  1619127765.5103762  eval_accuracy: 0.6839621067047119 , global_step: 4958
- AI-Rank-log  1619127809.3562498  eval_accuracy: 0.6834344267845154 , global_step: 4959
- AI-Rank-log  1619127853.215335  eval_accuracy: 0.6834520697593689 , global_step: 4960
- AI-Rank-log  1619127896.99581  eval_accuracy: 0.681821882724762 , global_step: 4961
- AI-Rank-log  1619127940.8392482  eval_accuracy: 0.6836572885513306 , global_step: 4962
- AI-Rank-log  1619127984.7348268  eval_accuracy: 0.6829168200492859 , global_step: 4963
- AI-Rank-log  1619128028.5593672  eval_accuracy: 0.6826596856117249 , global_step: 4964
- AI-Rank-log  1619128072.3771317  eval_accuracy: 0.6824538707733154 , global_step: 4965
- AI-Rank-log  1619128116.2372136  eval_accuracy: 0.6834986209869385 , global_step: 4966
- AI-Rank-log  1619128160.1135786  eval_accuracy: 0.6822304129600525 , global_step: 4967
- AI-Rank-log  1619128203.9345427  eval_accuracy: 0.6839792728424072 , global_step: 4968
- AI-Rank-log  1619128247.7922566  eval_accuracy: 0.6831470727920532 , global_step: 4969
- AI-Rank-log  1619128291.627743  eval_accuracy: 0.6836788654327393 , global_step: 4970
- AI-Rank-log  1619128335.5194652  eval_accuracy: 0.6823154091835022 , global_step: 4971
- AI-Rank-log  1619128379.3130846  eval_accuracy: 0.6834151744842529 , global_step: 4972
- AI-Rank-log  1619128423.1590035  eval_accuracy: 0.6832366585731506 , global_step: 4973
- AI-Rank-log  1619128467.037663  eval_accuracy: 0.6835286617279053 , global_step: 4974
- AI-Rank-log  1619128510.8194864  eval_accuracy: 0.6841286420822144 , global_step: 4975
- AI-Rank-log  1619128554.651614  eval_accuracy: 0.6834876537322998 , global_step: 4976
- AI-Rank-log  1619128598.5107057  eval_accuracy: 0.6843093037605286 , global_step: 4977
- AI-Rank-log  1619128642.2815304  eval_accuracy: 0.6827864050865173 , global_step: 4978
- AI-Rank-log  1619128686.1318622  eval_accuracy: 0.6840602159500122 , global_step: 4979
- AI-Rank-log  1619128729.9961717  eval_accuracy: 0.6835892796516418 , global_step: 4980
- AI-Rank-log  1619128773.7911813  eval_accuracy: 0.6834107041358948 , global_step: 4981
- AI-Rank-log  1619128817.6882603  eval_accuracy: 0.683998167514801 , global_step: 4982
- AI-Rank-log  1619128861.511519  eval_accuracy: 0.6841842532157898 , global_step: 4983
- AI-Rank-log  1619128905.3313897  eval_accuracy: 0.6844494342803955 , global_step: 4984
- AI-Rank-log  1619128949.215206  eval_accuracy: 0.6839138269424438 , global_step: 4985
- AI-Rank-log  1619128993.0227938  eval_accuracy: 0.6842103004455566 , global_step: 4986
- AI-Rank-log  1619129036.8670208  eval_accuracy: 0.6828460097312927 , global_step: 4987
- AI-Rank-log  1619129080.7446282  eval_accuracy: 0.682748019695282 , global_step: 4988
- AI-Rank-log  1619129124.5001438  eval_accuracy: 0.6832271218299866 , global_step: 4989
- AI-Rank-log  1619129168.410881  eval_accuracy: 0.6832605004310608 , global_step: 4990
- AI-Rank-log  1619129221.2175455  eval_accuracy: 0.6834556460380554 , global_step: 4991
- AI-Rank-log  1619129264.9845936  eval_accuracy: 0.6841639876365662 , global_step: 4992
- AI-Rank-log  1619129308.833112  eval_accuracy: 0.6840605139732361 , global_step: 4993
- AI-Rank-log  1619129352.6265037  eval_accuracy: 0.6837332248687744 , global_step: 4994
- AI-Rank-log  1619129396.4062264  eval_accuracy: 0.6849635243415833 , global_step: 4995
- AI-Rank-log  1619129440.3343995  eval_accuracy: 0.6835311651229858 , global_step: 4996
- AI-Rank-log  1619129484.1600592  eval_accuracy: 0.6832502484321594 , global_step: 4997
- AI-Rank-log  1619129527.9419634  eval_accuracy: 0.6825149059295654 , global_step: 4998
- AI-Rank-log  1619129571.7971425  eval_accuracy: 0.6836704611778259 , global_step: 4999
- AI-Rank-log  1619129615.6246986  eval_accuracy: 0.68385249376297 , global_step: 5000
- AI-Rank-log  1619129659.4322793  eval_accuracy: 0.6838945746421814 , global_step: 5001
- AI-Rank-log  1619129703.2757595  eval_accuracy: 0.6848025321960449 , global_step: 5002
- AI-Rank-log  1619129747.0743651  eval_accuracy: 0.6838470697402954 , global_step: 5003
- AI-Rank-log  1619129790.9477134  eval_accuracy: 0.6850726008415222 , global_step: 5004
- AI-Rank-log  1619129834.7629495  eval_accuracy: 0.6842414736747742 , global_step: 5005
- AI-Rank-log  1619129878.6155005  eval_accuracy: 0.6850288510322571 , global_step: 5006
- AI-Rank-log  1619129922.4932368  eval_accuracy: 0.6831791996955872 , global_step: 5007
- AI-Rank-log  1619129966.3269281  eval_accuracy: 0.6839762926101685 , global_step: 5008
- AI-Rank-log  1619130010.2415812  eval_accuracy: 0.6813755631446838 , global_step: 5009
- AI-Rank-log  1619130054.079953  eval_accuracy: 0.6839680075645447 , global_step: 5010
- AI-Rank-log  1619130097.9176571  eval_accuracy: 0.6833387017250061 , global_step: 5011
- AI-Rank-log  1619130141.7790277  eval_accuracy: 0.6830615401268005 , global_step: 5012
- AI-Rank-log  1619130185.5769637  eval_accuracy: 0.6839870810508728 , global_step: 5013
- AI-Rank-log  1619130229.3564215  eval_accuracy: 0.6833334565162659 , global_step: 5014
- AI-Rank-log  1619130273.241289  eval_accuracy: 0.6840882897377014 , global_step: 5015
- AI-Rank-log  1619130317.2012162  eval_accuracy: 0.6839063167572021 , global_step: 5016
- AI-Rank-log  1619130361.5819633  eval_accuracy: 0.6842628717422485 , global_step: 5017
- AI-Rank-log  1619130405.4198012  eval_accuracy: 0.6839014887809753 , global_step: 5018
- AI-Rank-log  1619130449.2010741  eval_accuracy: 0.6831232309341431 , global_step: 5019
- AI-Rank-log  1619130494.0472744  eval_accuracy: 0.6845188140869141 , global_step: 5020
- AI-Rank-log  1619130538.9780369  eval_accuracy: 0.6836535334587097 , global_step: 5021
- AI-Rank-log  1619130582.8708904  eval_accuracy: 0.6838998198509216 , global_step: 5022
- AI-Rank-log  1619130627.023633  eval_accuracy: 0.6831234693527222 , global_step: 5023
- AI-Rank-log  1619130670.8359396  eval_accuracy: 0.683837890625 , global_step: 5024
- AI-Rank-log  1619130715.652616  eval_accuracy: 0.6833170652389526 , global_step: 5025
- AI-Rank-log  1619130759.9789615  eval_accuracy: 0.6840597987174988 , global_step: 5026
- AI-Rank-log  1619130803.7607222  eval_accuracy: 0.6834844946861267 , global_step: 5027
- AI-Rank-log  1619130848.2418787  eval_accuracy: 0.685197651386261 , global_step: 5028
- AI-Rank-log  1619130892.3671582  eval_accuracy: 0.683430016040802 , global_step: 5029
- AI-Rank-log  1619130937.0883777  eval_accuracy: 0.6837806105613708 , global_step: 5030
- AI-Rank-log  1619130980.937811  eval_accuracy: 0.6833485960960388 , global_step: 5031
- AI-Rank-log  1619131024.734241  eval_accuracy: 0.6840259432792664 , global_step: 5032
- AI-Rank-log  1619131068.7813323  eval_accuracy: 0.6839362382888794 , global_step: 5033
- AI-Rank-log  1619131112.690911  eval_accuracy: 0.6833713054656982 , global_step: 5034
- AI-Rank-log  1619131156.5782456  eval_accuracy: 0.6839573383331299 , global_step: 5035
- AI-Rank-log  1619131200.3974726  eval_accuracy: 0.6842638850212097 , global_step: 5036
- AI-Rank-log  1619131244.2884743  eval_accuracy: 0.6841432452201843 , global_step: 5037
- AI-Rank-log  1619131288.0831714  eval_accuracy: 0.6847844123840332 , global_step: 5038
- AI-Rank-log  1619131331.9054794  eval_accuracy: 0.6838734149932861 , global_step: 5039
- AI-Rank-log  1619131375.7859027  eval_accuracy: 0.6842860579490662 , global_step: 5040
- AI-Rank-log  1619131419.6083467  eval_accuracy: 0.6840993165969849 , global_step: 5041
- AI-Rank-log  1619131463.405365  eval_accuracy: 0.6848762035369873 , global_step: 5042
- AI-Rank-log  1619131507.2654238  eval_accuracy: 0.6842136979103088 , global_step: 5043
- AI-Rank-log  1619131551.0469134  eval_accuracy: 0.6839842200279236 , global_step: 5044
- AI-Rank-log  1619131594.9385648  eval_accuracy: 0.6836763620376587 , global_step: 5045
- AI-Rank-log  1619131638.7509012  eval_accuracy: 0.6845510005950928 , global_step: 5046
- AI-Rank-log  1619131682.501969  eval_accuracy: 0.6838786602020264 , global_step: 5047
- AI-Rank-log  1619131726.3907773  eval_accuracy: 0.684865415096283 , global_step: 5048
- AI-Rank-log  1619131770.2469578  eval_accuracy: 0.6845334768295288 , global_step: 5049
- AI-Rank-log  1619131814.0942528  eval_accuracy: 0.6844829320907593 , global_step: 5050
- AI-Rank-log  1619131857.9977446  eval_accuracy: 0.6841561198234558 , global_step: 5051
- AI-Rank-log  1619131901.8093567  eval_accuracy: 0.6843334436416626 , global_step: 5052
- AI-Rank-log  1619131945.7081325  eval_accuracy: 0.6846762299537659 , global_step: 5053
- AI-Rank-log  1619131989.5313003  eval_accuracy: 0.6849245429039001 , global_step: 5054
- AI-Rank-log  1619132033.3319826  eval_accuracy: 0.684151828289032 , global_step: 5055
- AI-Rank-log  1619132077.2077096  eval_accuracy: 0.6852002739906311 , global_step: 5056
- AI-Rank-log  1619132121.02069  eval_accuracy: 0.6845553517341614 , global_step: 5057
- AI-Rank-log  1619132164.8179252  eval_accuracy: 0.6855788826942444 , global_step: 5058
- AI-Rank-log  1619132208.7221704  eval_accuracy: 0.6837290525436401 , global_step: 5059
- AI-Rank-log  1619132252.5224116  eval_accuracy: 0.6849684715270996 , global_step: 5060
- AI-Rank-log  1619132296.3359306  eval_accuracy: 0.6840484142303467 , global_step: 5061
- AI-Rank-log  1619132340.2089796  eval_accuracy: 0.6848174929618835 , global_step: 5062
- AI-Rank-log  1619132384.049581  eval_accuracy: 0.6852864623069763 , global_step: 5063
- AI-Rank-log  1619132427.904024  eval_accuracy: 0.684248685836792 , global_step: 5064
- AI-Rank-log  1619132471.7113662  eval_accuracy: 0.6849413514137268 , global_step: 5065
- AI-Rank-log  1619132515.5442486  eval_accuracy: 0.6835591793060303 , global_step: 5066
- AI-Rank-log  1619132559.41001  eval_accuracy: 0.68544602394104 , global_step: 5067
- AI-Rank-log  1619132603.285606  eval_accuracy: 0.6839057803153992 , global_step: 5068
- AI-Rank-log  1619132647.083981  eval_accuracy: 0.6846415400505066 , global_step: 5069
- AI-Rank-log  1619132690.957572  eval_accuracy: 0.6847773194313049 , global_step: 5070
- AI-Rank-log  1619132734.8494155  eval_accuracy: 0.6843094825744629 , global_step: 5071
- AI-Rank-log  1619132778.660571  eval_accuracy: 0.6841959357261658 , global_step: 5072
- AI-Rank-log  1619132822.555784  eval_accuracy: 0.6848963499069214 , global_step: 5073
- AI-Rank-log  1619132866.3516953  eval_accuracy: 0.6847184300422668 , global_step: 5074
- AI-Rank-log  1619132910.2363963  eval_accuracy: 0.6847155094146729 , global_step: 5075
- AI-Rank-log  1619132954.012403  eval_accuracy: 0.6849297285079956 , global_step: 5076
- AI-Rank-log  1619132997.8661046  eval_accuracy: 0.6848564743995667 , global_step: 5077
- AI-Rank-log  1619133041.7817965  eval_accuracy: 0.6833997964859009 , global_step: 5078
- AI-Rank-log  1619133085.5657148  eval_accuracy: 0.6849049925804138 , global_step: 5079
- AI-Rank-log  1619133129.4121277  eval_accuracy: 0.6839600205421448 , global_step: 5080
- AI-Rank-log  1619133173.3202024  eval_accuracy: 0.6853819489479065 , global_step: 5081
- AI-Rank-log  1619133217.1380339  eval_accuracy: 0.684611439704895 , global_step: 5082
- AI-Rank-log  1619133260.9883494  eval_accuracy: 0.684819757938385 , global_step: 5083
- AI-Rank-log  1619133304.8869984  eval_accuracy: 0.6844358444213867 , global_step: 5084
- AI-Rank-log  1619133348.7119966  eval_accuracy: 0.685495138168335 , global_step: 5085
- AI-Rank-log  1619133392.5878618  eval_accuracy: 0.6847332715988159 , global_step: 5086
- AI-Rank-log  1619133436.3729603  eval_accuracy: 0.6850795745849609 , global_step: 5087
- AI-Rank-log  1619133480.1984634  eval_accuracy: 0.6847758293151855 , global_step: 5088
- AI-Rank-log  1619133524.0709047  eval_accuracy: 0.6845778822898865 , global_step: 5089
- AI-Rank-log  1619133567.8900683  eval_accuracy: 0.6849679350852966 , global_step: 5090
- AI-Rank-log  1619133611.7033916  eval_accuracy: 0.6848209500312805 , global_step: 5091
- AI-Rank-log  1619133655.6795728  eval_accuracy: 0.6849663853645325 , global_step: 5092
- AI-Rank-log  1619133699.5371418  eval_accuracy: 0.6847198605537415 , global_step: 5093
- AI-Rank-log  1619133744.3803654  eval_accuracy: 0.6843171119689941 , global_step: 5094
- AI-Rank-log  1619133788.2916532  eval_accuracy: 0.6837068796157837 , global_step: 5095
- AI-Rank-log  1619133832.215193  eval_accuracy: 0.6844890117645264 , global_step: 5096
- AI-Rank-log  1619133876.74461  eval_accuracy: 0.6839007139205933 , global_step: 5097
- AI-Rank-log  1619133921.0694516  eval_accuracy: 0.6847502589225769 , global_step: 5098
- AI-Rank-log  1619133964.94139  eval_accuracy: 0.6834982633590698 , global_step: 5099
- AI-Rank-log  1619134009.1504717  eval_accuracy: 0.6845254302024841 , global_step: 5100
- AI-Rank-log  1619134053.1456878  eval_accuracy: 0.6836252212524414 , global_step: 5101
- AI-Rank-log  1619134097.9928982  eval_accuracy: 0.6844013333320618 , global_step: 5102
- AI-Rank-log  1619134142.322201  eval_accuracy: 0.6844774484634399 , global_step: 5103
- AI-Rank-log  1619134186.2096298  eval_accuracy: 0.6844381093978882 , global_step: 5104
- AI-Rank-log  1619134230.7688103  eval_accuracy: 0.6837816834449768 , global_step: 5105
- AI-Rank-log  1619134274.8734393  eval_accuracy: 0.6837159395217896 , global_step: 5106
- AI-Rank-log  1619134319.9236207  eval_accuracy: 0.6840081810951233 , global_step: 5107
- AI-Rank-log  1619134363.8795674  eval_accuracy: 0.684016227722168 , global_step: 5108
- AI-Rank-log  1619134407.677118  eval_accuracy: 0.6835902333259583 , global_step: 5109
- AI-Rank-log  1619134451.5802608  eval_accuracy: 0.6842009425163269 , global_step: 5110
- AI-Rank-log  1619134495.7742097  eval_accuracy: 0.683570146560669 , global_step: 5111
- AI-Rank-log  1619134539.6573956  eval_accuracy: 0.6842026710510254 , global_step: 5112
- AI-Rank-log  1619134583.549597  eval_accuracy: 0.6827908158302307 , global_step: 5113
- AI-Rank-log  1619134627.5424497  eval_accuracy: 0.6834204792976379 , global_step: 5114
- AI-Rank-log  1619134671.4282227  eval_accuracy: 0.6834298968315125 , global_step: 5115
- AI-Rank-log  1619134715.3635988  eval_accuracy: 0.6836873888969421 , global_step: 5116
- AI-Rank-log  1619134759.2665505  eval_accuracy: 0.6841882467269897 , global_step: 5117
- AI-Rank-log  1619134803.174119  eval_accuracy: 0.6844720244407654 , global_step: 5118
- AI-Rank-log  1619134847.1247725  eval_accuracy: 0.6842353343963623 , global_step: 5119
- AI-Rank-log  1619134891.038351  eval_accuracy: 0.6844764351844788 , global_step: 5120
- AI-Rank-log  1619134934.977071  eval_accuracy: 0.6852505207061768 , global_step: 5121
- AI-Rank-log  1619134978.892033  eval_accuracy: 0.6854725480079651 , global_step: 5122
- AI-Rank-log  1619135022.8125358  eval_accuracy: 0.6852915287017822 , global_step: 5123
- AI-Rank-log  1619135066.7205176  eval_accuracy: 0.6855398416519165 , global_step: 5124
- AI-Rank-log  1619135110.6782093  eval_accuracy: 0.6851818561553955 , global_step: 5125
- AI-Rank-log  1619135154.55986  eval_accuracy: 0.6858402490615845 , global_step: 5126
- AI-Rank-log  1619135198.4867725  eval_accuracy: 0.6847435832023621 , global_step: 5127
- AI-Rank-log  1619135242.3614104  eval_accuracy: 0.685146152973175 , global_step: 5128
- AI-Rank-log  1619135286.240655  eval_accuracy: 0.6849458813667297 , global_step: 5129
- AI-Rank-log  1619135330.1672637  eval_accuracy: 0.6856964230537415 , global_step: 5130
- AI-Rank-log  1619135374.0542295  eval_accuracy: 0.6851460337638855 , global_step: 5131
- AI-Rank-log  1619135417.953369  eval_accuracy: 0.6853445172309875 , global_step: 5132
- AI-Rank-log  1619135461.9297779  eval_accuracy: 0.6848586797714233 , global_step: 5133
- AI-Rank-log  1619135505.8034341  eval_accuracy: 0.6848618388175964 , global_step: 5134
- AI-Rank-log  1619135549.8403826  eval_accuracy: 0.6842068433761597 , global_step: 5135
- AI-Rank-log  1619135593.7215428  eval_accuracy: 0.6852670907974243 , global_step: 5136
- AI-Rank-log  1619135637.6241164  eval_accuracy: 0.6850965619087219 , global_step: 5137
- AI-Rank-log  1619135681.595623  eval_accuracy: 0.6849442720413208 , global_step: 5138
- AI-Rank-log  1619135725.5072258  eval_accuracy: 0.6851692199707031 , global_step: 5139
- AI-Rank-log  1619135769.4286706  eval_accuracy: 0.6851081252098083 , global_step: 5140
- AI-Rank-log  1619135813.4304783  eval_accuracy: 0.6850882172584534 , global_step: 5141
- AI-Rank-log  1619135857.3349612  eval_accuracy: 0.6855319738388062 , global_step: 5142
- AI-Rank-log  1619135901.2232544  eval_accuracy: 0.6843599081039429 , global_step: 5143
- AI-Rank-log  1619135945.261974  eval_accuracy: 0.6858152151107788 , global_step: 5144
- AI-Rank-log  1619135989.0981035  eval_accuracy: 0.6838696002960205 , global_step: 5145
- AI-Rank-log  1619136033.053726  eval_accuracy: 0.684980034828186 , global_step: 5146
- AI-Rank-log  1619136076.947964  eval_accuracy: 0.6843699216842651 , global_step: 5147
- AI-Rank-log  1619136120.828622  eval_accuracy: 0.6846829652786255 , global_step: 5148
- AI-Rank-log  1619136164.7833788  eval_accuracy: 0.6846610903739929 , global_step: 5149
- AI-Rank-log  1619136208.719351  eval_accuracy: 0.6850032806396484 , global_step: 5150
- AI-Rank-log  1619136252.5751207  eval_accuracy: 0.6852912902832031 , global_step: 5151
- AI-Rank-log  1619136296.5481267  eval_accuracy: 0.6854478716850281 , global_step: 5152
- AI-Rank-log  1619136340.4787414  eval_accuracy: 0.6839327216148376 , global_step: 5153
- AI-Rank-log  1619136384.3946037  eval_accuracy: 0.6850418448448181 , global_step: 5154
- AI-Rank-log  1619136428.345952  eval_accuracy: 0.6845898032188416 , global_step: 5155
- AI-Rank-log  1619136472.2302756  eval_accuracy: 0.68446284532547 , global_step: 5156
- AI-Rank-log  1619136516.0942397  eval_accuracy: 0.6839230060577393 , global_step: 5157
- AI-Rank-log  1619136560.0457802  eval_accuracy: 0.6850544214248657 , global_step: 5158
- AI-Rank-log  1619136603.914047  eval_accuracy: 0.6844999194145203 , global_step: 5159
- AI-Rank-log  1619136647.9640207  eval_accuracy: 0.6851964592933655 , global_step: 5160
- AI-Rank-log  1619136691.8511665  eval_accuracy: 0.685073971748352 , global_step: 5161
- AI-Rank-log  1619136735.7822785  eval_accuracy: 0.6849440336227417 , global_step: 5162
- AI-Rank-log  1619136779.7378206  eval_accuracy: 0.6845983862876892 , global_step: 5163
- AI-Rank-log  1619136823.653373  eval_accuracy: 0.685056746006012 , global_step: 5164
- AI-Rank-log  1619136867.5442123  eval_accuracy: 0.6845298409461975 , global_step: 5165
- AI-Rank-log  1619136911.535229  eval_accuracy: 0.6852850317955017 , global_step: 5166
- AI-Rank-log  1619136955.4608579  eval_accuracy: 0.6844887137413025 , global_step: 5167
- AI-Rank-log  1619136999.3884118  eval_accuracy: 0.6841766238212585 , global_step: 5168
- AI-Rank-log  1619137043.3138535  eval_accuracy: 0.6849101781845093 , global_step: 5169
- AI-Rank-log  1619137087.187328  eval_accuracy: 0.685276210308075 , global_step: 5170
- AI-Rank-log  1619137131.8816907  eval_accuracy: 0.6850071549415588 , global_step: 5171
- AI-Rank-log  1619137176.0125747  eval_accuracy: 0.6853234171867371 , global_step: 5172
- AI-Rank-log  1619137219.8932498  eval_accuracy: 0.6850019693374634 , global_step: 5173
- AI-Rank-log  1619137264.4228384  eval_accuracy: 0.6855836510658264 , global_step: 5174
- AI-Rank-log  1619137308.3388333  eval_accuracy: 0.6842925548553467 , global_step: 5175
- AI-Rank-log  1619137352.7760644  eval_accuracy: 0.6850237250328064 , global_step: 5176
- AI-Rank-log  1619137397.0091705  eval_accuracy: 0.6854906678199768 , global_step: 5177
- AI-Rank-log  1619137440.9118106  eval_accuracy: 0.6854904294013977 , global_step: 5178
- AI-Rank-log  1619137485.6379497  eval_accuracy: 0.6852902770042419 , global_step: 5179
- AI-Rank-log  1619137529.5538793  eval_accuracy: 0.6862367987632751 , global_step: 5180
- AI-Rank-log  1619137573.98692  eval_accuracy: 0.6848742365837097 , global_step: 5181
- AI-Rank-log  1619137618.6904182  eval_accuracy: 0.6856462359428406 , global_step: 5182
- AI-Rank-log  1619137662.5883222  eval_accuracy: 0.6855003833770752 , global_step: 5183
- AI-Rank-log  1619137706.5130467  eval_accuracy: 0.6850985288619995 , global_step: 5184
- AI-Rank-log  1619137751.6120446  eval_accuracy: 0.6839964389801025 , global_step: 5185
- AI-Rank-log  1619137795.7668762  eval_accuracy: 0.6847509145736694 , global_step: 5186
- AI-Rank-log  1619137839.742474  eval_accuracy: 0.6837663650512695 , global_step: 5187
- AI-Rank-log  1619137883.7808888  eval_accuracy: 0.6847309470176697 , global_step: 5188
- AI-Rank-log  1619137927.6718454  eval_accuracy: 0.6842015981674194 , global_step: 5189
- AI-Rank-log  1619137971.6676278  eval_accuracy: 0.6848828196525574 , global_step: 5190
- AI-Rank-log  1619138024.486984  eval_accuracy: 0.6848780512809753 , global_step: 5191
- AI-Rank-log  1619138068.3626773  eval_accuracy: 0.6847546100616455 , global_step: 5192
- AI-Rank-log  1619138112.3527877  eval_accuracy: 0.6843539476394653 , global_step: 5193
- AI-Rank-log  1619138156.2950122  eval_accuracy: 0.6858630180358887 , global_step: 5194
- AI-Rank-log  1619138200.224312  eval_accuracy: 0.6849545240402222 , global_step: 5195
- AI-Rank-log  1619138244.2126267  eval_accuracy: 0.6856821179389954 , global_step: 5196
- AI-Rank-log  1619138288.143759  eval_accuracy: 0.6842731833457947 , global_step: 5197
- AI-Rank-log  1619138332.0916855  eval_accuracy: 0.6856850981712341 , global_step: 5198
- AI-Rank-log  1619138376.0706978  eval_accuracy: 0.6852393746376038 , global_step: 5199
- AI-Rank-log  1619138420.0142498  eval_accuracy: 0.6857345104217529 , global_step: 5200
- AI-Rank-log  1619138464.0004303  eval_accuracy: 0.6853328943252563 , global_step: 5201
- AI-Rank-log  1619138507.908892  eval_accuracy: 0.6849252581596375 , global_step: 5202
- AI-Rank-log  1619138551.8010929  eval_accuracy: 0.6857814192771912 , global_step: 5203
- AI-Rank-log  1619138595.8051295  eval_accuracy: 0.6847131252288818 , global_step: 5204
- AI-Rank-log  1619138639.719014  eval_accuracy: 0.6866815090179443 , global_step: 5205
- AI-Rank-log  1619138683.6779952  eval_accuracy: 0.6856351494789124 , global_step: 5206
- AI-Rank-log  1619138727.5667467  eval_accuracy: 0.6859622597694397 , global_step: 5207
- AI-Rank-log  1619138771.4433963  eval_accuracy: 0.6857001185417175 , global_step: 5208
- AI-Rank-log  1619138815.4330194  eval_accuracy: 0.6859248280525208 , global_step: 5209
- AI-Rank-log  1619138859.3597722  eval_accuracy: 0.6845244765281677 , global_step: 5210
- AI-Rank-log  1619138903.2853384  eval_accuracy: 0.6853998303413391 , global_step: 5211
- AI-Rank-log  1619138947.239159  eval_accuracy: 0.6843487024307251 , global_step: 5212
- AI-Rank-log  1619138991.1834831  eval_accuracy: 0.6859230399131775 , global_step: 5213
- AI-Rank-log  1619139035.0944927  eval_accuracy: 0.6853498220443726 , global_step: 5214
- AI-Rank-log  1619139079.026398  eval_accuracy: 0.6854310035705566 , global_step: 5215
- AI-Rank-log  1619139122.9553666  eval_accuracy: 0.6850647330284119 , global_step: 5216
- AI-Rank-log  1619139166.8892677  eval_accuracy: 0.6859779357910156 , global_step: 5217
- AI-Rank-log  1619139210.8519177  eval_accuracy: 0.686188280582428 , global_step: 5218
- AI-Rank-log  1619139254.809634  eval_accuracy: 0.6866604685783386 , global_step: 5219
- AI-Rank-log  1619139298.7767258  eval_accuracy: 0.6859850287437439 , global_step: 5220
- AI-Rank-log  1619139342.6411934  eval_accuracy: 0.6858693361282349 , global_step: 5221
- AI-Rank-log  1619139386.6011536  eval_accuracy: 0.6859756112098694 , global_step: 5222
- AI-Rank-log  1619139430.553535  eval_accuracy: 0.685987114906311 , global_step: 5223
- AI-Rank-log  1619139474.4691544  eval_accuracy: 0.686323881149292 , global_step: 5224
- AI-Rank-log  1619139518.365621  eval_accuracy: 0.685312032699585 , global_step: 5225
- AI-Rank-log  1619139562.3257623  eval_accuracy: 0.686311662197113 , global_step: 5226
- AI-Rank-log  1619139606.173484  eval_accuracy: 0.6856837272644043 , global_step: 5227
- AI-Rank-log  1619139650.1608534  eval_accuracy: 0.6865529417991638 , global_step: 5228
- AI-Rank-log  1619139694.052788  eval_accuracy: 0.6853060722351074 , global_step: 5229
- AI-Rank-log  1619139737.9764178  eval_accuracy: 0.6867758631706238 , global_step: 5230
- AI-Rank-log  1619139781.9171584  eval_accuracy: 0.6855100393295288 , global_step: 5231
- AI-Rank-log  1619139825.8232458  eval_accuracy: 0.6859399676322937 , global_step: 5232
- AI-Rank-log  1619139869.7223368  eval_accuracy: 0.6852948069572449 , global_step: 5233
- AI-Rank-log  1619139913.7080762  eval_accuracy: 0.6860061287879944 , global_step: 5234
- AI-Rank-log  1619139957.5790234  eval_accuracy: 0.6856530904769897 , global_step: 5235
- AI-Rank-log  1619140001.4859807  eval_accuracy: 0.6854074001312256 , global_step: 5236
- AI-Rank-log  1619140045.4812546  eval_accuracy: 0.6856292486190796 , global_step: 5237
- AI-Rank-log  1619140089.34763  eval_accuracy: 0.6859666705131531 , global_step: 5238
- AI-Rank-log  1619140133.3478472  eval_accuracy: 0.68531334400177 , global_step: 5239
- AI-Rank-log  1619140177.261063  eval_accuracy: 0.6855027675628662 , global_step: 5240
- AI-Rank-log  1619140221.149684  eval_accuracy: 0.6855086088180542 , global_step: 5241
- AI-Rank-log  1619140265.161472  eval_accuracy: 0.6859416365623474 , global_step: 5242
- AI-Rank-log  1619140309.0786238  eval_accuracy: 0.6863422393798828 , global_step: 5243
- AI-Rank-log  1619140352.9462736  eval_accuracy: 0.6861086487770081 , global_step: 5244
- AI-Rank-log  1619140396.9160182  eval_accuracy: 0.6872268915176392 , global_step: 5245
- AI-Rank-log  1619140440.7876441  eval_accuracy: 0.6858319640159607 , global_step: 5246
- AI-Rank-log  1619140484.682977  eval_accuracy: 0.6872931718826294 , global_step: 5247
- AI-Rank-log  1619140529.3802106  eval_accuracy: 0.6866143345832825 , global_step: 5248
- AI-Rank-log  1619140573.3637223  eval_accuracy: 0.6866001486778259 , global_step: 5249
- AI-Rank-log  1619140617.3072402  eval_accuracy: 0.6864166259765625 , global_step: 5250
- AI-Rank-log  1619140661.7915518  eval_accuracy: 0.6865888237953186 , global_step: 5251
- AI-Rank-log  1619140705.6698148  eval_accuracy: 0.6862837672233582 , global_step: 5252
- AI-Rank-log  1619140750.082995  eval_accuracy: 0.6866095662117004 , global_step: 5253
- AI-Rank-log  1619140794.1754649  eval_accuracy: 0.6850497126579285 , global_step: 5254
- AI-Rank-log  1619140838.2194998  eval_accuracy: 0.6866430640220642 , global_step: 5255
- AI-Rank-log  1619140883.133709  eval_accuracy: 0.6862508058547974 , global_step: 5256
- AI-Rank-log  1619140927.3933194  eval_accuracy: 0.6857895255088806 , global_step: 5257
- AI-Rank-log  1619140971.6116836  eval_accuracy: 0.6856765747070312 , global_step: 5258
- AI-Rank-log  1619141015.531723  eval_accuracy: 0.6860213279724121 , global_step: 5259
- AI-Rank-log  1619141060.0781834  eval_accuracy: 0.6854581832885742 , global_step: 5260
- AI-Rank-log  1619141104.0492442  eval_accuracy: 0.6865939497947693 , global_step: 5261
- AI-Rank-log  1619141149.24701  eval_accuracy: 0.6856110095977783 , global_step: 5262
- AI-Rank-log  1619141193.135426  eval_accuracy: 0.6858217716217041 , global_step: 5263
- AI-Rank-log  1619141237.1125038  eval_accuracy: 0.6867173314094543 , global_step: 5264
- AI-Rank-log  1619141281.004949  eval_accuracy: 0.6848901510238647 , global_step: 5265
- AI-Rank-log  1619141325.2489917  eval_accuracy: 0.6863967180252075 , global_step: 5266
- AI-Rank-log  1619141369.1673646  eval_accuracy: 0.6852092146873474 , global_step: 5267
- AI-Rank-log  1619141413.0743291  eval_accuracy: 0.6865006685256958 , global_step: 5268
- AI-Rank-log  1619141457.0258818  eval_accuracy: 0.6862985491752625 , global_step: 5269
- AI-Rank-log  1619141500.9789045  eval_accuracy: 0.6870763897895813 , global_step: 5270
- AI-Rank-log  1619141544.8964076  eval_accuracy: 0.6867476105690002 , global_step: 5271
- AI-Rank-log  1619141588.8995697  eval_accuracy: 0.68635094165802 , global_step: 5272
- AI-Rank-log  1619141632.8149574  eval_accuracy: 0.6863827705383301 , global_step: 5273
- AI-Rank-log  1619141676.7102253  eval_accuracy: 0.6874326467514038 , global_step: 5274
- AI-Rank-log  1619141720.6896188  eval_accuracy: 0.6875212788581848 , global_step: 5275
- AI-Rank-log  1619141764.6045296  eval_accuracy: 0.6872649788856506 , global_step: 5276
- AI-Rank-log  1619141808.4847436  eval_accuracy: 0.6870654225349426 , global_step: 5277
- AI-Rank-log  1619141852.4516478  eval_accuracy: 0.6870685815811157 , global_step: 5278
- AI-Rank-log  1619141896.3401809  eval_accuracy: 0.686725378036499 , global_step: 5279
- AI-Rank-log  1619141940.3643684  eval_accuracy: 0.6869023442268372 , global_step: 5280
- AI-Rank-log  1619141984.2405367  eval_accuracy: 0.6866503953933716 , global_step: 5281
- AI-Rank-log  1619142028.1949234  eval_accuracy: 0.6864938735961914 , global_step: 5282
- AI-Rank-log  1619142072.227369  eval_accuracy: 0.6864081621170044 , global_step: 5283
- AI-Rank-log  1619142116.1602929  eval_accuracy: 0.6858512163162231 , global_step: 5284
- AI-Rank-log  1619142160.0777907  eval_accuracy: 0.6869131922721863 , global_step: 5285
- AI-Rank-log  1619142204.0882711  eval_accuracy: 0.6861083507537842 , global_step: 5286
- AI-Rank-log  1619142247.952507  eval_accuracy: 0.6857550144195557 , global_step: 5287
- AI-Rank-log  1619142291.8597276  eval_accuracy: 0.6860585808753967 , global_step: 5288
- AI-Rank-log  1619142335.869781  eval_accuracy: 0.686195433139801 , global_step: 5289
- AI-Rank-log  1619142379.7349522  eval_accuracy: 0.6861182451248169 , global_step: 5290
- AI-Rank-log  1619142423.7257044  eval_accuracy: 0.6863946914672852 , global_step: 5291
- AI-Rank-log  1619142467.6020718  eval_accuracy: 0.685951828956604 , global_step: 5292
- AI-Rank-log  1619142511.4889896  eval_accuracy: 0.6854696273803711 , global_step: 5293
- AI-Rank-log  1619142555.4298723  eval_accuracy: 0.6858330965042114 , global_step: 5294
- AI-Rank-log  1619142599.3093967  eval_accuracy: 0.6858850717544556 , global_step: 5295
- AI-Rank-log  1619142643.206061  eval_accuracy: 0.6856663227081299 , global_step: 5296
- AI-Rank-log  1619142687.1579747  eval_accuracy: 0.6863899827003479 , global_step: 5297
- AI-Rank-log  1619142731.0616286  eval_accuracy: 0.68592369556427 , global_step: 5298
- AI-Rank-log  1619142774.9546092  eval_accuracy: 0.6859094500541687 , global_step: 5299
- AI-Rank-log  1619142818.9309435  eval_accuracy: 0.6866028904914856 , global_step: 5300
- AI-Rank-log  1619142862.8650043  eval_accuracy: 0.6868420243263245 , global_step: 5301
- AI-Rank-log  1619142906.835576  eval_accuracy: 0.6868904232978821 , global_step: 5302
- AI-Rank-log  1619142950.7933443  eval_accuracy: 0.6863608360290527 , global_step: 5303
- AI-Rank-log  1619142994.697698  eval_accuracy: 0.6868501305580139 , global_step: 5304
- AI-Rank-log  1619143038.7332766  eval_accuracy: 0.6857420206069946 , global_step: 5305
- AI-Rank-log  1619143082.6370633  eval_accuracy: 0.6867616772651672 , global_step: 5306
- AI-Rank-log  1619143126.5042982  eval_accuracy: 0.686030924320221 , global_step: 5307
- AI-Rank-log  1619143170.473773  eval_accuracy: 0.6865602731704712 , global_step: 5308
- AI-Rank-log  1619143214.3539684  eval_accuracy: 0.6858797073364258 , global_step: 5309
- AI-Rank-log  1619143258.2144501  eval_accuracy: 0.686748743057251 , global_step: 5310
- AI-Rank-log  1619143302.1874645  eval_accuracy: 0.686408519744873 , global_step: 5311
- AI-Rank-log  1619143346.0644543  eval_accuracy: 0.6866397261619568 , global_step: 5312
- AI-Rank-log  1619143389.967199  eval_accuracy: 0.6865880489349365 , global_step: 5313
- AI-Rank-log  1619143433.867041  eval_accuracy: 0.6871340274810791 , global_step: 5314
- AI-Rank-log  1619143477.759079  eval_accuracy: 0.6871011853218079 , global_step: 5315
- AI-Rank-log  1619143521.690319  eval_accuracy: 0.6864653825759888 , global_step: 5316
- AI-Rank-log  1619143565.5671368  eval_accuracy: 0.6867877840995789 , global_step: 5317
- AI-Rank-log  1619143609.4627845  eval_accuracy: 0.6861268877983093 , global_step: 5318
- AI-Rank-log  1619143653.3945546  eval_accuracy: 0.6867837309837341 , global_step: 5319
- AI-Rank-log  1619143697.3094547  eval_accuracy: 0.6853872537612915 , global_step: 5320
- AI-Rank-log  1619143741.1849456  eval_accuracy: 0.6864102482795715 , global_step: 5321
- AI-Rank-log  1619143785.1305315  eval_accuracy: 0.6852324604988098 , global_step: 5322
- AI-Rank-log  1619143829.091288  eval_accuracy: 0.6858112812042236 , global_step: 5323
- AI-Rank-log  1619143873.006229  eval_accuracy: 0.6852489709854126 , global_step: 5324
- AI-Rank-log  1619143916.9663749  eval_accuracy: 0.686090886592865 , global_step: 5325
- AI-Rank-log  1619143961.8173823  eval_accuracy: 0.6851129531860352 , global_step: 5326
- AI-Rank-log  1619144005.7756865  eval_accuracy: 0.6867103576660156 , global_step: 5327
- AI-Rank-log  1619144049.6645908  eval_accuracy: 0.6859383583068848 , global_step: 5328
- AI-Rank-log  1619144094.2081447  eval_accuracy: 0.6865731477737427 , global_step: 5329
- AI-Rank-log  1619144138.7752912  eval_accuracy: 0.6850517392158508 , global_step: 5330
- AI-Rank-log  1619144182.7529318  eval_accuracy: 0.6861096024513245 , global_step: 5331
- AI-Rank-log  1619144226.8669307  eval_accuracy: 0.685587465763092 , global_step: 5332
- AI-Rank-log  1619144271.1505678  eval_accuracy: 0.6870352625846863 , global_step: 5333
- AI-Rank-log  1619144315.9164655  eval_accuracy: 0.6867849826812744 , global_step: 5334
- AI-Rank-log  1619144360.0021634  eval_accuracy: 0.686722993850708 , global_step: 5335
- AI-Rank-log  1619144404.329428  eval_accuracy: 0.6867832541465759 , global_step: 5336
- AI-Rank-log  1619144448.264029  eval_accuracy: 0.6861510276794434 , global_step: 5337
- AI-Rank-log  1619144492.9171784  eval_accuracy: 0.685581624507904 , global_step: 5338
- AI-Rank-log  1619144536.8150258  eval_accuracy: 0.6859659552574158 , global_step: 5339
- AI-Rank-log  1619144582.0045698  eval_accuracy: 0.6863970160484314 , global_step: 5340
- AI-Rank-log  1619144625.9490345  eval_accuracy: 0.6863858103752136 , global_step: 5341
- AI-Rank-log  1619144669.8286505  eval_accuracy: 0.68553626537323 , global_step: 5342
- AI-Rank-log  1619144713.7082934  eval_accuracy: 0.6864160299301147 , global_step: 5343
- AI-Rank-log  1619144757.9975123  eval_accuracy: 0.684947669506073 , global_step: 5344
- AI-Rank-log  1619144801.8456748  eval_accuracy: 0.6864146590232849 , global_step: 5345
- AI-Rank-log  1619144845.7922442  eval_accuracy: 0.685624361038208 , global_step: 5346
- AI-Rank-log  1619144889.6546686  eval_accuracy: 0.686377763748169 , global_step: 5347
- AI-Rank-log  1619144933.499147  eval_accuracy: 0.6863305568695068 , global_step: 5348
- AI-Rank-log  1619144977.446831  eval_accuracy: 0.686869740486145 , global_step: 5349
- AI-Rank-log  1619145021.3290768  eval_accuracy: 0.6872356534004211 , global_step: 5350
- AI-Rank-log  1619145065.1800294  eval_accuracy: 0.6864029765129089 , global_step: 5351
- AI-Rank-log  1619145109.1144075  eval_accuracy: 0.687176525592804 , global_step: 5352
- AI-Rank-log  1619145152.9464123  eval_accuracy: 0.6869385242462158 , global_step: 5353
- AI-Rank-log  1619145196.7854326  eval_accuracy: 0.6873190999031067 , global_step: 5354
- AI-Rank-log  1619145240.7769523  eval_accuracy: 0.6878542900085449 , global_step: 5355
- AI-Rank-log  1619145284.6748562  eval_accuracy: 0.6864566802978516 , global_step: 5356
- AI-Rank-log  1619145328.5552528  eval_accuracy: 0.688029408454895 , global_step: 5357
- AI-Rank-log  1619145372.5287108  eval_accuracy: 0.6867746710777283 , global_step: 5358
- AI-Rank-log  1619145416.3794124  eval_accuracy: 0.6877843737602234 , global_step: 5359
- AI-Rank-log  1619145460.3264384  eval_accuracy: 0.6870076060295105 , global_step: 5360
- AI-Rank-log  1619145504.2177582  eval_accuracy: 0.6872102618217468 , global_step: 5361
- AI-Rank-log  1619145548.0843384  eval_accuracy: 0.6881207227706909 , global_step: 5362
- AI-Rank-log  1619145592.0002298  eval_accuracy: 0.6864654421806335 , global_step: 5363
- AI-Rank-log  1619145635.9577515  eval_accuracy: 0.6874746680259705 , global_step: 5364
- AI-Rank-log  1619145679.7985125  eval_accuracy: 0.6860653758049011 , global_step: 5365
- AI-Rank-log  1619145723.7411423  eval_accuracy: 0.6869054436683655 , global_step: 5366
- AI-Rank-log  1619145767.5962632  eval_accuracy: 0.686631977558136 , global_step: 5367
- AI-Rank-log  1619145811.493103  eval_accuracy: 0.6877079606056213 , global_step: 5368
- AI-Rank-log  1619145855.358269  eval_accuracy: 0.68720942735672 , global_step: 5369
- AI-Rank-log  1619145899.2245235  eval_accuracy: 0.6867215037345886 , global_step: 5370
- AI-Rank-log  1619145943.1333678  eval_accuracy: 0.6872141361236572 , global_step: 5371
- AI-Rank-log  1619145986.9700189  eval_accuracy: 0.6878764033317566 , global_step: 5372
- AI-Rank-log  1619146030.8087678  eval_accuracy: 0.688027560710907 , global_step: 5373
- AI-Rank-log  1619146074.6905615  eval_accuracy: 0.6871402859687805 , global_step: 5374
- AI-Rank-log  1619146118.5282855  eval_accuracy: 0.6876885890960693 , global_step: 5375
- AI-Rank-log  1619146162.370736  eval_accuracy: 0.6877953410148621 , global_step: 5376
- AI-Rank-log  1619146206.2967784  eval_accuracy: 0.6872352957725525 , global_step: 5377
- AI-Rank-log  1619146250.165789  eval_accuracy: 0.6884608268737793 , global_step: 5378
- AI-Rank-log  1619146293.9790773  eval_accuracy: 0.6874616742134094 , global_step: 5379
- AI-Rank-log  1619146337.790309  eval_accuracy: 0.6874818801879883 , global_step: 5380
- AI-Rank-log  1619146381.6671295  eval_accuracy: 0.687382161617279 , global_step: 5381
- AI-Rank-log  1619146425.5012808  eval_accuracy: 0.6878787279129028 , global_step: 5382
- AI-Rank-log  1619146469.3205934  eval_accuracy: 0.6879604458808899 , global_step: 5383
- AI-Rank-log  1619146513.1652615  eval_accuracy: 0.6875608563423157 , global_step: 5384
- AI-Rank-log  1619146557.0647433  eval_accuracy: 0.6866565346717834 , global_step: 5385
- AI-Rank-log  1619146600.899858  eval_accuracy: 0.687583327293396 , global_step: 5386
- AI-Rank-log  1619146644.7701542  eval_accuracy: 0.6869872808456421 , global_step: 5387
- AI-Rank-log  1619146688.6311378  eval_accuracy: 0.6874250173568726 , global_step: 5388
- AI-Rank-log  1619146732.444269  eval_accuracy: 0.687418520450592 , global_step: 5389
- AI-Rank-log  1619146776.3627796  eval_accuracy: 0.6878183484077454 , global_step: 5390
- AI-Rank-log  1619146829.0728922  eval_accuracy: 0.6869449019432068 , global_step: 5391
- AI-Rank-log  1619146872.932519  eval_accuracy: 0.6873177886009216 , global_step: 5392
- AI-Rank-log  1619146916.8078141  eval_accuracy: 0.6866763234138489 , global_step: 5393
- AI-Rank-log  1619146960.6291118  eval_accuracy: 0.6883444786071777 , global_step: 5394
- AI-Rank-log  1619147004.478694  eval_accuracy: 0.6871647834777832 , global_step: 5395
- AI-Rank-log  1619147048.351571  eval_accuracy: 0.6879994869232178 , global_step: 5396
- AI-Rank-log  1619147093.2092638  eval_accuracy: 0.6864328980445862 , global_step: 5397
- AI-Rank-log  1619147137.0468376  eval_accuracy: 0.6867714524269104 , global_step: 5398
- AI-Rank-log  1619147181.0039043  eval_accuracy: 0.6860296726226807 , global_step: 5399
- AI-Rank-log  1619147224.8427022  eval_accuracy: 0.6871046423912048 , global_step: 5400
- AI-Rank-log  1619147268.7418537  eval_accuracy: 0.6868391633033752 , global_step: 5401
- AI-Rank-log  1619147312.5609925  eval_accuracy: 0.6870660781860352 , global_step: 5402
- AI-Rank-log  1619147357.6360676  eval_accuracy: 0.6867632269859314 , global_step: 5403
- AI-Rank-log  1619147401.5351188  eval_accuracy: 0.686979353427887 , global_step: 5404
- AI-Rank-log  1619147445.3616295  eval_accuracy: 0.6866638660430908 , global_step: 5405
- AI-Rank-log  1619147489.22575  eval_accuracy: 0.6862888336181641 , global_step: 5406
- AI-Rank-log  1619147533.7177784  eval_accuracy: 0.6877261996269226 , global_step: 5407
- AI-Rank-log  1619147578.022792  eval_accuracy: 0.6862327456474304 , global_step: 5408
- AI-Rank-log  1619147622.266191  eval_accuracy: 0.6866681575775146 , global_step: 5409
- AI-Rank-log  1619147666.298869  eval_accuracy: 0.6872014403343201 , global_step: 5410
- AI-Rank-log  1619147711.0368562  eval_accuracy: 0.6872431635856628 , global_step: 5411
- AI-Rank-log  1619147755.5165517  eval_accuracy: 0.6870402693748474 , global_step: 5412
- AI-Rank-log  1619147799.4193  eval_accuracy: 0.6870719790458679 , global_step: 5413
- AI-Rank-log  1619147843.397426  eval_accuracy: 0.6871132254600525 , global_step: 5414
- AI-Rank-log  1619147888.1427894  eval_accuracy: 0.6872075796127319 , global_step: 5415
- AI-Rank-log  1619147932.2984846  eval_accuracy: 0.6879108548164368 , global_step: 5416
- AI-Rank-log  1619147977.407184  eval_accuracy: 0.6864177584648132 , global_step: 5417
- AI-Rank-log  1619148021.277965  eval_accuracy: 0.6881793737411499 , global_step: 5418
- AI-Rank-log  1619148065.133279  eval_accuracy: 0.6874251961708069 , global_step: 5419
- AI-Rank-log  1619148108.9437127  eval_accuracy: 0.6890021562576294 , global_step: 5420
- AI-Rank-log  1619148152.9163706  eval_accuracy: 0.6873177886009216 , global_step: 5421
- AI-Rank-log  1619148197.2767978  eval_accuracy: 0.6885401010513306 , global_step: 5422
- AI-Rank-log  1619148241.1994774  eval_accuracy: 0.6882603168487549 , global_step: 5423
- AI-Rank-log  1619148285.1187255  eval_accuracy: 0.6875888705253601 , global_step: 5424
- AI-Rank-log  1619148328.9969418  eval_accuracy: 0.6877816319465637 , global_step: 5425
- AI-Rank-log  1619148372.9374897  eval_accuracy: 0.6877224445343018 , global_step: 5426
- AI-Rank-log  1619148416.8441007  eval_accuracy: 0.6881546378135681 , global_step: 5427
- AI-Rank-log  1619148460.7836752  eval_accuracy: 0.686555027961731 , global_step: 5428
- AI-Rank-log  1619148504.7844615  eval_accuracy: 0.6875653862953186 , global_step: 5429
- AI-Rank-log  1619148548.7175941  eval_accuracy: 0.6873803734779358 , global_step: 5430
- AI-Rank-log  1619148592.6740139  eval_accuracy: 0.6873151659965515 , global_step: 5431
- AI-Rank-log  1619148636.6739416  eval_accuracy: 0.6883125901222229 , global_step: 5432
- AI-Rank-log  1619148680.391354  eval_accuracy: 0.6879348754882812 , global_step: 5433
- AI-Rank-log  1619148724.391466  eval_accuracy: 0.6872693300247192 , global_step: 5434
- AI-Rank-log  1619148768.2841349  eval_accuracy: 0.687903881072998 , global_step: 5435
- AI-Rank-log  1619148812.216244  eval_accuracy: 0.6874207854270935 , global_step: 5436
- AI-Rank-log  1619148856.2015405  eval_accuracy: 0.6876299977302551 , global_step: 5437
- AI-Rank-log  1619148900.1006527  eval_accuracy: 0.6878404021263123 , global_step: 5438
- AI-Rank-log  1619148944.0876043  eval_accuracy: 0.6879477500915527 , global_step: 5439
- AI-Rank-log  1619148988.0424516  eval_accuracy: 0.6870588064193726 , global_step: 5440
- AI-Rank-log  1619149031.999864  eval_accuracy: 0.6873508095741272 , global_step: 5441
- AI-Rank-log  1619149075.9595118  eval_accuracy: 0.6871268153190613 , global_step: 5442
- AI-Rank-log  1619149119.9626122  eval_accuracy: 0.6878901124000549 , global_step: 5443
- AI-Rank-log  1619149163.9219751  eval_accuracy: 0.6869114637374878 , global_step: 5444
- AI-Rank-log  1619149208.001393  eval_accuracy: 0.688633143901825 , global_step: 5445
- AI-Rank-log  1619149251.9457345  eval_accuracy: 0.6865885853767395 , global_step: 5446
- AI-Rank-log  1619149295.9615855  eval_accuracy: 0.687770426273346 , global_step: 5447
- AI-Rank-log  1619149340.004095  eval_accuracy: 0.6869720220565796 , global_step: 5448
- AI-Rank-log  1619149383.9559171  eval_accuracy: 0.6874381303787231 , global_step: 5449
- AI-Rank-log  1619149427.9395761  eval_accuracy: 0.6869584918022156 , global_step: 5450
- AI-Rank-log  1619149471.986753  eval_accuracy: 0.687269389629364 , global_step: 5451
- AI-Rank-log  1619149515.9241345  eval_accuracy: 0.6876890063285828 , global_step: 5452
- AI-Rank-log  1619149559.9036498  eval_accuracy: 0.6870022416114807 , global_step: 5453
- AI-Rank-log  1619149604.0115254  eval_accuracy: 0.6879211068153381 , global_step: 5454
- AI-Rank-log  1619149647.957517  eval_accuracy: 0.6867984533309937 , global_step: 5455
- AI-Rank-log  1619149692.033585  eval_accuracy: 0.6878558993339539 , global_step: 5456
- AI-Rank-log  1619149735.9860475  eval_accuracy: 0.6872459650039673 , global_step: 5457
- AI-Rank-log  1619149779.932353  eval_accuracy: 0.6866651773452759 , global_step: 5458
- AI-Rank-log  1619149823.9990292  eval_accuracy: 0.6867420077323914 , global_step: 5459
- AI-Rank-log  1619149867.9276228  eval_accuracy: 0.6873112916946411 , global_step: 5460
- AI-Rank-log  1619149911.8992417  eval_accuracy: 0.6879100799560547 , global_step: 5461
- AI-Rank-log  1619149955.933283  eval_accuracy: 0.6877194046974182 , global_step: 5462
- AI-Rank-log  1619149999.8783634  eval_accuracy: 0.6878601908683777 , global_step: 5463
- AI-Rank-log  1619150043.793452  eval_accuracy: 0.687160313129425 , global_step: 5464
- AI-Rank-log  1619150087.8133256  eval_accuracy: 0.687591016292572 , global_step: 5465
- AI-Rank-log  1619150131.7364948  eval_accuracy: 0.6882330775260925 , global_step: 5466
- AI-Rank-log  1619150175.7411122  eval_accuracy: 0.6880167722702026 , global_step: 5467
- AI-Rank-log  1619150219.7048233  eval_accuracy: 0.6880438923835754 , global_step: 5468
- AI-Rank-log  1619150263.6304562  eval_accuracy: 0.6873466372489929 , global_step: 5469
- AI-Rank-log  1619150307.6563969  eval_accuracy: 0.6875970959663391 , global_step: 5470
- AI-Rank-log  1619150351.6062052  eval_accuracy: 0.6870646476745605 , global_step: 5471
- AI-Rank-log  1619150395.5462348  eval_accuracy: 0.6874815225601196 , global_step: 5472
- AI-Rank-log  1619150439.546122  eval_accuracy: 0.6864709258079529 , global_step: 5473
- AI-Rank-log  1619150483.5268736  eval_accuracy: 0.688048243522644 , global_step: 5474
- AI-Rank-log  1619150527.453588  eval_accuracy: 0.6872689127922058 , global_step: 5475
- AI-Rank-log  1619150571.4999306  eval_accuracy: 0.6883739233016968 , global_step: 5476
- AI-Rank-log  1619150615.4644055  eval_accuracy: 0.6872485280036926 , global_step: 5477
- AI-Rank-log  1619150659.4271982  eval_accuracy: 0.6876769065856934 , global_step: 5478
- AI-Rank-log  1619150703.4271133  eval_accuracy: 0.6870137453079224 , global_step: 5479
- AI-Rank-log  1619150747.4094052  eval_accuracy: 0.6871741414070129 , global_step: 5480
- AI-Rank-log  1619150792.3333554  eval_accuracy: 0.6870687007904053 , global_step: 5481
- AI-Rank-log  1619150836.2955403  eval_accuracy: 0.6875489950180054 , global_step: 5482
- AI-Rank-log  1619150880.3092113  eval_accuracy: 0.6871902346611023 , global_step: 5483
- AI-Rank-log  1619150924.9436214  eval_accuracy: 0.6878657341003418 , global_step: 5484
- AI-Rank-log  1619150969.369028  eval_accuracy: 0.6879136562347412 , global_step: 5485
- AI-Rank-log  1619151013.4286885  eval_accuracy: 0.6882330775260925 , global_step: 5486
- AI-Rank-log  1619151057.5266886  eval_accuracy: 0.6870242953300476 , global_step: 5487
- AI-Rank-log  1619151101.5917366  eval_accuracy: 0.6877357959747314 , global_step: 5488
- AI-Rank-log  1619151147.3192394  eval_accuracy: 0.6873325705528259 , global_step: 5489
- AI-Rank-log  1619151191.3856347  eval_accuracy: 0.6878678202629089 , global_step: 5490
- AI-Rank-log  1619151235.7489827  eval_accuracy: 0.6873549818992615 , global_step: 5491
- AI-Rank-log  1619151279.7407057  eval_accuracy: 0.688237190246582 , global_step: 5492
- AI-Rank-log  1619151324.5215042  eval_accuracy: 0.6873903870582581 , global_step: 5493
- AI-Rank-log  1619151368.5685258  eval_accuracy: 0.6877514123916626 , global_step: 5494
- AI-Rank-log  1619151413.7342403  eval_accuracy: 0.6874873638153076 , global_step: 5495
- AI-Rank-log  1619151457.9936228  eval_accuracy: 0.6874610781669617 , global_step: 5496
- AI-Rank-log  1619151501.9628122  eval_accuracy: 0.68692946434021 , global_step: 5497
- AI-Rank-log  1619151545.9932632  eval_accuracy: 0.6878625750541687 , global_step: 5498
- AI-Rank-log  1619151590.204856  eval_accuracy: 0.6875824332237244 , global_step: 5499
- AI-Rank-log  1619151634.2566884  eval_accuracy: 0.6875835657119751 , global_step: 5500
- AI-Rank-log  1619151678.193909  eval_accuracy: 0.6879555583000183 , global_step: 5501
- AI-Rank-log  1619151722.1228452  eval_accuracy: 0.6882863640785217 , global_step: 5502
- AI-Rank-log  1619151766.1509476  eval_accuracy: 0.6876393556594849 , global_step: 5503
- AI-Rank-log  1619151810.1180773  eval_accuracy: 0.6868932247161865 , global_step: 5504
- AI-Rank-log  1619151854.0613952  eval_accuracy: 0.6872929334640503 , global_step: 5505
- AI-Rank-log  1619151898.0553665  eval_accuracy: 0.6874580979347229 , global_step: 5506
- AI-Rank-log  1619151941.9873607  eval_accuracy: 0.6868199110031128 , global_step: 5507
- AI-Rank-log  1619151986.001243  eval_accuracy: 0.6875596642494202 , global_step: 5508
- AI-Rank-log  1619152029.9498124  eval_accuracy: 0.6870630979537964 , global_step: 5509
- AI-Rank-log  1619152073.8764157  eval_accuracy: 0.6874624490737915 , global_step: 5510
- AI-Rank-log  1619152117.9356554  eval_accuracy: 0.6877209544181824 , global_step: 5511
- AI-Rank-log  1619152161.8942451  eval_accuracy: 0.687503457069397 , global_step: 5512
- AI-Rank-log  1619152205.8148694  eval_accuracy: 0.6875572204589844 , global_step: 5513
- AI-Rank-log  1619152249.8413324  eval_accuracy: 0.6891152262687683 , global_step: 5514
- AI-Rank-log  1619152293.7840495  eval_accuracy: 0.6877503395080566 , global_step: 5515
- AI-Rank-log  1619152337.6961017  eval_accuracy: 0.6879661679267883 , global_step: 5516
- AI-Rank-log  1619152381.8060813  eval_accuracy: 0.6883266568183899 , global_step: 5517
- AI-Rank-log  1619152425.742422  eval_accuracy: 0.6877621412277222 , global_step: 5518
- AI-Rank-log  1619152469.7368875  eval_accuracy: 0.6883664727210999 , global_step: 5519
- AI-Rank-log  1619152513.692304  eval_accuracy: 0.6881890892982483 , global_step: 5520
- AI-Rank-log  1619152557.6426406  eval_accuracy: 0.688964307308197 , global_step: 5521
- AI-Rank-log  1619152601.6415198  eval_accuracy: 0.6883912682533264 , global_step: 5522
- AI-Rank-log  1619152645.6124163  eval_accuracy: 0.688955545425415 , global_step: 5523
- AI-Rank-log  1619152689.5389557  eval_accuracy: 0.6875318884849548 , global_step: 5524
- AI-Rank-log  1619152733.5093205  eval_accuracy: 0.6887717247009277 , global_step: 5525
- AI-Rank-log  1619152777.4429984  eval_accuracy: 0.6888087391853333 , global_step: 5526
- AI-Rank-log  1619152821.377949  eval_accuracy: 0.6883152723312378 , global_step: 5527
- AI-Rank-log  1619152865.4412625  eval_accuracy: 0.6889700889587402 , global_step: 5528
- AI-Rank-log  1619152909.3826942  eval_accuracy: 0.6885088682174683 , global_step: 5529
- AI-Rank-log  1619152953.4149165  eval_accuracy: 0.6888248324394226 , global_step: 5530
- AI-Rank-log  1619152997.313647  eval_accuracy: 0.6891379952430725 , global_step: 5531
- AI-Rank-log  1619153041.072285  eval_accuracy: 0.6891893148422241 , global_step: 5532
- AI-Rank-log  1619153085.0356898  eval_accuracy: 0.6886568069458008 , global_step: 5533
- AI-Rank-log  1619153128.9972706  eval_accuracy: 0.6892130374908447 , global_step: 5534
- AI-Rank-log  1619153172.935882  eval_accuracy: 0.6889954209327698 , global_step: 5535
- AI-Rank-log  1619153216.9559352  eval_accuracy: 0.6886602640151978 , global_step: 5536
- AI-Rank-log  1619153260.9038444  eval_accuracy: 0.6895880699157715 , global_step: 5537
- AI-Rank-log  1619153304.835804  eval_accuracy: 0.6885900497436523 , global_step: 5538
- AI-Rank-log  1619153348.8287592  eval_accuracy: 0.688620924949646 , global_step: 5539
- AI-Rank-log  1619153392.7823057  eval_accuracy: 0.6885460019111633 , global_step: 5540
- AI-Rank-log  1619153436.7918124  eval_accuracy: 0.6882838606834412 , global_step: 5541
- AI-Rank-log  1619153480.7378209  eval_accuracy: 0.6879777908325195 , global_step: 5542
- AI-Rank-log  1619153524.6725154  eval_accuracy: 0.6885154247283936 , global_step: 5543
- AI-Rank-log  1619153568.6710172  eval_accuracy: 0.6876609325408936 , global_step: 5544
- AI-Rank-log  1619153612.6322415  eval_accuracy: 0.6890918612480164 , global_step: 5545
- AI-Rank-log  1619153656.5562167  eval_accuracy: 0.6880892515182495 , global_step: 5546
- AI-Rank-log  1619153700.6151044  eval_accuracy: 0.6879549026489258 , global_step: 5547
- AI-Rank-log  1619153744.5839324  eval_accuracy: 0.6883214712142944 , global_step: 5548
- AI-Rank-log  1619153788.5875993  eval_accuracy: 0.6882423758506775 , global_step: 5549
- AI-Rank-log  1619153832.5328727  eval_accuracy: 0.687940239906311 , global_step: 5550
- AI-Rank-log  1619153876.5100126  eval_accuracy: 0.6885129809379578 , global_step: 5551
- AI-Rank-log  1619153920.4983568  eval_accuracy: 0.6876674890518188 , global_step: 5552
- AI-Rank-log  1619153964.4303052  eval_accuracy: 0.688422679901123 , global_step: 5553
- AI-Rank-log  1619154008.3802826  eval_accuracy: 0.6881294846534729 , global_step: 5554
- AI-Rank-log  1619154052.4574044  eval_accuracy: 0.6893872022628784 , global_step: 5555
- AI-Rank-log  1619154096.36649  eval_accuracy: 0.6884530782699585 , global_step: 5556
- AI-Rank-log  1619154140.3013175  eval_accuracy: 0.6885806322097778 , global_step: 5557
- AI-Rank-log  1619154185.1246378  eval_accuracy: 0.6884117722511292 , global_step: 5558
- AI-Rank-log  1619154229.1406965  eval_accuracy: 0.68904709815979 , global_step: 5559
- AI-Rank-log  1619154273.1290498  eval_accuracy: 0.6877707242965698 , global_step: 5560
- AI-Rank-log  1619154317.0394926  eval_accuracy: 0.688934862613678 , global_step: 5561
- AI-Rank-log  1619154361.2724078  eval_accuracy: 0.6880467534065247 , global_step: 5562
- AI-Rank-log  1619154405.9265165  eval_accuracy: 0.6891734004020691 , global_step: 5563
- AI-Rank-log  1619154450.1559944  eval_accuracy: 0.6877191066741943 , global_step: 5564
- AI-Rank-log  1619154494.0701602  eval_accuracy: 0.688982367515564 , global_step: 5565
- AI-Rank-log  1619154538.1400778  eval_accuracy: 0.6881168484687805 , global_step: 5566
- AI-Rank-log  1619154582.955938  eval_accuracy: 0.6890717148780823 , global_step: 5567
- AI-Rank-log  1619154627.3680246  eval_accuracy: 0.6883484125137329 , global_step: 5568
- AI-Rank-log  1619154671.3979611  eval_accuracy: 0.6890268325805664 , global_step: 5569
- AI-Rank-log  1619154716.175489  eval_accuracy: 0.6886979937553406 , global_step: 5570
- AI-Rank-log  1619154760.2176423  eval_accuracy: 0.6891621947288513 , global_step: 5571
- AI-Rank-log  1619154805.3916008  eval_accuracy: 0.6888264417648315 , global_step: 5572
- AI-Rank-log  1619154849.3712776  eval_accuracy: 0.688780665397644 , global_step: 5573
- AI-Rank-log  1619154893.414831  eval_accuracy: 0.6885911226272583 , global_step: 5574
- AI-Rank-log  1619154937.4184885  eval_accuracy: 0.688768744468689 , global_step: 5575
- AI-Rank-log  1619154981.3739688  eval_accuracy: 0.6887082457542419 , global_step: 5576
- AI-Rank-log  1619155025.6779792  eval_accuracy: 0.6876444220542908 , global_step: 5577
- AI-Rank-log  1619155069.6009493  eval_accuracy: 0.6890061497688293 , global_step: 5578
- AI-Rank-log  1619155113.652863  eval_accuracy: 0.6868159770965576 , global_step: 5579
- AI-Rank-log  1619155157.6255662  eval_accuracy: 0.6891300082206726 , global_step: 5580
- AI-Rank-log  1619155201.5401044  eval_accuracy: 0.6880981922149658 , global_step: 5581
- AI-Rank-log  1619155245.5634248  eval_accuracy: 0.6888582110404968 , global_step: 5582
- AI-Rank-log  1619155289.5240397  eval_accuracy: 0.6891103982925415 , global_step: 5583
- AI-Rank-log  1619155333.455638  eval_accuracy: 0.6886423230171204 , global_step: 5584
- AI-Rank-log  1619155377.4657142  eval_accuracy: 0.6887055039405823 , global_step: 5585
- AI-Rank-log  1619155421.4508657  eval_accuracy: 0.6883987188339233 , global_step: 5586
- AI-Rank-log  1619155465.4327497  eval_accuracy: 0.6890178322792053 , global_step: 5587
- AI-Rank-log  1619155509.4971602  eval_accuracy: 0.6879979372024536 , global_step: 5588
- AI-Rank-log  1619155553.4527402  eval_accuracy: 0.6884450912475586 , global_step: 5589
- AI-Rank-log  1619155597.417176  eval_accuracy: 0.6881940960884094 , global_step: 5590
- AI-Rank-log  1619155650.3571615  eval_accuracy: 0.688414454460144 , global_step: 5591
- AI-Rank-log  1619155694.2950542  eval_accuracy: 0.6888660788536072 , global_step: 5592
- AI-Rank-log  1619155738.408438  eval_accuracy: 0.6892269253730774 , global_step: 5593
- AI-Rank-log  1619155782.3334942  eval_accuracy: 0.6885945796966553 , global_step: 5594
- AI-Rank-log  1619155826.3354166  eval_accuracy: 0.6886572241783142 , global_step: 5595
- AI-Rank-log  1619155870.3517528  eval_accuracy: 0.6894983649253845 , global_step: 5596
- AI-Rank-log  1619155914.303208  eval_accuracy: 0.6887446641921997 , global_step: 5597
- AI-Rank-log  1619155958.3549743  eval_accuracy: 0.6886433959007263 , global_step: 5598
- AI-Rank-log  1619156002.310409  eval_accuracy: 0.6882596611976624 , global_step: 5599
- AI-Rank-log  1619156046.2416928  eval_accuracy: 0.688528835773468 , global_step: 5600
- AI-Rank-log  1619156090.2765276  eval_accuracy: 0.6886225938796997 , global_step: 5601
- AI-Rank-log  1619156134.2961347  eval_accuracy: 0.6887931823730469 , global_step: 5602
- AI-Rank-log  1619156178.2719834  eval_accuracy: 0.6892313361167908 , global_step: 5603
- AI-Rank-log  1619156222.3395078  eval_accuracy: 0.6883650422096252 , global_step: 5604
- AI-Rank-log  1619156266.285809  eval_accuracy: 0.689185380935669 , global_step: 5605
- AI-Rank-log  1619156310.2709284  eval_accuracy: 0.688938558101654 , global_step: 5606
- AI-Rank-log  1619156354.3080428  eval_accuracy: 0.68928462266922 , global_step: 5607
- AI-Rank-log  1619156398.281103  eval_accuracy: 0.689489483833313 , global_step: 5608
- AI-Rank-log  1619156442.2398195  eval_accuracy: 0.6889391541481018 , global_step: 5609
- AI-Rank-log  1619156486.252856  eval_accuracy: 0.6894435286521912 , global_step: 5610
- AI-Rank-log  1619156530.1993802  eval_accuracy: 0.6885356307029724 , global_step: 5611
- AI-Rank-log  1619156574.2219849  eval_accuracy: 0.6890062689781189 , global_step: 5612
- AI-Rank-log  1619156618.2227776  eval_accuracy: 0.6887190937995911 , global_step: 5613
- AI-Rank-log  1619156662.1659317  eval_accuracy: 0.689055323600769 , global_step: 5614
- AI-Rank-log  1619156706.1753871  eval_accuracy: 0.6895779371261597 , global_step: 5615
- AI-Rank-log  1619156750.157123  eval_accuracy: 0.6889371871948242 , global_step: 5616
- AI-Rank-log  1619156794.0833623  eval_accuracy: 0.6896928548812866 , global_step: 5617
- AI-Rank-log  1619156838.1092489  eval_accuracy: 0.6895312666893005 , global_step: 5618
- AI-Rank-log  1619156882.0477433  eval_accuracy: 0.6894975900650024 , global_step: 5619
- AI-Rank-log  1619156925.9319122  eval_accuracy: 0.6895753145217896 , global_step: 5620
- AI-Rank-log  1619156969.976274  eval_accuracy: 0.6899275779724121 , global_step: 5621
- AI-Rank-log  1619157013.9376338  eval_accuracy: 0.6884482502937317 , global_step: 5622
- AI-Rank-log  1619157057.930953  eval_accuracy: 0.6887346506118774 , global_step: 5623
- AI-Rank-log  1619157101.8726933  eval_accuracy: 0.6881110668182373 , global_step: 5624
- AI-Rank-log  1619157145.8606741  eval_accuracy: 0.6889625191688538 , global_step: 5625
- AI-Rank-log  1619157189.9129033  eval_accuracy: 0.6883372068405151 , global_step: 5626
- AI-Rank-log  1619157233.8800657  eval_accuracy: 0.6894016265869141 , global_step: 5627
- AI-Rank-log  1619157277.8626904  eval_accuracy: 0.6883875727653503 , global_step: 5628
- AI-Rank-log  1619157321.9068882  eval_accuracy: 0.6895854473114014 , global_step: 5629
- AI-Rank-log  1619157365.8731632  eval_accuracy: 0.6885116100311279 , global_step: 5630
- AI-Rank-log  1619157409.8741024  eval_accuracy: 0.6887710690498352 , global_step: 5631
- AI-Rank-log  1619157453.7972472  eval_accuracy: 0.6895540952682495 , global_step: 5632
- AI-Rank-log  1619157497.7548876  eval_accuracy: 0.6888430118560791 , global_step: 5633
- AI-Rank-log  1619157541.7757115  eval_accuracy: 0.6895100474357605 , global_step: 5634
- AI-Rank-log  1619157586.7159832  eval_accuracy: 0.6893883347511292 , global_step: 5635
- AI-Rank-log  1619157630.7265332  eval_accuracy: 0.6890886425971985 , global_step: 5636
- AI-Rank-log  1619157674.741205  eval_accuracy: 0.689302384853363 , global_step: 5637
- AI-Rank-log  1619157718.7012637  eval_accuracy: 0.6897114515304565 , global_step: 5638
- AI-Rank-log  1619157763.1298914  eval_accuracy: 0.6892879605293274 , global_step: 5639
- AI-Rank-log  1619157807.3991168  eval_accuracy: 0.688830554485321 , global_step: 5640
- AI-Rank-log  1619157851.3389196  eval_accuracy: 0.6895005702972412 , global_step: 5641
- AI-Rank-log  1619157895.5909774  eval_accuracy: 0.6887750029563904 , global_step: 5642
- AI-Rank-log  1619157939.557082  eval_accuracy: 0.6893193125724792 , global_step: 5643
- AI-Rank-log  1619157984.519661  eval_accuracy: 0.6885185241699219 , global_step: 5644
- AI-Rank-log  1619158029.0057948  eval_accuracy: 0.6896236538887024 , global_step: 5645
- AI-Rank-log  1619158072.9156399  eval_accuracy: 0.6881136298179626 , global_step: 5646
- AI-Rank-log  1619158116.8204951  eval_accuracy: 0.6898959875106812 , global_step: 5647
- AI-Rank-log  1619158161.313458  eval_accuracy: 0.688607394695282 , global_step: 5648
- AI-Rank-log  1619158205.219323  eval_accuracy: 0.6898136734962463 , global_step: 5649
- AI-Rank-log  1619158250.1666138  eval_accuracy: 0.6895663142204285 , global_step: 5650
- AI-Rank-log  1619158294.1648226  eval_accuracy: 0.6904946565628052 , global_step: 5651
- AI-Rank-log  1619158338.0947094  eval_accuracy: 0.6898841857910156 , global_step: 5652
- AI-Rank-log  1619158382.139328  eval_accuracy: 0.6896601319313049 , global_step: 5653
- AI-Rank-log  1619158426.3648252  eval_accuracy: 0.6899449229240417 , global_step: 5654
- AI-Rank-log  1619158470.2952578  eval_accuracy: 0.6896679401397705 , global_step: 5655
- AI-Rank-log  1619158514.3231134  eval_accuracy: 0.6894004940986633 , global_step: 5656
- AI-Rank-log  1619158558.2935324  eval_accuracy: 0.6904945373535156 , global_step: 5657
- AI-Rank-log  1619158602.182816  eval_accuracy: 0.6898883581161499 , global_step: 5658
- AI-Rank-log  1619158646.2580192  eval_accuracy: 0.6894877552986145 , global_step: 5659
- AI-Rank-log  1619158690.254491  eval_accuracy: 0.6900519728660583 , global_step: 5660
- AI-Rank-log  1619158733.9646485  eval_accuracy: 0.6894108653068542 , global_step: 5661
- AI-Rank-log  1619158777.9485223  eval_accuracy: 0.6889746189117432 , global_step: 5662
- AI-Rank-log  1619158821.879469  eval_accuracy: 0.6892675757408142 , global_step: 5663
- AI-Rank-log  1619158865.9057806  eval_accuracy: 0.6894680261611938 , global_step: 5664
- AI-Rank-log  1619158909.8204155  eval_accuracy: 0.6904057264328003 , global_step: 5665
- AI-Rank-log  1619158953.7384121  eval_accuracy: 0.6887212991714478 , global_step: 5666
- AI-Rank-log  1619158997.723342  eval_accuracy: 0.6901227235794067 , global_step: 5667
- AI-Rank-log  1619159041.7286634  eval_accuracy: 0.6883972883224487 , global_step: 5668
- AI-Rank-log  1619159085.6572838  eval_accuracy: 0.689307451248169 , global_step: 5669
- AI-Rank-log  1619159129.6966834  eval_accuracy: 0.6885966062545776 , global_step: 5670
- AI-Rank-log  1619159173.6911528  eval_accuracy: 0.6896355748176575 , global_step: 5671
- AI-Rank-log  1619159217.6745267  eval_accuracy: 0.689922034740448 , global_step: 5672
- AI-Rank-log  1619159261.5834863  eval_accuracy: 0.6892001628875732 , global_step: 5673
- AI-Rank-log  1619159305.5429218  eval_accuracy: 0.6894251704216003 , global_step: 5674
- AI-Rank-log  1619159349.494568  eval_accuracy: 0.6889626979827881 , global_step: 5675
- AI-Rank-log  1619159393.4321957  eval_accuracy: 0.6898230314254761 , global_step: 5676
- AI-Rank-log  1619159437.3534136  eval_accuracy: 0.6899532675743103 , global_step: 5677
- AI-Rank-log  1619159481.3770828  eval_accuracy: 0.6890936493873596 , global_step: 5678
- AI-Rank-log  1619159525.3552454  eval_accuracy: 0.6897310018539429 , global_step: 5679
- AI-Rank-log  1619159569.2856324  eval_accuracy: 0.6882625222206116 , global_step: 5680
- AI-Rank-log  1619159613.3243613  eval_accuracy: 0.6903610825538635 , global_step: 5681
- AI-Rank-log  1619159657.2987802  eval_accuracy: 0.6893442273139954 , global_step: 5682
- AI-Rank-log  1619159701.3421745  eval_accuracy: 0.6901105046272278 , global_step: 5683
- AI-Rank-log  1619159745.3255095  eval_accuracy: 0.6891624331474304 , global_step: 5684
- AI-Rank-log  1619159789.2724724  eval_accuracy: 0.6896283030509949 , global_step: 5685
- AI-Rank-log  1619159833.2796347  eval_accuracy: 0.6892349720001221 , global_step: 5686
- AI-Rank-log  1619159877.1816754  eval_accuracy: 0.6891041398048401 , global_step: 5687
- AI-Rank-log  1619159921.1317818  eval_accuracy: 0.6889868378639221 , global_step: 5688
- AI-Rank-log  1619159965.188145  eval_accuracy: 0.6880375742912292 , global_step: 5689
- AI-Rank-log  1619160009.1644888  eval_accuracy: 0.6895954608917236 , global_step: 5690
- AI-Rank-log  1619160053.0903206  eval_accuracy: 0.6882556080818176 , global_step: 5691
- AI-Rank-log  1619160097.1971228  eval_accuracy: 0.68953937292099 , global_step: 5692
- AI-Rank-log  1619160141.1435325  eval_accuracy: 0.6889970302581787 , global_step: 5693
- AI-Rank-log  1619160185.2818885  eval_accuracy: 0.6900534629821777 , global_step: 5694
- AI-Rank-log  1619160229.2094545  eval_accuracy: 0.6896675229072571 , global_step: 5695
- AI-Rank-log  1619160273.1010542  eval_accuracy: 0.69024258852005 , global_step: 5696
- AI-Rank-log  1619160317.118538  eval_accuracy: 0.6903172135353088 , global_step: 5697
- AI-Rank-log  1619160361.0220017  eval_accuracy: 0.6898241639137268 , global_step: 5698
- AI-Rank-log  1619160404.9227629  eval_accuracy: 0.690676748752594 , global_step: 5699
- AI-Rank-log  1619160448.9546783  eval_accuracy: 0.6905056834220886 , global_step: 5700
- AI-Rank-log  1619160492.8599644  eval_accuracy: 0.6901450753211975 , global_step: 5701
- AI-Rank-log  1619160536.807005  eval_accuracy: 0.6900789737701416 , global_step: 5702
- AI-Rank-log  1619160580.8516068  eval_accuracy: 0.6908029317855835 , global_step: 5703
- AI-Rank-log  1619160624.7824588  eval_accuracy: 0.6899169087409973 , global_step: 5704
- AI-Rank-log  1619160668.8061383  eval_accuracy: 0.690211296081543 , global_step: 5705
- AI-Rank-log  1619160712.7920613  eval_accuracy: 0.6902557611465454 , global_step: 5706
- AI-Rank-log  1619160756.7127438  eval_accuracy: 0.6901923418045044 , global_step: 5707
- AI-Rank-log  1619160800.726611  eval_accuracy: 0.689203679561615 , global_step: 5708
- AI-Rank-log  1619160844.6942894  eval_accuracy: 0.689541757106781 , global_step: 5709
- AI-Rank-log  1619160888.6365397  eval_accuracy: 0.6900332570075989 , global_step: 5710
- AI-Rank-log  1619160932.6994202  eval_accuracy: 0.6904423236846924 , global_step: 5711
- AI-Rank-log  1619160976.6380439  eval_accuracy: 0.6904318928718567 , global_step: 5712
- AI-Rank-log  1619161021.4352293  eval_accuracy: 0.6899155974388123 , global_step: 5713
- AI-Rank-log  1619161066.0334852  eval_accuracy: 0.6905275583267212 , global_step: 5714
- AI-Rank-log  1619161109.9713228  eval_accuracy: 0.6899062991142273 , global_step: 5715
- AI-Rank-log  1619161154.543141  eval_accuracy: 0.6905394196510315 , global_step: 5716
- AI-Rank-log  1619161198.88069  eval_accuracy: 0.6908200979232788 , global_step: 5717
- AI-Rank-log  1619161242.7960207  eval_accuracy: 0.6914307475090027 , global_step: 5718
- AI-Rank-log  1619161286.9912045  eval_accuracy: 0.6908082962036133 , global_step: 5719
- AI-Rank-log  1619161330.9504435  eval_accuracy: 0.6909315586090088 , global_step: 5720
- AI-Rank-log  1619161374.9584162  eval_accuracy: 0.6901016235351562 , global_step: 5721
- AI-Rank-log  1619161419.4325671  eval_accuracy: 0.6908581852912903 , global_step: 5722
- AI-Rank-log  1619161463.9482539  eval_accuracy: 0.6905297636985779 , global_step: 5723
- AI-Rank-log  1619161507.9969256  eval_accuracy: 0.6911497116088867 , global_step: 5724
- AI-Rank-log  1619161552.63769  eval_accuracy: 0.6901405453681946 , global_step: 5725
- AI-Rank-log  1619161596.9291825  eval_accuracy: 0.6905588507652283 , global_step: 5726
- AI-Rank-log  1619161642.1553783  eval_accuracy: 0.6901334524154663 , global_step: 5727
- AI-Rank-log  1619161686.1450055  eval_accuracy: 0.6908300518989563 , global_step: 5728
- AI-Rank-log  1619161730.095341  eval_accuracy: 0.6894121170043945 , global_step: 5729
- AI-Rank-log  1619161774.1162207  eval_accuracy: 0.691132128238678 , global_step: 5730
- AI-Rank-log  1619161818.065647  eval_accuracy: 0.6893110275268555 , global_step: 5731
- AI-Rank-log  1619161862.060438  eval_accuracy: 0.6896754503250122 , global_step: 5732
- AI-Rank-log  1619161906.085297  eval_accuracy: 0.6900290846824646 , global_step: 5733
- AI-Rank-log  1619161950.0471218  eval_accuracy: 0.6905940771102905 , global_step: 5734
- AI-Rank-log  1619161994.1056325  eval_accuracy: 0.6912005543708801 , global_step: 5735
- AI-Rank-log  1619162038.0359614  eval_accuracy: 0.68959641456604 , global_step: 5736
- AI-Rank-log  1619162082.0145679  eval_accuracy: 0.6902724504470825 , global_step: 5737
- AI-Rank-log  1619162126.041802  eval_accuracy: 0.6901693940162659 , global_step: 5738
- AI-Rank-log  1619162169.9839578  eval_accuracy: 0.6901106238365173 , global_step: 5739
- AI-Rank-log  1619162213.9920578  eval_accuracy: 0.689917266368866 , global_step: 5740
- AI-Rank-log  1619162258.0522451  eval_accuracy: 0.6903123259544373 , global_step: 5741
- AI-Rank-log  1619162301.967139  eval_accuracy: 0.6902129650115967 , global_step: 5742
- AI-Rank-log  1619162345.909133  eval_accuracy: 0.6901390552520752 , global_step: 5743
- AI-Rank-log  1619162389.9796247  eval_accuracy: 0.6901649832725525 , global_step: 5744
- AI-Rank-log  1619162433.9703357  eval_accuracy: 0.689507007598877 , global_step: 5745
- AI-Rank-log  1619162477.992857  eval_accuracy: 0.6900339722633362 , global_step: 5746
- AI-Rank-log  1619162521.9329393  eval_accuracy: 0.6893959045410156 , global_step: 5747
- AI-Rank-log  1619162565.8809862  eval_accuracy: 0.6904831528663635 , global_step: 5748
- AI-Rank-log  1619162609.9259145  eval_accuracy: 0.6901769042015076 , global_step: 5749
- AI-Rank-log  1619162653.863913  eval_accuracy: 0.6905232071876526 , global_step: 5750
- AI-Rank-log  1619162697.811927  eval_accuracy: 0.690118134021759 , global_step: 5751
- AI-Rank-log  1619162741.835466  eval_accuracy: 0.6905376315116882 , global_step: 5752
- AI-Rank-log  1619162785.747548  eval_accuracy: 0.6900293231010437 , global_step: 5753
- AI-Rank-log  1619162829.6882253  eval_accuracy: 0.6900865435600281 , global_step: 5754
- AI-Rank-log  1619162873.6882174  eval_accuracy: 0.6906540989875793 , global_step: 5755
- AI-Rank-log  1619162917.609788  eval_accuracy: 0.6901164054870605 , global_step: 5756
- AI-Rank-log  1619162961.6239743  eval_accuracy: 0.6905806660652161 , global_step: 5757
- AI-Rank-log  1619163005.5566185  eval_accuracy: 0.690257728099823 , global_step: 5758
- AI-Rank-log  1619163049.4729815  eval_accuracy: 0.6903904676437378 , global_step: 5759
- AI-Rank-log  1619163093.5057483  eval_accuracy: 0.6892246007919312 , global_step: 5760
- AI-Rank-log  1619163137.4738615  eval_accuracy: 0.6903305649757385 , global_step: 5761
- AI-Rank-log  1619163181.4004908  eval_accuracy: 0.6898233294487 , global_step: 5762
- AI-Rank-log  1619163225.4422119  eval_accuracy: 0.6900231242179871 , global_step: 5763
- AI-Rank-log  1619163269.398287  eval_accuracy: 0.6901928186416626 , global_step: 5764
- AI-Rank-log  1619163313.3827753  eval_accuracy: 0.690529465675354 , global_step: 5765
- AI-Rank-log  1619163357.3953438  eval_accuracy: 0.6899623274803162 , global_step: 5766
- AI-Rank-log  1619163401.4361272  eval_accuracy: 0.690157949924469 , global_step: 5767
- AI-Rank-log  1619163445.4201448  eval_accuracy: 0.6905342936515808 , global_step: 5768
- AI-Rank-log  1619163489.3894722  eval_accuracy: 0.6904312968254089 , global_step: 5769
- AI-Rank-log  1619163533.332045  eval_accuracy: 0.6900687217712402 , global_step: 5770
- AI-Rank-log  1619163577.3323774  eval_accuracy: 0.6904042959213257 , global_step: 5771
- AI-Rank-log  1619163621.2807045  eval_accuracy: 0.6905842423439026 , global_step: 5772
- AI-Rank-log  1619163665.216964  eval_accuracy: 0.6900326013565063 , global_step: 5773
- AI-Rank-log  1619163709.3155525  eval_accuracy: 0.6895500421524048 , global_step: 5774
- AI-Rank-log  1619163753.2623649  eval_accuracy: 0.6904758214950562 , global_step: 5775
- AI-Rank-log  1619163797.3127558  eval_accuracy: 0.6898050904273987 , global_step: 5776
- AI-Rank-log  1619163841.2703683  eval_accuracy: 0.6901446580886841 , global_step: 5777
- AI-Rank-log  1619163885.2578459  eval_accuracy: 0.6903621554374695 , global_step: 5778
- AI-Rank-log  1619163929.2207003  eval_accuracy: 0.6899905204772949 , global_step: 5779
- AI-Rank-log  1619163973.2040443  eval_accuracy: 0.6906867027282715 , global_step: 5780
- AI-Rank-log  1619164017.172974  eval_accuracy: 0.6896247267723083 , global_step: 5781
- AI-Rank-log  1619164061.1882713  eval_accuracy: 0.690633237361908 , global_step: 5782
- AI-Rank-log  1619164105.1486075  eval_accuracy: 0.6900902390480042 , global_step: 5783
- AI-Rank-log  1619164149.0773752  eval_accuracy: 0.6905503869056702 , global_step: 5784
- AI-Rank-log  1619164193.2095995  eval_accuracy: 0.6895670294761658 , global_step: 5785
- AI-Rank-log  1619164237.1946335  eval_accuracy: 0.6906746029853821 , global_step: 5786
- AI-Rank-log  1619164281.1590064  eval_accuracy: 0.6905255913734436 , global_step: 5787
- AI-Rank-log  1619164325.1241329  eval_accuracy: 0.690566897392273 , global_step: 5788
- AI-Rank-log  1619164369.1200027  eval_accuracy: 0.690420925617218 , global_step: 5789
- AI-Rank-log  1619164414.1603143  eval_accuracy: 0.6902363300323486 , global_step: 5790
- AI-Rank-log  1619164467.0653005  eval_accuracy: 0.6907228231430054 , global_step: 5791
- AI-Rank-log  1619164511.0010579  eval_accuracy: 0.6905337572097778 , global_step: 5792
- AI-Rank-log  1619164555.331374  eval_accuracy: 0.6906022429466248 , global_step: 5793
- AI-Rank-log  1619164600.095002  eval_accuracy: 0.690570056438446 , global_step: 5794
- AI-Rank-log  1619164644.768804  eval_accuracy: 0.6903414130210876 , global_step: 5795
- AI-Rank-log  1619164689.1342893  eval_accuracy: 0.6902984976768494 , global_step: 5796
- AI-Rank-log  1619164733.0569093  eval_accuracy: 0.6905470490455627 , global_step: 5797
- AI-Rank-log  1619164777.0439231  eval_accuracy: 0.6901013255119324 , global_step: 5798
- AI-Rank-log  1619164821.7978117  eval_accuracy: 0.6907331347465515 , global_step: 5799
- AI-Rank-log  1619164865.7773807  eval_accuracy: 0.6898131370544434 , global_step: 5800
- AI-Rank-log  1619164910.1773255  eval_accuracy: 0.6908183693885803 , global_step: 5801
- AI-Rank-log  1619164954.994056  eval_accuracy: 0.6897300481796265 , global_step: 5802
- AI-Rank-log  1619164998.8714502  eval_accuracy: 0.6906234622001648 , global_step: 5803
- AI-Rank-log  1619165042.945222  eval_accuracy: 0.689881443977356 , global_step: 5804
- AI-Rank-log  1619165088.1032522  eval_accuracy: 0.6905678510665894 , global_step: 5805
- AI-Rank-log  1619165132.061395  eval_accuracy: 0.6907181143760681 , global_step: 5806
- AI-Rank-log  1619165176.1301525  eval_accuracy: 0.6906329393386841 , global_step: 5807
- AI-Rank-log  1619165220.0786548  eval_accuracy: 0.6908143162727356 , global_step: 5808
- AI-Rank-log  1619165264.2804122  eval_accuracy: 0.6910535097122192 , global_step: 5809
- AI-Rank-log  1619165308.3136654  eval_accuracy: 0.690680980682373 , global_step: 5810
- AI-Rank-log  1619165352.2653775  eval_accuracy: 0.6911095380783081 , global_step: 5811
- AI-Rank-log  1619165396.2447448  eval_accuracy: 0.6909187436103821 , global_step: 5812
- AI-Rank-log  1619165440.4421434  eval_accuracy: 0.6914861798286438 , global_step: 5813
- AI-Rank-log  1619165484.4035344  eval_accuracy: 0.6909825205802917 , global_step: 5814
- AI-Rank-log  1619165528.4279737  eval_accuracy: 0.6911671161651611 , global_step: 5815
- AI-Rank-log  1619165572.3609629  eval_accuracy: 0.6910488605499268 , global_step: 5816
- AI-Rank-log  1619165616.2878015  eval_accuracy: 0.69061678647995 , global_step: 5817
- AI-Rank-log  1619165660.310094  eval_accuracy: 0.6911436915397644 , global_step: 5818
- AI-Rank-log  1619165704.2484853  eval_accuracy: 0.6911388039588928 , global_step: 5819
- AI-Rank-log  1619165748.2480288  eval_accuracy: 0.6917645335197449 , global_step: 5820
- AI-Rank-log  1619165792.1654885  eval_accuracy: 0.6912489533424377 , global_step: 5821
- AI-Rank-log  1619165836.1548612  eval_accuracy: 0.6910732984542847 , global_step: 5822
- AI-Rank-log  1619165880.1150823  eval_accuracy: 0.6903294920921326 , global_step: 5823
- AI-Rank-log  1619165924.0980167  eval_accuracy: 0.6902751326560974 , global_step: 5824
- AI-Rank-log  1619165968.0332954  eval_accuracy: 0.6899617910385132 , global_step: 5825
- AI-Rank-log  1619166012.0180259  eval_accuracy: 0.6907505989074707 , global_step: 5826
- AI-Rank-log  1619166055.9446626  eval_accuracy: 0.6908339858055115 , global_step: 5827
- AI-Rank-log  1619166099.9037256  eval_accuracy: 0.6904664039611816 , global_step: 5828
- AI-Rank-log  1619166143.8602607  eval_accuracy: 0.6907597184181213 , global_step: 5829
- AI-Rank-log  1619166187.7993743  eval_accuracy: 0.690141499042511 , global_step: 5830
- AI-Rank-log  1619166231.78928  eval_accuracy: 0.6897750496864319 , global_step: 5831
- AI-Rank-log  1619166275.7007997  eval_accuracy: 0.6907310485839844 , global_step: 5832
- AI-Rank-log  1619166319.6465077  eval_accuracy: 0.6905198693275452 , global_step: 5833
- AI-Rank-log  1619166363.7503643  eval_accuracy: 0.6910160183906555 , global_step: 5834
- AI-Rank-log  1619166407.6188076  eval_accuracy: 0.6900245547294617 , global_step: 5835
- AI-Rank-log  1619166451.5339909  eval_accuracy: 0.6912896037101746 , global_step: 5836
- AI-Rank-log  1619166495.5350814  eval_accuracy: 0.6905375123023987 , global_step: 5837
- AI-Rank-log  1619166539.4590611  eval_accuracy: 0.6912906169891357 , global_step: 5838
- AI-Rank-log  1619166583.4473364  eval_accuracy: 0.6909809112548828 , global_step: 5839
- AI-Rank-log  1619166627.470556  eval_accuracy: 0.6914349794387817 , global_step: 5840
- AI-Rank-log  1619166671.400147  eval_accuracy: 0.6912255883216858 , global_step: 5841
- AI-Rank-log  1619166715.4673085  eval_accuracy: 0.6908427476882935 , global_step: 5842
- AI-Rank-log  1619166759.415866  eval_accuracy: 0.6914523839950562 , global_step: 5843
- AI-Rank-log  1619166803.3929248  eval_accuracy: 0.6916071176528931 , global_step: 5844
- AI-Rank-log  1619166847.4516  eval_accuracy: 0.6904297471046448 , global_step: 5845
- AI-Rank-log  1619166891.3534224  eval_accuracy: 0.6917510628700256 , global_step: 5846
- AI-Rank-log  1619166935.2761943  eval_accuracy: 0.6904505491256714 , global_step: 5847
- AI-Rank-log  1619166979.2794304  eval_accuracy: 0.6912729144096375 , global_step: 5848
- AI-Rank-log  1619167023.1764705  eval_accuracy: 0.6905149221420288 , global_step: 5849
- AI-Rank-log  1619167067.0733936  eval_accuracy: 0.6915907263755798 , global_step: 5850
- AI-Rank-log  1619167111.10098  eval_accuracy: 0.6905475854873657 , global_step: 5851
- AI-Rank-log  1619167155.0041866  eval_accuracy: 0.690788209438324 , global_step: 5852
- AI-Rank-log  1619167199.044095  eval_accuracy: 0.6907597184181213 , global_step: 5853
- AI-Rank-log  1619167243.0080116  eval_accuracy: 0.690126359462738 , global_step: 5854
- AI-Rank-log  1619167286.6963701  eval_accuracy: 0.6912785768508911 , global_step: 5855
- AI-Rank-log  1619167330.7191663  eval_accuracy: 0.6900480389595032 , global_step: 5856
- AI-Rank-log  1619167374.6390922  eval_accuracy: 0.6908866167068481 , global_step: 5857
- AI-Rank-log  1619167418.5436432  eval_accuracy: 0.6910995244979858 , global_step: 5858
- AI-Rank-log  1619167462.5708988  eval_accuracy: 0.6912263035774231 , global_step: 5859
- AI-Rank-log  1619167506.5248995  eval_accuracy: 0.6911135315895081 , global_step: 5860
- AI-Rank-log  1619167550.4372387  eval_accuracy: 0.6906327605247498 , global_step: 5861
- AI-Rank-log  1619167594.4521239  eval_accuracy: 0.6911661624908447 , global_step: 5862
- AI-Rank-log  1619167638.388529  eval_accuracy: 0.6900470852851868 , global_step: 5863
- AI-Rank-log  1619167682.4446568  eval_accuracy: 0.6905454397201538 , global_step: 5864
- AI-Rank-log  1619167726.399073  eval_accuracy: 0.6901237368583679 , global_step: 5865
- AI-Rank-log  1619167770.3211827  eval_accuracy: 0.6904745697975159 , global_step: 5866
- AI-Rank-log  1619167815.1611114  eval_accuracy: 0.6899170875549316 , global_step: 5867
- AI-Rank-log  1619167859.315507  eval_accuracy: 0.689785361289978 , global_step: 5868
- AI-Rank-log  1619167903.205953  eval_accuracy: 0.6907753348350525 , global_step: 5869
- AI-Rank-log  1619167947.7274969  eval_accuracy: 0.6906057596206665 , global_step: 5870
- AI-Rank-log  1619167991.6755586  eval_accuracy: 0.6915048956871033 , global_step: 5871
- AI-Rank-log  1619168036.2106202  eval_accuracy: 0.6909133791923523 , global_step: 5872
- AI-Rank-log  1619168080.247999  eval_accuracy: 0.6905626654624939 , global_step: 5873
- AI-Rank-log  1619168124.599227  eval_accuracy: 0.690717339515686 , global_step: 5874
- AI-Rank-log  1619168169.6685698  eval_accuracy: 0.6912859678268433 , global_step: 5875
- AI-Rank-log  1619168214.6372666  eval_accuracy: 0.6910842061042786 , global_step: 5876
- AI-Rank-log  1619168258.6389585  eval_accuracy: 0.6911410093307495 , global_step: 5877
- AI-Rank-log  1619168302.85885  eval_accuracy: 0.6914213299751282 , global_step: 5878
- AI-Rank-log  1619168346.8552814  eval_accuracy: 0.6908420324325562 , global_step: 5879
- AI-Rank-log  1619168391.473254  eval_accuracy: 0.6913177967071533 , global_step: 5880
- AI-Rank-log  1619168435.5599403  eval_accuracy: 0.6913537979125977 , global_step: 5881
- AI-Rank-log  1619168479.7482367  eval_accuracy: 0.6916849613189697 , global_step: 5882
- AI-Rank-log  1619168524.4887102  eval_accuracy: 0.6907740831375122 , global_step: 5883
- AI-Rank-log  1619168568.494966  eval_accuracy: 0.6918190121650696 , global_step: 5884
- AI-Rank-log  1619168612.7311692  eval_accuracy: 0.6915678381919861 , global_step: 5885
- AI-Rank-log  1619168656.7945051  eval_accuracy: 0.691946268081665 , global_step: 5886
- AI-Rank-log  1619168701.1778638  eval_accuracy: 0.6914942264556885 , global_step: 5887
- AI-Rank-log  1619168745.1975327  eval_accuracy: 0.6917949318885803 , global_step: 5888
- AI-Rank-log  1619168789.3226824  eval_accuracy: 0.6915655136108398 , global_step: 5889
- AI-Rank-log  1619168833.2651381  eval_accuracy: 0.6913357973098755 , global_step: 5890
- AI-Rank-log  1619168877.2665875  eval_accuracy: 0.6905953288078308 , global_step: 5891
- AI-Rank-log  1619168921.3386724  eval_accuracy: 0.6920201182365417 , global_step: 5892
- AI-Rank-log  1619168965.276282  eval_accuracy: 0.6908155679702759 , global_step: 5893
- AI-Rank-log  1619169009.200005  eval_accuracy: 0.6923696994781494 , global_step: 5894
- AI-Rank-log  1619169053.265693  eval_accuracy: 0.6909887790679932 , global_step: 5895
- AI-Rank-log  1619169097.2033114  eval_accuracy: 0.6919012069702148 , global_step: 5896
- AI-Rank-log  1619169141.261393  eval_accuracy: 0.6917335391044617 , global_step: 5897
- AI-Rank-log  1619169185.2431223  eval_accuracy: 0.6918938159942627 , global_step: 5898
- AI-Rank-log  1619169229.2179937  eval_accuracy: 0.6921971440315247 , global_step: 5899
- AI-Rank-log  1619169273.251121  eval_accuracy: 0.6921895146369934 , global_step: 5900
- AI-Rank-log  1619169317.1809895  eval_accuracy: 0.6915371417999268 , global_step: 5901
- AI-Rank-log  1619169361.1174955  eval_accuracy: 0.6913843750953674 , global_step: 5902
- AI-Rank-log  1619169405.1802135  eval_accuracy: 0.6913166046142578 , global_step: 5903
- AI-Rank-log  1619169449.1680655  eval_accuracy: 0.6907118558883667 , global_step: 5904
- AI-Rank-log  1619169493.1605442  eval_accuracy: 0.6922608017921448 , global_step: 5905
- AI-Rank-log  1619169537.2221315  eval_accuracy: 0.6911464929580688 , global_step: 5906
- AI-Rank-log  1619169581.1644175  eval_accuracy: 0.6917926669120789 , global_step: 5907
- AI-Rank-log  1619169625.241974  eval_accuracy: 0.6916372776031494 , global_step: 5908
- AI-Rank-log  1619169669.190992  eval_accuracy: 0.69231778383255 , global_step: 5909
- AI-Rank-log  1619169713.1513524  eval_accuracy: 0.6925216317176819 , global_step: 5910
- AI-Rank-log  1619169757.1922925  eval_accuracy: 0.6917805671691895 , global_step: 5911
- AI-Rank-log  1619169801.1592522  eval_accuracy: 0.6913743019104004 , global_step: 5912
- AI-Rank-log  1619169845.143871  eval_accuracy: 0.6924536824226379 , global_step: 5913
- AI-Rank-log  1619169889.1794221  eval_accuracy: 0.6912806630134583 , global_step: 5914
- AI-Rank-log  1619169933.2301707  eval_accuracy: 0.6925604939460754 , global_step: 5915
- AI-Rank-log  1619169977.162625  eval_accuracy: 0.6917860507965088 , global_step: 5916
- AI-Rank-log  1619170021.203049  eval_accuracy: 0.6920201182365417 , global_step: 5917
- AI-Rank-log  1619170065.1739082  eval_accuracy: 0.6906626224517822 , global_step: 5918
- AI-Rank-log  1619170109.262028  eval_accuracy: 0.691268801689148 , global_step: 5919
- AI-Rank-log  1619170153.1952207  eval_accuracy: 0.6918621063232422 , global_step: 5920
- AI-Rank-log  1619170197.1418757  eval_accuracy: 0.6912463903427124 , global_step: 5921
- AI-Rank-log  1619170241.1928515  eval_accuracy: 0.6915968656539917 , global_step: 5922
- AI-Rank-log  1619170285.156858  eval_accuracy: 0.6911131143569946 , global_step: 5923
- AI-Rank-log  1619170329.0685833  eval_accuracy: 0.6915987133979797 , global_step: 5924
- AI-Rank-log  1619170373.0514383  eval_accuracy: 0.6916674971580505 , global_step: 5925
- AI-Rank-log  1619170417.0213702  eval_accuracy: 0.6910001039505005 , global_step: 5926
- AI-Rank-log  1619170461.000545  eval_accuracy: 0.6912051439285278 , global_step: 5927
- AI-Rank-log  1619170505.0381887  eval_accuracy: 0.6911106109619141 , global_step: 5928
- AI-Rank-log  1619170549.0361562  eval_accuracy: 0.6914231181144714 , global_step: 5929
- AI-Rank-log  1619170593.0663252  eval_accuracy: 0.6914039254188538 , global_step: 5930
- AI-Rank-log  1619170637.047171  eval_accuracy: 0.6917097568511963 , global_step: 5931
- AI-Rank-log  1619170681.0161996  eval_accuracy: 0.6914067268371582 , global_step: 5932
- AI-Rank-log  1619170725.0122933  eval_accuracy: 0.6919379234313965 , global_step: 5933
- AI-Rank-log  1619170768.9651136  eval_accuracy: 0.6916283369064331 , global_step: 5934
- AI-Rank-log  1619170812.9382586  eval_accuracy: 0.6915527582168579 , global_step: 5935
- AI-Rank-log  1619170856.9264205  eval_accuracy: 0.691787838935852 , global_step: 5936
- AI-Rank-log  1619170900.9122832  eval_accuracy: 0.6911714673042297 , global_step: 5937
- AI-Rank-log  1619170944.9387374  eval_accuracy: 0.6914564371109009 , global_step: 5938
- AI-Rank-log  1619170988.911199  eval_accuracy: 0.6905198693275452 , global_step: 5939
- AI-Rank-log  1619171032.8914661  eval_accuracy: 0.6914479732513428 , global_step: 5940
- AI-Rank-log  1619171076.9233751  eval_accuracy: 0.6906163096427917 , global_step: 5941
- AI-Rank-log  1619171120.8820539  eval_accuracy: 0.6909186840057373 , global_step: 5942
- AI-Rank-log  1619171164.8847015  eval_accuracy: 0.6906803250312805 , global_step: 5943
- AI-Rank-log  1619171209.7745628  eval_accuracy: 0.6910682916641235 , global_step: 5944
- AI-Rank-log  1619171254.5377247  eval_accuracy: 0.6903877258300781 , global_step: 5945
- AI-Rank-log  1619171298.5133786  eval_accuracy: 0.6910073757171631 , global_step: 5946
- AI-Rank-log  1619171342.586352  eval_accuracy: 0.6906207799911499 , global_step: 5947
- AI-Rank-log  1619171387.2062614  eval_accuracy: 0.6916889548301697 , global_step: 5948
- AI-Rank-log  1619171432.469359  eval_accuracy: 0.6908501982688904 , global_step: 5949
- AI-Rank-log  1619171476.4923198  eval_accuracy: 0.6914291381835938 , global_step: 5950
- AI-Rank-log  1619171520.740651  eval_accuracy: 0.691424548625946 , global_step: 5951
- AI-Rank-log  1619171564.8334305  eval_accuracy: 0.6913885474205017 , global_step: 5952
- AI-Rank-log  1619171609.6065528  eval_accuracy: 0.6914034485816956 , global_step: 5953
- AI-Rank-log  1619171653.5992754  eval_accuracy: 0.6910433173179626 , global_step: 5954
- AI-Rank-log  1619171697.6462905  eval_accuracy: 0.6912670731544495 , global_step: 5955
- AI-Rank-log  1619171741.8894951  eval_accuracy: 0.691795289516449 , global_step: 5956
- AI-Rank-log  1619171785.825203  eval_accuracy: 0.6926258206367493 , global_step: 5957
- AI-Rank-log  1619171830.4931397  eval_accuracy: 0.690935492515564 , global_step: 5958
- AI-Rank-log  1619171874.4837883  eval_accuracy: 0.6918366551399231 , global_step: 5959
- AI-Rank-log  1619171919.677794  eval_accuracy: 0.6904522180557251 , global_step: 5960
- AI-Rank-log  1619171963.6132934  eval_accuracy: 0.6922813653945923 , global_step: 5961
- AI-Rank-log  1619172007.5239837  eval_accuracy: 0.6917312741279602 , global_step: 5962
- AI-Rank-log  1619172051.5413764  eval_accuracy: 0.6918919086456299 , global_step: 5963
- AI-Rank-log  1619172095.4868336  eval_accuracy: 0.6921796202659607 , global_step: 5964
- AI-Rank-log  1619172139.4290578  eval_accuracy: 0.6912459135055542 , global_step: 5965
- AI-Rank-log  1619172183.4338715  eval_accuracy: 0.6918870806694031 , global_step: 5966
- AI-Rank-log  1619172227.3688161  eval_accuracy: 0.6913048624992371 , global_step: 5967
- AI-Rank-log  1619172271.3673024  eval_accuracy: 0.692230224609375 , global_step: 5968
- AI-Rank-log  1619172315.3309865  eval_accuracy: 0.6916722655296326 , global_step: 5969
- AI-Rank-log  1619172359.3018816  eval_accuracy: 0.6918792724609375 , global_step: 5970
- AI-Rank-log  1619172403.3032799  eval_accuracy: 0.6922372579574585 , global_step: 5971
- AI-Rank-log  1619172447.2791324  eval_accuracy: 0.692318320274353 , global_step: 5972
- AI-Rank-log  1619172491.239156  eval_accuracy: 0.6926501989364624 , global_step: 5973
- AI-Rank-log  1619172535.264955  eval_accuracy: 0.6923295259475708 , global_step: 5974
- AI-Rank-log  1619172579.278633  eval_accuracy: 0.6925438046455383 , global_step: 5975
- AI-Rank-log  1619172623.2449114  eval_accuracy: 0.6915639042854309 , global_step: 5976
- AI-Rank-log  1619172667.2140312  eval_accuracy: 0.6914457082748413 , global_step: 5977
- AI-Rank-log  1619172711.1277204  eval_accuracy: 0.6915895938873291 , global_step: 5978
- AI-Rank-log  1619172755.1126564  eval_accuracy: 0.6912762522697449 , global_step: 5979
- AI-Rank-log  1619172799.0174384  eval_accuracy: 0.6922205090522766 , global_step: 5980
- AI-Rank-log  1619172843.0046296  eval_accuracy: 0.6916635036468506 , global_step: 5981
- AI-Rank-log  1619172887.039248  eval_accuracy: 0.6921759843826294 , global_step: 5982
- AI-Rank-log  1619172930.994553  eval_accuracy: 0.6928845643997192 , global_step: 5983
- AI-Rank-log  1619172974.9651911  eval_accuracy: 0.6923204660415649 , global_step: 5984
- AI-Rank-log  1619173018.9364467  eval_accuracy: 0.6928495764732361 , global_step: 5985
- AI-Rank-log  1619173062.8947566  eval_accuracy: 0.6920514106750488 , global_step: 5986
- AI-Rank-log  1619173106.9078808  eval_accuracy: 0.6924306154251099 , global_step: 5987
- AI-Rank-log  1619173150.8409827  eval_accuracy: 0.6919304132461548 , global_step: 5988
- AI-Rank-log  1619173194.7667656  eval_accuracy: 0.6923183798789978 , global_step: 5989
- AI-Rank-log  1619173238.8070915  eval_accuracy: 0.6924089789390564 , global_step: 5990
- AI-Rank-log  1619173291.6643991  eval_accuracy: 0.692358136177063 , global_step: 5991
- AI-Rank-log  1619173335.5844388  eval_accuracy: 0.692852795124054 , global_step: 5992
- AI-Rank-log  1619173379.6375334  eval_accuracy: 0.6929255723953247 , global_step: 5993
- AI-Rank-log  1619173423.6142197  eval_accuracy: 0.6924183368682861 , global_step: 5994
- AI-Rank-log  1619173467.5539792  eval_accuracy: 0.692828357219696 , global_step: 5995
- AI-Rank-log  1619173511.5697572  eval_accuracy: 0.6920838356018066 , global_step: 5996
- AI-Rank-log  1619173555.525965  eval_accuracy: 0.6922096014022827 , global_step: 5997
- AI-Rank-log  1619173599.5523129  eval_accuracy: 0.6919753551483154 , global_step: 5998
- AI-Rank-log  1619173643.4972978  eval_accuracy: 0.6927779912948608 , global_step: 5999
- AI-Rank-log  1619173687.454275  eval_accuracy: 0.6923115849494934 , global_step: 6000
- AI-Rank-log  1619173731.4861188  eval_accuracy: 0.6921236515045166 , global_step: 6001
- AI-Rank-log  1619173775.4361794  eval_accuracy: 0.6925151348114014 , global_step: 6002
- AI-Rank-log  1619173819.347425  eval_accuracy: 0.6927153468132019 , global_step: 6003
- AI-Rank-log  1619173863.3583236  eval_accuracy: 0.6924888491630554 , global_step: 6004
- AI-Rank-log  1619173907.3277051  eval_accuracy: 0.6929362416267395 , global_step: 6005
- AI-Rank-log  1619173951.3079789  eval_accuracy: 0.6913231015205383 , global_step: 6006
- AI-Rank-log  1619173995.2674582  eval_accuracy: 0.6929203867912292 , global_step: 6007
- AI-Rank-log  1619174039.2639256  eval_accuracy: 0.6926888823509216 , global_step: 6008
- AI-Rank-log  1619174083.2063205  eval_accuracy: 0.692280113697052 , global_step: 6009
- AI-Rank-log  1619174127.1931756  eval_accuracy: 0.6922929286956787 , global_step: 6010
- AI-Rank-log  1619174171.1392612  eval_accuracy: 0.6922739148139954 , global_step: 6011
- AI-Rank-log  1619174215.1381545  eval_accuracy: 0.6922368407249451 , global_step: 6012
- AI-Rank-log  1619174259.0337913  eval_accuracy: 0.6925585269927979 , global_step: 6013
- AI-Rank-log  1619174302.9949136  eval_accuracy: 0.6922228336334229 , global_step: 6014
- AI-Rank-log  1619174346.9723997  eval_accuracy: 0.692368745803833 , global_step: 6015
- AI-Rank-log  1619174390.9441636  eval_accuracy: 0.6923926472663879 , global_step: 6016
- AI-Rank-log  1619174434.883049  eval_accuracy: 0.6924741864204407 , global_step: 6017
- AI-Rank-log  1619174478.9017084  eval_accuracy: 0.6924240589141846 , global_step: 6018
- AI-Rank-log  1619174522.8522098  eval_accuracy: 0.6918448805809021 , global_step: 6019
- AI-Rank-log  1619174566.8618035  eval_accuracy: 0.6924050450325012 , global_step: 6020
- AI-Rank-log  1619174610.7972085  eval_accuracy: 0.6916341185569763 , global_step: 6021
- AI-Rank-log  1619174655.6164918  eval_accuracy: 0.6927474141120911 , global_step: 6022
- AI-Rank-log  1619174699.6016502  eval_accuracy: 0.6919175982475281 , global_step: 6023
- AI-Rank-log  1619174743.5204997  eval_accuracy: 0.6928701996803284 , global_step: 6024
- AI-Rank-log  1619174787.5194468  eval_accuracy: 0.6918945908546448 , global_step: 6025
- AI-Rank-log  1619174832.0033739  eval_accuracy: 0.6925243139266968 , global_step: 6026
- AI-Rank-log  1619174876.335649  eval_accuracy: 0.6921152472496033 , global_step: 6027
- AI-Rank-log  1619174920.4973342  eval_accuracy: 0.6922160387039185 , global_step: 6028
- AI-Rank-log  1619174964.4090698  eval_accuracy: 0.6922759413719177 , global_step: 6029
- AI-Rank-log  1619175008.3708744  eval_accuracy: 0.6931976079940796 , global_step: 6030
- AI-Rank-log  1619175053.3277817  eval_accuracy: 0.6925681233406067 , global_step: 6031
- AI-Rank-log  1619175097.4022381  eval_accuracy: 0.6932081580162048 , global_step: 6032
- AI-Rank-log  1619175141.6899166  eval_accuracy: 0.6911147832870483 , global_step: 6033
- AI-Rank-log  1619175185.7569504  eval_accuracy: 0.692403256893158 , global_step: 6034
- AI-Rank-log  1619175230.5680916  eval_accuracy: 0.6921742558479309 , global_step: 6035
- AI-Rank-log  1619175274.733568  eval_accuracy: 0.6924468278884888 , global_step: 6036
- AI-Rank-log  1619175319.2521248  eval_accuracy: 0.6921054720878601 , global_step: 6037
- AI-Rank-log  1619175364.0499039  eval_accuracy: 0.6922680139541626 , global_step: 6038
- AI-Rank-log  1619175408.0758128  eval_accuracy: 0.691825270652771 , global_step: 6039
- AI-Rank-log  1619175452.0060096  eval_accuracy: 0.6919009685516357 , global_step: 6040
- AI-Rank-log  1619175495.9266346  eval_accuracy: 0.692199170589447 , global_step: 6041
- AI-Rank-log  1619175540.8581107  eval_accuracy: 0.6915838718414307 , global_step: 6042
- AI-Rank-log  1619175584.7486548  eval_accuracy: 0.6911513209342957 , global_step: 6043
- AI-Rank-log  1619175628.6961284  eval_accuracy: 0.6920638084411621 , global_step: 6044
- AI-Rank-log  1619175672.738081  eval_accuracy: 0.6926046013832092 , global_step: 6045
- AI-Rank-log  1619175716.663031  eval_accuracy: 0.6921509504318237 , global_step: 6046
- AI-Rank-log  1619175760.5962625  eval_accuracy: 0.6921235918998718 , global_step: 6047
- AI-Rank-log  1619175804.6966546  eval_accuracy: 0.6925866603851318 , global_step: 6048
- AI-Rank-log  1619175848.6369696  eval_accuracy: 0.6925824880599976 , global_step: 6049
- AI-Rank-log  1619175892.6588457  eval_accuracy: 0.6929214596748352 , global_step: 6050
- AI-Rank-log  1619175936.611702  eval_accuracy: 0.692477822303772 , global_step: 6051
- AI-Rank-log  1619175980.5545318  eval_accuracy: 0.6929404139518738 , global_step: 6052
- AI-Rank-log  1619176024.5643637  eval_accuracy: 0.692486047744751 , global_step: 6053
- AI-Rank-log  1619176068.5033891  eval_accuracy: 0.6926997900009155 , global_step: 6054
- AI-Rank-log  1619176112.4340155  eval_accuracy: 0.6921091079711914 , global_step: 6055
- AI-Rank-log  1619176156.3993337  eval_accuracy: 0.6925824284553528 , global_step: 6056
- AI-Rank-log  1619176200.3408794  eval_accuracy: 0.6915473937988281 , global_step: 6057
- AI-Rank-log  1619176244.3763077  eval_accuracy: 0.6926887631416321 , global_step: 6058
- AI-Rank-log  1619176288.3908033  eval_accuracy: 0.6920140981674194 , global_step: 6059
- AI-Rank-log  1619176332.4196332  eval_accuracy: 0.6919100284576416 , global_step: 6060
- AI-Rank-log  1619176376.4747157  eval_accuracy: 0.6918385624885559 , global_step: 6061
- AI-Rank-log  1619176420.433812  eval_accuracy: 0.6921530961990356 , global_step: 6062
- AI-Rank-log  1619176464.372527  eval_accuracy: 0.6924721598625183 , global_step: 6063
- AI-Rank-log  1619176508.3470836  eval_accuracy: 0.6929619908332825 , global_step: 6064
- AI-Rank-log  1619176552.283003  eval_accuracy: 0.6925053000450134 , global_step: 6065
- AI-Rank-log  1619176596.213041  eval_accuracy: 0.6930645108222961 , global_step: 6066
- AI-Rank-log  1619176640.2275789  eval_accuracy: 0.6923094987869263 , global_step: 6067
- AI-Rank-log  1619176684.1867115  eval_accuracy: 0.6933823227882385 , global_step: 6068
- AI-Rank-log  1619176728.1110117  eval_accuracy: 0.6925715208053589 , global_step: 6069
- AI-Rank-log  1619176772.131194  eval_accuracy: 0.6928098201751709 , global_step: 6070
- AI-Rank-log  1619176816.1024115  eval_accuracy: 0.6925642490386963 , global_step: 6071
- AI-Rank-log  1619176860.1083736  eval_accuracy: 0.6927034258842468 , global_step: 6072
- AI-Rank-log  1619176904.056128  eval_accuracy: 0.6926686763763428 , global_step: 6073
- AI-Rank-log  1619176948.0177743  eval_accuracy: 0.6928145289421082 , global_step: 6074
- AI-Rank-log  1619176991.9895391  eval_accuracy: 0.692754864692688 , global_step: 6075
- AI-Rank-log  1619177035.8750896  eval_accuracy: 0.6919255256652832 , global_step: 6076
- AI-Rank-log  1619177079.8165245  eval_accuracy: 0.6926417946815491 , global_step: 6077
- AI-Rank-log  1619177123.8410878  eval_accuracy: 0.6921178698539734 , global_step: 6078
- AI-Rank-log  1619177167.7665102  eval_accuracy: 0.6926596164703369 , global_step: 6079
- AI-Rank-log  1619177211.7311757  eval_accuracy: 0.692065417766571 , global_step: 6080
- AI-Rank-log  1619177255.7362797  eval_accuracy: 0.6920231580734253 , global_step: 6081
- AI-Rank-log  1619177299.670908  eval_accuracy: 0.6920056343078613 , global_step: 6082
- AI-Rank-log  1619177343.6932793  eval_accuracy: 0.6922200918197632 , global_step: 6083
- AI-Rank-log  1619177387.6048617  eval_accuracy: 0.6919099688529968 , global_step: 6084
- AI-Rank-log  1619177431.5695083  eval_accuracy: 0.691904604434967 , global_step: 6085
- AI-Rank-log  1619177475.5588481  eval_accuracy: 0.6920101046562195 , global_step: 6086
- AI-Rank-log  1619177519.4784117  eval_accuracy: 0.6920813918113708 , global_step: 6087
- AI-Rank-log  1619177563.4063714  eval_accuracy: 0.6924802660942078 , global_step: 6088
- AI-Rank-log  1619177607.4038503  eval_accuracy: 0.6925788521766663 , global_step: 6089
- AI-Rank-log  1619177651.3508017  eval_accuracy: 0.6913164854049683 , global_step: 6090
- AI-Rank-log  1619177695.3168986  eval_accuracy: 0.6924969553947449 , global_step: 6091
- AI-Rank-log  1619177739.1014216  eval_accuracy: 0.6916882395744324 , global_step: 6092
- AI-Rank-log  1619177783.0364106  eval_accuracy: 0.6922073364257812 , global_step: 6093
- AI-Rank-log  1619177827.0593703  eval_accuracy: 0.6913241744041443 , global_step: 6094
- AI-Rank-log  1619177870.983701  eval_accuracy: 0.6924054622650146 , global_step: 6095
- AI-Rank-log  1619177914.9024131  eval_accuracy: 0.6912926435470581 , global_step: 6096
- AI-Rank-log  1619177958.93825  eval_accuracy: 0.6921776533126831 , global_step: 6097
- AI-Rank-log  1619178002.8890345  eval_accuracy: 0.6916850805282593 , global_step: 6098
- AI-Rank-log  1619178047.8846862  eval_accuracy: 0.6930153965950012 , global_step: 6099
- AI-Rank-log  1619178092.2021353  eval_accuracy: 0.690873384475708 , global_step: 6100
- AI-Rank-log  1619178136.1301732  eval_accuracy: 0.6927343010902405 , global_step: 6101
- AI-Rank-log  1619178180.1582298  eval_accuracy: 0.6915546655654907 , global_step: 6102
- AI-Rank-log  1619178224.7469  eval_accuracy: 0.6924940943717957 , global_step: 6103
- AI-Rank-log  1619178268.6632996  eval_accuracy: 0.6919468641281128 , global_step: 6104
- AI-Rank-log  1619178312.8778334  eval_accuracy: 0.6930851340293884 , global_step: 6105
- AI-Rank-log  1619178357.0785744  eval_accuracy: 0.6922877430915833 , global_step: 6106
- AI-Rank-log  1619178400.9651873  eval_accuracy: 0.6930056214332581 , global_step: 6107
- AI-Rank-log  1619178445.0133133  eval_accuracy: 0.6930587887763977 , global_step: 6108
- AI-Rank-log  1619178489.8742716  eval_accuracy: 0.6925361752510071 , global_step: 6109
- AI-Rank-log  1619178533.7857435  eval_accuracy: 0.6930454969406128 , global_step: 6110
- AI-Rank-log  1619178578.148448  eval_accuracy: 0.6924776434898376 , global_step: 6111
- AI-Rank-log  1619178622.1329596  eval_accuracy: 0.6929025053977966 , global_step: 6112
- AI-Rank-log  1619178666.7445796  eval_accuracy: 0.6925712823867798 , global_step: 6113
- AI-Rank-log  1619178710.7191005  eval_accuracy: 0.6930345296859741 , global_step: 6114
- AI-Rank-log  1619178755.875041  eval_accuracy: 0.6917629837989807 , global_step: 6115
- AI-Rank-log  1619178799.8722878  eval_accuracy: 0.6919451951980591 , global_step: 6116
- AI-Rank-log  1619178843.832335  eval_accuracy: 0.6928521990776062 , global_step: 6117
- AI-Rank-log  1619178887.81976  eval_accuracy: 0.6926513314247131 , global_step: 6118
- AI-Rank-log  1619178931.786299  eval_accuracy: 0.6924590468406677 , global_step: 6119
- AI-Rank-log  1619178976.0984714  eval_accuracy: 0.6931687593460083 , global_step: 6120
- AI-Rank-log  1619179020.1425571  eval_accuracy: 0.6926447153091431 , global_step: 6121
- AI-Rank-log  1619179064.027163  eval_accuracy: 0.6929853558540344 , global_step: 6122
- AI-Rank-log  1619179107.9921024  eval_accuracy: 0.6922621130943298 , global_step: 6123
- AI-Rank-log  1619179152.0305634  eval_accuracy: 0.692326009273529 , global_step: 6124
- AI-Rank-log  1619179195.9849195  eval_accuracy: 0.6917714476585388 , global_step: 6125
- AI-Rank-log  1619179239.926879  eval_accuracy: 0.6924247145652771 , global_step: 6126
- AI-Rank-log  1619179284.035172  eval_accuracy: 0.6920533776283264 , global_step: 6127
- AI-Rank-log  1619179327.9782603  eval_accuracy: 0.6925965547561646 , global_step: 6128
- AI-Rank-log  1619179371.9275427  eval_accuracy: 0.6931473016738892 , global_step: 6129
- AI-Rank-log  1619179415.9256196  eval_accuracy: 0.6926252841949463 , global_step: 6130
- AI-Rank-log  1619179459.8325188  eval_accuracy: 0.6924954056739807 , global_step: 6131
- AI-Rank-log  1619179503.8246272  eval_accuracy: 0.6937302350997925 , global_step: 6132
- AI-Rank-log  1619179547.7769608  eval_accuracy: 0.6929545998573303 , global_step: 6133
- AI-Rank-log  1619179591.7240589  eval_accuracy: 0.6936116814613342 , global_step: 6134
- AI-Rank-log  1619179635.7580442  eval_accuracy: 0.6939232349395752 , global_step: 6135
- AI-Rank-log  1619179679.7280512  eval_accuracy: 0.6931286454200745 , global_step: 6136
- AI-Rank-log  1619179723.6599169  eval_accuracy: 0.6928773522377014 , global_step: 6137
- AI-Rank-log  1619179767.730413  eval_accuracy: 0.6927616000175476 , global_step: 6138
- AI-Rank-log  1619179811.6617708  eval_accuracy: 0.6930022835731506 , global_step: 6139
- AI-Rank-log  1619179855.6435745  eval_accuracy: 0.6933103203773499 , global_step: 6140
- AI-Rank-log  1619179899.6726034  eval_accuracy: 0.6929038166999817 , global_step: 6141
- AI-Rank-log  1619179943.619482  eval_accuracy: 0.6928865313529968 , global_step: 6142
- AI-Rank-log  1619179987.6986136  eval_accuracy: 0.6915615797042847 , global_step: 6143
- AI-Rank-log  1619180031.6693466  eval_accuracy: 0.6928030848503113 , global_step: 6144
- AI-Rank-log  1619180075.5972123  eval_accuracy: 0.6923297047615051 , global_step: 6145
- AI-Rank-log  1619180119.6106658  eval_accuracy: 0.6932287216186523 , global_step: 6146
- AI-Rank-log  1619180163.5529244  eval_accuracy: 0.69185870885849 , global_step: 6147
- AI-Rank-log  1619180207.4855351  eval_accuracy: 0.6934048533439636 , global_step: 6148
- AI-Rank-log  1619180251.5278583  eval_accuracy: 0.6923685073852539 , global_step: 6149
- AI-Rank-log  1619180295.4584897  eval_accuracy: 0.6931476593017578 , global_step: 6150
- AI-Rank-log  1619180339.4360642  eval_accuracy: 0.6926980018615723 , global_step: 6151
- AI-Rank-log  1619180383.4578698  eval_accuracy: 0.692436933517456 , global_step: 6152
- AI-Rank-log  1619180427.4646132  eval_accuracy: 0.6922257542610168 , global_step: 6153
- AI-Rank-log  1619180471.4323437  eval_accuracy: 0.693223774433136 , global_step: 6154
- AI-Rank-log  1619180515.4175456  eval_accuracy: 0.6930404901504517 , global_step: 6155
- AI-Rank-log  1619180559.3868523  eval_accuracy: 0.6931226849555969 , global_step: 6156
- AI-Rank-log  1619180603.4861405  eval_accuracy: 0.6924707889556885 , global_step: 6157
- AI-Rank-log  1619180647.4590678  eval_accuracy: 0.6932780742645264 , global_step: 6158
- AI-Rank-log  1619180691.4103322  eval_accuracy: 0.6914756894111633 , global_step: 6159
- AI-Rank-log  1619180735.4427338  eval_accuracy: 0.6929216384887695 , global_step: 6160
- AI-Rank-log  1619180779.4012382  eval_accuracy: 0.6925529837608337 , global_step: 6161
- AI-Rank-log  1619180823.3374119  eval_accuracy: 0.6927915811538696 , global_step: 6162
- AI-Rank-log  1619180867.3782814  eval_accuracy: 0.6934967041015625 , global_step: 6163
- AI-Rank-log  1619180911.353149  eval_accuracy: 0.6924978494644165 , global_step: 6164
- AI-Rank-log  1619180955.2986865  eval_accuracy: 0.6927191615104675 , global_step: 6165
- AI-Rank-log  1619180999.2239585  eval_accuracy: 0.6929100155830383 , global_step: 6166
- AI-Rank-log  1619181043.1886036  eval_accuracy: 0.6929868459701538 , global_step: 6167
- AI-Rank-log  1619181087.1890802  eval_accuracy: 0.6929067373275757 , global_step: 6168
- AI-Rank-log  1619181131.1091323  eval_accuracy: 0.6931037902832031 , global_step: 6169
- AI-Rank-log  1619181175.061127  eval_accuracy: 0.6928582191467285 , global_step: 6170
- AI-Rank-log  1619181219.0300055  eval_accuracy: 0.6932907700538635 , global_step: 6171
- AI-Rank-log  1619181262.98274  eval_accuracy: 0.6916355490684509 , global_step: 6172
- AI-Rank-log  1619181306.942463  eval_accuracy: 0.6935533285140991 , global_step: 6173
- AI-Rank-log  1619181350.9456298  eval_accuracy: 0.6919923424720764 , global_step: 6174
- AI-Rank-log  1619181394.9213746  eval_accuracy: 0.6933178901672363 , global_step: 6175
- AI-Rank-log  1619181438.9473662  eval_accuracy: 0.6930643320083618 , global_step: 6176
- AI-Rank-log  1619181483.5784016  eval_accuracy: 0.6929318904876709 , global_step: 6177
- AI-Rank-log  1619181527.5134668  eval_accuracy: 0.6935482025146484 , global_step: 6178
- AI-Rank-log  1619181571.5050502  eval_accuracy: 0.6931054592132568 , global_step: 6179
- AI-Rank-log  1619181615.4661744  eval_accuracy: 0.6930616497993469 , global_step: 6180
- AI-Rank-log  1619181659.7238343  eval_accuracy: 0.6923387050628662 , global_step: 6181
- AI-Rank-log  1619181704.2202115  eval_accuracy: 0.6932995915412903 , global_step: 6182
- AI-Rank-log  1619181748.5155988  eval_accuracy: 0.6926411986351013 , global_step: 6183
- AI-Rank-log  1619181793.4233103  eval_accuracy: 0.6934113502502441 , global_step: 6184
- AI-Rank-log  1619181837.4505599  eval_accuracy: 0.691834568977356 , global_step: 6185
- AI-Rank-log  1619181882.210862  eval_accuracy: 0.6928764581680298 , global_step: 6186
- AI-Rank-log  1619181926.2816985  eval_accuracy: 0.6932169198989868 , global_step: 6187
- AI-Rank-log  1619181970.9198961  eval_accuracy: 0.6926103234291077 , global_step: 6188
- AI-Rank-log  1619182014.864608  eval_accuracy: 0.6926289200782776 , global_step: 6189
- AI-Rank-log  1619182059.6199372  eval_accuracy: 0.6925828456878662 , global_step: 6190
- AI-Rank-log  1619182112.5265691  eval_accuracy: 0.6932166218757629 , global_step: 6191
- AI-Rank-log  1619182156.7293098  eval_accuracy: 0.6929397583007812 , global_step: 6192
- AI-Rank-log  1619182201.669722  eval_accuracy: 0.6928669214248657 , global_step: 6193
- AI-Rank-log  1619182245.6507382  eval_accuracy: 0.6934013962745667 , global_step: 6194
- AI-Rank-log  1619182289.6825051  eval_accuracy: 0.693597137928009 , global_step: 6195
- AI-Rank-log  1619182333.670539  eval_accuracy: 0.6937189102172852 , global_step: 6196
- AI-Rank-log  1619182377.9173274  eval_accuracy: 0.6930367946624756 , global_step: 6197
- AI-Rank-log  1619182421.9220695  eval_accuracy: 0.6932080984115601 , global_step: 6198
- AI-Rank-log  1619182465.8773293  eval_accuracy: 0.6929252743721008 , global_step: 6199
- AI-Rank-log  1619182509.8365285  eval_accuracy: 0.6927070021629333 , global_step: 6200
- AI-Rank-log  1619182553.8462324  eval_accuracy: 0.6934475898742676 , global_step: 6201
- AI-Rank-log  1619182597.8258212  eval_accuracy: 0.6935904622077942 , global_step: 6202
- AI-Rank-log  1619182641.7461386  eval_accuracy: 0.6934328079223633 , global_step: 6203
- AI-Rank-log  1619182685.7588568  eval_accuracy: 0.6939684152603149 , global_step: 6204
- AI-Rank-log  1619182729.703896  eval_accuracy: 0.693077802658081 , global_step: 6205
- AI-Rank-log  1619182773.707665  eval_accuracy: 0.6934059262275696 , global_step: 6206
- AI-Rank-log  1619182817.7011127  eval_accuracy: 0.6931072473526001 , global_step: 6207
- AI-Rank-log  1619182861.6731606  eval_accuracy: 0.6940259337425232 , global_step: 6208
- AI-Rank-log  1619182905.712613  eval_accuracy: 0.6937807202339172 , global_step: 6209
- AI-Rank-log  1619182949.6819162  eval_accuracy: 0.6937516927719116 , global_step: 6210
- AI-Rank-log  1619182993.668021  eval_accuracy: 0.6939491629600525 , global_step: 6211
- AI-Rank-log  1619183037.6388807  eval_accuracy: 0.6934560537338257 , global_step: 6212
- AI-Rank-log  1619183081.6448677  eval_accuracy: 0.6938148140907288 , global_step: 6213
- AI-Rank-log  1619183125.6760304  eval_accuracy: 0.6926416158676147 , global_step: 6214
- AI-Rank-log  1619183169.599336  eval_accuracy: 0.6936355829238892 , global_step: 6215
- AI-Rank-log  1619183213.561162  eval_accuracy: 0.693157970905304 , global_step: 6216
- AI-Rank-log  1619183257.5528975  eval_accuracy: 0.6928896307945251 , global_step: 6217
- AI-Rank-log  1619183301.5101767  eval_accuracy: 0.6936466693878174 , global_step: 6218
- AI-Rank-log  1619183345.4402475  eval_accuracy: 0.6932872533798218 , global_step: 6219
- AI-Rank-log  1619183389.4761996  eval_accuracy: 0.6928737759590149 , global_step: 6220
- AI-Rank-log  1619183433.4517617  eval_accuracy: 0.6931711435317993 , global_step: 6221
- AI-Rank-log  1619183477.391001  eval_accuracy: 0.6932557821273804 , global_step: 6222
- AI-Rank-log  1619183521.3835967  eval_accuracy: 0.694236159324646 , global_step: 6223
- AI-Rank-log  1619183565.3416343  eval_accuracy: 0.6934494972229004 , global_step: 6224
- AI-Rank-log  1619183609.402957  eval_accuracy: 0.6933848857879639 , global_step: 6225
- AI-Rank-log  1619183653.3460946  eval_accuracy: 0.6923746466636658 , global_step: 6226
- AI-Rank-log  1619183697.3009439  eval_accuracy: 0.6932744979858398 , global_step: 6227
- AI-Rank-log  1619183741.3400478  eval_accuracy: 0.6933907270431519 , global_step: 6228
- AI-Rank-log  1619183785.2933269  eval_accuracy: 0.6929556131362915 , global_step: 6229
- AI-Rank-log  1619183829.2314801  eval_accuracy: 0.692773163318634 , global_step: 6230
- AI-Rank-log  1619183873.2845097  eval_accuracy: 0.693867564201355 , global_step: 6231
- AI-Rank-log  1619183917.2268205  eval_accuracy: 0.6934148073196411 , global_step: 6232
- AI-Rank-log  1619183961.204343  eval_accuracy: 0.6933220624923706 , global_step: 6233
- AI-Rank-log  1619184005.1995828  eval_accuracy: 0.6941481232643127 , global_step: 6234
- AI-Rank-log  1619184049.2073472  eval_accuracy: 0.6929912567138672 , global_step: 6235
- AI-Rank-log  1619184093.239372  eval_accuracy: 0.694473147392273 , global_step: 6236
- AI-Rank-log  1619184137.214256  eval_accuracy: 0.6931326389312744 , global_step: 6237
- AI-Rank-log  1619184181.1820123  eval_accuracy: 0.6939449906349182 , global_step: 6238
- AI-Rank-log  1619184225.1933823  eval_accuracy: 0.6928775906562805 , global_step: 6239
- AI-Rank-log  1619184269.1367853  eval_accuracy: 0.6933205723762512 , global_step: 6240
- AI-Rank-log  1619184313.1235194  eval_accuracy: 0.6933616399765015 , global_step: 6241
- AI-Rank-log  1619184357.1197019  eval_accuracy: 0.6932286024093628 , global_step: 6242
- AI-Rank-log  1619184401.0924475  eval_accuracy: 0.6936889290809631 , global_step: 6243
- AI-Rank-log  1619184445.1264198  eval_accuracy: 0.6937954425811768 , global_step: 6244
- AI-Rank-log  1619184489.0797668  eval_accuracy: 0.6940644979476929 , global_step: 6245
- AI-Rank-log  1619184533.0133514  eval_accuracy: 0.6934541463851929 , global_step: 6246
- AI-Rank-log  1619184577.0039933  eval_accuracy: 0.693837583065033 , global_step: 6247
- AI-Rank-log  1619184620.9563704  eval_accuracy: 0.693070113658905 , global_step: 6248
- AI-Rank-log  1619184664.92071  eval_accuracy: 0.6931189894676208 , global_step: 6249
- AI-Rank-log  1619184708.8996189  eval_accuracy: 0.693024218082428 , global_step: 6250
- AI-Rank-log  1619184752.8405173  eval_accuracy: 0.6934358477592468 , global_step: 6251
- AI-Rank-log  1619184796.8539593  eval_accuracy: 0.6929678320884705 , global_step: 6252
- AI-Rank-log  1619184840.7946997  eval_accuracy: 0.6936906576156616 , global_step: 6253
- AI-Rank-log  1619184885.7451165  eval_accuracy: 0.6926265954971313 , global_step: 6254
- AI-Rank-log  1619184929.7313783  eval_accuracy: 0.6926109790802002 , global_step: 6255
- AI-Rank-log  1619184973.686331  eval_accuracy: 0.6931031346321106 , global_step: 6256
- AI-Rank-log  1619185017.6752706  eval_accuracy: 0.6934770345687866 , global_step: 6257
- AI-Rank-log  1619185062.2533991  eval_accuracy: 0.6937304735183716 , global_step: 6258
- AI-Rank-log  1619185106.5343049  eval_accuracy: 0.6927801966667175 , global_step: 6259
- AI-Rank-log  1619185150.4950545  eval_accuracy: 0.6930513381958008 , global_step: 6260
- AI-Rank-log  1619185194.6194015  eval_accuracy: 0.6919676065444946 , global_step: 6261
- AI-Rank-log  1619185238.6030028  eval_accuracy: 0.6927536725997925 , global_step: 6262
- AI-Rank-log  1619185282.6387556  eval_accuracy: 0.692274808883667 , global_step: 6263
- AI-Rank-log  1619185327.6094763  eval_accuracy: 0.6934069991111755 , global_step: 6264
- AI-Rank-log  1619185372.119643  eval_accuracy: 0.6935684084892273 , global_step: 6265
- AI-Rank-log  1619185416.1665492  eval_accuracy: 0.6937435865402222 , global_step: 6266
- AI-Rank-log  1619185460.8823104  eval_accuracy: 0.6931578516960144 , global_step: 6267
- AI-Rank-log  1619185504.9248247  eval_accuracy: 0.6941088438034058 , global_step: 6268
- AI-Rank-log  1619185549.0278885  eval_accuracy: 0.6933492422103882 , global_step: 6269
- AI-Rank-log  1619185594.0073204  eval_accuracy: 0.6948290467262268 , global_step: 6270
- AI-Rank-log  1619185637.955969  eval_accuracy: 0.6937870383262634 , global_step: 6271
- AI-Rank-log  1619185682.0000196  eval_accuracy: 0.6941957473754883 , global_step: 6272
- AI-Rank-log  1619185725.9559941  eval_accuracy: 0.6940195560455322 , global_step: 6273
- AI-Rank-log  1619185769.9915922  eval_accuracy: 0.6941062808036804 , global_step: 6274
- AI-Rank-log  1619185814.1324914  eval_accuracy: 0.69478440284729 , global_step: 6275
- AI-Rank-log  1619185858.1109934  eval_accuracy: 0.6943277716636658 , global_step: 6276
- AI-Rank-log  1619185902.156603  eval_accuracy: 0.6947882771492004 , global_step: 6277
- AI-Rank-log  1619185946.1236126  eval_accuracy: 0.6940124034881592 , global_step: 6278
- AI-Rank-log  1619185990.0666738  eval_accuracy: 0.6943142414093018 , global_step: 6279
- AI-Rank-log  1619186034.1052303  eval_accuracy: 0.693506121635437 , global_step: 6280
- AI-Rank-log  1619186078.069734  eval_accuracy: 0.6937819123268127 , global_step: 6281
- AI-Rank-log  1619186121.9642982  eval_accuracy: 0.6940972208976746 , global_step: 6282
- AI-Rank-log  1619186165.975172  eval_accuracy: 0.6934277415275574 , global_step: 6283
- AI-Rank-log  1619186209.9128366  eval_accuracy: 0.6940667033195496 , global_step: 6284
- AI-Rank-log  1619186253.9025195  eval_accuracy: 0.6937189102172852 , global_step: 6285
- AI-Rank-log  1619186297.8896673  eval_accuracy: 0.6936752796173096 , global_step: 6286
- AI-Rank-log  1619186341.794408  eval_accuracy: 0.6949005722999573 , global_step: 6287
- AI-Rank-log  1619186385.807817  eval_accuracy: 0.6934863924980164 , global_step: 6288
- AI-Rank-log  1619186429.7634242  eval_accuracy: 0.6943920254707336 , global_step: 6289
- AI-Rank-log  1619186473.662637  eval_accuracy: 0.693430483341217 , global_step: 6290
- AI-Rank-log  1619186517.668315  eval_accuracy: 0.6944595575332642 , global_step: 6291
- AI-Rank-log  1619186561.6336246  eval_accuracy: 0.6936874389648438 , global_step: 6292
- AI-Rank-log  1619186605.6493962  eval_accuracy: 0.6936392784118652 , global_step: 6293
- AI-Rank-log  1619186649.6114278  eval_accuracy: 0.6934285759925842 , global_step: 6294
- AI-Rank-log  1619186693.5842342  eval_accuracy: 0.6939732432365417 , global_step: 6295
- AI-Rank-log  1619186737.567966  eval_accuracy: 0.6930649280548096 , global_step: 6296
- AI-Rank-log  1619186781.5162575  eval_accuracy: 0.693641185760498 , global_step: 6297
- AI-Rank-log  1619186825.486496  eval_accuracy: 0.6937565803527832 , global_step: 6298
- AI-Rank-log  1619186869.4834821  eval_accuracy: 0.6935902237892151 , global_step: 6299
- AI-Rank-log  1619186913.4320288  eval_accuracy: 0.6938834190368652 , global_step: 6300
- AI-Rank-log  1619186957.4148912  eval_accuracy: 0.693145215511322 , global_step: 6301
- AI-Rank-log  1619187001.4498756  eval_accuracy: 0.6940649151802063 , global_step: 6302
- AI-Rank-log  1619187045.4389062  eval_accuracy: 0.6931895613670349 , global_step: 6303
- AI-Rank-log  1619187089.3227303  eval_accuracy: 0.6938461661338806 , global_step: 6304
- AI-Rank-log  1619187133.3449528  eval_accuracy: 0.6938095688819885 , global_step: 6305
- AI-Rank-log  1619187177.2770073  eval_accuracy: 0.692878246307373 , global_step: 6306
- AI-Rank-log  1619187221.325133  eval_accuracy: 0.6932394504547119 , global_step: 6307
- AI-Rank-log  1619187265.2366476  eval_accuracy: 0.6932240128517151 , global_step: 6308
- AI-Rank-log  1619187309.1855326  eval_accuracy: 0.6929858326911926 , global_step: 6309
- AI-Rank-log  1619187353.1607134  eval_accuracy: 0.6924347281455994 , global_step: 6310
- AI-Rank-log  1619187397.1236327  eval_accuracy: 0.6940388679504395 , global_step: 6311
- AI-Rank-log  1619187441.1123068  eval_accuracy: 0.693194568157196 , global_step: 6312
- AI-Rank-log  1619187485.1008806  eval_accuracy: 0.6935728788375854 , global_step: 6313
- AI-Rank-log  1619187529.1109061  eval_accuracy: 0.6932037472724915 , global_step: 6314
- AI-Rank-log  1619187573.168719  eval_accuracy: 0.6939934492111206 , global_step: 6315
- AI-Rank-log  1619187617.0862536  eval_accuracy: 0.6929044723510742 , global_step: 6316
- AI-Rank-log  1619187661.0424192  eval_accuracy: 0.693600058555603 , global_step: 6317
- AI-Rank-log  1619187705.0658474  eval_accuracy: 0.6931818127632141 , global_step: 6318
- AI-Rank-log  1619187748.9482186  eval_accuracy: 0.6932171583175659 , global_step: 6319
- AI-Rank-log  1619187792.9189315  eval_accuracy: 0.69272381067276 , global_step: 6320
- AI-Rank-log  1619187836.9403229  eval_accuracy: 0.6941312551498413 , global_step: 6321
- AI-Rank-log  1619187880.8581624  eval_accuracy: 0.6934428215026855 , global_step: 6322
- AI-Rank-log  1619187924.8259358  eval_accuracy: 0.6937798261642456 , global_step: 6323
- AI-Rank-log  1619187968.8376637  eval_accuracy: 0.6932662725448608 , global_step: 6324
- AI-Rank-log  1619188012.7638974  eval_accuracy: 0.6933170557022095 , global_step: 6325
- AI-Rank-log  1619188056.7661035  eval_accuracy: 0.6931331157684326 , global_step: 6326
- AI-Rank-log  1619188100.700252  eval_accuracy: 0.6943469047546387 , global_step: 6327
- AI-Rank-log  1619188144.648412  eval_accuracy: 0.6938478946685791 , global_step: 6328
- AI-Rank-log  1619188188.699808  eval_accuracy: 0.6935794949531555 , global_step: 6329
- AI-Rank-log  1619188232.617516  eval_accuracy: 0.6937240958213806 , global_step: 6330
- AI-Rank-log  1619188277.4971833  eval_accuracy: 0.6936247944831848 , global_step: 6331
- AI-Rank-log  1619188321.6070883  eval_accuracy: 0.6931180357933044 , global_step: 6332
- AI-Rank-log  1619188365.605096  eval_accuracy: 0.6925749778747559 , global_step: 6333
- AI-Rank-log  1619188409.5004716  eval_accuracy: 0.6932309865951538 , global_step: 6334
- AI-Rank-log  1619188454.1461122  eval_accuracy: 0.6938557028770447 , global_step: 6335
- AI-Rank-log  1619188498.5060697  eval_accuracy: 0.6937786340713501 , global_step: 6336
- AI-Rank-log  1619188542.5362737  eval_accuracy: 0.6933032870292664 , global_step: 6337
- AI-Rank-log  1619188587.213894  eval_accuracy: 0.693397045135498 , global_step: 6338
- AI-Rank-log  1619188631.2316046  eval_accuracy: 0.6942164301872253 , global_step: 6339
- AI-Rank-log  1619188675.375097  eval_accuracy: 0.6929007768630981 , global_step: 6340
- AI-Rank-log  1619188720.4782093  eval_accuracy: 0.6939383149147034 , global_step: 6341
- AI-Rank-log  1619188764.4084942  eval_accuracy: 0.6931161880493164 , global_step: 6342
- AI-Rank-log  1619188808.6728585  eval_accuracy: 0.6943219900131226 , global_step: 6343
- AI-Rank-log  1619188852.6711707  eval_accuracy: 0.693561315536499 , global_step: 6344
- AI-Rank-log  1619188897.3400538  eval_accuracy: 0.6943459510803223 , global_step: 6345
- AI-Rank-log  1619188941.547912  eval_accuracy: 0.6936615109443665 , global_step: 6346
- AI-Rank-log  1619188986.7802622  eval_accuracy: 0.6932400465011597 , global_step: 6347
- AI-Rank-log  1619189030.7901335  eval_accuracy: 0.6936095952987671 , global_step: 6348
- AI-Rank-log  1619189074.7397606  eval_accuracy: 0.6934379935264587 , global_step: 6349
- AI-Rank-log  1619189118.699198  eval_accuracy: 0.693664014339447 , global_step: 6350
- AI-Rank-log  1619189162.6621065  eval_accuracy: 0.6939574480056763 , global_step: 6351
- AI-Rank-log  1619189206.9111946  eval_accuracy: 0.6935935616493225 , global_step: 6352
- AI-Rank-log  1619189250.8002112  eval_accuracy: 0.6936834454536438 , global_step: 6353
- AI-Rank-log  1619189294.7881076  eval_accuracy: 0.6938564777374268 , global_step: 6354
- AI-Rank-log  1619189338.7510395  eval_accuracy: 0.6933721303939819 , global_step: 6355
- AI-Rank-log  1619189382.6492908  eval_accuracy: 0.6938636302947998 , global_step: 6356
- AI-Rank-log  1619189426.6621323  eval_accuracy: 0.6931416988372803 , global_step: 6357
- AI-Rank-log  1619189470.5803444  eval_accuracy: 0.6943376660346985 , global_step: 6358
- AI-Rank-log  1619189514.5771723  eval_accuracy: 0.6936508417129517 , global_step: 6359
- AI-Rank-log  1619189558.5024977  eval_accuracy: 0.6943280100822449 , global_step: 6360
- AI-Rank-log  1619189602.525441  eval_accuracy: 0.6939103603363037 , global_step: 6361
- AI-Rank-log  1619189646.6024044  eval_accuracy: 0.6944795846939087 , global_step: 6362
- AI-Rank-log  1619189690.5057724  eval_accuracy: 0.6940476298332214 , global_step: 6363
- AI-Rank-log  1619189734.494628  eval_accuracy: 0.6949436068534851 , global_step: 6364
- AI-Rank-log  1619189778.5643382  eval_accuracy: 0.6944726705551147 , global_step: 6365
- AI-Rank-log  1619189822.5035655  eval_accuracy: 0.6947144269943237 , global_step: 6366
- AI-Rank-log  1619189866.4583032  eval_accuracy: 0.6941019892692566 , global_step: 6367
- AI-Rank-log  1619189910.3889065  eval_accuracy: 0.6941743493080139 , global_step: 6368
- AI-Rank-log  1619189954.296457  eval_accuracy: 0.6933017373085022 , global_step: 6369
- AI-Rank-log  1619189998.3181894  eval_accuracy: 0.6938194632530212 , global_step: 6370
- AI-Rank-log  1619190042.2378776  eval_accuracy: 0.6941710710525513 , global_step: 6371
- AI-Rank-log  1619190086.1871173  eval_accuracy: 0.6942228674888611 , global_step: 6372
- AI-Rank-log  1619190130.2087433  eval_accuracy: 0.6937674283981323 , global_step: 6373
- AI-Rank-log  1619190174.1185756  eval_accuracy: 0.694604754447937 , global_step: 6374
- AI-Rank-log  1619190218.0766346  eval_accuracy: 0.6937201023101807 , global_step: 6375
- AI-Rank-log  1619190261.9024627  eval_accuracy: 0.6944110989570618 , global_step: 6376
- AI-Rank-log  1619190305.826689  eval_accuracy: 0.6935092806816101 , global_step: 6377
- AI-Rank-log  1619190349.8750982  eval_accuracy: 0.6943648457527161 , global_step: 6378
- AI-Rank-log  1619190393.8407934  eval_accuracy: 0.6935526728630066 , global_step: 6379
- AI-Rank-log  1619190437.759499  eval_accuracy: 0.6942797899246216 , global_step: 6380
- AI-Rank-log  1619190481.8075125  eval_accuracy: 0.6936097145080566 , global_step: 6381
- AI-Rank-log  1619190525.777051  eval_accuracy: 0.6940006017684937 , global_step: 6382
- AI-Rank-log  1619190569.7347834  eval_accuracy: 0.6938347220420837 , global_step: 6383
- AI-Rank-log  1619190613.713895  eval_accuracy: 0.6947174072265625 , global_step: 6384
- AI-Rank-log  1619190657.6454546  eval_accuracy: 0.6944631338119507 , global_step: 6385
- AI-Rank-log  1619190701.6172829  eval_accuracy: 0.6944926977157593 , global_step: 6386
- AI-Rank-log  1619190745.5985467  eval_accuracy: 0.693640947341919 , global_step: 6387
- AI-Rank-log  1619190789.546052  eval_accuracy: 0.6945268511772156 , global_step: 6388
- AI-Rank-log  1619190833.6012108  eval_accuracy: 0.6942663192749023 , global_step: 6389
- AI-Rank-log  1619190877.5194743  eval_accuracy: 0.6943995952606201 , global_step: 6390
- AI-Rank-log  1619190930.3216286  eval_accuracy: 0.6944804787635803 , global_step: 6391
- AI-Rank-log  1619190974.354523  eval_accuracy: 0.6949324011802673 , global_step: 6392
- AI-Rank-log  1619191018.2935693  eval_accuracy: 0.6945666670799255 , global_step: 6393
- AI-Rank-log  1619191062.2279387  eval_accuracy: 0.6942065954208374 , global_step: 6394
- AI-Rank-log  1619191106.2305286  eval_accuracy: 0.694380521774292 , global_step: 6395
- AI-Rank-log  1619191150.1921313  eval_accuracy: 0.693938136100769 , global_step: 6396
- AI-Rank-log  1619191194.1718714  eval_accuracy: 0.693949282169342 , global_step: 6397
- AI-Rank-log  1619191238.1176538  eval_accuracy: 0.6942141056060791 , global_step: 6398
- AI-Rank-log  1619191282.0795321  eval_accuracy: 0.6940240859985352 , global_step: 6399
- AI-Rank-log  1619191326.1069486  eval_accuracy: 0.6938797235488892 , global_step: 6400
- AI-Rank-log  1619191370.022792  eval_accuracy: 0.6934454441070557 , global_step: 6401
- AI-Rank-log  1619191414.0038147  eval_accuracy: 0.6936099529266357 , global_step: 6402
- AI-Rank-log  1619191458.0256312  eval_accuracy: 0.6935485005378723 , global_step: 6403
- AI-Rank-log  1619191501.935995  eval_accuracy: 0.6935417056083679 , global_step: 6404
- AI-Rank-log  1619191545.8886344  eval_accuracy: 0.6938877701759338 , global_step: 6405
- AI-Rank-log  1619191589.9243684  eval_accuracy: 0.6940513849258423 , global_step: 6406
- AI-Rank-log  1619191633.8505058  eval_accuracy: 0.6945386528968811 , global_step: 6407
- AI-Rank-log  1619191678.679946  eval_accuracy: 0.6945180892944336 , global_step: 6408
- AI-Rank-log  1619191722.681461  eval_accuracy: 0.6939449906349182 , global_step: 6409
- AI-Rank-log  1619191767.263446  eval_accuracy: 0.6944653391838074 , global_step: 6410
- AI-Rank-log  1619191812.1150453  eval_accuracy: 0.6942253112792969 , global_step: 6411
- AI-Rank-log  1619191856.426175  eval_accuracy: 0.6946424841880798 , global_step: 6412
- AI-Rank-log  1619191900.38975  eval_accuracy: 0.6935469508171082 , global_step: 6413
- AI-Rank-log  1619191944.961804  eval_accuracy: 0.6939195394515991 , global_step: 6414
- AI-Rank-log  1619191988.8768954  eval_accuracy: 0.69368976354599 , global_step: 6415
- AI-Rank-log  1619192033.6730833  eval_accuracy: 0.6943543553352356 , global_step: 6416
- AI-Rank-log  1619192077.698766  eval_accuracy: 0.6947160363197327 , global_step: 6417
- AI-Rank-log  1619192122.4414527  eval_accuracy: 0.6940849423408508 , global_step: 6418
- AI-Rank-log  1619192166.5809357  eval_accuracy: 0.6945868134498596 , global_step: 6419
- AI-Rank-log  1619192211.0537965  eval_accuracy: 0.69422847032547 , global_step: 6420
- AI-Rank-log  1619192254.9992712  eval_accuracy: 0.6941312551498413 , global_step: 6421
- AI-Rank-log  1619192299.7623806  eval_accuracy: 0.694044291973114 , global_step: 6422
- AI-Rank-log  1619192343.7164865  eval_accuracy: 0.6939505934715271 , global_step: 6423
- AI-Rank-log  1619192387.7161539  eval_accuracy: 0.6947290897369385 , global_step: 6424
- AI-Rank-log  1619192432.8988335  eval_accuracy: 0.6932316422462463 , global_step: 6425
- AI-Rank-log  1619192476.8694377  eval_accuracy: 0.6948745846748352 , global_step: 6426
- AI-Rank-log  1619192520.818678  eval_accuracy: 0.6938256621360779 , global_step: 6427
- AI-Rank-log  1619192564.8849459  eval_accuracy: 0.6949548721313477 , global_step: 6428
- AI-Rank-log  1619192608.8728724  eval_accuracy: 0.694108247756958 , global_step: 6429
- AI-Rank-log  1619192652.9920611  eval_accuracy: 0.6949947476387024 , global_step: 6430
- AI-Rank-log  1619192697.031263  eval_accuracy: 0.6941637992858887 , global_step: 6431
- AI-Rank-log  1619192740.9963696  eval_accuracy: 0.6944124102592468 , global_step: 6432
- AI-Rank-log  1619192785.034029  eval_accuracy: 0.6940277814865112 , global_step: 6433
- AI-Rank-log  1619192829.0498388  eval_accuracy: 0.6949921250343323 , global_step: 6434
- AI-Rank-log  1619192872.989291  eval_accuracy: 0.6939729452133179 , global_step: 6435
- AI-Rank-log  1619192917.099773  eval_accuracy: 0.6947910189628601 , global_step: 6436
- AI-Rank-log  1619192961.0946338  eval_accuracy: 0.6943726539611816 , global_step: 6437
- AI-Rank-log  1619193005.0184715  eval_accuracy: 0.6947300434112549 , global_step: 6438
- AI-Rank-log  1619193049.0536892  eval_accuracy: 0.6951496005058289 , global_step: 6439
- AI-Rank-log  1619193093.0353744  eval_accuracy: 0.6947786808013916 , global_step: 6440
- AI-Rank-log  1619193137.0327487  eval_accuracy: 0.6947202682495117 , global_step: 6441
- AI-Rank-log  1619193180.9927862  eval_accuracy: 0.6951974034309387 , global_step: 6442
- AI-Rank-log  1619193224.9562154  eval_accuracy: 0.6944918632507324 , global_step: 6443
- AI-Rank-log  1619193268.9332395  eval_accuracy: 0.6951256394386292 , global_step: 6444
- AI-Rank-log  1619193312.889039  eval_accuracy: 0.6948005557060242 , global_step: 6445
- AI-Rank-log  1619193356.8876421  eval_accuracy: 0.6952476501464844 , global_step: 6446
- AI-Rank-log  1619193400.9327378  eval_accuracy: 0.6940668821334839 , global_step: 6447
- AI-Rank-log  1619193444.9000003  eval_accuracy: 0.6952818632125854 , global_step: 6448
- AI-Rank-log  1619193488.87491  eval_accuracy: 0.6951805353164673 , global_step: 6449
- AI-Rank-log  1619193532.853395  eval_accuracy: 0.6953789591789246 , global_step: 6450
- AI-Rank-log  1619193576.8976035  eval_accuracy: 0.6942625641822815 , global_step: 6451
- AI-Rank-log  1619193620.93174  eval_accuracy: 0.6952145099639893 , global_step: 6452
- AI-Rank-log  1619193664.9109535  eval_accuracy: 0.6939606666564941 , global_step: 6453
- AI-Rank-log  1619193708.9033048  eval_accuracy: 0.694675087928772 , global_step: 6454
- AI-Rank-log  1619193752.9177604  eval_accuracy: 0.69496089220047 , global_step: 6455
- AI-Rank-log  1619193796.8532777  eval_accuracy: 0.6948395371437073 , global_step: 6456
- AI-Rank-log  1619193840.8576195  eval_accuracy: 0.6954488158226013 , global_step: 6457
- AI-Rank-log  1619193884.8569791  eval_accuracy: 0.6945761442184448 , global_step: 6458
- AI-Rank-log  1619193928.8149936  eval_accuracy: 0.6948806643486023 , global_step: 6459
- AI-Rank-log  1619193972.7936406  eval_accuracy: 0.695004403591156 , global_step: 6460
- AI-Rank-log  1619194016.8297553  eval_accuracy: 0.694731593132019 , global_step: 6461
- AI-Rank-log  1619194060.7665653  eval_accuracy: 0.6945766806602478 , global_step: 6462
- AI-Rank-log  1619194104.7771578  eval_accuracy: 0.695107638835907 , global_step: 6463
- AI-Rank-log  1619194148.6825178  eval_accuracy: 0.6947812438011169 , global_step: 6464
- AI-Rank-log  1619194192.6467228  eval_accuracy: 0.6949852108955383 , global_step: 6465
- AI-Rank-log  1619194236.735228  eval_accuracy: 0.6946102380752563 , global_step: 6466
- AI-Rank-log  1619194280.7191374  eval_accuracy: 0.6954730153083801 , global_step: 6467
- AI-Rank-log  1619194324.6843367  eval_accuracy: 0.6942707896232605 , global_step: 6468
- AI-Rank-log  1619194368.7267447  eval_accuracy: 0.6952627897262573 , global_step: 6469
- AI-Rank-log  1619194412.6795897  eval_accuracy: 0.6944937109947205 , global_step: 6470
- AI-Rank-log  1619194456.6321793  eval_accuracy: 0.6959469318389893 , global_step: 6471
- AI-Rank-log  1619194500.6576428  eval_accuracy: 0.6946094632148743 , global_step: 6472
- AI-Rank-log  1619194544.6235657  eval_accuracy: 0.6957341432571411 , global_step: 6473
- AI-Rank-log  1619194588.6964896  eval_accuracy: 0.6948565244674683 , global_step: 6474
- AI-Rank-log  1619194632.6690156  eval_accuracy: 0.6954694986343384 , global_step: 6475
- AI-Rank-log  1619194676.6244557  eval_accuracy: 0.6960069537162781 , global_step: 6476
- AI-Rank-log  1619194720.6855214  eval_accuracy: 0.6945958733558655 , global_step: 6477
- AI-Rank-log  1619194764.6859453  eval_accuracy: 0.6952263116836548 , global_step: 6478
- AI-Rank-log  1619194808.6189005  eval_accuracy: 0.6953497529029846 , global_step: 6479
- AI-Rank-log  1619194852.654353  eval_accuracy: 0.6949012875556946 , global_step: 6480
- AI-Rank-log  1619194896.6168585  eval_accuracy: 0.6956741809844971 , global_step: 6481
- AI-Rank-log  1619194940.5770752  eval_accuracy: 0.6954906582832336 , global_step: 6482
- AI-Rank-log  1619194984.6025627  eval_accuracy: 0.6957942247390747 , global_step: 6483
- AI-Rank-log  1619195028.5372667  eval_accuracy: 0.695468008518219 , global_step: 6484
- AI-Rank-log  1619195073.5007057  eval_accuracy: 0.6957953572273254 , global_step: 6485
- AI-Rank-log  1619195117.8034317  eval_accuracy: 0.6957937479019165 , global_step: 6486
- AI-Rank-log  1619195161.7549775  eval_accuracy: 0.6957518458366394 , global_step: 6487
- AI-Rank-log  1619195205.7991412  eval_accuracy: 0.6952361464500427 , global_step: 6488
- AI-Rank-log  1619195250.2130897  eval_accuracy: 0.6960290670394897 , global_step: 6489
- AI-Rank-log  1619195294.1738937  eval_accuracy: 0.6949823498725891 , global_step: 6490
- AI-Rank-log  1619195338.7344873  eval_accuracy: 0.6954814791679382 , global_step: 6491
- AI-Rank-log  1619195382.7033029  eval_accuracy: 0.6951879262924194 , global_step: 6492
- AI-Rank-log  1619195427.07618  eval_accuracy: 0.6956507563591003 , global_step: 6493
- AI-Rank-log  1619195471.0692217  eval_accuracy: 0.6950582265853882 , global_step: 6494
- AI-Rank-log  1619195515.11399  eval_accuracy: 0.6954201459884644 , global_step: 6495
- AI-Rank-log  1619195559.69711  eval_accuracy: 0.6951163411140442 , global_step: 6496
- AI-Rank-log  1619195603.6751468  eval_accuracy: 0.6952642202377319 , global_step: 6497
- AI-Rank-log  1619195648.4888277  eval_accuracy: 0.6952962875366211 , global_step: 6498
- AI-Rank-log  1619195692.4876509  eval_accuracy: 0.6955968141555786 , global_step: 6499
- AI-Rank-log  1619195737.0362158  eval_accuracy: 0.6958364248275757 , global_step: 6500
- AI-Rank-log  1619195781.0582125  eval_accuracy: 0.6953335404396057 , global_step: 6501
- AI-Rank-log  1619195825.1074882  eval_accuracy: 0.6958019137382507 , global_step: 6502
- AI-Rank-log  1619195870.143626  eval_accuracy: 0.6950459480285645 , global_step: 6503
- AI-Rank-log  1619195914.103466  eval_accuracy: 0.6952521800994873 , global_step: 6504
- AI-Rank-log  1619195958.0919876  eval_accuracy: 0.6947252154350281 , global_step: 6505
- AI-Rank-log  1619196002.0314963  eval_accuracy: 0.6951994299888611 , global_step: 6506
- AI-Rank-log  1619196046.9579659  eval_accuracy: 0.6945916414260864 , global_step: 6507
- AI-Rank-log  1619196090.8992476  eval_accuracy: 0.6955965161323547 , global_step: 6508
- AI-Rank-log  1619196134.8831131  eval_accuracy: 0.6956598162651062 , global_step: 6509
- AI-Rank-log  1619196178.9237537  eval_accuracy: 0.695418655872345 , global_step: 6510
- AI-Rank-log  1619196222.8794563  eval_accuracy: 0.6955973505973816 , global_step: 6511
- AI-Rank-log  1619196266.8713632  eval_accuracy: 0.6957256197929382 , global_step: 6512
- AI-Rank-log  1619196310.8821557  eval_accuracy: 0.6957723498344421 , global_step: 6513
- AI-Rank-log  1619196354.8051367  eval_accuracy: 0.6960668563842773 , global_step: 6514
- AI-Rank-log  1619196398.853226  eval_accuracy: 0.6953222751617432 , global_step: 6515
- AI-Rank-log  1619196442.8090854  eval_accuracy: 0.6957585215568542 , global_step: 6516
- AI-Rank-log  1619196486.752869  eval_accuracy: 0.6956235766410828 , global_step: 6517
- AI-Rank-log  1619196530.7888627  eval_accuracy: 0.6956782937049866 , global_step: 6518
- AI-Rank-log  1619196574.726068  eval_accuracy: 0.6962104439735413 , global_step: 6519
- AI-Rank-log  1619196618.7299094  eval_accuracy: 0.6952316761016846 , global_step: 6520
- AI-Rank-log  1619196662.7807457  eval_accuracy: 0.6952694654464722 , global_step: 6521
- AI-Rank-log  1619196706.7126296  eval_accuracy: 0.6949847936630249 , global_step: 6522
- AI-Rank-log  1619196750.664454  eval_accuracy: 0.6952781081199646 , global_step: 6523
- AI-Rank-log  1619196794.7290745  eval_accuracy: 0.6948325037956238 , global_step: 6524
- AI-Rank-log  1619196838.7032142  eval_accuracy: 0.6948117017745972 , global_step: 6525
- AI-Rank-log  1619196882.5205338  eval_accuracy: 0.6944023370742798 , global_step: 6526
- AI-Rank-log  1619196926.5120115  eval_accuracy: 0.6953216195106506 , global_step: 6527
- AI-Rank-log  1619196970.4509022  eval_accuracy: 0.6955159902572632 , global_step: 6528
- AI-Rank-log  1619197014.4641566  eval_accuracy: 0.695477306842804 , global_step: 6529
- AI-Rank-log  1619197058.424018  eval_accuracy: 0.6949869990348816 , global_step: 6530
- AI-Rank-log  1619197102.4133844  eval_accuracy: 0.6950352191925049 , global_step: 6531
- AI-Rank-log  1619197146.4334462  eval_accuracy: 0.6957899928092957 , global_step: 6532
- AI-Rank-log  1619197190.3825004  eval_accuracy: 0.6952748894691467 , global_step: 6533
- AI-Rank-log  1619197234.3307788  eval_accuracy: 0.6956959366798401 , global_step: 6534
- AI-Rank-log  1619197278.3179553  eval_accuracy: 0.6947876214981079 , global_step: 6535
- AI-Rank-log  1619197322.3267255  eval_accuracy: 0.6955869793891907 , global_step: 6536
- AI-Rank-log  1619197366.3836257  eval_accuracy: 0.6949872970581055 , global_step: 6537
- AI-Rank-log  1619197410.4224656  eval_accuracy: 0.6955942511558533 , global_step: 6538
- AI-Rank-log  1619197454.3482597  eval_accuracy: 0.6953561305999756 , global_step: 6539
- AI-Rank-log  1619197498.4208045  eval_accuracy: 0.6949763298034668 , global_step: 6540
- AI-Rank-log  1619197542.3846815  eval_accuracy: 0.6946666240692139 , global_step: 6541
- AI-Rank-log  1619197586.35239  eval_accuracy: 0.6953312754631042 , global_step: 6542
- AI-Rank-log  1619197630.3745675  eval_accuracy: 0.6954719424247742 , global_step: 6543
- AI-Rank-log  1619197674.364359  eval_accuracy: 0.6952946782112122 , global_step: 6544
- AI-Rank-log  1619197718.2879283  eval_accuracy: 0.6955121755599976 , global_step: 6545
- AI-Rank-log  1619197762.2944438  eval_accuracy: 0.695823609828949 , global_step: 6546
- AI-Rank-log  1619197806.2435544  eval_accuracy: 0.695720374584198 , global_step: 6547
- AI-Rank-log  1619197850.049307  eval_accuracy: 0.6957319974899292 , global_step: 6548
- AI-Rank-log  1619197893.9989192  eval_accuracy: 0.6959482431411743 , global_step: 6549
- AI-Rank-log  1619197937.996527  eval_accuracy: 0.6957014203071594 , global_step: 6550
- AI-Rank-log  1619197981.9472735  eval_accuracy: 0.6955815553665161 , global_step: 6551
- AI-Rank-log  1619198025.9173949  eval_accuracy: 0.6953268051147461 , global_step: 6552
- AI-Rank-log  1619198069.8901625  eval_accuracy: 0.6955191493034363 , global_step: 6553
- AI-Rank-log  1619198113.8921456  eval_accuracy: 0.6952821612358093 , global_step: 6554
- AI-Rank-log  1619198157.953547  eval_accuracy: 0.6958102583885193 , global_step: 6555
- AI-Rank-log  1619198201.9081504  eval_accuracy: 0.6948625445365906 , global_step: 6556
- AI-Rank-log  1619198245.8995166  eval_accuracy: 0.6959908604621887 , global_step: 6557
- AI-Rank-log  1619198289.8564444  eval_accuracy: 0.695494532585144 , global_step: 6558
- AI-Rank-log  1619198333.8364162  eval_accuracy: 0.6952579021453857 , global_step: 6559
- AI-Rank-log  1619198377.767065  eval_accuracy: 0.6957982182502747 , global_step: 6560
- AI-Rank-log  1619198421.7516935  eval_accuracy: 0.6956086754798889 , global_step: 6561
- AI-Rank-log  1619198465.7303193  eval_accuracy: 0.6958774924278259 , global_step: 6562
- AI-Rank-log  1619198510.652354  eval_accuracy: 0.6954721212387085 , global_step: 6563
- AI-Rank-log  1619198555.0226252  eval_accuracy: 0.6953270435333252 , global_step: 6564
- AI-Rank-log  1619198599.0372577  eval_accuracy: 0.6950796246528625 , global_step: 6565
- AI-Rank-log  1619198643.0258536  eval_accuracy: 0.6962903738021851 , global_step: 6566
- AI-Rank-log  1619198687.7592232  eval_accuracy: 0.695107638835907 , global_step: 6567
- AI-Rank-log  1619198731.7766197  eval_accuracy: 0.6954484581947327 , global_step: 6568
- AI-Rank-log  1619198776.0421436  eval_accuracy: 0.6948056817054749 , global_step: 6569
- AI-Rank-log  1619198820.0743046  eval_accuracy: 0.6952887177467346 , global_step: 6570
- AI-Rank-log  1619198864.1841931  eval_accuracy: 0.6952577233314514 , global_step: 6571
- AI-Rank-log  1619198908.2115955  eval_accuracy: 0.6952353715896606 , global_step: 6572
- AI-Rank-log  1619198953.0372722  eval_accuracy: 0.6953367590904236 , global_step: 6573
- AI-Rank-log  1619198996.9834158  eval_accuracy: 0.6950413584709167 , global_step: 6574
- AI-Rank-log  1619199040.9220638  eval_accuracy: 0.6949530839920044 , global_step: 6575
- AI-Rank-log  1619199085.1350367  eval_accuracy: 0.6950281262397766 , global_step: 6576
- AI-Rank-log  1619199129.0720906  eval_accuracy: 0.6953426003456116 , global_step: 6577
- AI-Rank-log  1619199173.5867796  eval_accuracy: 0.6946521997451782 , global_step: 6578
- AI-Rank-log  1619199217.6620834  eval_accuracy: 0.6950469613075256 , global_step: 6579
- AI-Rank-log  1619199262.8891988  eval_accuracy: 0.6949747800827026 , global_step: 6580
- AI-Rank-log  1619199306.9391036  eval_accuracy: 0.6950907111167908 , global_step: 6581
- AI-Rank-log  1619199350.8988595  eval_accuracy: 0.6944910287857056 , global_step: 6582
- AI-Rank-log  1619199394.8672771  eval_accuracy: 0.6951180696487427 , global_step: 6583
- AI-Rank-log  1619199438.9507623  eval_accuracy: 0.6948763728141785 , global_step: 6584
- AI-Rank-log  1619199483.1400924  eval_accuracy: 0.6952484846115112 , global_step: 6585
- AI-Rank-log  1619199527.1617563  eval_accuracy: 0.6948029398918152 , global_step: 6586
- AI-Rank-log  1619199571.1858618  eval_accuracy: 0.695354700088501 , global_step: 6587
- AI-Rank-log  1619199615.1215699  eval_accuracy: 0.6944773197174072 , global_step: 6588
- AI-Rank-log  1619199659.0721774  eval_accuracy: 0.6953914761543274 , global_step: 6589
- AI-Rank-log  1619199703.0621705  eval_accuracy: 0.6958233118057251 , global_step: 6590
- AI-Rank-log  1619199756.023666  eval_accuracy: 0.6956385374069214 , global_step: 6591
- AI-Rank-log  1619199799.9764225  eval_accuracy: 0.6950174570083618 , global_step: 6592
- AI-Rank-log  1619199843.9288979  eval_accuracy: 0.6949763894081116 , global_step: 6593
- AI-Rank-log  1619199887.8972895  eval_accuracy: 0.6941342353820801 , global_step: 6594
- AI-Rank-log  1619199931.884326  eval_accuracy: 0.6953978538513184 , global_step: 6595
- AI-Rank-log  1619199975.8910997  eval_accuracy: 0.6950705647468567 , global_step: 6596
- AI-Rank-log  1619200019.883315  eval_accuracy: 0.6955282092094421 , global_step: 6597
- AI-Rank-log  1619200063.885059  eval_accuracy: 0.6949108839035034 , global_step: 6598
- AI-Rank-log  1619200107.8108368  eval_accuracy: 0.6963005661964417 , global_step: 6599
- AI-Rank-log  1619200151.7735627  eval_accuracy: 0.6956077814102173 , global_step: 6600
- AI-Rank-log  1619200195.7798495  eval_accuracy: 0.6960244178771973 , global_step: 6601
- AI-Rank-log  1619200239.766971  eval_accuracy: 0.6954661011695862 , global_step: 6602
- AI-Rank-log  1619200283.7510254  eval_accuracy: 0.6962171196937561 , global_step: 6603
- AI-Rank-log  1619200327.6717582  eval_accuracy: 0.6958602666854858 , global_step: 6604
- AI-Rank-log  1619200371.6234584  eval_accuracy: 0.6961067914962769 , global_step: 6605
- AI-Rank-log  1619200415.6681623  eval_accuracy: 0.695469081401825 , global_step: 6606
- AI-Rank-log  1619200459.6252434  eval_accuracy: 0.6951266527175903 , global_step: 6607
- AI-Rank-log  1619200503.5604312  eval_accuracy: 0.6956169009208679 , global_step: 6608
- AI-Rank-log  1619200547.6084216  eval_accuracy: 0.6956685185432434 , global_step: 6609
- AI-Rank-log  1619200591.3591201  eval_accuracy: 0.6957636475563049 , global_step: 6610
- AI-Rank-log  1619200635.3165276  eval_accuracy: 0.6956461668014526 , global_step: 6611
- AI-Rank-log  1619200679.3453324  eval_accuracy: 0.695249617099762 , global_step: 6612
- AI-Rank-log  1619200723.2909791  eval_accuracy: 0.6957002282142639 , global_step: 6613
- AI-Rank-log  1619200767.24991  eval_accuracy: 0.6961118578910828 , global_step: 6614
- AI-Rank-log  1619200811.2151942  eval_accuracy: 0.6954427361488342 , global_step: 6615
- AI-Rank-log  1619200855.1870806  eval_accuracy: 0.6951616406440735 , global_step: 6616
- AI-Rank-log  1619200899.2433417  eval_accuracy: 0.6956931948661804 , global_step: 6617
- AI-Rank-log  1619200943.2280686  eval_accuracy: 0.6956788897514343 , global_step: 6618
- AI-Rank-log  1619200987.191406  eval_accuracy: 0.6959548592567444 , global_step: 6619
- AI-Rank-log  1619201031.2248144  eval_accuracy: 0.6956847906112671 , global_step: 6620
- AI-Rank-log  1619201075.1955051  eval_accuracy: 0.6961096525192261 , global_step: 6621
- AI-Rank-log  1619201119.1652794  eval_accuracy: 0.6957358121871948 , global_step: 6622
- AI-Rank-log  1619201163.1619027  eval_accuracy: 0.6953713893890381 , global_step: 6623
- AI-Rank-log  1619201207.1087015  eval_accuracy: 0.6954482793807983 , global_step: 6624
- AI-Rank-log  1619201251.134246  eval_accuracy: 0.6957512497901917 , global_step: 6625
- AI-Rank-log  1619201295.0669134  eval_accuracy: 0.6958702802658081 , global_step: 6626
- AI-Rank-log  1619201338.9875617  eval_accuracy: 0.6960800886154175 , global_step: 6627
- AI-Rank-log  1619201383.0239956  eval_accuracy: 0.6955995559692383 , global_step: 6628
- AI-Rank-log  1619201426.9808764  eval_accuracy: 0.6958221793174744 , global_step: 6629
- AI-Rank-log  1619201470.9350617  eval_accuracy: 0.6954420208930969 , global_step: 6630
- AI-Rank-log  1619201514.961803  eval_accuracy: 0.696533739566803 , global_step: 6631
- AI-Rank-log  1619201558.8981898  eval_accuracy: 0.6948224902153015 , global_step: 6632
- AI-Rank-log  1619201602.905561  eval_accuracy: 0.6962369680404663 , global_step: 6633
- AI-Rank-log  1619201646.9670532  eval_accuracy: 0.6955195665359497 , global_step: 6634
- AI-Rank-log  1619201690.907692  eval_accuracy: 0.6961978673934937 , global_step: 6635
- AI-Rank-log  1619201734.9302146  eval_accuracy: 0.6965464949607849 , global_step: 6636
- AI-Rank-log  1619201778.9334106  eval_accuracy: 0.6957107186317444 , global_step: 6637
- AI-Rank-log  1619201822.8718717  eval_accuracy: 0.6965978741645813 , global_step: 6638
- AI-Rank-log  1619201866.8709583  eval_accuracy: 0.6963117718696594 , global_step: 6639
- AI-Rank-log  1619201911.6967545  eval_accuracy: 0.6962491869926453 , global_step: 6640
- AI-Rank-log  1619201955.9130752  eval_accuracy: 0.6958234310150146 , global_step: 6641
- AI-Rank-log  1619201999.9350576  eval_accuracy: 0.6964290738105774 , global_step: 6642
- AI-Rank-log  1619202043.9086523  eval_accuracy: 0.6958912014961243 , global_step: 6643
- AI-Rank-log  1619202087.822008  eval_accuracy: 0.6968951225280762 , global_step: 6644
- AI-Rank-log  1619202133.1524088  eval_accuracy: 0.6956880688667297 , global_step: 6645
- AI-Rank-log  1619202177.5633445  eval_accuracy: 0.6965722441673279 , global_step: 6646
- AI-Rank-log  1619202221.545937  eval_accuracy: 0.6954968571662903 , global_step: 6647
- AI-Rank-log  1619202265.6703837  eval_accuracy: 0.6961287260055542 , global_step: 6648
- AI-Rank-log  1619202309.9182758  eval_accuracy: 0.6966487169265747 , global_step: 6649
- AI-Rank-log  1619202353.906417  eval_accuracy: 0.6961514353752136 , global_step: 6650
- AI-Rank-log  1619202399.4352176  eval_accuracy: 0.6957876086235046 , global_step: 6651
- AI-Rank-log  1619202444.2257528  eval_accuracy: 0.6964834928512573 , global_step: 6652
- AI-Rank-log  1619202488.4429078  eval_accuracy: 0.6962403059005737 , global_step: 6653
- AI-Rank-log  1619202532.4220989  eval_accuracy: 0.6965183615684509 , global_step: 6654
- AI-Rank-log  1619202577.2633355  eval_accuracy: 0.6971335411071777 , global_step: 6655
- AI-Rank-log  1619202621.3530715  eval_accuracy: 0.6958967447280884 , global_step: 6656
- AI-Rank-log  1619202665.387142  eval_accuracy: 0.6963040828704834 , global_step: 6657
- AI-Rank-log  1619202710.4654233  eval_accuracy: 0.6963175535202026 , global_step: 6658
- AI-Rank-log  1619202754.342284  eval_accuracy: 0.6959150433540344 , global_step: 6659
- AI-Rank-log  1619202798.2926188  eval_accuracy: 0.6960412859916687 , global_step: 6660
- AI-Rank-log  1619202842.289777  eval_accuracy: 0.6958929300308228 , global_step: 6661
- AI-Rank-log  1619202886.2027512  eval_accuracy: 0.6959598064422607 , global_step: 6662
- AI-Rank-log  1619202930.5945146  eval_accuracy: 0.6954154372215271 , global_step: 6663
- AI-Rank-log  1619202974.5643942  eval_accuracy: 0.6958633065223694 , global_step: 6664
- AI-Rank-log  1619203018.4681838  eval_accuracy: 0.6953850388526917 , global_step: 6665
- AI-Rank-log  1619203062.468137  eval_accuracy: 0.6961171627044678 , global_step: 6666
- AI-Rank-log  1619203106.5207982  eval_accuracy: 0.6951975226402283 , global_step: 6667
- AI-Rank-log  1619203150.4409592  eval_accuracy: 0.6963230967521667 , global_step: 6668
- AI-Rank-log  1619203194.4200835  eval_accuracy: 0.6960042715072632 , global_step: 6669
- AI-Rank-log  1619203238.41778  eval_accuracy: 0.6964609026908875 , global_step: 6670
- AI-Rank-log  1619203282.3711395  eval_accuracy: 0.6964166164398193 , global_step: 6671
- AI-Rank-log  1619203326.3950324  eval_accuracy: 0.696112334728241 , global_step: 6672
- AI-Rank-log  1619203370.3264818  eval_accuracy: 0.6968500018119812 , global_step: 6673
- AI-Rank-log  1619203414.3062434  eval_accuracy: 0.6961818933486938 , global_step: 6674
- AI-Rank-log  1619203458.3315856  eval_accuracy: 0.6963496208190918 , global_step: 6675
- AI-Rank-log  1619203502.2118573  eval_accuracy: 0.6960574388504028 , global_step: 6676
- AI-Rank-log  1619203546.1683867  eval_accuracy: 0.696384072303772 , global_step: 6677
- AI-Rank-log  1619203590.2316053  eval_accuracy: 0.6957551836967468 , global_step: 6678
- AI-Rank-log  1619203634.1428566  eval_accuracy: 0.6964042782783508 , global_step: 6679
- AI-Rank-log  1619203678.2197483  eval_accuracy: 0.6963269114494324 , global_step: 6680
- AI-Rank-log  1619203722.1864655  eval_accuracy: 0.6962636709213257 , global_step: 6681
- AI-Rank-log  1619203766.099427  eval_accuracy: 0.6965225338935852 , global_step: 6682
- AI-Rank-log  1619203810.134866  eval_accuracy: 0.6968687772750854 , global_step: 6683
- AI-Rank-log  1619203854.1039984  eval_accuracy: 0.6961885094642639 , global_step: 6684
- AI-Rank-log  1619203898.0469716  eval_accuracy: 0.695830762386322 , global_step: 6685
- AI-Rank-log  1619203942.069379  eval_accuracy: 0.6955531239509583 , global_step: 6686
- AI-Rank-log  1619203985.9979265  eval_accuracy: 0.6959035396575928 , global_step: 6687
- AI-Rank-log  1619204029.903113  eval_accuracy: 0.696073591709137 , global_step: 6688
- AI-Rank-log  1619204073.9412546  eval_accuracy: 0.6949430704116821 , global_step: 6689
- AI-Rank-log  1619204117.8627305  eval_accuracy: 0.6963111758232117 , global_step: 6690
- AI-Rank-log  1619204161.8720553  eval_accuracy: 0.6948668360710144 , global_step: 6691
- AI-Rank-log  1619204205.8296165  eval_accuracy: 0.6959380507469177 , global_step: 6692
- AI-Rank-log  1619204249.7369268  eval_accuracy: 0.6953643560409546 , global_step: 6693
- AI-Rank-log  1619204293.738411  eval_accuracy: 0.695722222328186 , global_step: 6694
- AI-Rank-log  1619204337.6707826  eval_accuracy: 0.695252001285553 , global_step: 6695
- AI-Rank-log  1619204381.5912607  eval_accuracy: 0.6961086988449097 , global_step: 6696
- AI-Rank-log  1619204425.6202075  eval_accuracy: 0.6951864957809448 , global_step: 6697
- AI-Rank-log  1619204469.5943637  eval_accuracy: 0.6958954930305481 , global_step: 6698
- AI-Rank-log  1619204513.5096714  eval_accuracy: 0.6955057978630066 , global_step: 6699
- AI-Rank-log  1619204557.5359404  eval_accuracy: 0.6966298818588257 , global_step: 6700
- AI-Rank-log  1619204601.5111573  eval_accuracy: 0.6958454251289368 , global_step: 6701
- AI-Rank-log  1619204645.5461748  eval_accuracy: 0.696131706237793 , global_step: 6702
- AI-Rank-log  1619204689.4926877  eval_accuracy: 0.6962804794311523 , global_step: 6703
- AI-Rank-log  1619204733.3872087  eval_accuracy: 0.6961545944213867 , global_step: 6704
- AI-Rank-log  1619204777.3470933  eval_accuracy: 0.6961863040924072 , global_step: 6705
- AI-Rank-log  1619204821.352504  eval_accuracy: 0.6961497664451599 , global_step: 6706
- AI-Rank-log  1619204865.2977157  eval_accuracy: 0.6961135864257812 , global_step: 6707
- AI-Rank-log  1619204909.259252  eval_accuracy: 0.6961527466773987 , global_step: 6708
- AI-Rank-log  1619204953.2535274  eval_accuracy: 0.6955121755599976 , global_step: 6709
- AI-Rank-log  1619204997.1813295  eval_accuracy: 0.6963935494422913 , global_step: 6710
- AI-Rank-log  1619205041.216763  eval_accuracy: 0.6956131458282471 , global_step: 6711
- AI-Rank-log  1619205085.1478467  eval_accuracy: 0.6955043077468872 , global_step: 6712
- AI-Rank-log  1619205129.1410394  eval_accuracy: 0.6952821612358093 , global_step: 6713
- AI-Rank-log  1619205173.0578365  eval_accuracy: 0.6961624026298523 , global_step: 6714
- AI-Rank-log  1619205217.04842  eval_accuracy: 0.6958995461463928 , global_step: 6715
- AI-Rank-log  1619205261.0292091  eval_accuracy: 0.6958428025245667 , global_step: 6716
- AI-Rank-log  1619205304.9856603  eval_accuracy: 0.69600510597229 , global_step: 6717
- AI-Rank-log  1619205350.019955  eval_accuracy: 0.6958305239677429 , global_step: 6718
- AI-Rank-log  1619205393.9693627  eval_accuracy: 0.695955753326416 , global_step: 6719
- AI-Rank-log  1619205437.9639468  eval_accuracy: 0.6956064105033875 , global_step: 6720
- AI-Rank-log  1619205481.907734  eval_accuracy: 0.6956154704093933 , global_step: 6721
- AI-Rank-log  1619205526.4616394  eval_accuracy: 0.6958205103874207 , global_step: 6722
- AI-Rank-log  1619205570.493739  eval_accuracy: 0.6955571174621582 , global_step: 6723
- AI-Rank-log  1619205614.8356473  eval_accuracy: 0.6957445740699768 , global_step: 6724
- AI-Rank-log  1619205659.0683954  eval_accuracy: 0.6953654885292053 , global_step: 6725
- AI-Rank-log  1619205703.02799  eval_accuracy: 0.6960139870643616 , global_step: 6726
- AI-Rank-log  1619205747.1777968  eval_accuracy: 0.6954164505004883 , global_step: 6727
- AI-Rank-log  1619205792.0602763  eval_accuracy: 0.6960121989250183 , global_step: 6728
- AI-Rank-log  1619205836.0465016  eval_accuracy: 0.6961056590080261 , global_step: 6729
- AI-Rank-log  1619205880.07681  eval_accuracy: 0.6967878341674805 , global_step: 6730
- AI-Rank-log  1619205924.17158  eval_accuracy: 0.6959755420684814 , global_step: 6731
- AI-Rank-log  1619205968.1841846  eval_accuracy: 0.6959631443023682 , global_step: 6732
- AI-Rank-log  1619206012.815125  eval_accuracy: 0.6950481534004211 , global_step: 6733
- AI-Rank-log  1619206056.78801  eval_accuracy: 0.6968607306480408 , global_step: 6734
- AI-Rank-log  1619206102.0853047  eval_accuracy: 0.6961137056350708 , global_step: 6735
- AI-Rank-log  1619206146.070007  eval_accuracy: 0.6965704560279846 , global_step: 6736
- AI-Rank-log  1619206190.0288665  eval_accuracy: 0.6966181993484497 , global_step: 6737
- AI-Rank-log  1619206234.0867972  eval_accuracy: 0.696243941783905 , global_step: 6738
- AI-Rank-log  1619206278.0348792  eval_accuracy: 0.6972007751464844 , global_step: 6739
- AI-Rank-log  1619206321.9774094  eval_accuracy: 0.6966611742973328 , global_step: 6740
- AI-Rank-log  1619206366.5065572  eval_accuracy: 0.6973379254341125 , global_step: 6741
- AI-Rank-log  1619206410.4995728  eval_accuracy: 0.6964390873908997 , global_step: 6742
- AI-Rank-log  1619206454.4795666  eval_accuracy: 0.6968755125999451 , global_step: 6743
- AI-Rank-log  1619206498.499345  eval_accuracy: 0.6963476538658142 , global_step: 6744
- AI-Rank-log  1619206542.4573874  eval_accuracy: 0.696823000907898 , global_step: 6745
- AI-Rank-log  1619206586.4134438  eval_accuracy: 0.6960359811782837 , global_step: 6746
- AI-Rank-log  1619206630.4487364  eval_accuracy: 0.6970402598381042 , global_step: 6747
- AI-Rank-log  1619206674.3851318  eval_accuracy: 0.6965371370315552 , global_step: 6748
- AI-Rank-log  1619206718.4720385  eval_accuracy: 0.6973945498466492 , global_step: 6749
- AI-Rank-log  1619206762.4248338  eval_accuracy: 0.696222186088562 , global_step: 6750
- AI-Rank-log  1619206806.3917942  eval_accuracy: 0.6974323391914368 , global_step: 6751
- AI-Rank-log  1619206850.431935  eval_accuracy: 0.6967440843582153 , global_step: 6752
- AI-Rank-log  1619206894.380484  eval_accuracy: 0.6971423029899597 , global_step: 6753
- AI-Rank-log  1619206938.2741394  eval_accuracy: 0.6973000764846802 , global_step: 6754
- AI-Rank-log  1619206982.3793354  eval_accuracy: 0.6970117688179016 , global_step: 6755
- AI-Rank-log  1619207026.3435135  eval_accuracy: 0.6973055601119995 , global_step: 6756
- AI-Rank-log  1619207070.3197014  eval_accuracy: 0.6963188648223877 , global_step: 6757
- AI-Rank-log  1619207114.3701339  eval_accuracy: 0.6972763538360596 , global_step: 6758
- AI-Rank-log  1619207158.435671  eval_accuracy: 0.6969144940376282 , global_step: 6759
- AI-Rank-log  1619207202.4496076  eval_accuracy: 0.6974323391914368 , global_step: 6760
- AI-Rank-log  1619207246.4690604  eval_accuracy: 0.697228729724884 , global_step: 6761
- AI-Rank-log  1619207290.4136178  eval_accuracy: 0.6967774629592896 , global_step: 6762
- AI-Rank-log  1619207334.437765  eval_accuracy: 0.697542667388916 , global_step: 6763
- AI-Rank-log  1619207378.3888762  eval_accuracy: 0.6964405179023743 , global_step: 6764
- AI-Rank-log  1619207422.3540895  eval_accuracy: 0.6976064443588257 , global_step: 6765
- AI-Rank-log  1619207466.3513682  eval_accuracy: 0.6968933939933777 , global_step: 6766
- AI-Rank-log  1619207510.365544  eval_accuracy: 0.6972140669822693 , global_step: 6767
- AI-Rank-log  1619207554.3676581  eval_accuracy: 0.6964166760444641 , global_step: 6768
- AI-Rank-log  1619207598.3138382  eval_accuracy: 0.6974658370018005 , global_step: 6769
- AI-Rank-log  1619207642.3045285  eval_accuracy: 0.697023868560791 , global_step: 6770
- AI-Rank-log  1619207686.3080075  eval_accuracy: 0.6959373950958252 , global_step: 6771
- AI-Rank-log  1619207730.2721698  eval_accuracy: 0.6964035630226135 , global_step: 6772
- AI-Rank-log  1619207774.2679327  eval_accuracy: 0.6965422034263611 , global_step: 6773
- AI-Rank-log  1619207818.3106565  eval_accuracy: 0.6961097717285156 , global_step: 6774
- AI-Rank-log  1619207862.2770357  eval_accuracy: 0.6966784000396729 , global_step: 6775
- AI-Rank-log  1619207906.263286  eval_accuracy: 0.6965944766998291 , global_step: 6776
- AI-Rank-log  1619207950.285123  eval_accuracy: 0.6963285803794861 , global_step: 6777
- AI-Rank-log  1619207994.2273567  eval_accuracy: 0.6969862580299377 , global_step: 6778
- AI-Rank-log  1619208038.375367  eval_accuracy: 0.6968522667884827 , global_step: 6779
- AI-Rank-log  1619208082.3671548  eval_accuracy: 0.6969908475875854 , global_step: 6780
- AI-Rank-log  1619208126.360531  eval_accuracy: 0.6964722871780396 , global_step: 6781
- AI-Rank-log  1619208170.412728  eval_accuracy: 0.69694584608078 , global_step: 6782
- AI-Rank-log  1619208214.3524556  eval_accuracy: 0.6972864866256714 , global_step: 6783
- AI-Rank-log  1619208258.3261647  eval_accuracy: 0.6961593627929688 , global_step: 6784
- AI-Rank-log  1619208302.3688228  eval_accuracy: 0.6968061923980713 , global_step: 6785
- AI-Rank-log  1619208346.2801178  eval_accuracy: 0.6970443725585938 , global_step: 6786
- AI-Rank-log  1619208390.2801816  eval_accuracy: 0.6970053911209106 , global_step: 6787
- AI-Rank-log  1619208434.299353  eval_accuracy: 0.6978181600570679 , global_step: 6788
- AI-Rank-log  1619208478.239908  eval_accuracy: 0.6970746517181396 , global_step: 6789
- AI-Rank-log  1619208522.265251  eval_accuracy: 0.6967490315437317 , global_step: 6790
- AI-Rank-log  1619208575.247737  eval_accuracy: 0.6970471739768982 , global_step: 6791
- AI-Rank-log  1619208619.13211  eval_accuracy: 0.6973782777786255 , global_step: 6792
- AI-Rank-log  1619208663.123777  eval_accuracy: 0.6971662044525146 , global_step: 6793
- AI-Rank-log  1619208707.0945165  eval_accuracy: 0.6969553828239441 , global_step: 6794
- AI-Rank-log  1619208752.0155165  eval_accuracy: 0.69614177942276 , global_step: 6795
- AI-Rank-log  1619208796.08031  eval_accuracy: 0.696453869342804 , global_step: 6796
- AI-Rank-log  1619208840.0440185  eval_accuracy: 0.6966158151626587 , global_step: 6797
- AI-Rank-log  1619208883.974906  eval_accuracy: 0.6965817809104919 , global_step: 6798
- AI-Rank-log  1619208928.0008497  eval_accuracy: 0.6964304447174072 , global_step: 6799
- AI-Rank-log  1619208972.3267024  eval_accuracy: 0.6964807510375977 , global_step: 6800
- AI-Rank-log  1619209016.8747332  eval_accuracy: 0.6968042850494385 , global_step: 6801
- AI-Rank-log  1619209060.851868  eval_accuracy: 0.6968244910240173 , global_step: 6802
- AI-Rank-log  1619209105.0659049  eval_accuracy: 0.6971900463104248 , global_step: 6803
- AI-Rank-log  1619209149.0226238  eval_accuracy: 0.6972598433494568 , global_step: 6804
- AI-Rank-log  1619209192.9847717  eval_accuracy: 0.6966666579246521 , global_step: 6805
- AI-Rank-log  1619209238.0385294  eval_accuracy: 0.6967261433601379 , global_step: 6806
- AI-Rank-log  1619209282.0504122  eval_accuracy: 0.6969115138053894 , global_step: 6807
- AI-Rank-log  1619209326.6700218  eval_accuracy: 0.6974912285804749 , global_step: 6808
- AI-Rank-log  1619209370.6815252  eval_accuracy: 0.696948766708374 , global_step: 6809
- AI-Rank-log  1619209415.422064  eval_accuracy: 0.6977682709693909 , global_step: 6810
- AI-Rank-log  1619209460.2442188  eval_accuracy: 0.697089672088623 , global_step: 6811
- AI-Rank-log  1619209504.306822  eval_accuracy: 0.6975588202476501 , global_step: 6812
- AI-Rank-log  1619209549.4783473  eval_accuracy: 0.6973623037338257 , global_step: 6813
- AI-Rank-log  1619209593.4159002  eval_accuracy: 0.697878897190094 , global_step: 6814
- AI-Rank-log  1619209637.402971  eval_accuracy: 0.6978259086608887 , global_step: 6815
- AI-Rank-log  1619209681.328833  eval_accuracy: 0.69754958152771 , global_step: 6816
- AI-Rank-log  1619209725.2947018  eval_accuracy: 0.6972538232803345 , global_step: 6817
- AI-Rank-log  1619209769.851296  eval_accuracy: 0.6977699398994446 , global_step: 6818
- AI-Rank-log  1619209813.7451148  eval_accuracy: 0.6969207525253296 , global_step: 6819
- AI-Rank-log  1619209857.803389  eval_accuracy: 0.6978257298469543 , global_step: 6820
- AI-Rank-log  1619209901.706923  eval_accuracy: 0.6973457336425781 , global_step: 6821
- AI-Rank-log  1619209945.6736114  eval_accuracy: 0.6971249580383301 , global_step: 6822
- AI-Rank-log  1619209989.6977143  eval_accuracy: 0.6977524161338806 , global_step: 6823
- AI-Rank-log  1619210033.6142378  eval_accuracy: 0.6970442533493042 , global_step: 6824
- AI-Rank-log  1619210077.5978358  eval_accuracy: 0.6969910860061646 , global_step: 6825
- AI-Rank-log  1619210121.675428  eval_accuracy: 0.6968564987182617 , global_step: 6826
- AI-Rank-log  1619210165.6254482  eval_accuracy: 0.6964758634567261 , global_step: 6827
- AI-Rank-log  1619210209.581929  eval_accuracy: 0.6971554756164551 , global_step: 6828
- AI-Rank-log  1619210253.6116846  eval_accuracy: 0.6974330544471741 , global_step: 6829
- AI-Rank-log  1619210297.5395112  eval_accuracy: 0.6975669860839844 , global_step: 6830
- AI-Rank-log  1619210341.560885  eval_accuracy: 0.6974409818649292 , global_step: 6831
- AI-Rank-log  1619210385.5377407  eval_accuracy: 0.6973062753677368 , global_step: 6832
- AI-Rank-log  1619210429.5124364  eval_accuracy: 0.6969111561775208 , global_step: 6833
- AI-Rank-log  1619210473.5200067  eval_accuracy: 0.6973036527633667 , global_step: 6834
- AI-Rank-log  1619210517.4892209  eval_accuracy: 0.6964355707168579 , global_step: 6835
- AI-Rank-log  1619210561.4090385  eval_accuracy: 0.6972228288650513 , global_step: 6836
- AI-Rank-log  1619210605.4588506  eval_accuracy: 0.6965534687042236 , global_step: 6837
- AI-Rank-log  1619210649.4118228  eval_accuracy: 0.6969220042228699 , global_step: 6838
- AI-Rank-log  1619210693.3759658  eval_accuracy: 0.6968792676925659 , global_step: 6839
- AI-Rank-log  1619210737.3617244  eval_accuracy: 0.696864902973175 , global_step: 6840
- AI-Rank-log  1619210781.3194165  eval_accuracy: 0.6970028877258301 , global_step: 6841
- AI-Rank-log  1619210825.322939  eval_accuracy: 0.6977598667144775 , global_step: 6842
- AI-Rank-log  1619210869.2407365  eval_accuracy: 0.697182297706604 , global_step: 6843
- AI-Rank-log  1619210913.1699312  eval_accuracy: 0.6974607110023499 , global_step: 6844
- AI-Rank-log  1619210957.266622  eval_accuracy: 0.697720468044281 , global_step: 6845
- AI-Rank-log  1619211001.225593  eval_accuracy: 0.69767165184021 , global_step: 6846
- AI-Rank-log  1619211045.1742177  eval_accuracy: 0.6974806189537048 , global_step: 6847
- AI-Rank-log  1619211089.2035928  eval_accuracy: 0.6976306438446045 , global_step: 6848
- AI-Rank-log  1619211133.1406367  eval_accuracy: 0.6969463229179382 , global_step: 6849
- AI-Rank-log  1619211177.0706382  eval_accuracy: 0.6973214149475098 , global_step: 6850
- AI-Rank-log  1619211221.1117249  eval_accuracy: 0.6965802907943726 , global_step: 6851
- AI-Rank-log  1619211265.0528512  eval_accuracy: 0.6978232264518738 , global_step: 6852
- AI-Rank-log  1619211309.0567667  eval_accuracy: 0.6961985230445862 , global_step: 6853
- AI-Rank-log  1619211353.0006483  eval_accuracy: 0.6977499127388 , global_step: 6854
- AI-Rank-log  1619211396.9232688  eval_accuracy: 0.69808030128479 , global_step: 6855
- AI-Rank-log  1619211440.9423954  eval_accuracy: 0.6969377398490906 , global_step: 6856
- AI-Rank-log  1619211484.9052217  eval_accuracy: 0.6976317763328552 , global_step: 6857
- AI-Rank-log  1619211528.8630085  eval_accuracy: 0.6975324153900146 , global_step: 6858
- AI-Rank-log  1619211572.9129193  eval_accuracy: 0.697673499584198 , global_step: 6859
- AI-Rank-log  1619211616.8831265  eval_accuracy: 0.6972705125808716 , global_step: 6860
- AI-Rank-log  1619211660.840833  eval_accuracy: 0.6975871920585632 , global_step: 6861
- AI-Rank-log  1619211704.842765  eval_accuracy: 0.6976701617240906 , global_step: 6862
- AI-Rank-log  1619211748.8226154  eval_accuracy: 0.6974734663963318 , global_step: 6863
- AI-Rank-log  1619211792.8167615  eval_accuracy: 0.6971455812454224 , global_step: 6864
- AI-Rank-log  1619211836.7894423  eval_accuracy: 0.697130024433136 , global_step: 6865
- AI-Rank-log  1619211880.7823365  eval_accuracy: 0.6971644163131714 , global_step: 6866
- AI-Rank-log  1619211924.847149  eval_accuracy: 0.6977601647377014 , global_step: 6867
- AI-Rank-log  1619211968.788434  eval_accuracy: 0.6975597739219666 , global_step: 6868
- AI-Rank-log  1619212012.7468467  eval_accuracy: 0.6980843544006348 , global_step: 6869
- AI-Rank-log  1619212056.7725315  eval_accuracy: 0.6973487138748169 , global_step: 6870
- AI-Rank-log  1619212100.7223656  eval_accuracy: 0.6968694925308228 , global_step: 6871
- AI-Rank-log  1619212145.530596  eval_accuracy: 0.6970910429954529 , global_step: 6872
- AI-Rank-log  1619212189.5687475  eval_accuracy: 0.6966740489006042 , global_step: 6873
- AI-Rank-log  1619212233.5178905  eval_accuracy: 0.6969510316848755 , global_step: 6874
- AI-Rank-log  1619212277.5499961  eval_accuracy: 0.6969868540763855 , global_step: 6875
- AI-Rank-log  1619212321.4825978  eval_accuracy: 0.6976016163825989 , global_step: 6876
- AI-Rank-log  1619212366.0845256  eval_accuracy: 0.6962794065475464 , global_step: 6877
- AI-Rank-log  1619212410.4316564  eval_accuracy: 0.6970523595809937 , global_step: 6878
- AI-Rank-log  1619212454.515907  eval_accuracy: 0.6962538957595825 , global_step: 6879
- AI-Rank-log  1619212498.7323067  eval_accuracy: 0.6968315839767456 , global_step: 6880
- AI-Rank-log  1619212542.936194  eval_accuracy: 0.6970124244689941 , global_step: 6881
- AI-Rank-log  1619212586.9368932  eval_accuracy: 0.6963265538215637 , global_step: 6882
- AI-Rank-log  1619212631.0004659  eval_accuracy: 0.6973049640655518 , global_step: 6883
- AI-Rank-log  1619212675.4932785  eval_accuracy: 0.6978406310081482 , global_step: 6884
- AI-Rank-log  1619212720.4293077  eval_accuracy: 0.6970722079277039 , global_step: 6885
- AI-Rank-log  1619212764.4612947  eval_accuracy: 0.6967278122901917 , global_step: 6886
- AI-Rank-log  1619212809.106189  eval_accuracy: 0.6977200508117676 , global_step: 6887
- AI-Rank-log  1619212853.233682  eval_accuracy: 0.6970313191413879 , global_step: 6888
- AI-Rank-log  1619212897.302128  eval_accuracy: 0.6974459886550903 , global_step: 6889
- AI-Rank-log  1619212942.298221  eval_accuracy: 0.6966444253921509 , global_step: 6890
- AI-Rank-log  1619212986.2502263  eval_accuracy: 0.6971638798713684 , global_step: 6891
- AI-Rank-log  1619213030.3709586  eval_accuracy: 0.6974044442176819 , global_step: 6892
- AI-Rank-log  1619213074.3416412  eval_accuracy: 0.6975203156471252 , global_step: 6893
- AI-Rank-log  1619213118.3505144  eval_accuracy: 0.6976146697998047 , global_step: 6894
- AI-Rank-log  1619213162.797014  eval_accuracy: 0.6975025534629822 , global_step: 6895
- AI-Rank-log  1619213206.8591092  eval_accuracy: 0.6975100636482239 , global_step: 6896
- AI-Rank-log  1619213250.9164865  eval_accuracy: 0.6972625255584717 , global_step: 6897
- AI-Rank-log  1619213294.9739764  eval_accuracy: 0.6978247761726379 , global_step: 6898
- AI-Rank-log  1619213339.001177  eval_accuracy: 0.6972031593322754 , global_step: 6899
- AI-Rank-log  1619213383.0816653  eval_accuracy: 0.6980273723602295 , global_step: 6900
- AI-Rank-log  1619213427.0993037  eval_accuracy: 0.697969377040863 , global_step: 6901
- AI-Rank-log  1619213471.1775265  eval_accuracy: 0.6980080008506775 , global_step: 6902
- AI-Rank-log  1619213515.2493083  eval_accuracy: 0.6982594728469849 , global_step: 6903
- AI-Rank-log  1619213559.2870615  eval_accuracy: 0.6975988149642944 , global_step: 6904
- AI-Rank-log  1619213603.393192  eval_accuracy: 0.6979717016220093 , global_step: 6905
- AI-Rank-log  1619213647.3917227  eval_accuracy: 0.6973924040794373 , global_step: 6906
- AI-Rank-log  1619213691.4201365  eval_accuracy: 0.6978834271430969 , global_step: 6907
- AI-Rank-log  1619213735.471724  eval_accuracy: 0.6974620223045349 , global_step: 6908
- AI-Rank-log  1619213779.4976566  eval_accuracy: 0.6980487108230591 , global_step: 6909
- AI-Rank-log  1619213823.5132463  eval_accuracy: 0.6974336504936218 , global_step: 6910
- AI-Rank-log  1619213867.537659  eval_accuracy: 0.6977725028991699 , global_step: 6911
- AI-Rank-log  1619213911.62952  eval_accuracy: 0.6976296901702881 , global_step: 6912
- AI-Rank-log  1619213955.475413  eval_accuracy: 0.6972010135650635 , global_step: 6913
- AI-Rank-log  1619213999.437369  eval_accuracy: 0.6979105472564697 , global_step: 6914
- AI-Rank-log  1619214043.4563103  eval_accuracy: 0.697396993637085 , global_step: 6915
- AI-Rank-log  1619214087.558982  eval_accuracy: 0.6977887153625488 , global_step: 6916
- AI-Rank-log  1619214131.5408165  eval_accuracy: 0.6973578929901123 , global_step: 6917
- AI-Rank-log  1619214175.5631862  eval_accuracy: 0.6978165507316589 , global_step: 6918
- AI-Rank-log  1619214219.7457936  eval_accuracy: 0.6964694261550903 , global_step: 6919
- AI-Rank-log  1619214263.697707  eval_accuracy: 0.6972973942756653 , global_step: 6920
- AI-Rank-log  1619214307.718166  eval_accuracy: 0.6970359683036804 , global_step: 6921
- AI-Rank-log  1619214351.8261294  eval_accuracy: 0.6973711252212524 , global_step: 6922
- AI-Rank-log  1619214395.8618667  eval_accuracy: 0.6976372003555298 , global_step: 6923
- AI-Rank-log  1619214439.9697316  eval_accuracy: 0.6975985169410706 , global_step: 6924
- AI-Rank-log  1619214484.003646  eval_accuracy: 0.6979349255561829 , global_step: 6925
- AI-Rank-log  1619214528.0146081  eval_accuracy: 0.6981614828109741 , global_step: 6926
- AI-Rank-log  1619214572.0670087  eval_accuracy: 0.6969215273857117 , global_step: 6927
- AI-Rank-log  1619214616.0883243  eval_accuracy: 0.6974485516548157 , global_step: 6928
- AI-Rank-log  1619214660.162833  eval_accuracy: 0.6975424289703369 , global_step: 6929
- AI-Rank-log  1619214704.1605444  eval_accuracy: 0.6979665756225586 , global_step: 6930
- AI-Rank-log  1619214748.1861396  eval_accuracy: 0.6977584958076477 , global_step: 6931
- AI-Rank-log  1619214792.2500587  eval_accuracy: 0.6982767581939697 , global_step: 6932
- AI-Rank-log  1619214836.279691  eval_accuracy: 0.6973598003387451 , global_step: 6933
- AI-Rank-log  1619214880.2304306  eval_accuracy: 0.6988084316253662 , global_step: 6934
- AI-Rank-log  1619214924.333478  eval_accuracy: 0.6975054740905762 , global_step: 6935
- AI-Rank-log  1619214968.3670504  eval_accuracy: 0.6985560655593872 , global_step: 6936
- AI-Rank-log  1619215012.3622031  eval_accuracy: 0.6980875730514526 , global_step: 6937
- AI-Rank-log  1619215056.465451  eval_accuracy: 0.6987282633781433 , global_step: 6938
- AI-Rank-log  1619215100.499381  eval_accuracy: 0.6978152394294739 , global_step: 6939
- AI-Rank-log  1619215144.5520792  eval_accuracy: 0.6976394057273865 , global_step: 6940
- AI-Rank-log  1619215188.6327899  eval_accuracy: 0.6984414458274841 , global_step: 6941
- AI-Rank-log  1619215232.7135398  eval_accuracy: 0.6985414624214172 , global_step: 6942
- AI-Rank-log  1619215276.8023496  eval_accuracy: 0.6977849006652832 , global_step: 6943
- AI-Rank-log  1619215320.8899834  eval_accuracy: 0.697899580001831 , global_step: 6944
- AI-Rank-log  1619215364.9666896  eval_accuracy: 0.6969622373580933 , global_step: 6945
- AI-Rank-log  1619215409.121226  eval_accuracy: 0.69749516248703 , global_step: 6946
- AI-Rank-log  1619215453.1455364  eval_accuracy: 0.6975930333137512 , global_step: 6947
- AI-Rank-log  1619215497.1588776  eval_accuracy: 0.6973366141319275 , global_step: 6948
- AI-Rank-log  1619215541.2644846  eval_accuracy: 0.6975597143173218 , global_step: 6949
- AI-Rank-log  1619215586.0545318  eval_accuracy: 0.6971615552902222 , global_step: 6950
- AI-Rank-log  1619215630.1532016  eval_accuracy: 0.6973587274551392 , global_step: 6951
- AI-Rank-log  1619215674.175505  eval_accuracy: 0.6976839900016785 , global_step: 6952
- AI-Rank-log  1619215718.1294155  eval_accuracy: 0.6974859833717346 , global_step: 6953
- AI-Rank-log  1619215762.7570088  eval_accuracy: 0.6976923942565918 , global_step: 6954
- AI-Rank-log  1619215807.6344867  eval_accuracy: 0.6967635750770569 , global_step: 6955
- AI-Rank-log  1619215851.703757  eval_accuracy: 0.6978001594543457 , global_step: 6956
- AI-Rank-log  1619215895.7573636  eval_accuracy: 0.6967712044715881 , global_step: 6957
- AI-Rank-log  1619215939.9211452  eval_accuracy: 0.6977667808532715 , global_step: 6958
- AI-Rank-log  1619215984.0187693  eval_accuracy: 0.6974494457244873 , global_step: 6959
- AI-Rank-log  1619216028.167051  eval_accuracy: 0.6974204778671265 , global_step: 6960
- AI-Rank-log  1619216073.0112185  eval_accuracy: 0.6971456408500671 , global_step: 6961
- AI-Rank-log  1619216117.1122026  eval_accuracy: 0.6984661221504211 , global_step: 6962
- AI-Rank-log  1619216161.4293766  eval_accuracy: 0.6974229216575623 , global_step: 6963
- AI-Rank-log  1619216205.4839869  eval_accuracy: 0.6975705623626709 , global_step: 6964
- AI-Rank-log  1619216250.1365905  eval_accuracy: 0.6977248191833496 , global_step: 6965
- AI-Rank-log  1619216294.3146195  eval_accuracy: 0.6981462240219116 , global_step: 6966
- AI-Rank-log  1619216338.7324023  eval_accuracy: 0.6971165537834167 , global_step: 6967
- AI-Rank-log  1619216383.6358974  eval_accuracy: 0.6976889371871948 , global_step: 6968
- AI-Rank-log  1619216427.647247  eval_accuracy: 0.6982245445251465 , global_step: 6969
- AI-Rank-log  1619216471.8344915  eval_accuracy: 0.6978221535682678 , global_step: 6970
- AI-Rank-log  1619216515.8951979  eval_accuracy: 0.6977763175964355 , global_step: 6971
- AI-Rank-log  1619216559.9421322  eval_accuracy: 0.6978161931037903 , global_step: 6972
- AI-Rank-log  1619216604.212034  eval_accuracy: 0.697685182094574 , global_step: 6973
- AI-Rank-log  1619216648.2683675  eval_accuracy: 0.6979762315750122 , global_step: 6974
- AI-Rank-log  1619216692.3213868  eval_accuracy: 0.6976396441459656 , global_step: 6975
- AI-Rank-log  1619216736.50499  eval_accuracy: 0.6984394788742065 , global_step: 6976
- AI-Rank-log  1619216780.5852554  eval_accuracy: 0.6975312829017639 , global_step: 6977
- AI-Rank-log  1619216824.5629923  eval_accuracy: 0.6979824304580688 , global_step: 6978
- AI-Rank-log  1619216868.7158465  eval_accuracy: 0.6967014074325562 , global_step: 6979
- AI-Rank-log  1619216912.7989924  eval_accuracy: 0.6972602009773254 , global_step: 6980
- AI-Rank-log  1619216956.8593562  eval_accuracy: 0.6971495151519775 , global_step: 6981
- AI-Rank-log  1619217000.9780636  eval_accuracy: 0.6970691084861755 , global_step: 6982
- AI-Rank-log  1619217045.0213969  eval_accuracy: 0.6968012452125549 , global_step: 6983
- AI-Rank-log  1619217089.1093693  eval_accuracy: 0.6969357132911682 , global_step: 6984
- AI-Rank-log  1619217133.145781  eval_accuracy: 0.6974000334739685 , global_step: 6985
- AI-Rank-log  1619217177.2034504  eval_accuracy: 0.6974550485610962 , global_step: 6986
- AI-Rank-log  1619217221.040159  eval_accuracy: 0.6979726552963257 , global_step: 6987
- AI-Rank-log  1619217265.074366  eval_accuracy: 0.6974260807037354 , global_step: 6988
- AI-Rank-log  1619217309.083812  eval_accuracy: 0.6980307102203369 , global_step: 6989
- AI-Rank-log  1619217353.242628  eval_accuracy: 0.6979852318763733 , global_step: 6990
- AI-Rank-log  1619217406.2580125  eval_accuracy: 0.6974688172340393 , global_step: 6991
- AI-Rank-log  1619217450.2840137  eval_accuracy: 0.6972061395645142 , global_step: 6992
- AI-Rank-log  1619217494.4110029  eval_accuracy: 0.6978983879089355 , global_step: 6993
- AI-Rank-log  1619217538.440155  eval_accuracy: 0.6976646184921265 , global_step: 6994
- AI-Rank-log  1619217582.5393913  eval_accuracy: 0.6986353993415833 , global_step: 6995
- AI-Rank-log  1619217626.5773191  eval_accuracy: 0.6975349187850952 , global_step: 6996
- AI-Rank-log  1619217670.6035545  eval_accuracy: 0.6970726847648621 , global_step: 6997
- AI-Rank-log  1619217714.7238324  eval_accuracy: 0.6977556347846985 , global_step: 6998
- AI-Rank-log  1619217758.7206702  eval_accuracy: 0.6970339417457581 , global_step: 6999
- AI-Rank-log  1619217802.7573211  eval_accuracy: 0.6977887153625488 , global_step: 7000
- AI-Rank-log  1619217846.6580696  eval_accuracy: 0.6969524025917053 , global_step: 7001
- AI-Rank-log  1619217890.677613  eval_accuracy: 0.6977114677429199 , global_step: 7002
- AI-Rank-log  1619217934.811923  eval_accuracy: 0.697037935256958 , global_step: 7003
- AI-Rank-log  1619217978.8068926  eval_accuracy: 0.6976537704467773 , global_step: 7004
- AI-Rank-log  1619218022.8889933  eval_accuracy: 0.6974714994430542 , global_step: 7005
- AI-Rank-log  1619218067.006542  eval_accuracy: 0.6978246569633484 , global_step: 7006
- AI-Rank-log  1619218110.995031  eval_accuracy: 0.6973854303359985 , global_step: 7007
- AI-Rank-log  1619218155.0152361  eval_accuracy: 0.697596549987793 , global_step: 7008
- AI-Rank-log  1619218199.1231213  eval_accuracy: 0.6980342268943787 , global_step: 7009
- AI-Rank-log  1619218243.1354692  eval_accuracy: 0.6969141960144043 , global_step: 7010
- AI-Rank-log  1619218287.244208  eval_accuracy: 0.697310745716095 , global_step: 7011
- AI-Rank-log  1619218331.3403175  eval_accuracy: 0.6968898177146912 , global_step: 7012
- AI-Rank-log  1619218375.3437026  eval_accuracy: 0.6977744698524475 , global_step: 7013
- AI-Rank-log  1619218419.4233034  eval_accuracy: 0.6963998675346375 , global_step: 7014
- AI-Rank-log  1619218463.4906816  eval_accuracy: 0.6975241303443909 , global_step: 7015
- AI-Rank-log  1619218507.4958026  eval_accuracy: 0.6967918872833252 , global_step: 7016
- AI-Rank-log  1619218551.6165211  eval_accuracy: 0.6974267363548279 , global_step: 7017
- AI-Rank-log  1619218595.6327887  eval_accuracy: 0.6977515816688538 , global_step: 7018
- AI-Rank-log  1619218639.6712372  eval_accuracy: 0.6969181895256042 , global_step: 7019
- AI-Rank-log  1619218683.7285235  eval_accuracy: 0.6978155970573425 , global_step: 7020
- AI-Rank-log  1619218727.7412667  eval_accuracy: 0.6972774267196655 , global_step: 7021
- AI-Rank-log  1619218771.822526  eval_accuracy: 0.6980029344558716 , global_step: 7022
- AI-Rank-log  1619218815.9230027  eval_accuracy: 0.6972771883010864 , global_step: 7023
- AI-Rank-log  1619218859.9960935  eval_accuracy: 0.6975927352905273 , global_step: 7024
- AI-Rank-log  1619218904.1055684  eval_accuracy: 0.6970224976539612 , global_step: 7025
- AI-Rank-log  1619218948.1312027  eval_accuracy: 0.6972036361694336 , global_step: 7026
- AI-Rank-log  1619218992.9836686  eval_accuracy: 0.6978128552436829 , global_step: 7027
- AI-Rank-log  1619219037.122402  eval_accuracy: 0.6974744200706482 , global_step: 7028
- AI-Rank-log  1619219081.1642141  eval_accuracy: 0.6975405216217041 , global_step: 7029
- AI-Rank-log  1619219125.1784523  eval_accuracy: 0.6971207857131958 , global_step: 7030
- AI-Rank-log  1619219169.607272  eval_accuracy: 0.6977129578590393 , global_step: 7031
- AI-Rank-log  1619219213.649366  eval_accuracy: 0.6976831555366516 , global_step: 7032
- AI-Rank-log  1619219258.1726346  eval_accuracy: 0.6978098750114441 , global_step: 7033
- AI-Rank-log  1619219302.255569  eval_accuracy: 0.6979680061340332 , global_step: 7034
- AI-Rank-log  1619219346.398474  eval_accuracy: 0.6980816125869751 , global_step: 7035
- AI-Rank-log  1619219390.4863884  eval_accuracy: 0.6975729465484619 , global_step: 7036
- AI-Rank-log  1619219434.567749  eval_accuracy: 0.6982935070991516 , global_step: 7037
- AI-Rank-log  1619219479.4189014  eval_accuracy: 0.6973949074745178 , global_step: 7038
- AI-Rank-log  1619219523.4624093  eval_accuracy: 0.6985230445861816 , global_step: 7039
- AI-Rank-log  1619219567.9908834  eval_accuracy: 0.6977318525314331 , global_step: 7040
- AI-Rank-log  1619219612.059105  eval_accuracy: 0.6982640624046326 , global_step: 7041
- AI-Rank-log  1619219656.8561404  eval_accuracy: 0.6978370547294617 , global_step: 7042
- AI-Rank-log  1619219700.9381278  eval_accuracy: 0.6978344917297363 , global_step: 7043
- AI-Rank-log  1619219745.0503168  eval_accuracy: 0.6982391476631165 , global_step: 7044
- AI-Rank-log  1619219790.2650928  eval_accuracy: 0.6976717114448547 , global_step: 7045
- AI-Rank-log  1619219834.292874  eval_accuracy: 0.6976991891860962 , global_step: 7046
- AI-Rank-log  1619219879.247418  eval_accuracy: 0.6981152892112732 , global_step: 7047
- AI-Rank-log  1619219923.2296352  eval_accuracy: 0.6979994177818298 , global_step: 7048
- AI-Rank-log  1619219967.238019  eval_accuracy: 0.697560727596283 , global_step: 7049
- AI-Rank-log  1619220011.4752607  eval_accuracy: 0.6978693008422852 , global_step: 7050
- AI-Rank-log  1619220055.4892454  eval_accuracy: 0.6971125602722168 , global_step: 7051
- AI-Rank-log  1619220099.5608797  eval_accuracy: 0.698373019695282 , global_step: 7052
- AI-Rank-log  1619220143.6297703  eval_accuracy: 0.6979091167449951 , global_step: 7053
- AI-Rank-log  1619220187.6420662  eval_accuracy: 0.6988124251365662 , global_step: 7054
- AI-Rank-log  1619220231.805199  eval_accuracy: 0.6983712911605835 , global_step: 7055
- AI-Rank-log  1619220275.823169  eval_accuracy: 0.6981673836708069 , global_step: 7056
- AI-Rank-log  1619220319.8480964  eval_accuracy: 0.6977141499519348 , global_step: 7057
- AI-Rank-log  1619220363.9692156  eval_accuracy: 0.698113203048706 , global_step: 7058
- AI-Rank-log  1619220407.9748046  eval_accuracy: 0.698695182800293 , global_step: 7059
- AI-Rank-log  1619220451.924904  eval_accuracy: 0.6980330348014832 , global_step: 7060
- AI-Rank-log  1619220496.0540433  eval_accuracy: 0.6989547610282898 , global_step: 7061
- AI-Rank-log  1619220540.0176792  eval_accuracy: 0.6977856755256653 , global_step: 7062
- AI-Rank-log  1619220584.0374758  eval_accuracy: 0.6981754899024963 , global_step: 7063
- AI-Rank-log  1619220628.0573218  eval_accuracy: 0.6982097625732422 , global_step: 7064
- AI-Rank-log  1619220672.0332093  eval_accuracy: 0.6983977556228638 , global_step: 7065
- AI-Rank-log  1619220716.1170452  eval_accuracy: 0.6984638571739197 , global_step: 7066
- AI-Rank-log  1619220760.10754  eval_accuracy: 0.6986786127090454 , global_step: 7067
- AI-Rank-log  1619220804.0794828  eval_accuracy: 0.6979663968086243 , global_step: 7068
- AI-Rank-log  1619220848.1497326  eval_accuracy: 0.698806881904602 , global_step: 7069
- AI-Rank-log  1619220892.166278  eval_accuracy: 0.6981629729270935 , global_step: 7070
- AI-Rank-log  1619220936.1858337  eval_accuracy: 0.6982713937759399 , global_step: 7071
- AI-Rank-log  1619220980.1789765  eval_accuracy: 0.6984230875968933 , global_step: 7072
- AI-Rank-log  1619221024.1900034  eval_accuracy: 0.6986355781555176 , global_step: 7073
- AI-Rank-log  1619221068.2352607  eval_accuracy: 0.698573887348175 , global_step: 7074
- AI-Rank-log  1619221112.243269  eval_accuracy: 0.6989983916282654 , global_step: 7075
- AI-Rank-log  1619221156.212166  eval_accuracy: 0.6987757086753845 , global_step: 7076
- AI-Rank-log  1619221200.244163  eval_accuracy: 0.6977529525756836 , global_step: 7077
- AI-Rank-log  1619221244.243243  eval_accuracy: 0.6988438963890076 , global_step: 7078
- AI-Rank-log  1619221288.215865  eval_accuracy: 0.6985617876052856 , global_step: 7079
- AI-Rank-log  1619221332.2484007  eval_accuracy: 0.6992155909538269 , global_step: 7080
- AI-Rank-log  1619221376.2280073  eval_accuracy: 0.6984961032867432 , global_step: 7081
- AI-Rank-log  1619221420.2112837  eval_accuracy: 0.6985659599304199 , global_step: 7082
- AI-Rank-log  1619221464.222071  eval_accuracy: 0.6979730129241943 , global_step: 7083
- AI-Rank-log  1619221508.2240236  eval_accuracy: 0.6989020109176636 , global_step: 7084
- AI-Rank-log  1619221552.2523863  eval_accuracy: 0.6981174945831299 , global_step: 7085
- AI-Rank-log  1619221596.2684553  eval_accuracy: 0.6986230611801147 , global_step: 7086
- AI-Rank-log  1619221640.252559  eval_accuracy: 0.6984667778015137 , global_step: 7087
- AI-Rank-log  1619221684.2855282  eval_accuracy: 0.6988523006439209 , global_step: 7088
- AI-Rank-log  1619221728.2670152  eval_accuracy: 0.6991869807243347 , global_step: 7089
- AI-Rank-log  1619221772.2531643  eval_accuracy: 0.6990702152252197 , global_step: 7090
- AI-Rank-log  1619221816.2971306  eval_accuracy: 0.6982727646827698 , global_step: 7091
- AI-Rank-log  1619221860.2859807  eval_accuracy: 0.6990552544593811 , global_step: 7092
- AI-Rank-log  1619221904.2643466  eval_accuracy: 0.6990254521369934 , global_step: 7093
- AI-Rank-log  1619221948.261605  eval_accuracy: 0.6985247731208801 , global_step: 7094
- AI-Rank-log  1619221992.2374706  eval_accuracy: 0.6984380483627319 , global_step: 7095
- AI-Rank-log  1619222036.2966957  eval_accuracy: 0.698787271976471 , global_step: 7096
- AI-Rank-log  1619222080.2312567  eval_accuracy: 0.6985805034637451 , global_step: 7097
- AI-Rank-log  1619222124.2289782  eval_accuracy: 0.6986223459243774 , global_step: 7098
- AI-Rank-log  1619222168.269244  eval_accuracy: 0.6991555690765381 , global_step: 7099
- AI-Rank-log  1619222212.1913517  eval_accuracy: 0.6987007260322571 , global_step: 7100
- AI-Rank-log  1619222256.1799805  eval_accuracy: 0.6982445120811462 , global_step: 7101
- AI-Rank-log  1619222300.2390928  eval_accuracy: 0.6992725729942322 , global_step: 7102
- AI-Rank-log  1619222344.1589162  eval_accuracy: 0.6986258625984192 , global_step: 7103
- AI-Rank-log  1619222388.927645  eval_accuracy: 0.6989656090736389 , global_step: 7104
- AI-Rank-log  1619222433.0187197  eval_accuracy: 0.6975641846656799 , global_step: 7105
- AI-Rank-log  1619222476.9783223  eval_accuracy: 0.699356198310852 , global_step: 7106
- AI-Rank-log  1619222521.0287848  eval_accuracy: 0.6972081065177917 , global_step: 7107
- AI-Rank-log  1619222565.4194152  eval_accuracy: 0.6986330151557922 , global_step: 7108
- AI-Rank-log  1619222609.1480577  eval_accuracy: 0.6982092261314392 , global_step: 7109
- AI-Rank-log  1619222653.552005  eval_accuracy: 0.6984691619873047 , global_step: 7110
- AI-Rank-log  1619222697.5255363  eval_accuracy: 0.6984880566596985 , global_step: 7111
- AI-Rank-log  1619222741.7983048  eval_accuracy: 0.6983212232589722 , global_step: 7112
- AI-Rank-log  1619222785.8163698  eval_accuracy: 0.698532223701477 , global_step: 7113
- AI-Rank-log  1619222829.747839  eval_accuracy: 0.698679506778717 , global_step: 7114
- AI-Rank-log  1619222874.6222882  eval_accuracy: 0.6987577080726624 , global_step: 7115
- AI-Rank-log  1619222918.7168937  eval_accuracy: 0.6980044841766357 , global_step: 7116
- AI-Rank-log  1619222962.6920142  eval_accuracy: 0.6992922425270081 , global_step: 7117
- AI-Rank-log  1619223007.0503695  eval_accuracy: 0.6976396441459656 , global_step: 7118
- AI-Rank-log  1619223051.049724  eval_accuracy: 0.6987019777297974 , global_step: 7119
- AI-Rank-log  1619223095.7170367  eval_accuracy: 0.6992532014846802 , global_step: 7120
- AI-Rank-log  1619223139.7837212  eval_accuracy: 0.6984943151473999 , global_step: 7121
- AI-Rank-log  1619223183.8068821  eval_accuracy: 0.6989169120788574 , global_step: 7122
- AI-Rank-log  1619223228.8212407  eval_accuracy: 0.6986768841743469 , global_step: 7123
- AI-Rank-log  1619223272.8595986  eval_accuracy: 0.6981019377708435 , global_step: 7124
- AI-Rank-log  1619223316.8137016  eval_accuracy: 0.6986387372016907 , global_step: 7125
- AI-Rank-log  1619223360.831139  eval_accuracy: 0.6986237168312073 , global_step: 7126
- AI-Rank-log  1619223404.8169506  eval_accuracy: 0.6982911825180054 , global_step: 7127
- AI-Rank-log  1619223448.879731  eval_accuracy: 0.6989955306053162 , global_step: 7128
- AI-Rank-log  1619223492.8992581  eval_accuracy: 0.6989531517028809 , global_step: 7129
- AI-Rank-log  1619223536.892444  eval_accuracy: 0.6988869309425354 , global_step: 7130
- AI-Rank-log  1619223580.8793645  eval_accuracy: 0.6990736722946167 , global_step: 7131
- AI-Rank-log  1619223624.9164195  eval_accuracy: 0.69930100440979 , global_step: 7132
- AI-Rank-log  1619223668.9037373  eval_accuracy: 0.6988697648048401 , global_step: 7133
- AI-Rank-log  1619223712.8887215  eval_accuracy: 0.6982969045639038 , global_step: 7134
- AI-Rank-log  1619223756.895692  eval_accuracy: 0.6986605525016785 , global_step: 7135
- AI-Rank-log  1619223800.906218  eval_accuracy: 0.6984788775444031 , global_step: 7136
- AI-Rank-log  1619223844.9496412  eval_accuracy: 0.6990348696708679 , global_step: 7137
- AI-Rank-log  1619223888.8778343  eval_accuracy: 0.6987825632095337 , global_step: 7138
- AI-Rank-log  1619223932.8663242  eval_accuracy: 0.6984556913375854 , global_step: 7139
- AI-Rank-log  1619223976.8429613  eval_accuracy: 0.6983612775802612 , global_step: 7140
- AI-Rank-log  1619224020.81317  eval_accuracy: 0.6981591582298279 , global_step: 7141
- AI-Rank-log  1619224064.8332164  eval_accuracy: 0.698742151260376 , global_step: 7142
- AI-Rank-log  1619224108.892237  eval_accuracy: 0.6980426907539368 , global_step: 7143
- AI-Rank-log  1619224152.8224194  eval_accuracy: 0.6993628740310669 , global_step: 7144
- AI-Rank-log  1619224196.8006153  eval_accuracy: 0.6990150213241577 , global_step: 7145
- AI-Rank-log  1619224240.849822  eval_accuracy: 0.6993238925933838 , global_step: 7146
- AI-Rank-log  1619224284.8351297  eval_accuracy: 0.6989246010780334 , global_step: 7147
- AI-Rank-log  1619224328.7851686  eval_accuracy: 0.699429452419281 , global_step: 7148
- AI-Rank-log  1619224372.7949436  eval_accuracy: 0.6993241310119629 , global_step: 7149
- AI-Rank-log  1619224416.7552195  eval_accuracy: 0.6988694667816162 , global_step: 7150
- AI-Rank-log  1619224460.822908  eval_accuracy: 0.6988399624824524 , global_step: 7151
- AI-Rank-log  1619224504.7863293  eval_accuracy: 0.6986095309257507 , global_step: 7152
- AI-Rank-log  1619224548.7636628  eval_accuracy: 0.6988188028335571 , global_step: 7153
- AI-Rank-log  1619224592.7982056  eval_accuracy: 0.6988670825958252 , global_step: 7154
- AI-Rank-log  1619224636.7477844  eval_accuracy: 0.6987107992172241 , global_step: 7155
- AI-Rank-log  1619224680.7298884  eval_accuracy: 0.69965660572052 , global_step: 7156
- AI-Rank-log  1619224724.7979665  eval_accuracy: 0.699478805065155 , global_step: 7157
- AI-Rank-log  1619224768.764026  eval_accuracy: 0.6991457939147949 , global_step: 7158
- AI-Rank-log  1619224812.749071  eval_accuracy: 0.6993738412857056 , global_step: 7159
- AI-Rank-log  1619224856.7897756  eval_accuracy: 0.6990755796432495 , global_step: 7160
- AI-Rank-log  1619224900.7467582  eval_accuracy: 0.6988788843154907 , global_step: 7161
- AI-Rank-log  1619224944.78035  eval_accuracy: 0.6991928815841675 , global_step: 7162
- AI-Rank-log  1619224988.7098787  eval_accuracy: 0.6986348032951355 , global_step: 7163
- AI-Rank-log  1619225032.6693618  eval_accuracy: 0.6990150809288025 , global_step: 7164
- AI-Rank-log  1619225076.7017205  eval_accuracy: 0.6979265809059143 , global_step: 7165
- AI-Rank-log  1619225120.7137942  eval_accuracy: 0.6989203691482544 , global_step: 7166
- AI-Rank-log  1619225164.686294  eval_accuracy: 0.697868287563324 , global_step: 7167
- AI-Rank-log  1619225208.7718499  eval_accuracy: 0.6988340020179749 , global_step: 7168
- AI-Rank-log  1619225252.7363932  eval_accuracy: 0.6979331374168396 , global_step: 7169
- AI-Rank-log  1619225296.8100843  eval_accuracy: 0.6991692781448364 , global_step: 7170
- AI-Rank-log  1619225340.7854002  eval_accuracy: 0.6986738443374634 , global_step: 7171
- AI-Rank-log  1619225384.7025461  eval_accuracy: 0.6988084316253662 , global_step: 7172
- AI-Rank-log  1619225428.784173  eval_accuracy: 0.6985478401184082 , global_step: 7173
- AI-Rank-log  1619225472.7281992  eval_accuracy: 0.698940634727478 , global_step: 7174
- AI-Rank-log  1619225516.6576543  eval_accuracy: 0.6987391710281372 , global_step: 7175
- AI-Rank-log  1619225560.7283723  eval_accuracy: 0.6978201866149902 , global_step: 7176
- AI-Rank-log  1619225604.6740465  eval_accuracy: 0.6984095573425293 , global_step: 7177
- AI-Rank-log  1619225648.5760076  eval_accuracy: 0.6984096169471741 , global_step: 7178
- AI-Rank-log  1619225692.6411848  eval_accuracy: 0.6981415748596191 , global_step: 7179
- AI-Rank-log  1619225736.6365893  eval_accuracy: 0.6989975571632385 , global_step: 7180
- AI-Rank-log  1619225780.6751258  eval_accuracy: 0.698051393032074 , global_step: 7181
- AI-Rank-log  1619225825.1300678  eval_accuracy: 0.6982512474060059 , global_step: 7182
- AI-Rank-log  1619225869.0869224  eval_accuracy: 0.6987555027008057 , global_step: 7183
- AI-Rank-log  1619225913.104086  eval_accuracy: 0.6989634037017822 , global_step: 7184
- AI-Rank-log  1619225957.05114  eval_accuracy: 0.6982246041297913 , global_step: 7185
- AI-Rank-log  1619226001.576115  eval_accuracy: 0.6987177729606628 , global_step: 7186
- AI-Rank-log  1619226046.439371  eval_accuracy: 0.6987735629081726 , global_step: 7187
- AI-Rank-log  1619226091.8171334  eval_accuracy: 0.6989499926567078 , global_step: 7188
- AI-Rank-log  1619226135.829258  eval_accuracy: 0.6988831162452698 , global_step: 7189
- AI-Rank-log  1619226180.2518883  eval_accuracy: 0.6990690231323242 , global_step: 7190
- AI-Rank-log  1619226233.0589569  eval_accuracy: 0.6987344026565552 , global_step: 7191
- AI-Rank-log  1619226277.049774  eval_accuracy: 0.6983091831207275 , global_step: 7192
- AI-Rank-log  1619226321.6176374  eval_accuracy: 0.6979519724845886 , global_step: 7193
- AI-Rank-log  1619226365.6394327  eval_accuracy: 0.698088526725769 , global_step: 7194
- AI-Rank-log  1619226409.8683653  eval_accuracy: 0.6984525918960571 , global_step: 7195
- AI-Rank-log  1619226453.8242905  eval_accuracy: 0.6980277299880981 , global_step: 7196
- AI-Rank-log  1619226497.8062375  eval_accuracy: 0.6983973979949951 , global_step: 7197
- AI-Rank-log  1619226542.2085826  eval_accuracy: 0.698397696018219 , global_step: 7198
- AI-Rank-log  1619226586.166296  eval_accuracy: 0.6984090209007263 , global_step: 7199
- AI-Rank-log  1619226631.4552965  eval_accuracy: 0.6981837749481201 , global_step: 7200
- AI-Rank-log  1619226675.3972318  eval_accuracy: 0.69880211353302 , global_step: 7201
- AI-Rank-log  1619226719.3559701  eval_accuracy: 0.6979115605354309 , global_step: 7202
- AI-Rank-log  1619226763.3544157  eval_accuracy: 0.6983022689819336 , global_step: 7203
- AI-Rank-log  1619226807.3453512  eval_accuracy: 0.6988958716392517 , global_step: 7204
- AI-Rank-log  1619226851.2667034  eval_accuracy: 0.6986571550369263 , global_step: 7205
- AI-Rank-log  1619226895.5525663  eval_accuracy: 0.698679506778717 , global_step: 7206
- AI-Rank-log  1619226939.4911613  eval_accuracy: 0.6988485455513 , global_step: 7207
- AI-Rank-log  1619226983.4156985  eval_accuracy: 0.6979884505271912 , global_step: 7208
- AI-Rank-log  1619227027.4537663  eval_accuracy: 0.6985123753547668 , global_step: 7209
- AI-Rank-log  1619227071.3886986  eval_accuracy: 0.697778046131134 , global_step: 7210
- AI-Rank-log  1619227115.4279675  eval_accuracy: 0.6987150311470032 , global_step: 7211
- AI-Rank-log  1619227159.3829284  eval_accuracy: 0.6982401609420776 , global_step: 7212
- AI-Rank-log  1619227203.2817724  eval_accuracy: 0.6985249519348145 , global_step: 7213
- AI-Rank-log  1619227247.278056  eval_accuracy: 0.6982042789459229 , global_step: 7214
- AI-Rank-log  1619227291.2304192  eval_accuracy: 0.698034405708313 , global_step: 7215
- AI-Rank-log  1619227335.1036623  eval_accuracy: 0.6987013220787048 , global_step: 7216
- AI-Rank-log  1619227379.092111  eval_accuracy: 0.6993719339370728 , global_step: 7217
- AI-Rank-log  1619227423.065966  eval_accuracy: 0.6991246342658997 , global_step: 7218
- AI-Rank-log  1619227467.014361  eval_accuracy: 0.6988767385482788 , global_step: 7219
- AI-Rank-log  1619227510.9456155  eval_accuracy: 0.6988087296485901 , global_step: 7220
- AI-Rank-log  1619227554.897054  eval_accuracy: 0.6990715861320496 , global_step: 7221
- AI-Rank-log  1619227598.9122436  eval_accuracy: 0.6987812519073486 , global_step: 7222
- AI-Rank-log  1619227642.8168957  eval_accuracy: 0.6989227533340454 , global_step: 7223
- AI-Rank-log  1619227686.767368  eval_accuracy: 0.6986809968948364 , global_step: 7224
- AI-Rank-log  1619227730.7639391  eval_accuracy: 0.6987447142601013 , global_step: 7225
- AI-Rank-log  1619227774.720935  eval_accuracy: 0.698695719242096 , global_step: 7226
- AI-Rank-log  1619227818.6407208  eval_accuracy: 0.698930025100708 , global_step: 7227
- AI-Rank-log  1619227862.7747412  eval_accuracy: 0.699430525302887 , global_step: 7228
- AI-Rank-log  1619227906.7008774  eval_accuracy: 0.6990868449211121 , global_step: 7229
- AI-Rank-log  1619227950.6433206  eval_accuracy: 0.6992694735527039 , global_step: 7230
- AI-Rank-log  1619227994.6297612  eval_accuracy: 0.6995335221290588 , global_step: 7231
- AI-Rank-log  1619228038.5389712  eval_accuracy: 0.6991587281227112 , global_step: 7232
- AI-Rank-log  1619228082.6299214  eval_accuracy: 0.6995041370391846 , global_step: 7233
- AI-Rank-log  1619228126.5748556  eval_accuracy: 0.6993707418441772 , global_step: 7234
- AI-Rank-log  1619228170.4857252  eval_accuracy: 0.6995491981506348 , global_step: 7235
- AI-Rank-log  1619228214.488913  eval_accuracy: 0.6993191242218018 , global_step: 7236
- AI-Rank-log  1619228258.4060745  eval_accuracy: 0.6993501782417297 , global_step: 7237
- AI-Rank-log  1619228302.3774395  eval_accuracy: 0.6991294026374817 , global_step: 7238
- AI-Rank-log  1619228346.331699  eval_accuracy: 0.699000358581543 , global_step: 7239
- AI-Rank-log  1619228390.3024557  eval_accuracy: 0.699572741985321 , global_step: 7240
- AI-Rank-log  1619228434.3519847  eval_accuracy: 0.6994631290435791 , global_step: 7241
- AI-Rank-log  1619228478.2516515  eval_accuracy: 0.6993787884712219 , global_step: 7242
- AI-Rank-log  1619228522.1806514  eval_accuracy: 0.6992173790931702 , global_step: 7243
- AI-Rank-log  1619228566.1891632  eval_accuracy: 0.7005060315132141 , global_step: 7244
- AI-Rank-log  1619228610.1299853  eval_accuracy: 0.6993573904037476 , global_step: 7245
- AI-Rank-log  1619228654.1197836  eval_accuracy: 0.6997460126876831 , global_step: 7246
- AI-Rank-log  1619228698.1737144  eval_accuracy: 0.6987113356590271 , global_step: 7247
- AI-Rank-log  1619228742.0751271  eval_accuracy: 0.6991180181503296 , global_step: 7248
- AI-Rank-log  1619228786.1132383  eval_accuracy: 0.6986352205276489 , global_step: 7249
- AI-Rank-log  1619228830.0796235  eval_accuracy: 0.6996318697929382 , global_step: 7250
- AI-Rank-log  1619228874.0114586  eval_accuracy: 0.6993780732154846 , global_step: 7251
- AI-Rank-log  1619228918.0458035  eval_accuracy: 0.7000712752342224 , global_step: 7252
- AI-Rank-log  1619228961.9687233  eval_accuracy: 0.6998454928398132 , global_step: 7253
- AI-Rank-log  1619229005.8981032  eval_accuracy: 0.6999918222427368 , global_step: 7254
- AI-Rank-log  1619229049.9687781  eval_accuracy: 0.7002540230751038 , global_step: 7255
- AI-Rank-log  1619229093.880498  eval_accuracy: 0.6996563673019409 , global_step: 7256
- AI-Rank-log  1619229137.823629  eval_accuracy: 0.6997183561325073 , global_step: 7257
- AI-Rank-log  1619229181.8479834  eval_accuracy: 0.6995243430137634 , global_step: 7258
- AI-Rank-log  1619229226.4192584  eval_accuracy: 0.6991610527038574 , global_step: 7259
- AI-Rank-log  1619229270.4337547  eval_accuracy: 0.6994349360466003 , global_step: 7260
- AI-Rank-log  1619229314.4285889  eval_accuracy: 0.6992716193199158 , global_step: 7261
- AI-Rank-log  1619229358.372652  eval_accuracy: 0.6995294690132141 , global_step: 7262
- AI-Rank-log  1619229402.375199  eval_accuracy: 0.6992884278297424 , global_step: 7263
- AI-Rank-log  1619229446.964928  eval_accuracy: 0.6993497610092163 , global_step: 7264
- AI-Rank-log  1619229491.3156402  eval_accuracy: 0.6992615461349487 , global_step: 7265
- AI-Rank-log  1619229535.3516161  eval_accuracy: 0.6988352537155151 , global_step: 7266
- AI-Rank-log  1619229579.5095322  eval_accuracy: 0.6999606490135193 , global_step: 7267
- AI-Rank-log  1619229623.5142548  eval_accuracy: 0.6990067362785339 , global_step: 7268
- AI-Rank-log  1619229667.5458696  eval_accuracy: 0.6994010210037231 , global_step: 7269
- AI-Rank-log  1619229712.4750645  eval_accuracy: 0.6999966502189636 , global_step: 7270
- AI-Rank-log  1619229756.47474  eval_accuracy: 0.7000182271003723 , global_step: 7271
- AI-Rank-log  1619229800.451557  eval_accuracy: 0.6998064517974854 , global_step: 7272
- AI-Rank-log  1619229844.8046467  eval_accuracy: 0.6996611952781677 , global_step: 7273
- AI-Rank-log  1619229888.7734249  eval_accuracy: 0.6996063590049744 , global_step: 7274
- AI-Rank-log  1619229933.4992714  eval_accuracy: 0.6995847225189209 , global_step: 7275
- AI-Rank-log  1619229977.601823  eval_accuracy: 0.700065016746521 , global_step: 7276
- AI-Rank-log  1619230021.6341863  eval_accuracy: 0.6988897919654846 , global_step: 7277
- AI-Rank-log  1619230066.8771615  eval_accuracy: 0.7001535296440125 , global_step: 7278
- AI-Rank-log  1619230110.8600695  eval_accuracy: 0.6994070410728455 , global_step: 7279
- AI-Rank-log  1619230154.8357882  eval_accuracy: 0.6995499134063721 , global_step: 7280
- AI-Rank-log  1619230198.8342574  eval_accuracy: 0.6997644901275635 , global_step: 7281
- AI-Rank-log  1619230242.8442235  eval_accuracy: 0.6996044516563416 , global_step: 7282
- AI-Rank-log  1619230286.7897618  eval_accuracy: 0.6997843384742737 , global_step: 7283
- AI-Rank-log  1619230331.2007425  eval_accuracy: 0.6997969746589661 , global_step: 7284
- AI-Rank-log  1619230375.2892714  eval_accuracy: 0.699933648109436 , global_step: 7285
- AI-Rank-log  1619230419.2480533  eval_accuracy: 0.7000449895858765 , global_step: 7286
- AI-Rank-log  1619230463.209626  eval_accuracy: 0.7000361680984497 , global_step: 7287
- AI-Rank-log  1619230507.249657  eval_accuracy: 0.6994504332542419 , global_step: 7288
- AI-Rank-log  1619230551.2160652  eval_accuracy: 0.6994429230690002 , global_step: 7289
- AI-Rank-log  1619230595.252178  eval_accuracy: 0.6989591121673584 , global_step: 7290
- AI-Rank-log  1619230639.2297437  eval_accuracy: 0.6991896629333496 , global_step: 7291
- AI-Rank-log  1619230683.2009332  eval_accuracy: 0.6988548636436462 , global_step: 7292
- AI-Rank-log  1619230727.2144263  eval_accuracy: 0.6995341777801514 , global_step: 7293
- AI-Rank-log  1619230771.155862  eval_accuracy: 0.6989681720733643 , global_step: 7294
- AI-Rank-log  1619230815.1318295  eval_accuracy: 0.699828028678894 , global_step: 7295
- AI-Rank-log  1619230859.2393122  eval_accuracy: 0.6994901895523071 , global_step: 7296
- AI-Rank-log  1619230903.1936617  eval_accuracy: 0.6999278664588928 , global_step: 7297
- AI-Rank-log  1619230947.1530383  eval_accuracy: 0.7000902891159058 , global_step: 7298
- AI-Rank-log  1619230991.1803827  eval_accuracy: 0.6999788880348206 , global_step: 7299
- AI-Rank-log  1619231035.1285152  eval_accuracy: 0.6995104551315308 , global_step: 7300
- AI-Rank-log  1619231079.1984751  eval_accuracy: 0.6996431946754456 , global_step: 7301
- AI-Rank-log  1619231123.2397795  eval_accuracy: 0.6992163062095642 , global_step: 7302
- AI-Rank-log  1619231167.2217298  eval_accuracy: 0.6995869874954224 , global_step: 7303
- AI-Rank-log  1619231211.2329464  eval_accuracy: 0.6994444131851196 , global_step: 7304
- AI-Rank-log  1619231255.1940389  eval_accuracy: 0.6987876296043396 , global_step: 7305
- AI-Rank-log  1619231299.1102676  eval_accuracy: 0.6995887160301208 , global_step: 7306
- AI-Rank-log  1619231343.1630492  eval_accuracy: 0.6991836428642273 , global_step: 7307
- AI-Rank-log  1619231387.135157  eval_accuracy: 0.699675440788269 , global_step: 7308
- AI-Rank-log  1619231431.1399283  eval_accuracy: 0.6993646025657654 , global_step: 7309
- AI-Rank-log  1619231475.1219103  eval_accuracy: 0.7000870108604431 , global_step: 7310
- AI-Rank-log  1619231519.1218584  eval_accuracy: 0.6996638774871826 , global_step: 7311
- AI-Rank-log  1619231563.1423798  eval_accuracy: 0.6997922658920288 , global_step: 7312
- AI-Rank-log  1619231607.1053896  eval_accuracy: 0.6996267437934875 , global_step: 7313
- AI-Rank-log  1619231651.0782304  eval_accuracy: 0.699970543384552 , global_step: 7314
- AI-Rank-log  1619231695.0992424  eval_accuracy: 0.6990576386451721 , global_step: 7315
- AI-Rank-log  1619231739.0783186  eval_accuracy: 0.6996391415596008 , global_step: 7316
- AI-Rank-log  1619231783.0309038  eval_accuracy: 0.6999011039733887 , global_step: 7317
- AI-Rank-log  1619231827.0473337  eval_accuracy: 0.6997042894363403 , global_step: 7318
- AI-Rank-log  1619231870.9999158  eval_accuracy: 0.6993163824081421 , global_step: 7319
- AI-Rank-log  1619231915.0520785  eval_accuracy: 0.6993412971496582 , global_step: 7320
- AI-Rank-log  1619231959.0344136  eval_accuracy: 0.7000287771224976 , global_step: 7321
- AI-Rank-log  1619232003.0333672  eval_accuracy: 0.6990500092506409 , global_step: 7322
- AI-Rank-log  1619232047.043967  eval_accuracy: 0.7001978754997253 , global_step: 7323
- AI-Rank-log  1619232091.0036037  eval_accuracy: 0.6994250416755676 , global_step: 7324
- AI-Rank-log  1619232134.9637728  eval_accuracy: 0.6997919678688049 , global_step: 7325
- AI-Rank-log  1619232178.9361236  eval_accuracy: 0.6998947858810425 , global_step: 7326
- AI-Rank-log  1619232222.867481  eval_accuracy: 0.6994568109512329 , global_step: 7327
- AI-Rank-log  1619232266.840445  eval_accuracy: 0.6997343897819519 , global_step: 7328
- AI-Rank-log  1619232310.854753  eval_accuracy: 0.6997678875923157 , global_step: 7329
- AI-Rank-log  1619232354.8377252  eval_accuracy: 0.6994885206222534 , global_step: 7330
- AI-Rank-log  1619232398.89519  eval_accuracy: 0.6996580362319946 , global_step: 7331
- AI-Rank-log  1619232442.8244996  eval_accuracy: 0.699449896812439 , global_step: 7332
- AI-Rank-log  1619232486.7768521  eval_accuracy: 0.700019121170044 , global_step: 7333
- AI-Rank-log  1619232530.7679405  eval_accuracy: 0.6998703479766846 , global_step: 7334
- AI-Rank-log  1619232574.7199438  eval_accuracy: 0.7000516653060913 , global_step: 7335
- AI-Rank-log  1619232618.7752512  eval_accuracy: 0.7000212073326111 , global_step: 7336
- AI-Rank-log  1619232663.28495  eval_accuracy: 0.6997981667518616 , global_step: 7337
- AI-Rank-log  1619232707.1793737  eval_accuracy: 0.6998006105422974 , global_step: 7338
- AI-Rank-log  1619232751.2000906  eval_accuracy: 0.6989219784736633 , global_step: 7339
- AI-Rank-log  1619232795.102875  eval_accuracy: 0.6998564600944519 , global_step: 7340
- AI-Rank-log  1619232839.7768855  eval_accuracy: 0.6995235085487366 , global_step: 7341
- AI-Rank-log  1619232883.8842752  eval_accuracy: 0.6988791823387146 , global_step: 7342
- AI-Rank-log  1619232928.323011  eval_accuracy: 0.6988924145698547 , global_step: 7343
- AI-Rank-log  1619232972.4333227  eval_accuracy: 0.6989040374755859 , global_step: 7344
- AI-Rank-log  1619233016.5775375  eval_accuracy: 0.6997020244598389 , global_step: 7345
- AI-Rank-log  1619233060.4782481  eval_accuracy: 0.6996465921401978 , global_step: 7346
- AI-Rank-log  1619233104.4798925  eval_accuracy: 0.6995606422424316 , global_step: 7347
- AI-Rank-log  1619233149.4469578  eval_accuracy: 0.6998140215873718 , global_step: 7348
- AI-Rank-log  1619233193.6130297  eval_accuracy: 0.6999585032463074 , global_step: 7349
- AI-Rank-log  1619233238.0122228  eval_accuracy: 0.6987790465354919 , global_step: 7350
- AI-Rank-log  1619233281.997531  eval_accuracy: 0.6992829442024231 , global_step: 7351
- AI-Rank-log  1619233325.8738384  eval_accuracy: 0.6998232007026672 , global_step: 7352
- AI-Rank-log  1619233370.2982912  eval_accuracy: 0.6990023851394653 , global_step: 7353
- AI-Rank-log  1619233414.325743  eval_accuracy: 0.699687659740448 , global_step: 7354
- AI-Rank-log  1619233458.2596488  eval_accuracy: 0.698456346988678 , global_step: 7355
- AI-Rank-log  1619233503.322977  eval_accuracy: 0.6995944380760193 , global_step: 7356
- AI-Rank-log  1619233547.2691693  eval_accuracy: 0.6990072131156921 , global_step: 7357
- AI-Rank-log  1619233591.3091059  eval_accuracy: 0.7000012993812561 , global_step: 7358
- AI-Rank-log  1619233635.2839375  eval_accuracy: 0.7000988721847534 , global_step: 7359
- AI-Rank-log  1619233679.2589347  eval_accuracy: 0.6994669437408447 , global_step: 7360
- AI-Rank-log  1619233723.5831835  eval_accuracy: 0.699571430683136 , global_step: 7361
- AI-Rank-log  1619233767.5644588  eval_accuracy: 0.6999557614326477 , global_step: 7362
- AI-Rank-log  1619233811.539101  eval_accuracy: 0.6992859244346619 , global_step: 7363
- AI-Rank-log  1619233855.526197  eval_accuracy: 0.6998335123062134 , global_step: 7364
- AI-Rank-log  1619233899.4793482  eval_accuracy: 0.6987918019294739 , global_step: 7365
- AI-Rank-log  1619233943.448054  eval_accuracy: 0.699400782585144 , global_step: 7366
- AI-Rank-log  1619233987.4790933  eval_accuracy: 0.6995156407356262 , global_step: 7367
- AI-Rank-log  1619234031.419033  eval_accuracy: 0.6998264789581299 , global_step: 7368
- AI-Rank-log  1619234075.4361408  eval_accuracy: 0.6998651623725891 , global_step: 7369
- AI-Rank-log  1619234119.3740017  eval_accuracy: 0.6998216509819031 , global_step: 7370
- AI-Rank-log  1619234163.359343  eval_accuracy: 0.699453592300415 , global_step: 7371
- AI-Rank-log  1619234207.3718178  eval_accuracy: 0.6998259425163269 , global_step: 7372
- AI-Rank-log  1619234251.336673  eval_accuracy: 0.7003551721572876 , global_step: 7373
- AI-Rank-log  1619234295.2851071  eval_accuracy: 0.700369119644165 , global_step: 7374
- AI-Rank-log  1619234339.3691494  eval_accuracy: 0.7002095580101013 , global_step: 7375
- AI-Rank-log  1619234383.3275502  eval_accuracy: 0.7006049156188965 , global_step: 7376
- AI-Rank-log  1619234427.3333926  eval_accuracy: 0.7001901865005493 , global_step: 7377
- AI-Rank-log  1619234471.362804  eval_accuracy: 0.700307309627533 , global_step: 7378
- AI-Rank-log  1619234515.3305936  eval_accuracy: 0.700299859046936 , global_step: 7379
- AI-Rank-log  1619234559.3309457  eval_accuracy: 0.7007558345794678 , global_step: 7380
- AI-Rank-log  1619234603.3085437  eval_accuracy: 0.6999680995941162 , global_step: 7381
- AI-Rank-log  1619234647.3071434  eval_accuracy: 0.7004210352897644 , global_step: 7382
- AI-Rank-log  1619234691.3950536  eval_accuracy: 0.6997666954994202 , global_step: 7383
- AI-Rank-log  1619234735.3338287  eval_accuracy: 0.6994155645370483 , global_step: 7384
- AI-Rank-log  1619234779.291516  eval_accuracy: 0.7000654339790344 , global_step: 7385
- AI-Rank-log  1619234823.3400137  eval_accuracy: 0.6999680399894714 , global_step: 7386
- AI-Rank-log  1619234867.2855651  eval_accuracy: 0.7002983093261719 , global_step: 7387
- AI-Rank-log  1619234911.2632935  eval_accuracy: 0.6999844312667847 , global_step: 7388
- AI-Rank-log  1619234955.3393867  eval_accuracy: 0.6996837258338928 , global_step: 7389
- AI-Rank-log  1619234999.2902067  eval_accuracy: 0.6994750499725342 , global_step: 7390
- AI-Rank-log  1619235052.2323635  eval_accuracy: 0.699130654335022 , global_step: 7391
- AI-Rank-log  1619235096.1534271  eval_accuracy: 0.6996748447418213 , global_step: 7392
- AI-Rank-log  1619235140.0663056  eval_accuracy: 0.6994481682777405 , global_step: 7393
- AI-Rank-log  1619235184.0540867  eval_accuracy: 0.6993123292922974 , global_step: 7394
- AI-Rank-log  1619235228.0011911  eval_accuracy: 0.6996679902076721 , global_step: 7395
- AI-Rank-log  1619235271.9224422  eval_accuracy: 0.6998223066329956 , global_step: 7396
- AI-Rank-log  1619235315.9772055  eval_accuracy: 0.6997546553611755 , global_step: 7397
- AI-Rank-log  1619235359.9273977  eval_accuracy: 0.7003667950630188 , global_step: 7398
- AI-Rank-log  1619235403.918651  eval_accuracy: 0.6998008489608765 , global_step: 7399
- AI-Rank-log  1619235447.9392333  eval_accuracy: 0.7005013227462769 , global_step: 7400
- AI-Rank-log  1619235491.88654  eval_accuracy: 0.6993404030799866 , global_step: 7401
- AI-Rank-log  1619235535.9140928  eval_accuracy: 0.6998717188835144 , global_step: 7402
- AI-Rank-log  1619235579.8381217  eval_accuracy: 0.7002400755882263 , global_step: 7403
- AI-Rank-log  1619235623.8399336  eval_accuracy: 0.699974000453949 , global_step: 7404
- AI-Rank-log  1619235667.8608124  eval_accuracy: 0.6998169422149658 , global_step: 7405
- AI-Rank-log  1619235711.7877135  eval_accuracy: 0.7000893950462341 , global_step: 7406
- AI-Rank-log  1619235755.719056  eval_accuracy: 0.7003697752952576 , global_step: 7407
- AI-Rank-log  1619235799.7309082  eval_accuracy: 0.700219452381134 , global_step: 7408
- AI-Rank-log  1619235843.7021616  eval_accuracy: 0.7010875344276428 , global_step: 7409
- AI-Rank-log  1619235887.6528747  eval_accuracy: 0.7000684142112732 , global_step: 7410
- AI-Rank-log  1619235931.7051425  eval_accuracy: 0.7009141445159912 , global_step: 7411
- AI-Rank-log  1619235975.675497  eval_accuracy: 0.699854850769043 , global_step: 7412
- AI-Rank-log  1619236019.6857817  eval_accuracy: 0.7000102996826172 , global_step: 7413
- AI-Rank-log  1619236064.5486987  eval_accuracy: 0.6999786496162415 , global_step: 7414
- AI-Rank-log  1619236108.7747388  eval_accuracy: 0.7006485462188721 , global_step: 7415
- AI-Rank-log  1619236152.7661862  eval_accuracy: 0.7004238963127136 , global_step: 7416
- AI-Rank-log  1619236196.7310393  eval_accuracy: 0.7008873820304871 , global_step: 7417
- AI-Rank-log  1619236240.7266238  eval_accuracy: 0.7005297541618347 , global_step: 7418
- AI-Rank-log  1619236285.0394619  eval_accuracy: 0.7004044651985168 , global_step: 7419
- AI-Rank-log  1619236329.5286899  eval_accuracy: 0.7000654339790344 , global_step: 7420
- AI-Rank-log  1619236373.4969888  eval_accuracy: 0.700126051902771 , global_step: 7421
- AI-Rank-log  1619236418.5893748  eval_accuracy: 0.7002311944961548 , global_step: 7422
- AI-Rank-log  1619236462.523696  eval_accuracy: 0.7000898718833923 , global_step: 7423
- AI-Rank-log  1619236506.5049202  eval_accuracy: 0.7002030611038208 , global_step: 7424
- AI-Rank-log  1619236550.453544  eval_accuracy: 0.6999466419219971 , global_step: 7425
- AI-Rank-log  1619236595.2222607  eval_accuracy: 0.700237512588501 , global_step: 7426
- AI-Rank-log  1619236639.2621202  eval_accuracy: 0.6993985772132874 , global_step: 7427
- AI-Rank-log  1619236683.26051  eval_accuracy: 0.7002742290496826 , global_step: 7428
- AI-Rank-log  1619236727.197418  eval_accuracy: 0.6996431350708008 , global_step: 7429
- AI-Rank-log  1619236772.64968  eval_accuracy: 0.7006552815437317 , global_step: 7430
- AI-Rank-log  1619236816.575861  eval_accuracy: 0.7000044584274292 , global_step: 7431
- AI-Rank-log  1619236860.6387775  eval_accuracy: 0.7000305652618408 , global_step: 7432
- AI-Rank-log  1619236905.662073  eval_accuracy: 0.7001707553863525 , global_step: 7433
- AI-Rank-log  1619236949.6069257  eval_accuracy: 0.6994641423225403 , global_step: 7434
- AI-Rank-log  1619236993.7199688  eval_accuracy: 0.7006208300590515 , global_step: 7435
- AI-Rank-log  1619237037.6651785  eval_accuracy: 0.7002359628677368 , global_step: 7436
- AI-Rank-log  1619237081.6243286  eval_accuracy: 0.7002754211425781 , global_step: 7437
- AI-Rank-log  1619237125.6850498  eval_accuracy: 0.6999280452728271 , global_step: 7438
- AI-Rank-log  1619237169.9943726  eval_accuracy: 0.7001792192459106 , global_step: 7439
- AI-Rank-log  1619237213.9170709  eval_accuracy: 0.6999891400337219 , global_step: 7440
- AI-Rank-log  1619237257.9639244  eval_accuracy: 0.7001551985740662 , global_step: 7441
- AI-Rank-log  1619237301.8966272  eval_accuracy: 0.6999381184577942 , global_step: 7442
- AI-Rank-log  1619237345.8560154  eval_accuracy: 0.7003573179244995 , global_step: 7443
- AI-Rank-log  1619237389.8734155  eval_accuracy: 0.6998918652534485 , global_step: 7444
- AI-Rank-log  1619237433.7910595  eval_accuracy: 0.6997888684272766 , global_step: 7445
- AI-Rank-log  1619237477.820594  eval_accuracy: 0.699975311756134 , global_step: 7446
- AI-Rank-log  1619237521.8017526  eval_accuracy: 0.6988815665245056 , global_step: 7447
- AI-Rank-log  1619237565.5280719  eval_accuracy: 0.700558066368103 , global_step: 7448
- AI-Rank-log  1619237609.5613148  eval_accuracy: 0.7002546191215515 , global_step: 7449
- AI-Rank-log  1619237653.5529354  eval_accuracy: 0.7000786066055298 , global_step: 7450
- AI-Rank-log  1619237697.4793274  eval_accuracy: 0.6997909545898438 , global_step: 7451
- AI-Rank-log  1619237741.5181456  eval_accuracy: 0.700265645980835 , global_step: 7452
- AI-Rank-log  1619237785.476154  eval_accuracy: 0.7001135945320129 , global_step: 7453
- AI-Rank-log  1619237829.486702  eval_accuracy: 0.7003414630889893 , global_step: 7454
- AI-Rank-log  1619237873.4462414  eval_accuracy: 0.7010420560836792 , global_step: 7455
- AI-Rank-log  1619237917.4156137  eval_accuracy: 0.7005600929260254 , global_step: 7456
- AI-Rank-log  1619237961.436719  eval_accuracy: 0.7006241083145142 , global_step: 7457
- AI-Rank-log  1619238005.4149055  eval_accuracy: 0.7006420493125916 , global_step: 7458
- AI-Rank-log  1619238049.3702354  eval_accuracy: 0.7008421421051025 , global_step: 7459
- AI-Rank-log  1619238093.3872771  eval_accuracy: 0.7010573148727417 , global_step: 7460
- AI-Rank-log  1619238137.3453732  eval_accuracy: 0.7009848952293396 , global_step: 7461
- AI-Rank-log  1619238181.3117223  eval_accuracy: 0.7003448009490967 , global_step: 7462
- AI-Rank-log  1619238225.0948377  eval_accuracy: 0.7012306451797485 , global_step: 7463
- AI-Rank-log  1619238269.038355  eval_accuracy: 0.7000285983085632 , global_step: 7464
- AI-Rank-log  1619238313.0244317  eval_accuracy: 0.7002450823783875 , global_step: 7465
- AI-Rank-log  1619238356.925339  eval_accuracy: 0.7005189657211304 , global_step: 7466
- AI-Rank-log  1619238400.8750997  eval_accuracy: 0.7006871700286865 , global_step: 7467
- AI-Rank-log  1619238444.8961673  eval_accuracy: 0.700604259967804 , global_step: 7468
- AI-Rank-log  1619238488.832695  eval_accuracy: 0.7004284262657166 , global_step: 7469
- AI-Rank-log  1619238532.773321  eval_accuracy: 0.7001202702522278 , global_step: 7470
- AI-Rank-log  1619238576.7866719  eval_accuracy: 0.7005698680877686 , global_step: 7471
- AI-Rank-log  1619238620.7481143  eval_accuracy: 0.7005240321159363 , global_step: 7472
- AI-Rank-log  1619238664.7242184  eval_accuracy: 0.701141357421875 , global_step: 7473
- AI-Rank-log  1619238708.7290263  eval_accuracy: 0.7006942629814148 , global_step: 7474
- AI-Rank-log  1619238752.6384182  eval_accuracy: 0.6999118328094482 , global_step: 7475
- AI-Rank-log  1619238796.7169285  eval_accuracy: 0.7006791830062866 , global_step: 7476
- AI-Rank-log  1619238840.664849  eval_accuracy: 0.7012073397636414 , global_step: 7477
- AI-Rank-log  1619238884.6319878  eval_accuracy: 0.7007169723510742 , global_step: 7478
- AI-Rank-log  1619238928.6169107  eval_accuracy: 0.7007340788841248 , global_step: 7479
- AI-Rank-log  1619238972.527372  eval_accuracy: 0.7008112072944641 , global_step: 7480
- AI-Rank-log  1619239016.4706054  eval_accuracy: 0.7004809379577637 , global_step: 7481
- AI-Rank-log  1619239060.4833024  eval_accuracy: 0.7009214758872986 , global_step: 7482
- AI-Rank-log  1619239104.4147437  eval_accuracy: 0.7009220719337463 , global_step: 7483
- AI-Rank-log  1619239148.3757684  eval_accuracy: 0.7012173533439636 , global_step: 7484
- AI-Rank-log  1619239192.3722203  eval_accuracy: 0.7014947533607483 , global_step: 7485
- AI-Rank-log  1619239236.3168373  eval_accuracy: 0.7003904581069946 , global_step: 7486
- AI-Rank-log  1619239280.2517939  eval_accuracy: 0.7013225555419922 , global_step: 7487
- AI-Rank-log  1619239324.2560601  eval_accuracy: 0.6998892426490784 , global_step: 7488
- AI-Rank-log  1619239368.1707432  eval_accuracy: 0.7011820673942566 , global_step: 7489
- AI-Rank-log  1619239412.2386448  eval_accuracy: 0.7005017995834351 , global_step: 7490
- AI-Rank-log  1619239456.9837892  eval_accuracy: 0.7009258270263672 , global_step: 7491
- AI-Rank-log  1619239501.246388  eval_accuracy: 0.7010436058044434 , global_step: 7492
- AI-Rank-log  1619239545.2482104  eval_accuracy: 0.7013692259788513 , global_step: 7493
- AI-Rank-log  1619239589.169189  eval_accuracy: 0.7008942365646362 , global_step: 7494
- AI-Rank-log  1619239633.095957  eval_accuracy: 0.7005898356437683 , global_step: 7495
- AI-Rank-log  1619239677.6424415  eval_accuracy: 0.7005295157432556 , global_step: 7496
- AI-Rank-log  1619239721.983066  eval_accuracy: 0.7004434466362 , global_step: 7497
- AI-Rank-log  1619239765.9241805  eval_accuracy: 0.7000041604042053 , global_step: 7498
- AI-Rank-log  1619239809.9792316  eval_accuracy: 0.7011774778366089 , global_step: 7499
- AI-Rank-log  1619239854.1443405  eval_accuracy: 0.7006528973579407 , global_step: 7500
- AI-Rank-log  1619239898.1792505  eval_accuracy: 0.7010437846183777 , global_step: 7501
- AI-Rank-log  1619239942.1385953  eval_accuracy: 0.7004886269569397 , global_step: 7502
- AI-Rank-log  1619239987.1239772  eval_accuracy: 0.7011323571205139 , global_step: 7503
- AI-Rank-log  1619240031.1725  eval_accuracy: 0.7005003094673157 , global_step: 7504
- AI-Rank-log  1619240075.6238809  eval_accuracy: 0.7014455795288086 , global_step: 7505
- AI-Rank-log  1619240119.5911317  eval_accuracy: 0.7006651759147644 , global_step: 7506
- AI-Rank-log  1619240164.3459492  eval_accuracy: 0.7006396651268005 , global_step: 7507
- AI-Rank-log  1619240208.4998887  eval_accuracy: 0.7007194757461548 , global_step: 7508
- AI-Rank-log  1619240253.1342542  eval_accuracy: 0.700775146484375 , global_step: 7509
- AI-Rank-log  1619240298.2961757  eval_accuracy: 0.7004626989364624 , global_step: 7510
- AI-Rank-log  1619240342.2667003  eval_accuracy: 0.7004960775375366 , global_step: 7511
- AI-Rank-log  1619240386.8158932  eval_accuracy: 0.700842022895813 , global_step: 7512
- AI-Rank-log  1619240430.7928076  eval_accuracy: 0.700411319732666 , global_step: 7513
- AI-Rank-log  1619240474.7912445  eval_accuracy: 0.7006474137306213 , global_step: 7514
- AI-Rank-log  1619240518.8747554  eval_accuracy: 0.6998010873794556 , global_step: 7515
- AI-Rank-log  1619240563.2139726  eval_accuracy: 0.7003657221794128 , global_step: 7516
- AI-Rank-log  1619240607.1806738  eval_accuracy: 0.7000628709793091 , global_step: 7517
- AI-Rank-log  1619240651.2091718  eval_accuracy: 0.7010370492935181 , global_step: 7518
- AI-Rank-log  1619240695.202907  eval_accuracy: 0.700803816318512 , global_step: 7519
- AI-Rank-log  1619240739.1882045  eval_accuracy: 0.7008861303329468 , global_step: 7520
- AI-Rank-log  1619240783.1343405  eval_accuracy: 0.7006106376647949 , global_step: 7521
- AI-Rank-log  1619240827.0471072  eval_accuracy: 0.7012841105461121 , global_step: 7522
- AI-Rank-log  1619240871.0920026  eval_accuracy: 0.7006134390830994 , global_step: 7523
- AI-Rank-log  1619240915.0198703  eval_accuracy: 0.7010403871536255 , global_step: 7524
- AI-Rank-log  1619240958.9753609  eval_accuracy: 0.7010622024536133 , global_step: 7525
- AI-Rank-log  1619241002.9688017  eval_accuracy: 0.7009745240211487 , global_step: 7526
- AI-Rank-log  1619241046.9387364  eval_accuracy: 0.7006250619888306 , global_step: 7527
- AI-Rank-log  1619241090.8872595  eval_accuracy: 0.7013344168663025 , global_step: 7528
- AI-Rank-log  1619241134.8627088  eval_accuracy: 0.7007649540901184 , global_step: 7529
- AI-Rank-log  1619241178.7906756  eval_accuracy: 0.7017359137535095 , global_step: 7530
- AI-Rank-log  1619241222.7916992  eval_accuracy: 0.7014583349227905 , global_step: 7531
- AI-Rank-log  1619241266.7620986  eval_accuracy: 0.7016619443893433 , global_step: 7532
- AI-Rank-log  1619241310.682451  eval_accuracy: 0.7011929154396057 , global_step: 7533
- AI-Rank-log  1619241354.7141223  eval_accuracy: 0.7014249563217163 , global_step: 7534
- AI-Rank-log  1619241398.6358745  eval_accuracy: 0.7014201879501343 , global_step: 7535
- AI-Rank-log  1619241442.6093855  eval_accuracy: 0.7019546627998352 , global_step: 7536
- AI-Rank-log  1619241486.5885253  eval_accuracy: 0.7008680701255798 , global_step: 7537
- AI-Rank-log  1619241530.502251  eval_accuracy: 0.702221691608429 , global_step: 7538
- AI-Rank-log  1619241574.476434  eval_accuracy: 0.7009541988372803 , global_step: 7539
- AI-Rank-log  1619241618.502995  eval_accuracy: 0.7017887830734253 , global_step: 7540
- AI-Rank-log  1619241662.4521053  eval_accuracy: 0.7011681199073792 , global_step: 7541
- AI-Rank-log  1619241706.483971  eval_accuracy: 0.7016376852989197 , global_step: 7542
- AI-Rank-log  1619241750.4509401  eval_accuracy: 0.7011009454727173 , global_step: 7543
- AI-Rank-log  1619241794.3874235  eval_accuracy: 0.702059268951416 , global_step: 7544
- AI-Rank-log  1619241838.4132826  eval_accuracy: 0.7005563378334045 , global_step: 7545
- AI-Rank-log  1619241882.3623078  eval_accuracy: 0.7012871503829956 , global_step: 7546
- AI-Rank-log  1619241926.3180408  eval_accuracy: 0.7011006474494934 , global_step: 7547
- AI-Rank-log  1619241970.3653967  eval_accuracy: 0.7018597722053528 , global_step: 7548
- AI-Rank-log  1619242014.3162212  eval_accuracy: 0.7018470168113708 , global_step: 7549
- AI-Rank-log  1619242058.2434022  eval_accuracy: 0.7011021375656128 , global_step: 7550
- AI-Rank-log  1619242102.2827973  eval_accuracy: 0.7019036412239075 , global_step: 7551
- AI-Rank-log  1619242146.195942  eval_accuracy: 0.7009584307670593 , global_step: 7552
- AI-Rank-log  1619242190.174543  eval_accuracy: 0.7007502913475037 , global_step: 7553
- AI-Rank-log  1619242234.227619  eval_accuracy: 0.7006816267967224 , global_step: 7554
- AI-Rank-log  1619242278.1565983  eval_accuracy: 0.7008342146873474 , global_step: 7555
- AI-Rank-log  1619242322.1921728  eval_accuracy: 0.7010853290557861 , global_step: 7556
- AI-Rank-log  1619242366.1719434  eval_accuracy: 0.7015525102615356 , global_step: 7557
- AI-Rank-log  1619242410.110798  eval_accuracy: 0.7011144161224365 , global_step: 7558
- AI-Rank-log  1619242454.1231153  eval_accuracy: 0.7015537619590759 , global_step: 7559
- AI-Rank-log  1619242498.133042  eval_accuracy: 0.7015939950942993 , global_step: 7560
- AI-Rank-log  1619242542.0771415  eval_accuracy: 0.7012341022491455 , global_step: 7561
- AI-Rank-log  1619242586.0862098  eval_accuracy: 0.7016500234603882 , global_step: 7562
- AI-Rank-log  1619242630.0532093  eval_accuracy: 0.7008718252182007 , global_step: 7563
- AI-Rank-log  1619242674.1388464  eval_accuracy: 0.7014815807342529 , global_step: 7564
- AI-Rank-log  1619242718.0610197  eval_accuracy: 0.7014557123184204 , global_step: 7565
- AI-Rank-log  1619242762.0296001  eval_accuracy: 0.7010186910629272 , global_step: 7566
- AI-Rank-log  1619242806.0674627  eval_accuracy: 0.7020372748374939 , global_step: 7567
- AI-Rank-log  1619242850.0738852  eval_accuracy: 0.7008708715438843 , global_step: 7568
- AI-Rank-log  1619242894.520117  eval_accuracy: 0.7010179162025452 , global_step: 7569
- AI-Rank-log  1619242938.3649697  eval_accuracy: 0.7005168795585632 , global_step: 7570
- AI-Rank-log  1619242982.3840554  eval_accuracy: 0.7011132836341858 , global_step: 7571
- AI-Rank-log  1619243026.3217177  eval_accuracy: 0.700496256351471 , global_step: 7572
- AI-Rank-log  1619243070.9125686  eval_accuracy: 0.7007765769958496 , global_step: 7573
- AI-Rank-log  1619243114.8925848  eval_accuracy: 0.7006878852844238 , global_step: 7574
- AI-Rank-log  1619243159.1276922  eval_accuracy: 0.7009330987930298 , global_step: 7575
- AI-Rank-log  1619243203.6886044  eval_accuracy: 0.7011198997497559 , global_step: 7576
- AI-Rank-log  1619243247.8776438  eval_accuracy: 0.7008439898490906 , global_step: 7577
- AI-Rank-log  1619243291.9111807  eval_accuracy: 0.7011528015136719 , global_step: 7578
- AI-Rank-log  1619243336.0271263  eval_accuracy: 0.7013129591941833 , global_step: 7579
- AI-Rank-log  1619243380.9223177  eval_accuracy: 0.7018436789512634 , global_step: 7580
- AI-Rank-log  1619243425.039799  eval_accuracy: 0.7009236812591553 , global_step: 7581
- AI-Rank-log  1619243469.4925907  eval_accuracy: 0.701775312423706 , global_step: 7582
- AI-Rank-log  1619243513.4816716  eval_accuracy: 0.7015718817710876 , global_step: 7583
- AI-Rank-log  1619243557.503412  eval_accuracy: 0.7009897828102112 , global_step: 7584
- AI-Rank-log  1619243602.1412175  eval_accuracy: 0.7013954520225525 , global_step: 7585
- AI-Rank-log  1619243646.373497  eval_accuracy: 0.7007229924201965 , global_step: 7586
- AI-Rank-log  1619243690.316249  eval_accuracy: 0.7009840607643127 , global_step: 7587
- AI-Rank-log  1619243735.5191958  eval_accuracy: 0.7007492184638977 , global_step: 7588
- AI-Rank-log  1619243779.6341033  eval_accuracy: 0.7011952996253967 , global_step: 7589
- AI-Rank-log  1619243823.569628  eval_accuracy: 0.7014232873916626 , global_step: 7590
- AI-Rank-log  1619243876.6230674  eval_accuracy: 0.700918972492218 , global_step: 7591
- AI-Rank-log  1619243920.6318223  eval_accuracy: 0.7007261514663696 , global_step: 7592
- AI-Rank-log  1619243964.5583372  eval_accuracy: 0.700343906879425 , global_step: 7593
- AI-Rank-log  1619244008.760336  eval_accuracy: 0.7004846334457397 , global_step: 7594
- AI-Rank-log  1619244052.8213258  eval_accuracy: 0.7007434964179993 , global_step: 7595
- AI-Rank-log  1619244096.7528176  eval_accuracy: 0.7002190947532654 , global_step: 7596
- AI-Rank-log  1619244140.7990205  eval_accuracy: 0.7009487748146057 , global_step: 7597
- AI-Rank-log  1619244184.7382298  eval_accuracy: 0.7007822394371033 , global_step: 7598
- AI-Rank-log  1619244228.6636012  eval_accuracy: 0.7006708383560181 , global_step: 7599
- AI-Rank-log  1619244272.7274818  eval_accuracy: 0.7014256715774536 , global_step: 7600
- AI-Rank-log  1619244316.7003784  eval_accuracy: 0.7009005546569824 , global_step: 7601
- AI-Rank-log  1619244360.6529336  eval_accuracy: 0.7011213302612305 , global_step: 7602
- AI-Rank-log  1619244404.6518939  eval_accuracy: 0.7008013129234314 , global_step: 7603
- AI-Rank-log  1619244448.6115987  eval_accuracy: 0.7013955116271973 , global_step: 7604
- AI-Rank-log  1619244492.5550818  eval_accuracy: 0.7008858919143677 , global_step: 7605
- AI-Rank-log  1619244536.5618625  eval_accuracy: 0.7014122605323792 , global_step: 7606
- AI-Rank-log  1619244580.513339  eval_accuracy: 0.7008112072944641 , global_step: 7607
- AI-Rank-log  1619244624.4513345  eval_accuracy: 0.7016721963882446 , global_step: 7608
- AI-Rank-log  1619244668.452875  eval_accuracy: 0.7006394267082214 , global_step: 7609
- AI-Rank-log  1619244712.3895712  eval_accuracy: 0.701734185218811 , global_step: 7610
- AI-Rank-log  1619244756.4510326  eval_accuracy: 0.7007302641868591 , global_step: 7611
- AI-Rank-log  1619244800.4049122  eval_accuracy: 0.7013014554977417 , global_step: 7612
- AI-Rank-log  1619244844.3404372  eval_accuracy: 0.7010654807090759 , global_step: 7613
- AI-Rank-log  1619244888.357817  eval_accuracy: 0.7012802958488464 , global_step: 7614
- AI-Rank-log  1619244932.3506076  eval_accuracy: 0.7004581093788147 , global_step: 7615
- AI-Rank-log  1619244976.3259034  eval_accuracy: 0.7008823752403259 , global_step: 7616
- AI-Rank-log  1619245020.305217  eval_accuracy: 0.700948178768158 , global_step: 7617
- AI-Rank-log  1619245064.2768657  eval_accuracy: 0.7013149261474609 , global_step: 7618
- AI-Rank-log  1619245108.2695253  eval_accuracy: 0.7013713717460632 , global_step: 7619
- AI-Rank-log  1619245152.2033238  eval_accuracy: 0.7004879713058472 , global_step: 7620
- AI-Rank-log  1619245196.16139  eval_accuracy: 0.7007802128791809 , global_step: 7621
- AI-Rank-log  1619245240.1807702  eval_accuracy: 0.7008814215660095 , global_step: 7622
- AI-Rank-log  1619245284.1357312  eval_accuracy: 0.7009105682373047 , global_step: 7623
- AI-Rank-log  1619245328.0696049  eval_accuracy: 0.7007371187210083 , global_step: 7624
- AI-Rank-log  1619245372.036931  eval_accuracy: 0.7002980709075928 , global_step: 7625
- AI-Rank-log  1619245416.0550628  eval_accuracy: 0.7009641528129578 , global_step: 7626
- AI-Rank-log  1619245460.0294483  eval_accuracy: 0.700923502445221 , global_step: 7627
- AI-Rank-log  1619245504.0279574  eval_accuracy: 0.7006834745407104 , global_step: 7628
- AI-Rank-log  1619245547.996966  eval_accuracy: 0.7019995450973511 , global_step: 7629
- AI-Rank-log  1619245592.0114677  eval_accuracy: 0.701374351978302 , global_step: 7630
- AI-Rank-log  1619245635.9680183  eval_accuracy: 0.7011653780937195 , global_step: 7631
- AI-Rank-log  1619245679.9195964  eval_accuracy: 0.7014104127883911 , global_step: 7632
- AI-Rank-log  1619245723.9549508  eval_accuracy: 0.7016196250915527 , global_step: 7633
- AI-Rank-log  1619245767.8562186  eval_accuracy: 0.700810432434082 , global_step: 7634
- AI-Rank-log  1619245811.7734392  eval_accuracy: 0.7018118500709534 , global_step: 7635
- AI-Rank-log  1619245855.8533285  eval_accuracy: 0.7011123299598694 , global_step: 7636
- AI-Rank-log  1619245899.786026  eval_accuracy: 0.701360821723938 , global_step: 7637
- AI-Rank-log  1619245943.6939497  eval_accuracy: 0.7013499140739441 , global_step: 7638
- AI-Rank-log  1619245987.7009628  eval_accuracy: 0.7007384896278381 , global_step: 7639
- AI-Rank-log  1619246031.60527  eval_accuracy: 0.7018177509307861 , global_step: 7640
- AI-Rank-log  1619246075.6419272  eval_accuracy: 0.7017027139663696 , global_step: 7641
- AI-Rank-log  1619246119.59272  eval_accuracy: 0.701424241065979 , global_step: 7642
- AI-Rank-log  1619246163.5272908  eval_accuracy: 0.7006286978721619 , global_step: 7643
- AI-Rank-log  1619246207.5523462  eval_accuracy: 0.7007864713668823 , global_step: 7644
- AI-Rank-log  1619246251.532115  eval_accuracy: 0.7004646062850952 , global_step: 7645
- AI-Rank-log  1619246296.0386863  eval_accuracy: 0.7009450197219849 , global_step: 7646
- AI-Rank-log  1619246340.0367155  eval_accuracy: 0.7003797292709351 , global_step: 7647
- AI-Rank-log  1619246383.9664736  eval_accuracy: 0.7009826898574829 , global_step: 7648
- AI-Rank-log  1619246427.9384012  eval_accuracy: 0.7000923156738281 , global_step: 7649
- AI-Rank-log  1619246472.3489342  eval_accuracy: 0.7013292908668518 , global_step: 7650
- AI-Rank-log  1619246516.279397  eval_accuracy: 0.7004189491271973 , global_step: 7651
- AI-Rank-log  1619246560.9031737  eval_accuracy: 0.7018567323684692 , global_step: 7652
- AI-Rank-log  1619246604.8698258  eval_accuracy: 0.7017530202865601 , global_step: 7653
- AI-Rank-log  1619246649.1712534  eval_accuracy: 0.7013781666755676 , global_step: 7654
- AI-Rank-log  1619246693.2955306  eval_accuracy: 0.700916588306427 , global_step: 7655
- AI-Rank-log  1619246737.2935874  eval_accuracy: 0.7017870545387268 , global_step: 7656
- AI-Rank-log  1619246782.0445688  eval_accuracy: 0.7015116214752197 , global_step: 7657
- AI-Rank-log  1619246826.0774252  eval_accuracy: 0.7015131115913391 , global_step: 7658
- AI-Rank-log  1619246870.0801232  eval_accuracy: 0.7012247443199158 , global_step: 7659
- AI-Rank-log  1619246914.6018736  eval_accuracy: 0.7015750408172607 , global_step: 7660
- AI-Rank-log  1619246958.6151092  eval_accuracy: 0.7009074687957764 , global_step: 7661
- AI-Rank-log  1619247003.4628124  eval_accuracy: 0.7010958194732666 , global_step: 7662
- AI-Rank-log  1619247047.446077  eval_accuracy: 0.7006238102912903 , global_step: 7663
- AI-Rank-log  1619247091.5107934  eval_accuracy: 0.7011439204216003 , global_step: 7664
- AI-Rank-log  1619247135.8384457  eval_accuracy: 0.7011277079582214 , global_step: 7665
- AI-Rank-log  1619247180.7128613  eval_accuracy: 0.6999422311782837 , global_step: 7666
- AI-Rank-log  1619247224.6822872  eval_accuracy: 0.7006697654724121 , global_step: 7667
- AI-Rank-log  1619247268.6676183  eval_accuracy: 0.7010906934738159 , global_step: 7668
- AI-Rank-log  1619247312.7113147  eval_accuracy: 0.7009872794151306 , global_step: 7669
- AI-Rank-log  1619247356.6725392  eval_accuracy: 0.7009303569793701 , global_step: 7670
- AI-Rank-log  1619247400.807673  eval_accuracy: 0.7007806897163391 , global_step: 7671
- AI-Rank-log  1619247444.8003316  eval_accuracy: 0.7010423541069031 , global_step: 7672
- AI-Rank-log  1619247488.7806246  eval_accuracy: 0.7015835046768188 , global_step: 7673
- AI-Rank-log  1619247532.7699187  eval_accuracy: 0.7007799744606018 , global_step: 7674
- AI-Rank-log  1619247576.709774  eval_accuracy: 0.7018900513648987 , global_step: 7675
- AI-Rank-log  1619247620.693812  eval_accuracy: 0.7009069323539734 , global_step: 7676
- AI-Rank-log  1619247664.6665525  eval_accuracy: 0.7013179659843445 , global_step: 7677
- AI-Rank-log  1619247708.5645618  eval_accuracy: 0.7009928226470947 , global_step: 7678
- AI-Rank-log  1619247752.5592625  eval_accuracy: 0.7015273571014404 , global_step: 7679
- AI-Rank-log  1619247796.5360267  eval_accuracy: 0.7012581825256348 , global_step: 7680
- AI-Rank-log  1619247840.5080178  eval_accuracy: 0.7015429735183716 , global_step: 7681
- AI-Rank-log  1619247884.4975426  eval_accuracy: 0.700785219669342 , global_step: 7682
- AI-Rank-log  1619247928.5536268  eval_accuracy: 0.70158451795578 , global_step: 7683
- AI-Rank-log  1619247972.4890308  eval_accuracy: 0.7015275955200195 , global_step: 7684
- AI-Rank-log  1619248016.4395518  eval_accuracy: 0.7018086910247803 , global_step: 7685
- AI-Rank-log  1619248060.4332557  eval_accuracy: 0.70160973072052 , global_step: 7686
- AI-Rank-log  1619248104.3638303  eval_accuracy: 0.7017505764961243 , global_step: 7687
- AI-Rank-log  1619248148.419168  eval_accuracy: 0.7014200091362 , global_step: 7688
- AI-Rank-log  1619248192.380085  eval_accuracy: 0.7018344402313232 , global_step: 7689
- AI-Rank-log  1619248236.3133695  eval_accuracy: 0.701067328453064 , global_step: 7690
- AI-Rank-log  1619248280.3198657  eval_accuracy: 0.7020282745361328 , global_step: 7691
- AI-Rank-log  1619248324.2595413  eval_accuracy: 0.7009544372558594 , global_step: 7692
- AI-Rank-log  1619248368.2111742  eval_accuracy: 0.7017405033111572 , global_step: 7693
- AI-Rank-log  1619248412.2277634  eval_accuracy: 0.7015239596366882 , global_step: 7694
- AI-Rank-log  1619248456.1593034  eval_accuracy: 0.7019639015197754 , global_step: 7695
- AI-Rank-log  1619248500.1432834  eval_accuracy: 0.7013705968856812 , global_step: 7696
- AI-Rank-log  1619248544.1529763  eval_accuracy: 0.7019397616386414 , global_step: 7697
- AI-Rank-log  1619248588.0916717  eval_accuracy: 0.7019874453544617 , global_step: 7698
- AI-Rank-log  1619248632.1333792  eval_accuracy: 0.7015460133552551 , global_step: 7699
- AI-Rank-log  1619248676.0498867  eval_accuracy: 0.7023128867149353 , global_step: 7700
- AI-Rank-log  1619248719.9867587  eval_accuracy: 0.701805591583252 , global_step: 7701
- AI-Rank-log  1619248763.9816155  eval_accuracy: 0.7023240327835083 , global_step: 7702
- AI-Rank-log  1619248807.9134402  eval_accuracy: 0.7013788819313049 , global_step: 7703
- AI-Rank-log  1619248851.891407  eval_accuracy: 0.702368438243866 , global_step: 7704
- AI-Rank-log  1619248895.8787253  eval_accuracy: 0.7018209099769592 , global_step: 7705
- AI-Rank-log  1619248939.8057513  eval_accuracy: 0.7024208903312683 , global_step: 7706
- AI-Rank-log  1619248983.8417044  eval_accuracy: 0.7021889686584473 , global_step: 7707
- AI-Rank-log  1619249027.8293943  eval_accuracy: 0.7025645971298218 , global_step: 7708
- AI-Rank-log  1619249071.7548237  eval_accuracy: 0.7025657296180725 , global_step: 7709
- AI-Rank-log  1619249115.7908874  eval_accuracy: 0.7024957537651062 , global_step: 7710
- AI-Rank-log  1619249159.7950103  eval_accuracy: 0.7020110487937927 , global_step: 7711
- AI-Rank-log  1619249203.7007537  eval_accuracy: 0.7018237709999084 , global_step: 7712
- AI-Rank-log  1619249247.7529325  eval_accuracy: 0.7018145322799683 , global_step: 7713
- AI-Rank-log  1619249291.7003882  eval_accuracy: 0.7012218832969666 , global_step: 7714
- AI-Rank-log  1619249335.6585777  eval_accuracy: 0.7017326951026917 , global_step: 7715
- AI-Rank-log  1619249379.6909237  eval_accuracy: 0.7015570402145386 , global_step: 7716
- AI-Rank-log  1619249423.6332092  eval_accuracy: 0.700715184211731 , global_step: 7717
- AI-Rank-log  1619249467.6539938  eval_accuracy: 0.7017854452133179 , global_step: 7718
- AI-Rank-log  1619249511.654047  eval_accuracy: 0.7006494402885437 , global_step: 7719
- AI-Rank-log  1619249555.5932362  eval_accuracy: 0.7013441324234009 , global_step: 7720
- AI-Rank-log  1619249599.6305442  eval_accuracy: 0.7013686299324036 , global_step: 7721
- AI-Rank-log  1619249643.5551424  eval_accuracy: 0.7013437151908875 , global_step: 7722
- AI-Rank-log  1619249688.3034828  eval_accuracy: 0.7012235522270203 , global_step: 7723
- AI-Rank-log  1619249732.3068235  eval_accuracy: 0.7013208866119385 , global_step: 7724
- AI-Rank-log  1619249776.2623024  eval_accuracy: 0.7009864449501038 , global_step: 7725
- AI-Rank-log  1619249820.1837409  eval_accuracy: 0.701251208782196 , global_step: 7726
- AI-Rank-log  1619249864.7843194  eval_accuracy: 0.7017250061035156 , global_step: 7727
- AI-Rank-log  1619249908.725827  eval_accuracy: 0.701229453086853 , global_step: 7728
- AI-Rank-log  1619249952.854251  eval_accuracy: 0.7013228535652161 , global_step: 7729
- AI-Rank-log  1619249996.9923422  eval_accuracy: 0.7014119625091553 , global_step: 7730
- AI-Rank-log  1619250040.9291482  eval_accuracy: 0.7016177773475647 , global_step: 7731
- AI-Rank-log  1619250085.1365204  eval_accuracy: 0.7020129561424255 , global_step: 7732
- AI-Rank-log  1619250129.1164682  eval_accuracy: 0.7019727826118469 , global_step: 7733
- AI-Rank-log  1619250173.1371527  eval_accuracy: 0.7020972371101379 , global_step: 7734
- AI-Rank-log  1619250217.9163742  eval_accuracy: 0.7019392251968384 , global_step: 7735
- AI-Rank-log  1619250261.9198582  eval_accuracy: 0.7026863098144531 , global_step: 7736
- AI-Rank-log  1619250306.1680944  eval_accuracy: 0.7025136351585388 , global_step: 7737
- AI-Rank-log  1619250350.1634688  eval_accuracy: 0.7025402188301086 , global_step: 7738
- AI-Rank-log  1619250394.1192198  eval_accuracy: 0.7022168636322021 , global_step: 7739
- AI-Rank-log  1619250439.7044532  eval_accuracy: 0.7021996378898621 , global_step: 7740
- AI-Rank-log  1619250483.7029805  eval_accuracy: 0.7022454738616943 , global_step: 7741
- AI-Rank-log  1619250527.655047  eval_accuracy: 0.702308177947998 , global_step: 7742
- AI-Rank-log  1619250572.7022665  eval_accuracy: 0.7013643383979797 , global_step: 7743
- AI-Rank-log  1619250616.6270227  eval_accuracy: 0.7019587755203247 , global_step: 7744
- AI-Rank-log  1619250660.6556137  eval_accuracy: 0.7013857364654541 , global_step: 7745
- AI-Rank-log  1619250704.6968443  eval_accuracy: 0.7023056745529175 , global_step: 7746
- AI-Rank-log  1619250748.6496506  eval_accuracy: 0.7023705840110779 , global_step: 7747
- AI-Rank-log  1619250792.722431  eval_accuracy: 0.7022987604141235 , global_step: 7748
- AI-Rank-log  1619250836.7447872  eval_accuracy: 0.701701819896698 , global_step: 7749
- AI-Rank-log  1619250880.670369  eval_accuracy: 0.7015841007232666 , global_step: 7750
- AI-Rank-log  1619250924.7320309  eval_accuracy: 0.702125608921051 , global_step: 7751
- AI-Rank-log  1619250968.6990576  eval_accuracy: 0.7014927864074707 , global_step: 7752
- AI-Rank-log  1619251012.6420696  eval_accuracy: 0.7019030451774597 , global_step: 7753
- AI-Rank-log  1619251056.7096958  eval_accuracy: 0.7017269730567932 , global_step: 7754
- AI-Rank-log  1619251100.6728992  eval_accuracy: 0.7020314335823059 , global_step: 7755
- AI-Rank-log  1619251144.6319547  eval_accuracy: 0.7015274167060852 , global_step: 7756
- AI-Rank-log  1619251188.5954719  eval_accuracy: 0.7022922039031982 , global_step: 7757
- AI-Rank-log  1619251232.549901  eval_accuracy: 0.7013975381851196 , global_step: 7758
- AI-Rank-log  1619251276.528401  eval_accuracy: 0.7023424506187439 , global_step: 7759
- AI-Rank-log  1619251320.4715598  eval_accuracy: 0.701198160648346 , global_step: 7760
- AI-Rank-log  1619251364.3739402  eval_accuracy: 0.7019731402397156 , global_step: 7761
- AI-Rank-log  1619251408.4106166  eval_accuracy: 0.7021963596343994 , global_step: 7762
- AI-Rank-log  1619251452.3703713  eval_accuracy: 0.7013773918151855 , global_step: 7763
- AI-Rank-log  1619251496.3150864  eval_accuracy: 0.7023026943206787 , global_step: 7764
- AI-Rank-log  1619251540.3529973  eval_accuracy: 0.7011045217514038 , global_step: 7765
- AI-Rank-log  1619251584.3380032  eval_accuracy: 0.7014345526695251 , global_step: 7766
- AI-Rank-log  1619251628.2801547  eval_accuracy: 0.7019691467285156 , global_step: 7767
- AI-Rank-log  1619251672.3103294  eval_accuracy: 0.7014850974082947 , global_step: 7768
- AI-Rank-log  1619251716.2773275  eval_accuracy: 0.7020179629325867 , global_step: 7769
- AI-Rank-log  1619251760.2115312  eval_accuracy: 0.7016677260398865 , global_step: 7770
- AI-Rank-log  1619251804.2839465  eval_accuracy: 0.7019551992416382 , global_step: 7771
- AI-Rank-log  1619251848.320364  eval_accuracy: 0.7019840478897095 , global_step: 7772
- AI-Rank-log  1619251892.3421748  eval_accuracy: 0.7017424702644348 , global_step: 7773
- AI-Rank-log  1619251936.3046436  eval_accuracy: 0.7019822597503662 , global_step: 7774
- AI-Rank-log  1619251980.2597091  eval_accuracy: 0.7019675970077515 , global_step: 7775
- AI-Rank-log  1619252024.2545164  eval_accuracy: 0.7023563981056213 , global_step: 7776
- AI-Rank-log  1619252068.2227285  eval_accuracy: 0.7020047903060913 , global_step: 7777
- AI-Rank-log  1619252112.1525369  eval_accuracy: 0.7017139196395874 , global_step: 7778
- AI-Rank-log  1619252156.1820245  eval_accuracy: 0.7019531726837158 , global_step: 7779
- AI-Rank-log  1619252200.1557353  eval_accuracy: 0.7016559839248657 , global_step: 7780
- AI-Rank-log  1619252244.1433294  eval_accuracy: 0.7014768123626709 , global_step: 7781
- AI-Rank-log  1619252288.0889618  eval_accuracy: 0.7012288570404053 , global_step: 7782
- AI-Rank-log  1619252332.0774903  eval_accuracy: 0.701568067073822 , global_step: 7783
- AI-Rank-log  1619252376.02247  eval_accuracy: 0.7014244794845581 , global_step: 7784
- AI-Rank-log  1619252419.9511666  eval_accuracy: 0.7014185786247253 , global_step: 7785
- AI-Rank-log  1619252463.9258194  eval_accuracy: 0.7009420990943909 , global_step: 7786
- AI-Rank-log  1619252507.8758333  eval_accuracy: 0.7013307213783264 , global_step: 7787
- AI-Rank-log  1619252551.829677  eval_accuracy: 0.7017229795455933 , global_step: 7788
- AI-Rank-log  1619252595.7589517  eval_accuracy: 0.7013341784477234 , global_step: 7789
- AI-Rank-log  1619252639.748925  eval_accuracy: 0.7018805146217346 , global_step: 7790
- AI-Rank-log  1619252692.5966523  eval_accuracy: 0.7013441920280457 , global_step: 7791
- AI-Rank-log  1619252736.527423  eval_accuracy: 0.7019424438476562 , global_step: 7792
- AI-Rank-log  1619252780.5106683  eval_accuracy: 0.7022932171821594 , global_step: 7793
- AI-Rank-log  1619252824.4833932  eval_accuracy: 0.701229989528656 , global_step: 7794
- AI-Rank-log  1619252868.4691262  eval_accuracy: 0.7019928693771362 , global_step: 7795
- AI-Rank-log  1619252912.404273  eval_accuracy: 0.7014957666397095 , global_step: 7796
- AI-Rank-log  1619252956.347575  eval_accuracy: 0.7016924619674683 , global_step: 7797
- AI-Rank-log  1619253000.3655517  eval_accuracy: 0.7018334865570068 , global_step: 7798
- AI-Rank-log  1619253044.2829113  eval_accuracy: 0.701402485370636 , global_step: 7799
- AI-Rank-log  1619253089.0620751  eval_accuracy: 0.7019562721252441 , global_step: 7800
- AI-Rank-log  1619253133.388069  eval_accuracy: 0.7009548544883728 , global_step: 7801
- AI-Rank-log  1619253177.283623  eval_accuracy: 0.7021018862724304 , global_step: 7802
- AI-Rank-log  1619253221.1004305  eval_accuracy: 0.7011873722076416 , global_step: 7803
- AI-Rank-log  1619253265.0598037  eval_accuracy: 0.7023544311523438 , global_step: 7804
- AI-Rank-log  1619253309.6539633  eval_accuracy: 0.7014285922050476 , global_step: 7805
- AI-Rank-log  1619253353.7088459  eval_accuracy: 0.7020503878593445 , global_step: 7806
- AI-Rank-log  1619253398.325979  eval_accuracy: 0.7017472386360168 , global_step: 7807
- AI-Rank-log  1619253442.237554  eval_accuracy: 0.7019078135490417 , global_step: 7808
- AI-Rank-log  1619253486.6021748  eval_accuracy: 0.7012807726860046 , global_step: 7809
- AI-Rank-log  1619253530.588005  eval_accuracy: 0.7021775841712952 , global_step: 7810
- AI-Rank-log  1619253574.5609338  eval_accuracy: 0.7013673782348633 , global_step: 7811
- AI-Rank-log  1619253619.3765366  eval_accuracy: 0.7026461362838745 , global_step: 7812
- AI-Rank-log  1619253663.3681052  eval_accuracy: 0.7021258473396301 , global_step: 7813
- AI-Rank-log  1619253707.3635755  eval_accuracy: 0.7019232511520386 , global_step: 7814
- AI-Rank-log  1619253751.7817297  eval_accuracy: 0.701589822769165 , global_step: 7815
- AI-Rank-log  1619253795.7315722  eval_accuracy: 0.701939582824707 , global_step: 7816
- AI-Rank-log  1619253840.457021  eval_accuracy: 0.7018005847930908 , global_step: 7817
- AI-Rank-log  1619253884.4286814  eval_accuracy: 0.701654851436615 , global_step: 7818
- AI-Rank-log  1619253929.0857625  eval_accuracy: 0.702340304851532 , global_step: 7819
- AI-Rank-log  1619253973.5008469  eval_accuracy: 0.7021505236625671 , global_step: 7820
- AI-Rank-log  1619254018.574712  eval_accuracy: 0.702277660369873 , global_step: 7821
- AI-Rank-log  1619254062.6329741  eval_accuracy: 0.7022163271903992 , global_step: 7822
- AI-Rank-log  1619254106.6064107  eval_accuracy: 0.7020630836486816 , global_step: 7823
- AI-Rank-log  1619254150.5932987  eval_accuracy: 0.7023741006851196 , global_step: 7824
- AI-Rank-log  1619254194.6215992  eval_accuracy: 0.7020295262336731 , global_step: 7825
- AI-Rank-log  1619254238.6430666  eval_accuracy: 0.7019504308700562 , global_step: 7826
- AI-Rank-log  1619254282.6408842  eval_accuracy: 0.7019194960594177 , global_step: 7827
- AI-Rank-log  1619254326.6441925  eval_accuracy: 0.7023864388465881 , global_step: 7828
- AI-Rank-log  1619254370.607825  eval_accuracy: 0.7016769647598267 , global_step: 7829
- AI-Rank-log  1619254414.5533092  eval_accuracy: 0.7019661068916321 , global_step: 7830
- AI-Rank-log  1619254458.525901  eval_accuracy: 0.7014222145080566 , global_step: 7831
- AI-Rank-log  1619254502.4891365  eval_accuracy: 0.7023962736129761 , global_step: 7832
- AI-Rank-log  1619254546.6037455  eval_accuracy: 0.7017887234687805 , global_step: 7833
- AI-Rank-log  1619254590.5406826  eval_accuracy: 0.7015935182571411 , global_step: 7834
- AI-Rank-log  1619254634.4905102  eval_accuracy: 0.701836347579956 , global_step: 7835
- AI-Rank-log  1619254678.5038168  eval_accuracy: 0.7017167806625366 , global_step: 7836
- AI-Rank-log  1619254722.4137647  eval_accuracy: 0.7020851373672485 , global_step: 7837
- AI-Rank-log  1619254766.374792  eval_accuracy: 0.7015512585639954 , global_step: 7838
- AI-Rank-log  1619254810.38801  eval_accuracy: 0.7018212676048279 , global_step: 7839
- AI-Rank-log  1619254854.3398838  eval_accuracy: 0.701749861240387 , global_step: 7840
- AI-Rank-log  1619254898.3503773  eval_accuracy: 0.701589822769165 , global_step: 7841
- AI-Rank-log  1619254942.3445008  eval_accuracy: 0.7018018364906311 , global_step: 7842
- AI-Rank-log  1619254986.2868261  eval_accuracy: 0.7019043564796448 , global_step: 7843
- AI-Rank-log  1619255030.3172553  eval_accuracy: 0.7014027833938599 , global_step: 7844
- AI-Rank-log  1619255074.2753375  eval_accuracy: 0.7014790773391724 , global_step: 7845
- AI-Rank-log  1619255118.2207263  eval_accuracy: 0.7018798589706421 , global_step: 7846
- AI-Rank-log  1619255162.2503166  eval_accuracy: 0.702089250087738 , global_step: 7847
- AI-Rank-log  1619255206.151564  eval_accuracy: 0.7017824649810791 , global_step: 7848
- AI-Rank-log  1619255250.1701267  eval_accuracy: 0.7013425230979919 , global_step: 7849
- AI-Rank-log  1619255294.1486347  eval_accuracy: 0.7018322348594666 , global_step: 7850
- AI-Rank-log  1619255338.1070883  eval_accuracy: 0.70130854845047 , global_step: 7851
- AI-Rank-log  1619255382.1418679  eval_accuracy: 0.7020345330238342 , global_step: 7852
- AI-Rank-log  1619255426.119291  eval_accuracy: 0.7018029689788818 , global_step: 7853
- AI-Rank-log  1619255469.804114  eval_accuracy: 0.7023663520812988 , global_step: 7854
- AI-Rank-log  1619255513.8806438  eval_accuracy: 0.7021291851997375 , global_step: 7855
- AI-Rank-log  1619255557.8509479  eval_accuracy: 0.7020846605300903 , global_step: 7856
- AI-Rank-log  1619255601.8222094  eval_accuracy: 0.7019079923629761 , global_step: 7857
- AI-Rank-log  1619255645.8205123  eval_accuracy: 0.7020447850227356 , global_step: 7858
- AI-Rank-log  1619255689.780879  eval_accuracy: 0.7023922801017761 , global_step: 7859
- AI-Rank-log  1619255733.8057232  eval_accuracy: 0.7018625140190125 , global_step: 7860
- AI-Rank-log  1619255777.7766287  eval_accuracy: 0.7021845579147339 , global_step: 7861
- AI-Rank-log  1619255821.7714267  eval_accuracy: 0.7020673155784607 , global_step: 7862
- AI-Rank-log  1619255865.8132975  eval_accuracy: 0.7022792100906372 , global_step: 7863
- AI-Rank-log  1619255909.748309  eval_accuracy: 0.7023847103118896 , global_step: 7864
- AI-Rank-log  1619255953.699176  eval_accuracy: 0.7021779417991638 , global_step: 7865
- AI-Rank-log  1619255997.6898952  eval_accuracy: 0.7016953825950623 , global_step: 7866
- AI-Rank-log  1619256041.695055  eval_accuracy: 0.7021979689598083 , global_step: 7867
- AI-Rank-log  1619256085.6439393  eval_accuracy: 0.7020967602729797 , global_step: 7868
- AI-Rank-log  1619256129.660984  eval_accuracy: 0.7022331357002258 , global_step: 7869
- AI-Rank-log  1619256173.6269002  eval_accuracy: 0.7021954655647278 , global_step: 7870
- AI-Rank-log  1619256217.6443284  eval_accuracy: 0.7025895714759827 , global_step: 7871
- AI-Rank-log  1619256261.5592966  eval_accuracy: 0.701866626739502 , global_step: 7872
- AI-Rank-log  1619256305.514503  eval_accuracy: 0.7023950219154358 , global_step: 7873
- AI-Rank-log  1619256349.5051584  eval_accuracy: 0.7020277380943298 , global_step: 7874
- AI-Rank-log  1619256393.4357383  eval_accuracy: 0.7020177245140076 , global_step: 7875
- AI-Rank-log  1619256437.4283307  eval_accuracy: 0.7016887068748474 , global_step: 7876
- AI-Rank-log  1619256481.4184127  eval_accuracy: 0.7020899057388306 , global_step: 7877
- AI-Rank-log  1619256525.9369688  eval_accuracy: 0.701805830001831 , global_step: 7878
- AI-Rank-log  1619256569.892531  eval_accuracy: 0.7021813988685608 , global_step: 7879
- AI-Rank-log  1619256613.9198616  eval_accuracy: 0.7026491761207581 , global_step: 7880
- AI-Rank-log  1619256657.8485692  eval_accuracy: 0.7024144530296326 , global_step: 7881
- AI-Rank-log  1619256701.8942776  eval_accuracy: 0.7022181153297424 , global_step: 7882
- AI-Rank-log  1619256746.6190195  eval_accuracy: 0.702052652835846 , global_step: 7883
- AI-Rank-log  1619256791.6996505  eval_accuracy: 0.7020352482795715 , global_step: 7884
- AI-Rank-log  1619256835.7530997  eval_accuracy: 0.7020968794822693 , global_step: 7885
- AI-Rank-log  1619256879.899214  eval_accuracy: 0.7022002339363098 , global_step: 7886
- AI-Rank-log  1619256923.8679597  eval_accuracy: 0.7020428776741028 , global_step: 7887
- AI-Rank-log  1619256967.9319592  eval_accuracy: 0.702591598033905 , global_step: 7888
- AI-Rank-log  1619257011.8747892  eval_accuracy: 0.7024478316307068 , global_step: 7889
- AI-Rank-log  1619257056.6521513  eval_accuracy: 0.7022446990013123 , global_step: 7890
- AI-Rank-log  1619257100.6396651  eval_accuracy: 0.7021923065185547 , global_step: 7891
- AI-Rank-log  1619257144.6144705  eval_accuracy: 0.7025710940361023 , global_step: 7892
- AI-Rank-log  1619257188.8001556  eval_accuracy: 0.7032676339149475 , global_step: 7893
- AI-Rank-log  1619257232.797032  eval_accuracy: 0.702796220779419 , global_step: 7894
- AI-Rank-log  1619257277.5338914  eval_accuracy: 0.7028889656066895 , global_step: 7895
- AI-Rank-log  1619257321.6235008  eval_accuracy: 0.7028347253799438 , global_step: 7896
- AI-Rank-log  1619257365.6312165  eval_accuracy: 0.703073263168335 , global_step: 7897
- AI-Rank-log  1619257410.9193127  eval_accuracy: 0.7032830119132996 , global_step: 7898
- AI-Rank-log  1619257454.9365675  eval_accuracy: 0.7034701704978943 , global_step: 7899
- AI-Rank-log  1619257498.876572  eval_accuracy: 0.7026815414428711 , global_step: 7900
- AI-Rank-log  1619257542.903969  eval_accuracy: 0.7027857899665833 , global_step: 7901
- AI-Rank-log  1619257586.8651605  eval_accuracy: 0.7021535634994507 , global_step: 7902
- AI-Rank-log  1619257630.8158913  eval_accuracy: 0.7033578753471375 , global_step: 7903
- AI-Rank-log  1619257674.8552825  eval_accuracy: 0.7030691504478455 , global_step: 7904
- AI-Rank-log  1619257718.912815  eval_accuracy: 0.7028579115867615 , global_step: 7905
- AI-Rank-log  1619257762.8883226  eval_accuracy: 0.7024306654930115 , global_step: 7906
- AI-Rank-log  1619257806.9369953  eval_accuracy: 0.7028136253356934 , global_step: 7907
- AI-Rank-log  1619257850.9191244  eval_accuracy: 0.7020638585090637 , global_step: 7908
- AI-Rank-log  1619257895.0029693  eval_accuracy: 0.7023197412490845 , global_step: 7909
- AI-Rank-log  1619257939.071472  eval_accuracy: 0.702716052532196 , global_step: 7910
- AI-Rank-log  1619257983.0241413  eval_accuracy: 0.7018849849700928 , global_step: 7911
- AI-Rank-log  1619258027.0516825  eval_accuracy: 0.7022974491119385 , global_step: 7912
- AI-Rank-log  1619258071.0264885  eval_accuracy: 0.7022417187690735 , global_step: 7913
- AI-Rank-log  1619258115.006708  eval_accuracy: 0.7025122046470642 , global_step: 7914
- AI-Rank-log  1619258159.0357924  eval_accuracy: 0.7020480632781982 , global_step: 7915
- AI-Rank-log  1619258202.9899256  eval_accuracy: 0.7023554444313049 , global_step: 7916
- AI-Rank-log  1619258246.939818  eval_accuracy: 0.7024088501930237 , global_step: 7917
- AI-Rank-log  1619258290.9243004  eval_accuracy: 0.7025866508483887 , global_step: 7918
- AI-Rank-log  1619258334.8843868  eval_accuracy: 0.7024757862091064 , global_step: 7919
- AI-Rank-log  1619258378.9269066  eval_accuracy: 0.7030390501022339 , global_step: 7920
- AI-Rank-log  1619258422.8502743  eval_accuracy: 0.7026721239089966 , global_step: 7921
- AI-Rank-log  1619258466.7850993  eval_accuracy: 0.7031080722808838 , global_step: 7922
- AI-Rank-log  1619258510.8907003  eval_accuracy: 0.7029235363006592 , global_step: 7923
- AI-Rank-log  1619258554.833614  eval_accuracy: 0.7029147148132324 , global_step: 7924
- AI-Rank-log  1619258598.811385  eval_accuracy: 0.7029168009757996 , global_step: 7925
- AI-Rank-log  1619258642.8404841  eval_accuracy: 0.7034143209457397 , global_step: 7926
- AI-Rank-log  1619258686.7829888  eval_accuracy: 0.7028471231460571 , global_step: 7927
- AI-Rank-log  1619258730.7739635  eval_accuracy: 0.703318178653717 , global_step: 7928
- AI-Rank-log  1619258774.7709694  eval_accuracy: 0.7031471133232117 , global_step: 7929
- AI-Rank-log  1619258818.7224646  eval_accuracy: 0.7030489444732666 , global_step: 7930
- AI-Rank-log  1619258862.7075853  eval_accuracy: 0.7032606601715088 , global_step: 7931
- AI-Rank-log  1619258906.7937672  eval_accuracy: 0.7026640772819519 , global_step: 7932
- AI-Rank-log  1619258950.771354  eval_accuracy: 0.702946126461029 , global_step: 7933
- AI-Rank-log  1619258994.8066888  eval_accuracy: 0.702858567237854 , global_step: 7934
- AI-Rank-log  1619259038.8190892  eval_accuracy: 0.7024103403091431 , global_step: 7935
- AI-Rank-log  1619259082.7650266  eval_accuracy: 0.7036904692649841 , global_step: 7936
- AI-Rank-log  1619259126.8175936  eval_accuracy: 0.7023778557777405 , global_step: 7937
- AI-Rank-log  1619259170.7612224  eval_accuracy: 0.7030357718467712 , global_step: 7938
- AI-Rank-log  1619259214.701382  eval_accuracy: 0.7028084993362427 , global_step: 7939
- AI-Rank-log  1619259258.7620068  eval_accuracy: 0.7025997638702393 , global_step: 7940
- AI-Rank-log  1619259302.6630375  eval_accuracy: 0.7029479146003723 , global_step: 7941
- AI-Rank-log  1619259346.6322405  eval_accuracy: 0.7030766606330872 , global_step: 7942
- AI-Rank-log  1619259390.7996838  eval_accuracy: 0.7030472159385681 , global_step: 7943
- AI-Rank-log  1619259434.7402265  eval_accuracy: 0.7032614946365356 , global_step: 7944
- AI-Rank-log  1619259478.7824986  eval_accuracy: 0.7030259370803833 , global_step: 7945
- AI-Rank-log  1619259522.7403553  eval_accuracy: 0.7033144235610962 , global_step: 7946
- AI-Rank-log  1619259566.4822721  eval_accuracy: 0.7023064494132996 , global_step: 7947
- AI-Rank-log  1619259610.4909241  eval_accuracy: 0.7034885287284851 , global_step: 7948
- AI-Rank-log  1619259654.4600203  eval_accuracy: 0.7027637362480164 , global_step: 7949
- AI-Rank-log  1619259698.3934445  eval_accuracy: 0.7033564448356628 , global_step: 7950
- AI-Rank-log  1619259742.4700723  eval_accuracy: 0.7029114961624146 , global_step: 7951
- AI-Rank-log  1619259786.427379  eval_accuracy: 0.7028244137763977 , global_step: 7952
- AI-Rank-log  1619259830.3750236  eval_accuracy: 0.7028053998947144 , global_step: 7953
- AI-Rank-log  1619259874.415011  eval_accuracy: 0.7033098936080933 , global_step: 7954
- AI-Rank-log  1619259919.283838  eval_accuracy: 0.7026932835578918 , global_step: 7955
- AI-Rank-log  1619259963.443895  eval_accuracy: 0.7023909091949463 , global_step: 7956
- AI-Rank-log  1619260007.386724  eval_accuracy: 0.7028478384017944 , global_step: 7957
- AI-Rank-log  1619260051.4526083  eval_accuracy: 0.7028712630271912 , global_step: 7958
- AI-Rank-log  1619260095.4938529  eval_accuracy: 0.7028175592422485 , global_step: 7959
- AI-Rank-log  1619260140.0165272  eval_accuracy: 0.7024664282798767 , global_step: 7960
- AI-Rank-log  1619260183.9797578  eval_accuracy: 0.7020731568336487 , global_step: 7961
- AI-Rank-log  1619260228.4117901  eval_accuracy: 0.7023219466209412 , global_step: 7962
- AI-Rank-log  1619260272.4028342  eval_accuracy: 0.7023444771766663 , global_step: 7963
- AI-Rank-log  1619260316.5696766  eval_accuracy: 0.702993631362915 , global_step: 7964
- AI-Rank-log  1619260360.5787306  eval_accuracy: 0.7027513384819031 , global_step: 7965
- AI-Rank-log  1619260404.5962965  eval_accuracy: 0.7036813497543335 , global_step: 7966
- AI-Rank-log  1619260449.492516  eval_accuracy: 0.7033861875534058 , global_step: 7967
- AI-Rank-log  1619260493.4784863  eval_accuracy: 0.7034000754356384 , global_step: 7968
- AI-Rank-log  1619260537.4264805  eval_accuracy: 0.70307856798172 , global_step: 7969
- AI-Rank-log  1619260581.9441948  eval_accuracy: 0.7031277418136597 , global_step: 7970
- AI-Rank-log  1619260625.9021878  eval_accuracy: 0.7031181454658508 , global_step: 7971
- AI-Rank-log  1619260669.8725028  eval_accuracy: 0.7030664086341858 , global_step: 7972
- AI-Rank-log  1619260714.4823956  eval_accuracy: 0.7038336396217346 , global_step: 7973
- AI-Rank-log  1619260758.488846  eval_accuracy: 0.7030937075614929 , global_step: 7974
- AI-Rank-log  1619260802.5224202  eval_accuracy: 0.7035285830497742 , global_step: 7975
- AI-Rank-log  1619260847.809157  eval_accuracy: 0.7032119631767273 , global_step: 7976
- AI-Rank-log  1619260891.7804205  eval_accuracy: 0.7035283446311951 , global_step: 7977
- AI-Rank-log  1619260935.8682165  eval_accuracy: 0.70350581407547 , global_step: 7978
- AI-Rank-log  1619260979.8660254  eval_accuracy: 0.7033379077911377 , global_step: 7979
- AI-Rank-log  1619261023.8406801  eval_accuracy: 0.7031545042991638 , global_step: 7980
- AI-Rank-log  1619261067.8570569  eval_accuracy: 0.7026960253715515 , global_step: 7981
- AI-Rank-log  1619261112.2406144  eval_accuracy: 0.7030826210975647 , global_step: 7982
- AI-Rank-log  1619261156.2184205  eval_accuracy: 0.703047513961792 , global_step: 7983
- AI-Rank-log  1619261200.2312891  eval_accuracy: 0.7025760412216187 , global_step: 7984
- AI-Rank-log  1619261244.1562135  eval_accuracy: 0.7025805711746216 , global_step: 7985
- AI-Rank-log  1619261288.1807375  eval_accuracy: 0.7028161883354187 , global_step: 7986
- AI-Rank-log  1619261332.0999694  eval_accuracy: 0.7027284502983093 , global_step: 7987
- AI-Rank-log  1619261376.0579238  eval_accuracy: 0.7028080821037292 , global_step: 7988
- AI-Rank-log  1619261420.098404  eval_accuracy: 0.7026767730712891 , global_step: 7989
- AI-Rank-log  1619261464.0399723  eval_accuracy: 0.7026323080062866 , global_step: 7990
- AI-Rank-log  1619261516.9361203  eval_accuracy: 0.7032054662704468 , global_step: 7991
- AI-Rank-log  1619261560.9655304  eval_accuracy: 0.7029675841331482 , global_step: 7992
- AI-Rank-log  1619261604.9166846  eval_accuracy: 0.7036510705947876 , global_step: 7993
- AI-Rank-log  1619261648.974041  eval_accuracy: 0.7036442160606384 , global_step: 7994
- AI-Rank-log  1619261692.9325852  eval_accuracy: 0.7032095193862915 , global_step: 7995
- AI-Rank-log  1619261736.8865328  eval_accuracy: 0.703534722328186 , global_step: 7996
- AI-Rank-log  1619261780.978556  eval_accuracy: 0.7038281559944153 , global_step: 7997
- AI-Rank-log  1619261824.953372  eval_accuracy: 0.7031552791595459 , global_step: 7998
- AI-Rank-log  1619261868.9162633  eval_accuracy: 0.7031098008155823 , global_step: 7999
- AI-Rank-log  1619261912.9484336  eval_accuracy: 0.7032665610313416 , global_step: 8000
- AI-Rank-log  1619261956.9407682  eval_accuracy: 0.7033843398094177 , global_step: 8001
- AI-Rank-log  1619262000.8520672  eval_accuracy: 0.7033577561378479 , global_step: 8002
- AI-Rank-log  1619262044.9186957  eval_accuracy: 0.7028871178627014 , global_step: 8003
- AI-Rank-log  1619262088.9062004  eval_accuracy: 0.7032143473625183 , global_step: 8004
- AI-Rank-log  1619262132.8872516  eval_accuracy: 0.7030077576637268 , global_step: 8005
- AI-Rank-log  1619262176.844496  eval_accuracy: 0.7036212086677551 , global_step: 8006
- AI-Rank-log  1619262220.585195  eval_accuracy: 0.7029308080673218 , global_step: 8007
- AI-Rank-log  1619262264.5941305  eval_accuracy: 0.7038233876228333 , global_step: 8008
- AI-Rank-log  1619262308.5726075  eval_accuracy: 0.7029986381530762 , global_step: 8009
- AI-Rank-log  1619262352.5330772  eval_accuracy: 0.703437089920044 , global_step: 8010
- AI-Rank-log  1619262396.5341072  eval_accuracy: 0.7032564878463745 , global_step: 8011
- AI-Rank-log  1619262440.5087547  eval_accuracy: 0.7036660313606262 , global_step: 8012
- AI-Rank-log  1619262484.554756  eval_accuracy: 0.70308518409729 , global_step: 8013
- AI-Rank-log  1619262528.5051389  eval_accuracy: 0.7036759853363037 , global_step: 8014
- AI-Rank-log  1619262572.4806798  eval_accuracy: 0.7035120129585266 , global_step: 8015
- AI-Rank-log  1619262616.5509965  eval_accuracy: 0.7033625245094299 , global_step: 8016
- AI-Rank-log  1619262660.5298924  eval_accuracy: 0.7035504579544067 , global_step: 8017
- AI-Rank-log  1619262704.472928  eval_accuracy: 0.7031007409095764 , global_step: 8018
- AI-Rank-log  1619262748.4911995  eval_accuracy: 0.7038679718971252 , global_step: 8019
- AI-Rank-log  1619262792.4080987  eval_accuracy: 0.7034697532653809 , global_step: 8020
- AI-Rank-log  1619262836.3842502  eval_accuracy: 0.7038524746894836 , global_step: 8021
- AI-Rank-log  1619262880.3741264  eval_accuracy: 0.7028478384017944 , global_step: 8022
- AI-Rank-log  1619262924.307699  eval_accuracy: 0.7034082412719727 , global_step: 8023
- AI-Rank-log  1619262968.2590618  eval_accuracy: 0.7031697034835815 , global_step: 8024
- AI-Rank-log  1619263012.26634  eval_accuracy: 0.7033718824386597 , global_step: 8025
- AI-Rank-log  1619263056.1864407  eval_accuracy: 0.7028317451477051 , global_step: 8026
- AI-Rank-log  1619263100.2642636  eval_accuracy: 0.7035819292068481 , global_step: 8027
- AI-Rank-log  1619263144.18062  eval_accuracy: 0.7031110525131226 , global_step: 8028
- AI-Rank-log  1619263188.129983  eval_accuracy: 0.703681230545044 , global_step: 8029
- AI-Rank-log  1619263232.1843607  eval_accuracy: 0.7028809785842896 , global_step: 8030
- AI-Rank-log  1619263276.1702597  eval_accuracy: 0.7037118077278137 , global_step: 8031
- AI-Rank-log  1619263320.9332438  eval_accuracy: 0.7030647397041321 , global_step: 8032
- AI-Rank-log  1619263365.0654683  eval_accuracy: 0.7033494114875793 , global_step: 8033
- AI-Rank-log  1619263408.988735  eval_accuracy: 0.703652024269104 , global_step: 8034
- AI-Rank-log  1619263452.9312208  eval_accuracy: 0.7038317322731018 , global_step: 8035
- AI-Rank-log  1619263496.9803247  eval_accuracy: 0.7035738229751587 , global_step: 8036
- AI-Rank-log  1619263540.9659805  eval_accuracy: 0.7033418416976929 , global_step: 8037
- AI-Rank-log  1619263585.3053153  eval_accuracy: 0.7028490304946899 , global_step: 8038
- AI-Rank-log  1619263629.8461685  eval_accuracy: 0.7034066319465637 , global_step: 8039
- AI-Rank-log  1619263673.7520409  eval_accuracy: 0.7020851969718933 , global_step: 8040
- AI-Rank-log  1619263718.0279555  eval_accuracy: 0.7031248211860657 , global_step: 8041
- AI-Rank-log  1619263762.2353868  eval_accuracy: 0.7030376195907593 , global_step: 8042
- AI-Rank-log  1619263806.173124  eval_accuracy: 0.702933669090271 , global_step: 8043
- AI-Rank-log  1619263850.2518897  eval_accuracy: 0.703020453453064 , global_step: 8044
- AI-Rank-log  1619263895.03221  eval_accuracy: 0.7025464177131653 , global_step: 8045
- AI-Rank-log  1619263939.1919384  eval_accuracy: 0.7019688487052917 , global_step: 8046
- AI-Rank-log  1619263983.895967  eval_accuracy: 0.7025703191757202 , global_step: 8047
- AI-Rank-log  1619264027.8252475  eval_accuracy: 0.7032424211502075 , global_step: 8048
- AI-Rank-log  1619264071.8171558  eval_accuracy: 0.7026635408401489 , global_step: 8049
- AI-Rank-log  1619264117.5099435  eval_accuracy: 0.7034193873405457 , global_step: 8050
- AI-Rank-log  1619264161.4527242  eval_accuracy: 0.7035320997238159 , global_step: 8051
- AI-Rank-log  1619264205.5470684  eval_accuracy: 0.703861653804779 , global_step: 8052
- AI-Rank-log  1619264251.0092435  eval_accuracy: 0.7036198973655701 , global_step: 8053
- AI-Rank-log  1619264294.9653325  eval_accuracy: 0.7044470310211182 , global_step: 8054
- AI-Rank-log  1619264338.986844  eval_accuracy: 0.7028907537460327 , global_step: 8055
- AI-Rank-log  1619264382.9410195  eval_accuracy: 0.703790009021759 , global_step: 8056
- AI-Rank-log  1619264426.8920648  eval_accuracy: 0.7034340500831604 , global_step: 8057
- AI-Rank-log  1619264470.8957257  eval_accuracy: 0.7032235264778137 , global_step: 8058
- AI-Rank-log  1619264515.5758536  eval_accuracy: 0.7034139633178711 , global_step: 8059
- AI-Rank-log  1619264559.5292833  eval_accuracy: 0.7031198740005493 , global_step: 8060
- AI-Rank-log  1619264603.533066  eval_accuracy: 0.7033766508102417 , global_step: 8061
- AI-Rank-log  1619264647.4749906  eval_accuracy: 0.7032000422477722 , global_step: 8062
- AI-Rank-log  1619264691.4934046  eval_accuracy: 0.7041150331497192 , global_step: 8063
- AI-Rank-log  1619264735.4686687  eval_accuracy: 0.7038179039955139 , global_step: 8064
- AI-Rank-log  1619264779.403157  eval_accuracy: 0.7038354277610779 , global_step: 8065
- AI-Rank-log  1619264823.4415777  eval_accuracy: 0.7036415338516235 , global_step: 8066
- AI-Rank-log  1619264867.4358563  eval_accuracy: 0.7034604549407959 , global_step: 8067
- AI-Rank-log  1619264911.4226034  eval_accuracy: 0.7029207944869995 , global_step: 8068
- AI-Rank-log  1619264955.4087565  eval_accuracy: 0.7036646008491516 , global_step: 8069
- AI-Rank-log  1619264999.4199653  eval_accuracy: 0.7034869194030762 , global_step: 8070
- AI-Rank-log  1619265043.4872532  eval_accuracy: 0.70350182056427 , global_step: 8071
- AI-Rank-log  1619265087.418417  eval_accuracy: 0.7031782865524292 , global_step: 8072
- AI-Rank-log  1619265131.4208307  eval_accuracy: 0.7037797570228577 , global_step: 8073
- AI-Rank-log  1619265175.464384  eval_accuracy: 0.7038759589195251 , global_step: 8074
- AI-Rank-log  1619265219.4055824  eval_accuracy: 0.7033392786979675 , global_step: 8075
- AI-Rank-log  1619265263.3575976  eval_accuracy: 0.7028282284736633 , global_step: 8076
- AI-Rank-log  1619265307.399696  eval_accuracy: 0.7030256986618042 , global_step: 8077
- AI-Rank-log  1619265351.35523  eval_accuracy: 0.7032054662704468 , global_step: 8078
- AI-Rank-log  1619265395.336605  eval_accuracy: 0.7030051946640015 , global_step: 8079
- AI-Rank-log  1619265439.3418999  eval_accuracy: 0.7032423615455627 , global_step: 8080
- AI-Rank-log  1619265483.3121636  eval_accuracy: 0.7030591368675232 , global_step: 8081
- AI-Rank-log  1619265527.3632724  eval_accuracy: 0.7028098702430725 , global_step: 8082
- AI-Rank-log  1619265571.3290715  eval_accuracy: 0.7031522393226624 , global_step: 8083
- AI-Rank-log  1619265615.2408204  eval_accuracy: 0.70317542552948 , global_step: 8084
- AI-Rank-log  1619265659.2745068  eval_accuracy: 0.7025591731071472 , global_step: 8085
- AI-Rank-log  1619265703.2198572  eval_accuracy: 0.703269362449646 , global_step: 8086
- AI-Rank-log  1619265747.192772  eval_accuracy: 0.7031340599060059 , global_step: 8087
- AI-Rank-log  1619265791.264077  eval_accuracy: 0.7033708095550537 , global_step: 8088
- AI-Rank-log  1619265835.2117562  eval_accuracy: 0.7033177614212036 , global_step: 8089
- AI-Rank-log  1619265879.2532873  eval_accuracy: 0.7033710479736328 , global_step: 8090
- AI-Rank-log  1619265923.235193  eval_accuracy: 0.7033469080924988 , global_step: 8091
- AI-Rank-log  1619265967.175699  eval_accuracy: 0.7028321027755737 , global_step: 8092
- AI-Rank-log  1619266011.2116063  eval_accuracy: 0.7036675214767456 , global_step: 8093
- AI-Rank-log  1619266055.2339513  eval_accuracy: 0.7031007409095764 , global_step: 8094
- AI-Rank-log  1619266099.3309896  eval_accuracy: 0.7043537497520447 , global_step: 8095
- AI-Rank-log  1619266143.3491914  eval_accuracy: 0.7034875750541687 , global_step: 8096
- AI-Rank-log  1619266187.3478065  eval_accuracy: 0.7036463022232056 , global_step: 8097
- AI-Rank-log  1619266231.3305225  eval_accuracy: 0.7037327289581299 , global_step: 8098
- AI-Rank-log  1619266275.3704627  eval_accuracy: 0.704240620136261 , global_step: 8099
- AI-Rank-log  1619266319.3363695  eval_accuracy: 0.7037907838821411 , global_step: 8100
- AI-Rank-log  1619266363.2604377  eval_accuracy: 0.7037429213523865 , global_step: 8101
- AI-Rank-log  1619266407.2520783  eval_accuracy: 0.7038957476615906 , global_step: 8102
- AI-Rank-log  1619266451.1921737  eval_accuracy: 0.7035972476005554 , global_step: 8103
- AI-Rank-log  1619266495.1780279  eval_accuracy: 0.7041071057319641 , global_step: 8104
- AI-Rank-log  1619266539.1596951  eval_accuracy: 0.7035632133483887 , global_step: 8105
- AI-Rank-log  1619266583.1144886  eval_accuracy: 0.7042784690856934 , global_step: 8106
- AI-Rank-log  1619266627.1321204  eval_accuracy: 0.7038113474845886 , global_step: 8107
- AI-Rank-log  1619266671.148482  eval_accuracy: 0.7041625380516052 , global_step: 8108
- AI-Rank-log  1619266715.2037785  eval_accuracy: 0.7043378353118896 , global_step: 8109
- AI-Rank-log  1619266759.6721966  eval_accuracy: 0.7040091156959534 , global_step: 8110
- AI-Rank-log  1619266803.650866  eval_accuracy: 0.703799843788147 , global_step: 8111
- AI-Rank-log  1619266847.5892324  eval_accuracy: 0.7035569548606873 , global_step: 8112
- AI-Rank-log  1619266891.6522858  eval_accuracy: 0.7036387920379639 , global_step: 8113
- AI-Rank-log  1619266935.5969365  eval_accuracy: 0.7037039995193481 , global_step: 8114
- AI-Rank-log  1619266980.2643147  eval_accuracy: 0.7035795450210571 , global_step: 8115
- AI-Rank-log  1619267024.6202998  eval_accuracy: 0.7031015753746033 , global_step: 8116
- AI-Rank-log  1619267068.6509778  eval_accuracy: 0.7040064930915833 , global_step: 8117
- AI-Rank-log  1619267112.6225216  eval_accuracy: 0.7035704255104065 , global_step: 8118
- AI-Rank-log  1619267156.7487915  eval_accuracy: 0.7038982510566711 , global_step: 8119
- AI-Rank-log  1619267200.7273812  eval_accuracy: 0.7034093737602234 , global_step: 8120
- AI-Rank-log  1619267244.7443879  eval_accuracy: 0.7034427523612976 , global_step: 8121
- AI-Rank-log  1619267288.7338128  eval_accuracy: 0.7034839987754822 , global_step: 8122
- AI-Rank-log  1619267333.6625254  eval_accuracy: 0.7043145895004272 , global_step: 8123
- AI-Rank-log  1619267378.1674235  eval_accuracy: 0.7037196755409241 , global_step: 8124
- AI-Rank-log  1619267422.1782846  eval_accuracy: 0.7041664123535156 , global_step: 8125
- AI-Rank-log  1619267466.2232263  eval_accuracy: 0.70371413230896 , global_step: 8126
- AI-Rank-log  1619267510.923244  eval_accuracy: 0.7044927477836609 , global_step: 8127
- AI-Rank-log  1619267555.0652137  eval_accuracy: 0.7038235068321228 , global_step: 8128
- AI-Rank-log  1619267599.1554399  eval_accuracy: 0.7043493390083313 , global_step: 8129
- AI-Rank-log  1619267643.27102  eval_accuracy: 0.7044860124588013 , global_step: 8130
- AI-Rank-log  1619267688.3513067  eval_accuracy: 0.704255223274231 , global_step: 8131
- AI-Rank-log  1619267732.299898  eval_accuracy: 0.7039846181869507 , global_step: 8132
- AI-Rank-log  1619267776.251227  eval_accuracy: 0.7046430110931396 , global_step: 8133
- AI-Rank-log  1619267820.3038068  eval_accuracy: 0.7044336199760437 , global_step: 8134
- AI-Rank-log  1619267864.2287185  eval_accuracy: 0.7049362659454346 , global_step: 8135
- AI-Rank-log  1619267908.1508987  eval_accuracy: 0.7044979929924011 , global_step: 8136
- AI-Rank-log  1619267952.3839564  eval_accuracy: 0.7051417827606201 , global_step: 8137
- AI-Rank-log  1619267996.1292562  eval_accuracy: 0.7046569585800171 , global_step: 8138
- AI-Rank-log  1619268040.1029725  eval_accuracy: 0.704390287399292 , global_step: 8139
- AI-Rank-log  1619268084.121874  eval_accuracy: 0.704083263874054 , global_step: 8140
- AI-Rank-log  1619268128.06822  eval_accuracy: 0.7041118741035461 , global_step: 8141
- AI-Rank-log  1619268172.1130333  eval_accuracy: 0.704731822013855 , global_step: 8142
- AI-Rank-log  1619268216.0672214  eval_accuracy: 0.7041720151901245 , global_step: 8143
- AI-Rank-log  1619268260.0276852  eval_accuracy: 0.70391845703125 , global_step: 8144
- AI-Rank-log  1619268304.032039  eval_accuracy: 0.703125536441803 , global_step: 8145
- AI-Rank-log  1619268348.04603  eval_accuracy: 0.7038986682891846 , global_step: 8146
- AI-Rank-log  1619268392.0212188  eval_accuracy: 0.7030534148216248 , global_step: 8147
- AI-Rank-log  1619268436.0704129  eval_accuracy: 0.7037215828895569 , global_step: 8148
- AI-Rank-log  1619268480.0741527  eval_accuracy: 0.7033767700195312 , global_step: 8149
- AI-Rank-log  1619268524.0125768  eval_accuracy: 0.7037451267242432 , global_step: 8150
- AI-Rank-log  1619268568.0542252  eval_accuracy: 0.7033933997154236 , global_step: 8151
- AI-Rank-log  1619268612.0793898  eval_accuracy: 0.7037510275840759 , global_step: 8152
- AI-Rank-log  1619268655.8795977  eval_accuracy: 0.7038180828094482 , global_step: 8153
- AI-Rank-log  1619268699.8778067  eval_accuracy: 0.7032719254493713 , global_step: 8154
- AI-Rank-log  1619268743.8522892  eval_accuracy: 0.7038667798042297 , global_step: 8155
- AI-Rank-log  1619268787.9222853  eval_accuracy: 0.7042617201805115 , global_step: 8156
- AI-Rank-log  1619268831.870867  eval_accuracy: 0.7036996483802795 , global_step: 8157
- AI-Rank-log  1619268875.8574905  eval_accuracy: 0.704526960849762 , global_step: 8158
- AI-Rank-log  1619268919.8814785  eval_accuracy: 0.7037646770477295 , global_step: 8159
- AI-Rank-log  1619268963.8923392  eval_accuracy: 0.70371413230896 , global_step: 8160
- AI-Rank-log  1619269007.8440866  eval_accuracy: 0.7037243247032166 , global_step: 8161
- AI-Rank-log  1619269051.8540206  eval_accuracy: 0.7038363218307495 , global_step: 8162
- AI-Rank-log  1619269095.811094  eval_accuracy: 0.7039531469345093 , global_step: 8163
- AI-Rank-log  1619269139.8538525  eval_accuracy: 0.703903079032898 , global_step: 8164
- AI-Rank-log  1619269183.790077  eval_accuracy: 0.7032458782196045 , global_step: 8165
- AI-Rank-log  1619269227.7297652  eval_accuracy: 0.7033849954605103 , global_step: 8166
- AI-Rank-log  1619269271.7838473  eval_accuracy: 0.7034490704536438 , global_step: 8167
- AI-Rank-log  1619269315.7623944  eval_accuracy: 0.7031652927398682 , global_step: 8168
- AI-Rank-log  1619269359.6985738  eval_accuracy: 0.7035489082336426 , global_step: 8169
- AI-Rank-log  1619269403.6895096  eval_accuracy: 0.7039366364479065 , global_step: 8170
- AI-Rank-log  1619269447.7032835  eval_accuracy: 0.7038502097129822 , global_step: 8171
- AI-Rank-log  1619269491.7586527  eval_accuracy: 0.7038069367408752 , global_step: 8172
- AI-Rank-log  1619269535.6708062  eval_accuracy: 0.703325092792511 , global_step: 8173
- AI-Rank-log  1619269579.6341453  eval_accuracy: 0.7037283182144165 , global_step: 8174
- AI-Rank-log  1619269623.669746  eval_accuracy: 0.7028387188911438 , global_step: 8175
- AI-Rank-log  1619269667.6169593  eval_accuracy: 0.703544557094574 , global_step: 8176
- AI-Rank-log  1619269711.5908303  eval_accuracy: 0.7034298777580261 , global_step: 8177
- AI-Rank-log  1619269755.6283855  eval_accuracy: 0.7032796144485474 , global_step: 8178
- AI-Rank-log  1619269799.5424929  eval_accuracy: 0.7038264870643616 , global_step: 8179
- AI-Rank-log  1619269843.5123677  eval_accuracy: 0.703261137008667 , global_step: 8180
- AI-Rank-log  1619269887.5291615  eval_accuracy: 0.704049289226532 , global_step: 8181
- AI-Rank-log  1619269931.4548178  eval_accuracy: 0.7041934132575989 , global_step: 8182
- AI-Rank-log  1619269975.4656062  eval_accuracy: 0.703992486000061 , global_step: 8183
- AI-Rank-log  1619270019.431832  eval_accuracy: 0.7038538455963135 , global_step: 8184
- AI-Rank-log  1619270063.3457165  eval_accuracy: 0.7038666605949402 , global_step: 8185
- AI-Rank-log  1619270107.42472  eval_accuracy: 0.7037848830223083 , global_step: 8186
- AI-Rank-log  1619270152.1294837  eval_accuracy: 0.7038258910179138 , global_step: 8187
- AI-Rank-log  1619270196.1952045  eval_accuracy: 0.703923761844635 , global_step: 8188
- AI-Rank-log  1619270240.2201715  eval_accuracy: 0.7036685347557068 , global_step: 8189
- AI-Rank-log  1619270284.136396  eval_accuracy: 0.7039839625358582 , global_step: 8190
- AI-Rank-log  1619270337.165195  eval_accuracy: 0.7034764885902405 , global_step: 8191
- AI-Rank-log  1619270381.694117  eval_accuracy: 0.7040165662765503 , global_step: 8192
- AI-Rank-log  1619270425.651247  eval_accuracy: 0.7033173441886902 , global_step: 8193
- AI-Rank-log  1619270470.0964515  eval_accuracy: 0.7043458819389343 , global_step: 8194
- AI-Rank-log  1619270514.050209  eval_accuracy: 0.7040656805038452 , global_step: 8195
- AI-Rank-log  1619270558.2693458  eval_accuracy: 0.7045577764511108 , global_step: 8196
- AI-Rank-log  1619270602.3184242  eval_accuracy: 0.7033398747444153 , global_step: 8197
- AI-Rank-log  1619270646.3614264  eval_accuracy: 0.7043800354003906 , global_step: 8198
- AI-Rank-log  1619270690.3674495  eval_accuracy: 0.7039938569068909 , global_step: 8199
- AI-Rank-log  1619270735.177586  eval_accuracy: 0.7041671872138977 , global_step: 8200
- AI-Rank-log  1619270779.231529  eval_accuracy: 0.7046643495559692 , global_step: 8201
- AI-Rank-log  1619270823.5742576  eval_accuracy: 0.7041386365890503 , global_step: 8202
- AI-Rank-log  1619270867.5285664  eval_accuracy: 0.7044729590415955 , global_step: 8203
- AI-Rank-log  1619270911.5124483  eval_accuracy: 0.7041193246841431 , global_step: 8204
- AI-Rank-log  1619270956.2784247  eval_accuracy: 0.7044035196304321 , global_step: 8205
- AI-Rank-log  1619271000.5116892  eval_accuracy: 0.7042950987815857 , global_step: 8206
- AI-Rank-log  1619271044.4936113  eval_accuracy: 0.704017698764801 , global_step: 8207
- AI-Rank-log  1619271090.038432  eval_accuracy: 0.7045872211456299 , global_step: 8208
- AI-Rank-log  1619271134.0090847  eval_accuracy: 0.7043365836143494 , global_step: 8209
- AI-Rank-log  1619271177.976039  eval_accuracy: 0.7044517397880554 , global_step: 8210
- AI-Rank-log  1619271221.9727123  eval_accuracy: 0.7044450640678406 , global_step: 8211
- AI-Rank-log  1619271265.9550142  eval_accuracy: 0.7044071555137634 , global_step: 8212
- AI-Rank-log  1619271309.893323  eval_accuracy: 0.7039855718612671 , global_step: 8213
- AI-Rank-log  1619271354.1107929  eval_accuracy: 0.7043128609657288 , global_step: 8214
- AI-Rank-log  1619271398.0790963  eval_accuracy: 0.70432448387146 , global_step: 8215
- AI-Rank-log  1619271442.1167865  eval_accuracy: 0.7040959000587463 , global_step: 8216
- AI-Rank-log  1619271486.039157  eval_accuracy: 0.7044298648834229 , global_step: 8217
- AI-Rank-log  1619271530.008652  eval_accuracy: 0.7038357853889465 , global_step: 8218
- AI-Rank-log  1619271574.0778255  eval_accuracy: 0.7049533128738403 , global_step: 8219
- AI-Rank-log  1619271617.9948747  eval_accuracy: 0.7039967775344849 , global_step: 8220
- AI-Rank-log  1619271661.99924  eval_accuracy: 0.7047668099403381 , global_step: 8221
- AI-Rank-log  1619271706.0118494  eval_accuracy: 0.7043002843856812 , global_step: 8222
- AI-Rank-log  1619271749.9777842  eval_accuracy: 0.7042916417121887 , global_step: 8223
- AI-Rank-log  1619271793.9936595  eval_accuracy: 0.7039903998374939 , global_step: 8224
- AI-Rank-log  1619271837.9537938  eval_accuracy: 0.7038775086402893 , global_step: 8225
- AI-Rank-log  1619271881.9112437  eval_accuracy: 0.7041277885437012 , global_step: 8226
- AI-Rank-log  1619271925.9647427  eval_accuracy: 0.7037524580955505 , global_step: 8227
- AI-Rank-log  1619271969.9309845  eval_accuracy: 0.7039666771888733 , global_step: 8228
- AI-Rank-log  1619272013.8670762  eval_accuracy: 0.7038466930389404 , global_step: 8229
- AI-Rank-log  1619272057.9109964  eval_accuracy: 0.7039713263511658 , global_step: 8230
- AI-Rank-log  1619272101.8500388  eval_accuracy: 0.7039743661880493 , global_step: 8231
- AI-Rank-log  1619272145.797343  eval_accuracy: 0.7039796113967896 , global_step: 8232
- AI-Rank-log  1619272189.7992642  eval_accuracy: 0.7034668922424316 , global_step: 8233
- AI-Rank-log  1619272233.7560794  eval_accuracy: 0.7043956518173218 , global_step: 8234
- AI-Rank-log  1619272277.7718983  eval_accuracy: 0.7043316960334778 , global_step: 8235
- AI-Rank-log  1619272321.7023134  eval_accuracy: 0.7041980624198914 , global_step: 8236
- AI-Rank-log  1619272365.5958824  eval_accuracy: 0.7045396566390991 , global_step: 8237
- AI-Rank-log  1619272409.6076155  eval_accuracy: 0.7039688229560852 , global_step: 8238
- AI-Rank-log  1619272453.6206808  eval_accuracy: 0.7042234539985657 , global_step: 8239
- AI-Rank-log  1619272497.559509  eval_accuracy: 0.7045671343803406 , global_step: 8240
- AI-Rank-log  1619272541.6348314  eval_accuracy: 0.7038717865943909 , global_step: 8241
- AI-Rank-log  1619272585.611055  eval_accuracy: 0.7041689157485962 , global_step: 8242
- AI-Rank-log  1619272629.5441153  eval_accuracy: 0.7041041254997253 , global_step: 8243
- AI-Rank-log  1619272673.6113214  eval_accuracy: 0.7035072445869446 , global_step: 8244
- AI-Rank-log  1619272717.6486523  eval_accuracy: 0.7041980624198914 , global_step: 8245
- AI-Rank-log  1619272761.7091339  eval_accuracy: 0.7037155628204346 , global_step: 8246
- AI-Rank-log  1619272805.677588  eval_accuracy: 0.7043327689170837 , global_step: 8247
- AI-Rank-log  1619272849.6537113  eval_accuracy: 0.7037197947502136 , global_step: 8248
- AI-Rank-log  1619272893.6536186  eval_accuracy: 0.7040033936500549 , global_step: 8249
- AI-Rank-log  1619272937.679028  eval_accuracy: 0.7040398120880127 , global_step: 8250
- AI-Rank-log  1619272981.639018  eval_accuracy: 0.7041913866996765 , global_step: 8251
- AI-Rank-log  1619273025.6549711  eval_accuracy: 0.7039909362792969 , global_step: 8252
- AI-Rank-log  1619273069.6221466  eval_accuracy: 0.7046444416046143 , global_step: 8253
- AI-Rank-log  1619273113.7186358  eval_accuracy: 0.7036076188087463 , global_step: 8254
- AI-Rank-log  1619273157.4648736  eval_accuracy: 0.7041348218917847 , global_step: 8255
- AI-Rank-log  1619273201.4193585  eval_accuracy: 0.7035470008850098 , global_step: 8256
- AI-Rank-log  1619273245.449062  eval_accuracy: 0.7042989730834961 , global_step: 8257
- AI-Rank-log  1619273289.410068  eval_accuracy: 0.7043486833572388 , global_step: 8258
- AI-Rank-log  1619273333.3798833  eval_accuracy: 0.7040086984634399 , global_step: 8259
- AI-Rank-log  1619273377.421025  eval_accuracy: 0.7043291330337524 , global_step: 8260
- AI-Rank-log  1619273421.4149437  eval_accuracy: 0.7037272453308105 , global_step: 8261
- AI-Rank-log  1619273465.4446876  eval_accuracy: 0.7036237120628357 , global_step: 8262
- AI-Rank-log  1619273509.4659412  eval_accuracy: 0.7040945887565613 , global_step: 8263
- AI-Rank-log  1619273554.1864102  eval_accuracy: 0.704248309135437 , global_step: 8264
- AI-Rank-log  1619273598.4229796  eval_accuracy: 0.7039182782173157 , global_step: 8265
- AI-Rank-log  1619273642.4711642  eval_accuracy: 0.704092800617218 , global_step: 8266
- AI-Rank-log  1619273686.4327085  eval_accuracy: 0.7039579749107361 , global_step: 8267
- AI-Rank-log  1619273730.5065987  eval_accuracy: 0.7036427855491638 , global_step: 8268
- AI-Rank-log  1619273774.9580271  eval_accuracy: 0.7041745185852051 , global_step: 8269
- AI-Rank-log  1619273819.6236339  eval_accuracy: 0.7038958072662354 , global_step: 8270
- AI-Rank-log  1619273864.3300524  eval_accuracy: 0.7042350769042969 , global_step: 8271
- AI-Rank-log  1619273908.284304  eval_accuracy: 0.7036141753196716 , global_step: 8272
- AI-Rank-log  1619273952.2490945  eval_accuracy: 0.7048733830451965 , global_step: 8273
- AI-Rank-log  1619273996.392888  eval_accuracy: 0.7043241858482361 , global_step: 8274
- AI-Rank-log  1619274041.1174505  eval_accuracy: 0.7044724822044373 , global_step: 8275
- AI-Rank-log  1619274085.1032507  eval_accuracy: 0.7049005627632141 , global_step: 8276
- AI-Rank-log  1619274129.793052  eval_accuracy: 0.7048899531364441 , global_step: 8277
- AI-Rank-log  1619274173.7623057  eval_accuracy: 0.7044802308082581 , global_step: 8278
- AI-Rank-log  1619274217.742133  eval_accuracy: 0.7039118409156799 , global_step: 8279
- AI-Rank-log  1619274262.2178297  eval_accuracy: 0.7044168710708618 , global_step: 8280
- AI-Rank-log  1619274306.1435945  eval_accuracy: 0.7047847509384155 , global_step: 8281
- AI-Rank-log  1619274350.977212  eval_accuracy: 0.7046388983726501 , global_step: 8282
- AI-Rank-log  1619274394.9252684  eval_accuracy: 0.7042633295059204 , global_step: 8283
- AI-Rank-log  1619274438.8165345  eval_accuracy: 0.704563558101654 , global_step: 8284
- AI-Rank-log  1619274482.866586  eval_accuracy: 0.7041357755661011 , global_step: 8285
- AI-Rank-log  1619274527.9119687  eval_accuracy: 0.703910231590271 , global_step: 8286
- AI-Rank-log  1619274571.9323804  eval_accuracy: 0.7038924098014832 , global_step: 8287
- AI-Rank-log  1619274616.051893  eval_accuracy: 0.704391360282898 , global_step: 8288
- AI-Rank-log  1619274659.9587407  eval_accuracy: 0.7040186524391174 , global_step: 8289
- AI-Rank-log  1619274703.989591  eval_accuracy: 0.7045038938522339 , global_step: 8290
- AI-Rank-log  1619274747.9697604  eval_accuracy: 0.7042800188064575 , global_step: 8291
- AI-Rank-log  1619274792.084046  eval_accuracy: 0.7046723961830139 , global_step: 8292
- AI-Rank-log  1619274836.1016128  eval_accuracy: 0.7049499154090881 , global_step: 8293
- AI-Rank-log  1619274880.046076  eval_accuracy: 0.7043364644050598 , global_step: 8294
- AI-Rank-log  1619274924.0285122  eval_accuracy: 0.7043876647949219 , global_step: 8295
- AI-Rank-log  1619274968.0068157  eval_accuracy: 0.7044394016265869 , global_step: 8296
- AI-Rank-log  1619275011.953653  eval_accuracy: 0.7040534019470215 , global_step: 8297
- AI-Rank-log  1619275055.9462926  eval_accuracy: 0.7041033506393433 , global_step: 8298
- AI-Rank-log  1619275099.8997326  eval_accuracy: 0.7039690613746643 , global_step: 8299
- AI-Rank-log  1619275143.8915772  eval_accuracy: 0.7046030163764954 , global_step: 8300
- AI-Rank-log  1619275187.8825257  eval_accuracy: 0.7051130533218384 , global_step: 8301
- AI-Rank-log  1619275231.8562942  eval_accuracy: 0.7049112319946289 , global_step: 8302
- AI-Rank-log  1619275275.8033714  eval_accuracy: 0.7049276232719421 , global_step: 8303
- AI-Rank-log  1619275319.757697  eval_accuracy: 0.7049831748008728 , global_step: 8304
- AI-Rank-log  1619275363.694915  eval_accuracy: 0.7049475312232971 , global_step: 8305
- AI-Rank-log  1619275407.6730623  eval_accuracy: 0.7046514749526978 , global_step: 8306
- AI-Rank-log  1619275451.5898597  eval_accuracy: 0.704908549785614 , global_step: 8307
- AI-Rank-log  1619275495.5386672  eval_accuracy: 0.7054101824760437 , global_step: 8308
- AI-Rank-log  1619275539.567887  eval_accuracy: 0.7053711414337158 , global_step: 8309
- AI-Rank-log  1619275583.5060203  eval_accuracy: 0.7046411633491516 , global_step: 8310
- AI-Rank-log  1619275627.4147282  eval_accuracy: 0.704823911190033 , global_step: 8311
- AI-Rank-log  1619275671.4228806  eval_accuracy: 0.7049426436424255 , global_step: 8312
- AI-Rank-log  1619275715.3669555  eval_accuracy: 0.7047623991966248 , global_step: 8313
- AI-Rank-log  1619275759.378369  eval_accuracy: 0.7049501538276672 , global_step: 8314
- AI-Rank-log  1619275803.286865  eval_accuracy: 0.7050926089286804 , global_step: 8315
- AI-Rank-log  1619275847.2586653  eval_accuracy: 0.705181360244751 , global_step: 8316
- AI-Rank-log  1619275891.2939389  eval_accuracy: 0.7049815654754639 , global_step: 8317
- AI-Rank-log  1619275935.2055662  eval_accuracy: 0.7047349810600281 , global_step: 8318
- AI-Rank-log  1619275979.1623569  eval_accuracy: 0.7043265104293823 , global_step: 8319
- AI-Rank-log  1619276023.1546812  eval_accuracy: 0.7047680616378784 , global_step: 8320
- AI-Rank-log  1619276067.0395243  eval_accuracy: 0.7045606970787048 , global_step: 8321
- AI-Rank-log  1619276110.9695022  eval_accuracy: 0.7044818997383118 , global_step: 8322
- AI-Rank-log  1619276154.999142  eval_accuracy: 0.7051975727081299 , global_step: 8323
- AI-Rank-log  1619276198.883502  eval_accuracy: 0.705082356929779 , global_step: 8324
- AI-Rank-log  1619276242.8789144  eval_accuracy: 0.704953670501709 , global_step: 8325
- AI-Rank-log  1619276286.8282712  eval_accuracy: 0.7044923305511475 , global_step: 8326
- AI-Rank-log  1619276330.7279308  eval_accuracy: 0.7046772241592407 , global_step: 8327
- AI-Rank-log  1619276374.7287629  eval_accuracy: 0.7045174837112427 , global_step: 8328
- AI-Rank-log  1619276418.6553986  eval_accuracy: 0.7048394083976746 , global_step: 8329
- AI-Rank-log  1619276462.5940974  eval_accuracy: 0.7041538953781128 , global_step: 8330
- AI-Rank-log  1619276506.6253397  eval_accuracy: 0.7050008773803711 , global_step: 8331
- AI-Rank-log  1619276550.5902703  eval_accuracy: 0.7050309181213379 , global_step: 8332
- AI-Rank-log  1619276594.5195456  eval_accuracy: 0.7053573131561279 , global_step: 8333
- AI-Rank-log  1619276638.5293586  eval_accuracy: 0.7047120928764343 , global_step: 8334
- AI-Rank-log  1619276682.475914  eval_accuracy: 0.7044965028762817 , global_step: 8335
- AI-Rank-log  1619276726.4891994  eval_accuracy: 0.7050734758377075 , global_step: 8336
- AI-Rank-log  1619276770.4785619  eval_accuracy: 0.7052464485168457 , global_step: 8337
- AI-Rank-log  1619276814.348686  eval_accuracy: 0.7051864862442017 , global_step: 8338
- AI-Rank-log  1619276858.2791905  eval_accuracy: 0.7045921087265015 , global_step: 8339
- AI-Rank-log  1619276902.2644362  eval_accuracy: 0.7042653560638428 , global_step: 8340
- AI-Rank-log  1619276947.0587816  eval_accuracy: 0.7047459483146667 , global_step: 8341
- AI-Rank-log  1619276991.137943  eval_accuracy: 0.7048120498657227 , global_step: 8342
- AI-Rank-log  1619277035.0862458  eval_accuracy: 0.7044257521629333 , global_step: 8343
- AI-Rank-log  1619277079.0798364  eval_accuracy: 0.7048298716545105 , global_step: 8344
- AI-Rank-log  1619277123.0581508  eval_accuracy: 0.7046278715133667 , global_step: 8345
- AI-Rank-log  1619277167.5364265  eval_accuracy: 0.7048269510269165 , global_step: 8346
- AI-Rank-log  1619277211.4494905  eval_accuracy: 0.7050173878669739 , global_step: 8347
- AI-Rank-log  1619277255.4941235  eval_accuracy: 0.7048220038414001 , global_step: 8348
- AI-Rank-log  1619277299.968614  eval_accuracy: 0.7045660614967346 , global_step: 8349
- AI-Rank-log  1619277344.0049853  eval_accuracy: 0.7046014666557312 , global_step: 8350
- AI-Rank-log  1619277388.3184707  eval_accuracy: 0.7053186893463135 , global_step: 8351
- AI-Rank-log  1619277432.3139658  eval_accuracy: 0.7047402858734131 , global_step: 8352
- AI-Rank-log  1619277476.4039454  eval_accuracy: 0.7049095034599304 , global_step: 8353
- AI-Rank-log  1619277521.2427044  eval_accuracy: 0.7047662734985352 , global_step: 8354
- AI-Rank-log  1619277565.2700043  eval_accuracy: 0.7048922181129456 , global_step: 8355
- AI-Rank-log  1619277609.3355675  eval_accuracy: 0.7056559324264526 , global_step: 8356
- AI-Rank-log  1619277654.4452913  eval_accuracy: 0.7052448987960815 , global_step: 8357
- AI-Rank-log  1619277698.4081762  eval_accuracy: 0.7051622867584229 , global_step: 8358
- AI-Rank-log  1619277742.3860252  eval_accuracy: 0.7054963707923889 , global_step: 8359
- AI-Rank-log  1619277787.6971874  eval_accuracy: 0.70549476146698 , global_step: 8360
- AI-Rank-log  1619277831.7887375  eval_accuracy: 0.7051893472671509 , global_step: 8361
- AI-Rank-log  1619277875.7737474  eval_accuracy: 0.7050377130508423 , global_step: 8362
- AI-Rank-log  1619277920.7831566  eval_accuracy: 0.7053690552711487 , global_step: 8363
- AI-Rank-log  1619277964.7974544  eval_accuracy: 0.7052987813949585 , global_step: 8364
- AI-Rank-log  1619278008.7763393  eval_accuracy: 0.7044479846954346 , global_step: 8365
- AI-Rank-log  1619278052.7225974  eval_accuracy: 0.7052440047264099 , global_step: 8366
- AI-Rank-log  1619278096.781109  eval_accuracy: 0.7048141360282898 , global_step: 8367
- AI-Rank-log  1619278140.731143  eval_accuracy: 0.7049471139907837 , global_step: 8368
- AI-Rank-log  1619278184.7685823  eval_accuracy: 0.7056160569190979 , global_step: 8369
- AI-Rank-log  1619278228.7827659  eval_accuracy: 0.7051818370819092 , global_step: 8370
- AI-Rank-log  1619278272.775342  eval_accuracy: 0.7052212357521057 , global_step: 8371
- AI-Rank-log  1619278316.8785033  eval_accuracy: 0.7052357196807861 , global_step: 8372
- AI-Rank-log  1619278360.818446  eval_accuracy: 0.7054012417793274 , global_step: 8373
- AI-Rank-log  1619278404.7759328  eval_accuracy: 0.7055365443229675 , global_step: 8374
- AI-Rank-log  1619278448.7869034  eval_accuracy: 0.7053744792938232 , global_step: 8375
- AI-Rank-log  1619278492.7255306  eval_accuracy: 0.7047611474990845 , global_step: 8376
- AI-Rank-log  1619278536.7153306  eval_accuracy: 0.7052732706069946 , global_step: 8377
- AI-Rank-log  1619278580.7544434  eval_accuracy: 0.7045994997024536 , global_step: 8378
- AI-Rank-log  1619278624.715284  eval_accuracy: 0.7042772769927979 , global_step: 8379
- AI-Rank-log  1619278668.7825575  eval_accuracy: 0.7049400210380554 , global_step: 8380
- AI-Rank-log  1619278712.77168  eval_accuracy: 0.7048190832138062 , global_step: 8381
- AI-Rank-log  1619278756.7489579  eval_accuracy: 0.705405592918396 , global_step: 8382
- AI-Rank-log  1619278800.8010752  eval_accuracy: 0.704841136932373 , global_step: 8383
- AI-Rank-log  1619278844.806013  eval_accuracy: 0.7050302624702454 , global_step: 8384
- AI-Rank-log  1619278888.7206078  eval_accuracy: 0.7051827907562256 , global_step: 8385
- AI-Rank-log  1619278932.7733245  eval_accuracy: 0.705072820186615 , global_step: 8386
- AI-Rank-log  1619278976.7457933  eval_accuracy: 0.7055097222328186 , global_step: 8387
- AI-Rank-log  1619279020.6981146  eval_accuracy: 0.7048737406730652 , global_step: 8388
- AI-Rank-log  1619279064.7247276  eval_accuracy: 0.7054998874664307 , global_step: 8389
- AI-Rank-log  1619279108.6942909  eval_accuracy: 0.705336332321167 , global_step: 8390
- AI-Rank-log  1619279161.736456  eval_accuracy: 0.705521285533905 , global_step: 8391
- AI-Rank-log  1619279205.6790988  eval_accuracy: 0.7050051689147949 , global_step: 8392
- AI-Rank-log  1619279249.6292753  eval_accuracy: 0.7049692273139954 , global_step: 8393
- AI-Rank-log  1619279293.629897  eval_accuracy: 0.7045326232910156 , global_step: 8394
- AI-Rank-log  1619279337.6152234  eval_accuracy: 0.7048036456108093 , global_step: 8395
- AI-Rank-log  1619279381.6083267  eval_accuracy: 0.704329788684845 , global_step: 8396
- AI-Rank-log  1619279425.6204786  eval_accuracy: 0.7047913670539856 , global_step: 8397
- AI-Rank-log  1619279469.6072583  eval_accuracy: 0.7040797472000122 , global_step: 8398
- AI-Rank-log  1619279513.578049  eval_accuracy: 0.7043973207473755 , global_step: 8399
- AI-Rank-log  1619279557.5932627  eval_accuracy: 0.7042618989944458 , global_step: 8400
- AI-Rank-log  1619279601.5876603  eval_accuracy: 0.7046345472335815 , global_step: 8401
- AI-Rank-log  1619279645.5414033  eval_accuracy: 0.7044795751571655 , global_step: 8402
- AI-Rank-log  1619279689.5576344  eval_accuracy: 0.7048410177230835 , global_step: 8403
- AI-Rank-log  1619279733.5966907  eval_accuracy: 0.704872190952301 , global_step: 8404
- AI-Rank-log  1619279777.6819832  eval_accuracy: 0.7057518362998962 , global_step: 8405
- AI-Rank-log  1619279821.651538  eval_accuracy: 0.7051612734794617 , global_step: 8406
- AI-Rank-log  1619279865.6845605  eval_accuracy: 0.7048555016517639 , global_step: 8407
- AI-Rank-log  1619279909.6881475  eval_accuracy: 0.7050491571426392 , global_step: 8408
- AI-Rank-log  1619279953.6277118  eval_accuracy: 0.7050009369850159 , global_step: 8409
- AI-Rank-log  1619279997.5941453  eval_accuracy: 0.7045592665672302 , global_step: 8410
- AI-Rank-log  1619280041.59847  eval_accuracy: 0.7046539783477783 , global_step: 8411
- AI-Rank-log  1619280085.5689003  eval_accuracy: 0.704106867313385 , global_step: 8412
- AI-Rank-log  1619280129.5609329  eval_accuracy: 0.7048983573913574 , global_step: 8413
- AI-Rank-log  1619280173.5944657  eval_accuracy: 0.7045983076095581 , global_step: 8414
- AI-Rank-log  1619280217.587637  eval_accuracy: 0.7047296762466431 , global_step: 8415
- AI-Rank-log  1619280261.61576  eval_accuracy: 0.7052399516105652 , global_step: 8416
- AI-Rank-log  1619280305.5450099  eval_accuracy: 0.7048683762550354 , global_step: 8417
- AI-Rank-log  1619280349.525488  eval_accuracy: 0.704548716545105 , global_step: 8418
- AI-Rank-log  1619280394.3359373  eval_accuracy: 0.7051942348480225 , global_step: 8419
- AI-Rank-log  1619280438.5568094  eval_accuracy: 0.7043536305427551 , global_step: 8420
- AI-Rank-log  1619280482.5392246  eval_accuracy: 0.7053226232528687 , global_step: 8421
- AI-Rank-log  1619280526.5850546  eval_accuracy: 0.704818069934845 , global_step: 8422
- AI-Rank-log  1619280570.5475183  eval_accuracy: 0.7047348022460938 , global_step: 8423
- AI-Rank-log  1619280615.1766193  eval_accuracy: 0.7050236463546753 , global_step: 8424
- AI-Rank-log  1619280659.626937  eval_accuracy: 0.7049759030342102 , global_step: 8425
- AI-Rank-log  1619280704.2467113  eval_accuracy: 0.7051066756248474 , global_step: 8426
- AI-Rank-log  1619280748.2499046  eval_accuracy: 0.7048883438110352 , global_step: 8427
- AI-Rank-log  1619280792.5514946  eval_accuracy: 0.7053409218788147 , global_step: 8428
- AI-Rank-log  1619280836.5018728  eval_accuracy: 0.7050987482070923 , global_step: 8429
- AI-Rank-log  1619280880.5503168  eval_accuracy: 0.7051236629486084 , global_step: 8430
- AI-Rank-log  1619280924.5107238  eval_accuracy: 0.7049538493156433 , global_step: 8431
- AI-Rank-log  1619280969.2462618  eval_accuracy: 0.7050904631614685 , global_step: 8432
- AI-Rank-log  1619281013.341179  eval_accuracy: 0.7048103213310242 , global_step: 8433
- AI-Rank-log  1619281057.2693565  eval_accuracy: 0.7046457529067993 , global_step: 8434
- AI-Rank-log  1619281101.5489063  eval_accuracy: 0.704729437828064 , global_step: 8435
- AI-Rank-log  1619281145.592971  eval_accuracy: 0.7047672867774963 , global_step: 8436
- AI-Rank-log  1619281190.3103774  eval_accuracy: 0.7041677236557007 , global_step: 8437
- AI-Rank-log  1619281234.332082  eval_accuracy: 0.7045453190803528 , global_step: 8438
- AI-Rank-log  1619281278.307245  eval_accuracy: 0.7044091820716858 , global_step: 8439
- AI-Rank-log  1619281322.2765703  eval_accuracy: 0.7047265768051147 , global_step: 8440
- AI-Rank-log  1619281367.58625  eval_accuracy: 0.7049719095230103 , global_step: 8441
- AI-Rank-log  1619281411.552211  eval_accuracy: 0.7050583958625793 , global_step: 8442
- AI-Rank-log  1619281455.5216825  eval_accuracy: 0.705277144908905 , global_step: 8443
- AI-Rank-log  1619281499.565068  eval_accuracy: 0.704788327217102 , global_step: 8444
- AI-Rank-log  1619281543.553978  eval_accuracy: 0.7046397924423218 , global_step: 8445
- AI-Rank-log  1619281587.4789395  eval_accuracy: 0.7048223614692688 , global_step: 8446
- AI-Rank-log  1619281631.781251  eval_accuracy: 0.7048009037971497 , global_step: 8447
- AI-Rank-log  1619281675.7541285  eval_accuracy: 0.7050847411155701 , global_step: 8448
- AI-Rank-log  1619281719.7165394  eval_accuracy: 0.7049840688705444 , global_step: 8449
- AI-Rank-log  1619281763.6874902  eval_accuracy: 0.7044989466667175 , global_step: 8450
- AI-Rank-log  1619281807.708141  eval_accuracy: 0.7048513889312744 , global_step: 8451
- AI-Rank-log  1619281851.7356062  eval_accuracy: 0.70421302318573 , global_step: 8452
- AI-Rank-log  1619281895.7150733  eval_accuracy: 0.7041813135147095 , global_step: 8453
- AI-Rank-log  1619281939.6655023  eval_accuracy: 0.7044262290000916 , global_step: 8454
- AI-Rank-log  1619281983.6694772  eval_accuracy: 0.7042043805122375 , global_step: 8455
- AI-Rank-log  1619282027.6420412  eval_accuracy: 0.7044336795806885 , global_step: 8456
- AI-Rank-log  1619282071.567802  eval_accuracy: 0.7042194604873657 , global_step: 8457
- AI-Rank-log  1619282115.5402107  eval_accuracy: 0.70408695936203 , global_step: 8458
- AI-Rank-log  1619282159.499101  eval_accuracy: 0.7042155265808105 , global_step: 8459
- AI-Rank-log  1619282203.5043776  eval_accuracy: 0.7041409611701965 , global_step: 8460
- AI-Rank-log  1619282247.4401007  eval_accuracy: 0.7048476934432983 , global_step: 8461
- AI-Rank-log  1619282291.448309  eval_accuracy: 0.7051806449890137 , global_step: 8462
- AI-Rank-log  1619282335.4521651  eval_accuracy: 0.7049676179885864 , global_step: 8463
- AI-Rank-log  1619282379.3800647  eval_accuracy: 0.7044447064399719 , global_step: 8464
- AI-Rank-log  1619282423.377301  eval_accuracy: 0.7048912644386292 , global_step: 8465
- AI-Rank-log  1619282467.3875833  eval_accuracy: 0.7044273614883423 , global_step: 8466
- AI-Rank-log  1619282511.329317  eval_accuracy: 0.7049897313117981 , global_step: 8467
- AI-Rank-log  1619282555.2742226  eval_accuracy: 0.705040693283081 , global_step: 8468
- AI-Rank-log  1619282599.256061  eval_accuracy: 0.7049100995063782 , global_step: 8469
- AI-Rank-log  1619282643.20799  eval_accuracy: 0.7053175568580627 , global_step: 8470
- AI-Rank-log  1619282687.250968  eval_accuracy: 0.7051174640655518 , global_step: 8471
- AI-Rank-log  1619282731.2085552  eval_accuracy: 0.7053884267807007 , global_step: 8472
- AI-Rank-log  1619282775.1892145  eval_accuracy: 0.7055821418762207 , global_step: 8473
- AI-Rank-log  1619282819.2164845  eval_accuracy: 0.7052188515663147 , global_step: 8474
- AI-Rank-log  1619282863.1176994  eval_accuracy: 0.7055248022079468 , global_step: 8475
- AI-Rank-log  1619282907.11295  eval_accuracy: 0.7054541110992432 , global_step: 8476
- AI-Rank-log  1619282951.1669412  eval_accuracy: 0.7050618529319763 , global_step: 8477
- AI-Rank-log  1619282995.0807507  eval_accuracy: 0.7055132389068604 , global_step: 8478
- AI-Rank-log  1619283039.1383355  eval_accuracy: 0.7054043412208557 , global_step: 8479
- AI-Rank-log  1619283083.0789576  eval_accuracy: 0.7050735950469971 , global_step: 8480
- AI-Rank-log  1619283127.0197215  eval_accuracy: 0.7051109671592712 , global_step: 8481
- AI-Rank-log  1619283171.0313003  eval_accuracy: 0.7053854465484619 , global_step: 8482
- AI-Rank-log  1619283214.962308  eval_accuracy: 0.7051767110824585 , global_step: 8483
- AI-Rank-log  1619283258.67607  eval_accuracy: 0.7048964500427246 , global_step: 8484
- AI-Rank-log  1619283302.6411438  eval_accuracy: 0.7048715353012085 , global_step: 8485
- AI-Rank-log  1619283346.665123  eval_accuracy: 0.7052721381187439 , global_step: 8486
- AI-Rank-log  1619283390.5987718  eval_accuracy: 0.7045378088951111 , global_step: 8487
- AI-Rank-log  1619283434.631397  eval_accuracy: 0.7053946852684021 , global_step: 8488
- AI-Rank-log  1619283478.5948853  eval_accuracy: 0.7046898007392883 , global_step: 8489
- AI-Rank-log  1619283522.558208  eval_accuracy: 0.7052032947540283 , global_step: 8490
- AI-Rank-log  1619283566.577307  eval_accuracy: 0.7048407196998596 , global_step: 8491
- AI-Rank-log  1619283610.47881  eval_accuracy: 0.7051848769187927 , global_step: 8492
- AI-Rank-log  1619283654.4751565  eval_accuracy: 0.7051357626914978 , global_step: 8493
- AI-Rank-log  1619283698.412263  eval_accuracy: 0.7050570249557495 , global_step: 8494
- AI-Rank-log  1619283742.336443  eval_accuracy: 0.7049965262413025 , global_step: 8495
- AI-Rank-log  1619283786.8311744  eval_accuracy: 0.7047770619392395 , global_step: 8496
- AI-Rank-log  1619283831.0202563  eval_accuracy: 0.7046836614608765 , global_step: 8497
- AI-Rank-log  1619283874.93777  eval_accuracy: 0.7050665616989136 , global_step: 8498
- AI-Rank-log  1619283918.9335742  eval_accuracy: 0.7044262290000916 , global_step: 8499
- AI-Rank-log  1619283962.8868928  eval_accuracy: 0.7047445774078369 , global_step: 8500
- AI-Rank-log  1619284006.8521547  eval_accuracy: 0.7054163813591003 , global_step: 8501
- AI-Rank-log  1619284051.5329983  eval_accuracy: 0.7052022218704224 , global_step: 8502
- AI-Rank-log  1619284095.4769397  eval_accuracy: 0.7052562236785889 , global_step: 8503
- AI-Rank-log  1619284139.748111  eval_accuracy: 0.705181360244751 , global_step: 8504
- AI-Rank-log  1619284183.7098112  eval_accuracy: 0.7052015662193298 , global_step: 8505
- AI-Rank-log  1619284227.796834  eval_accuracy: 0.7049652934074402 , global_step: 8506
- AI-Rank-log  1619284271.7750566  eval_accuracy: 0.7059478163719177 , global_step: 8507
- AI-Rank-log  1619284315.9454675  eval_accuracy: 0.7052394151687622 , global_step: 8508
- AI-Rank-log  1619284360.7610269  eval_accuracy: 0.7057446837425232 , global_step: 8509
- AI-Rank-log  1619284404.7222288  eval_accuracy: 0.705492377281189 , global_step: 8510
- AI-Rank-log  1619284448.6512375  eval_accuracy: 0.7056861519813538 , global_step: 8511
- AI-Rank-log  1619284492.9368827  eval_accuracy: 0.7054559588432312 , global_step: 8512
- AI-Rank-log  1619284536.870562  eval_accuracy: 0.7051761746406555 , global_step: 8513
- AI-Rank-log  1619284580.7944946  eval_accuracy: 0.7054563164710999 , global_step: 8514
- AI-Rank-log  1619284625.7068489  eval_accuracy: 0.7052981853485107 , global_step: 8515
- AI-Rank-log  1619284669.9169703  eval_accuracy: 0.7053087949752808 , global_step: 8516
- AI-Rank-log  1619284713.8926332  eval_accuracy: 0.7054135799407959 , global_step: 8517
- AI-Rank-log  1619284759.1864212  eval_accuracy: 0.70537930727005 , global_step: 8518
- AI-Rank-log  1619284803.1904578  eval_accuracy: 0.7055184245109558 , global_step: 8519
- AI-Rank-log  1619284847.2175071  eval_accuracy: 0.7056365013122559 , global_step: 8520
- AI-Rank-log  1619284891.1728356  eval_accuracy: 0.705833911895752 , global_step: 8521
- AI-Rank-log  1619284935.136584  eval_accuracy: 0.7057984471321106 , global_step: 8522
- AI-Rank-log  1619284979.16545  eval_accuracy: 0.7056888937950134 , global_step: 8523
- AI-Rank-log  1619285023.1181064  eval_accuracy: 0.7053642868995667 , global_step: 8524
- AI-Rank-log  1619285067.5073774  eval_accuracy: 0.7058079838752747 , global_step: 8525
- AI-Rank-log  1619285111.5381048  eval_accuracy: 0.7055609226226807 , global_step: 8526
- AI-Rank-log  1619285155.4809487  eval_accuracy: 0.7055230140686035 , global_step: 8527
- AI-Rank-log  1619285199.4242573  eval_accuracy: 0.7052028179168701 , global_step: 8528
- AI-Rank-log  1619285243.4493692  eval_accuracy: 0.7059630751609802 , global_step: 8529
- AI-Rank-log  1619285287.3910162  eval_accuracy: 0.7054333686828613 , global_step: 8530
- AI-Rank-log  1619285331.4406366  eval_accuracy: 0.7057082653045654 , global_step: 8531
- AI-Rank-log  1619285375.4394057  eval_accuracy: 0.7061561346054077 , global_step: 8532
- AI-Rank-log  1619285419.341618  eval_accuracy: 0.7057182788848877 , global_step: 8533
- AI-Rank-log  1619285463.382265  eval_accuracy: 0.7059374451637268 , global_step: 8534
- AI-Rank-log  1619285507.3488445  eval_accuracy: 0.7061327695846558 , global_step: 8535
- AI-Rank-log  1619285551.2775223  eval_accuracy: 0.7061889171600342 , global_step: 8536
- AI-Rank-log  1619285595.3241713  eval_accuracy: 0.7057956457138062 , global_step: 8537
- AI-Rank-log  1619285639.2878327  eval_accuracy: 0.7058376669883728 , global_step: 8538
- AI-Rank-log  1619285683.2756014  eval_accuracy: 0.7053424715995789 , global_step: 8539
- AI-Rank-log  1619285727.1998062  eval_accuracy: 0.70539391040802 , global_step: 8540
- AI-Rank-log  1619285771.15061  eval_accuracy: 0.7054601907730103 , global_step: 8541
- AI-Rank-log  1619285815.2013311  eval_accuracy: 0.705382764339447 , global_step: 8542
- AI-Rank-log  1619285859.176065  eval_accuracy: 0.7057728171348572 , global_step: 8543
- AI-Rank-log  1619285903.0898898  eval_accuracy: 0.7053738236427307 , global_step: 8544
- AI-Rank-log  1619285947.1195402  eval_accuracy: 0.705866277217865 , global_step: 8545
- AI-Rank-log  1619285991.0957568  eval_accuracy: 0.7055774927139282 , global_step: 8546
- AI-Rank-log  1619286035.0421922  eval_accuracy: 0.7060514688491821 , global_step: 8547
- AI-Rank-log  1619286079.102765  eval_accuracy: 0.7058459520339966 , global_step: 8548
- AI-Rank-log  1619286123.0650523  eval_accuracy: 0.7055386304855347 , global_step: 8549
- AI-Rank-log  1619286167.07863  eval_accuracy: 0.7061975002288818 , global_step: 8550
- AI-Rank-log  1619286211.0101447  eval_accuracy: 0.7058600783348083 , global_step: 8551
- AI-Rank-log  1619286254.9866211  eval_accuracy: 0.7056727409362793 , global_step: 8552
- AI-Rank-log  1619286298.9418225  eval_accuracy: 0.7056251168251038 , global_step: 8553
- AI-Rank-log  1619286342.8894706  eval_accuracy: 0.7059973478317261 , global_step: 8554
- AI-Rank-log  1619286386.8815522  eval_accuracy: 0.7059504985809326 , global_step: 8555
- AI-Rank-log  1619286430.8926077  eval_accuracy: 0.7061894536018372 , global_step: 8556
- AI-Rank-log  1619286474.8262627  eval_accuracy: 0.7057011723518372 , global_step: 8557
- AI-Rank-log  1619286518.7626207  eval_accuracy: 0.7058049440383911 , global_step: 8558
- AI-Rank-log  1619286562.8004973  eval_accuracy: 0.7058649063110352 , global_step: 8559
- AI-Rank-log  1619286606.7902763  eval_accuracy: 0.7059633135795593 , global_step: 8560
- AI-Rank-log  1619286650.8330426  eval_accuracy: 0.7062073349952698 , global_step: 8561
- AI-Rank-log  1619286694.8090384  eval_accuracy: 0.705768883228302 , global_step: 8562
- AI-Rank-log  1619286738.874281  eval_accuracy: 0.7060098052024841 , global_step: 8563
- AI-Rank-log  1619286782.8452864  eval_accuracy: 0.7059227824211121 , global_step: 8564
- AI-Rank-log  1619286826.79941  eval_accuracy: 0.705668032169342 , global_step: 8565
- AI-Rank-log  1619286870.7507584  eval_accuracy: 0.7058777809143066 , global_step: 8566
- AI-Rank-log  1619286914.7764359  eval_accuracy: 0.7057831287384033 , global_step: 8567
- AI-Rank-log  1619286958.774365  eval_accuracy: 0.7064911127090454 , global_step: 8568
- AI-Rank-log  1619287002.7625127  eval_accuracy: 0.7059370875358582 , global_step: 8569
- AI-Rank-log  1619287046.798898  eval_accuracy: 0.7057897448539734 , global_step: 8570
- AI-Rank-log  1619287090.7177694  eval_accuracy: 0.7060679197311401 , global_step: 8571
- AI-Rank-log  1619287134.7494812  eval_accuracy: 0.7060551047325134 , global_step: 8572
- AI-Rank-log  1619287178.6745782  eval_accuracy: 0.7062339782714844 , global_step: 8573
- AI-Rank-log  1619287223.71081  eval_accuracy: 0.7058167457580566 , global_step: 8574
- AI-Rank-log  1619287267.7488668  eval_accuracy: 0.7063290476799011 , global_step: 8575
- AI-Rank-log  1619287311.6700122  eval_accuracy: 0.7061251401901245 , global_step: 8576
- AI-Rank-log  1619287355.6660202  eval_accuracy: 0.7058872580528259 , global_step: 8577
- AI-Rank-log  1619287399.7122276  eval_accuracy: 0.7065525650978088 , global_step: 8578
- AI-Rank-log  1619287444.3309166  eval_accuracy: 0.7058883905410767 , global_step: 8579
- AI-Rank-log  1619287488.330757  eval_accuracy: 0.7058470249176025 , global_step: 8580
- AI-Rank-log  1619287532.8744826  eval_accuracy: 0.7055560946464539 , global_step: 8581
- AI-Rank-log  1619287576.895396  eval_accuracy: 0.7064447402954102 , global_step: 8582
- AI-Rank-log  1619287621.0658734  eval_accuracy: 0.7056722044944763 , global_step: 8583
- AI-Rank-log  1619287665.060135  eval_accuracy: 0.7066657543182373 , global_step: 8584
- AI-Rank-log  1619287709.1936798  eval_accuracy: 0.7055885791778564 , global_step: 8585
- AI-Rank-log  1619287753.6923778  eval_accuracy: 0.7061707377433777 , global_step: 8586
- AI-Rank-log  1619287798.5778248  eval_accuracy: 0.7062155604362488 , global_step: 8587
- AI-Rank-log  1619287842.5906243  eval_accuracy: 0.7059924602508545 , global_step: 8588
- AI-Rank-log  1619287886.616725  eval_accuracy: 0.7056919932365417 , global_step: 8589
- AI-Rank-log  1619287930.9275203  eval_accuracy: 0.7056570053100586 , global_step: 8590
- AI-Rank-log  1619287983.9396954  eval_accuracy: 0.7061461806297302 , global_step: 8591
- AI-Rank-log  1619288028.540054  eval_accuracy: 0.7055121660232544 , global_step: 8592
- AI-Rank-log  1619288072.6578321  eval_accuracy: 0.7058447003364563 , global_step: 8593
- AI-Rank-log  1619288116.7869997  eval_accuracy: 0.705622673034668 , global_step: 8594
- AI-Rank-log  1619288160.625136  eval_accuracy: 0.7056933641433716 , global_step: 8595
- AI-Rank-log  1619288205.864967  eval_accuracy: 0.7051222920417786 , global_step: 8596
- AI-Rank-log  1619288249.9936888  eval_accuracy: 0.7059677243232727 , global_step: 8597
- AI-Rank-log  1619288294.0277565  eval_accuracy: 0.7059211730957031 , global_step: 8598
- AI-Rank-log  1619288338.0874357  eval_accuracy: 0.7063615918159485 , global_step: 8599
- AI-Rank-log  1619288382.1342113  eval_accuracy: 0.7062423229217529 , global_step: 8600
- AI-Rank-log  1619288426.2235165  eval_accuracy: 0.706544816493988 , global_step: 8601
- AI-Rank-log  1619288470.320672  eval_accuracy: 0.7059034705162048 , global_step: 8602
- AI-Rank-log  1619288514.718933  eval_accuracy: 0.7065586447715759 , global_step: 8603
- AI-Rank-log  1619288558.7606728  eval_accuracy: 0.7059277892112732 , global_step: 8604
- AI-Rank-log  1619288602.877396  eval_accuracy: 0.7063978910446167 , global_step: 8605
- AI-Rank-log  1619288646.9559534  eval_accuracy: 0.7063091397285461 , global_step: 8606
- AI-Rank-log  1619288690.9683943  eval_accuracy: 0.7062649726867676 , global_step: 8607
- AI-Rank-log  1619288735.0819023  eval_accuracy: 0.7053030729293823 , global_step: 8608
- AI-Rank-log  1619288779.102926  eval_accuracy: 0.7060037851333618 , global_step: 8609
- AI-Rank-log  1619288823.1759846  eval_accuracy: 0.7054043412208557 , global_step: 8610
- AI-Rank-log  1619288867.2254827  eval_accuracy: 0.7059160470962524 , global_step: 8611
- AI-Rank-log  1619288911.2202241  eval_accuracy: 0.705420970916748 , global_step: 8612
- AI-Rank-log  1619288955.352999  eval_accuracy: 0.7056415677070618 , global_step: 8613
- AI-Rank-log  1619288999.3660154  eval_accuracy: 0.7061496376991272 , global_step: 8614
- AI-Rank-log  1619289043.4083827  eval_accuracy: 0.7059466242790222 , global_step: 8615
- AI-Rank-log  1619289087.4984176  eval_accuracy: 0.7056647539138794 , global_step: 8616
- AI-Rank-log  1619289131.4946394  eval_accuracy: 0.705844521522522 , global_step: 8617
- AI-Rank-log  1619289175.5615957  eval_accuracy: 0.7064041495323181 , global_step: 8618
- AI-Rank-log  1619289219.6343613  eval_accuracy: 0.7064598202705383 , global_step: 8619
- AI-Rank-log  1619289263.6160493  eval_accuracy: 0.706333577632904 , global_step: 8620
- AI-Rank-log  1619289307.7440908  eval_accuracy: 0.7062293887138367 , global_step: 8621
- AI-Rank-log  1619289351.756438  eval_accuracy: 0.7063969969749451 , global_step: 8622
- AI-Rank-log  1619289395.786174  eval_accuracy: 0.7063630223274231 , global_step: 8623
- AI-Rank-log  1619289439.9149616  eval_accuracy: 0.7067719101905823 , global_step: 8624
- AI-Rank-log  1619289483.9829707  eval_accuracy: 0.7060216665267944 , global_step: 8625
- AI-Rank-log  1619289528.015081  eval_accuracy: 0.7065765857696533 , global_step: 8626
- AI-Rank-log  1619289572.1545181  eval_accuracy: 0.7060157060623169 , global_step: 8627
- AI-Rank-log  1619289616.1749895  eval_accuracy: 0.706034779548645 , global_step: 8628
- AI-Rank-log  1619289660.1828022  eval_accuracy: 0.706132709980011 , global_step: 8629
- AI-Rank-log  1619289704.3301299  eval_accuracy: 0.7062410116195679 , global_step: 8630
- AI-Rank-log  1619289748.3592935  eval_accuracy: 0.7064403891563416 , global_step: 8631
- AI-Rank-log  1619289792.464021  eval_accuracy: 0.7062416672706604 , global_step: 8632
- AI-Rank-log  1619289836.4878678  eval_accuracy: 0.7061619162559509 , global_step: 8633
- AI-Rank-log  1619289880.5317948  eval_accuracy: 0.7061311602592468 , global_step: 8634
- AI-Rank-log  1619289924.64421  eval_accuracy: 0.7058057188987732 , global_step: 8635
- AI-Rank-log  1619289968.6806855  eval_accuracy: 0.7064495086669922 , global_step: 8636
- AI-Rank-log  1619290012.715014  eval_accuracy: 0.7061322927474976 , global_step: 8637
- AI-Rank-log  1619290056.7566483  eval_accuracy: 0.7061776518821716 , global_step: 8638
- AI-Rank-log  1619290100.8169732  eval_accuracy: 0.7061024308204651 , global_step: 8639
- AI-Rank-log  1619290144.8798623  eval_accuracy: 0.7063895463943481 , global_step: 8640
- AI-Rank-log  1619290188.940677  eval_accuracy: 0.7058685421943665 , global_step: 8641
- AI-Rank-log  1619290233.091565  eval_accuracy: 0.7059873342514038 , global_step: 8642
- AI-Rank-log  1619290277.192376  eval_accuracy: 0.7056527137756348 , global_step: 8643
- AI-Rank-log  1619290321.2063441  eval_accuracy: 0.7058090567588806 , global_step: 8644
- AI-Rank-log  1619290365.222688  eval_accuracy: 0.705702543258667 , global_step: 8645
- AI-Rank-log  1619290409.3353512  eval_accuracy: 0.7055651545524597 , global_step: 8646
- AI-Rank-log  1619290453.359567  eval_accuracy: 0.7056174278259277 , global_step: 8647
- AI-Rank-log  1619290497.3997235  eval_accuracy: 0.7056114077568054 , global_step: 8648
- AI-Rank-log  1619290541.2656326  eval_accuracy: 0.7052788138389587 , global_step: 8649
- AI-Rank-log  1619290585.3264878  eval_accuracy: 0.7058534622192383 , global_step: 8650
- AI-Rank-log  1619290630.0308852  eval_accuracy: 0.7062872648239136 , global_step: 8651
- AI-Rank-log  1619290674.0811334  eval_accuracy: 0.7059438228607178 , global_step: 8652
- AI-Rank-log  1619290718.176076  eval_accuracy: 0.7060094475746155 , global_step: 8653
- AI-Rank-log  1619290762.2512732  eval_accuracy: 0.70601886510849 , global_step: 8654
- AI-Rank-log  1619290806.2469006  eval_accuracy: 0.705863893032074 , global_step: 8655
- AI-Rank-log  1619290850.6896412  eval_accuracy: 0.7060943245887756 , global_step: 8656
- AI-Rank-log  1619290895.9879565  eval_accuracy: 0.7060098052024841 , global_step: 8657
- AI-Rank-log  1619290940.5415158  eval_accuracy: 0.7063283920288086 , global_step: 8658
- AI-Rank-log  1619290984.5991244  eval_accuracy: 0.7060549855232239 , global_step: 8659
- AI-Rank-log  1619291028.7218843  eval_accuracy: 0.7055268287658691 , global_step: 8660
- AI-Rank-log  1619291072.8887198  eval_accuracy: 0.7058047652244568 , global_step: 8661
- AI-Rank-log  1619291116.9120722  eval_accuracy: 0.7062661647796631 , global_step: 8662
- AI-Rank-log  1619291161.0778742  eval_accuracy: 0.7057855725288391 , global_step: 8663
- AI-Rank-log  1619291205.0814114  eval_accuracy: 0.705861508846283 , global_step: 8664
- AI-Rank-log  1619291249.825869  eval_accuracy: 0.7054335474967957 , global_step: 8665
- AI-Rank-log  1619291293.888003  eval_accuracy: 0.7062200307846069 , global_step: 8666
- AI-Rank-log  1619291338.4231472  eval_accuracy: 0.706015408039093 , global_step: 8667
- AI-Rank-log  1619291382.578311  eval_accuracy: 0.7065855264663696 , global_step: 8668
- AI-Rank-log  1619291426.5835268  eval_accuracy: 0.7060038447380066 , global_step: 8669
- AI-Rank-log  1619291472.0457416  eval_accuracy: 0.7059057950973511 , global_step: 8670
- AI-Rank-log  1619291516.162159  eval_accuracy: 0.7063797116279602 , global_step: 8671
- AI-Rank-log  1619291560.2543957  eval_accuracy: 0.7058362364768982 , global_step: 8672
- AI-Rank-log  1619291605.4603333  eval_accuracy: 0.7067519426345825 , global_step: 8673
- AI-Rank-log  1619291649.5284925  eval_accuracy: 0.7063528299331665 , global_step: 8674
- AI-Rank-log  1619291693.5556035  eval_accuracy: 0.7068468928337097 , global_step: 8675
- AI-Rank-log  1619291737.671495  eval_accuracy: 0.7067607045173645 , global_step: 8676
- AI-Rank-log  1619291781.6939983  eval_accuracy: 0.7067059874534607 , global_step: 8677
- AI-Rank-log  1619291825.7721639  eval_accuracy: 0.70726478099823 , global_step: 8678
- AI-Rank-log  1619291869.8993833  eval_accuracy: 0.7069025039672852 , global_step: 8679
- AI-Rank-log  1619291914.2701497  eval_accuracy: 0.7068244218826294 , global_step: 8680
- AI-Rank-log  1619291958.3264897  eval_accuracy: 0.7064785957336426 , global_step: 8681
- AI-Rank-log  1619292002.4667366  eval_accuracy: 0.7063544988632202 , global_step: 8682
- AI-Rank-log  1619292046.5213642  eval_accuracy: 0.706686794757843 , global_step: 8683
- AI-Rank-log  1619292090.64031  eval_accuracy: 0.7067461609840393 , global_step: 8684
- AI-Rank-log  1619292134.7094464  eval_accuracy: 0.7070088982582092 , global_step: 8685
- AI-Rank-log  1619292178.7608476  eval_accuracy: 0.7066417932510376 , global_step: 8686
- AI-Rank-log  1619292222.855718  eval_accuracy: 0.7068268656730652 , global_step: 8687
- AI-Rank-log  1619292266.921862  eval_accuracy: 0.7067175507545471 , global_step: 8688
- AI-Rank-log  1619292310.9822388  eval_accuracy: 0.7066264748573303 , global_step: 8689
- AI-Rank-log  1619292355.0611255  eval_accuracy: 0.7066239714622498 , global_step: 8690
- AI-Rank-log  1619292399.1042192  eval_accuracy: 0.7062419056892395 , global_step: 8691
- AI-Rank-log  1619292443.168138  eval_accuracy: 0.7064005136489868 , global_step: 8692
- AI-Rank-log  1619292487.207775  eval_accuracy: 0.7063077092170715 , global_step: 8693
- AI-Rank-log  1619292531.230751  eval_accuracy: 0.705735981464386 , global_step: 8694
- AI-Rank-log  1619292575.2640672  eval_accuracy: 0.7061794996261597 , global_step: 8695
- AI-Rank-log  1619292619.319988  eval_accuracy: 0.70639967918396 , global_step: 8696
- AI-Rank-log  1619292663.418674  eval_accuracy: 0.7062559127807617 , global_step: 8697
- AI-Rank-log  1619292707.545904  eval_accuracy: 0.7059581279754639 , global_step: 8698
- AI-Rank-log  1619292751.559311  eval_accuracy: 0.7064048051834106 , global_step: 8699
- AI-Rank-log  1619292795.5698369  eval_accuracy: 0.7061961889266968 , global_step: 8700
- AI-Rank-log  1619292839.6548355  eval_accuracy: 0.7065454721450806 , global_step: 8701
- AI-Rank-log  1619292883.6743696  eval_accuracy: 0.7062551379203796 , global_step: 8702
- AI-Rank-log  1619292927.6955025  eval_accuracy: 0.7068742513656616 , global_step: 8703
- AI-Rank-log  1619292971.8856003  eval_accuracy: 0.7071669697761536 , global_step: 8704
- AI-Rank-log  1619293015.919042  eval_accuracy: 0.7067650556564331 , global_step: 8705
- AI-Rank-log  1619293060.0143545  eval_accuracy: 0.7065885663032532 , global_step: 8706
- AI-Rank-log  1619293104.0698807  eval_accuracy: 0.7062233686447144 , global_step: 8707
- AI-Rank-log  1619293148.099661  eval_accuracy: 0.7065934538841248 , global_step: 8708
- AI-Rank-log  1619293192.2135084  eval_accuracy: 0.7064434289932251 , global_step: 8709
- AI-Rank-log  1619293236.2726576  eval_accuracy: 0.7064164280891418 , global_step: 8710
- AI-Rank-log  1619293280.2765005  eval_accuracy: 0.7061915397644043 , global_step: 8711
- AI-Rank-log  1619293324.3688822  eval_accuracy: 0.7062160968780518 , global_step: 8712
- AI-Rank-log  1619293368.4377227  eval_accuracy: 0.7060998678207397 , global_step: 8713
- AI-Rank-log  1619293412.4885235  eval_accuracy: 0.7062095403671265 , global_step: 8714
- AI-Rank-log  1619293456.5966797  eval_accuracy: 0.7066790461540222 , global_step: 8715
- AI-Rank-log  1619293500.6471832  eval_accuracy: 0.7064483761787415 , global_step: 8716
- AI-Rank-log  1619293544.8027756  eval_accuracy: 0.706546425819397 , global_step: 8717
- AI-Rank-log  1619293588.8452656  eval_accuracy: 0.706270694732666 , global_step: 8718
- AI-Rank-log  1619293632.8812768  eval_accuracy: 0.7067763805389404 , global_step: 8719
- AI-Rank-log  1619293676.9183657  eval_accuracy: 0.7068694829940796 , global_step: 8720
- AI-Rank-log  1619293720.9594285  eval_accuracy: 0.7067574262619019 , global_step: 8721
- AI-Rank-log  1619293764.944822  eval_accuracy: 0.706957221031189 , global_step: 8722
- AI-Rank-log  1619293809.0818326  eval_accuracy: 0.7067593932151794 , global_step: 8723
- AI-Rank-log  1619293853.152051  eval_accuracy: 0.7072271704673767 , global_step: 8724
- AI-Rank-log  1619293897.1705627  eval_accuracy: 0.7065363526344299 , global_step: 8725
- AI-Rank-log  1619293941.3198564  eval_accuracy: 0.7063881158828735 , global_step: 8726
- AI-Rank-log  1619293985.1563835  eval_accuracy: 0.7061986327171326 , global_step: 8727
- AI-Rank-log  1619294030.1454592  eval_accuracy: 0.7062416076660156 , global_step: 8728
- AI-Rank-log  1619294074.166182  eval_accuracy: 0.7062175273895264 , global_step: 8729
- AI-Rank-log  1619294118.2130215  eval_accuracy: 0.706454336643219 , global_step: 8730
- AI-Rank-log  1619294162.2663333  eval_accuracy: 0.7059807181358337 , global_step: 8731
- AI-Rank-log  1619294206.4935722  eval_accuracy: 0.7064410448074341 , global_step: 8732
- AI-Rank-log  1619294250.520719  eval_accuracy: 0.7065404057502747 , global_step: 8733
- AI-Rank-log  1619294295.1400874  eval_accuracy: 0.7060146927833557 , global_step: 8734
- AI-Rank-log  1619294339.199888  eval_accuracy: 0.7064197659492493 , global_step: 8735
- AI-Rank-log  1619294383.4375758  eval_accuracy: 0.7061070203781128 , global_step: 8736
- AI-Rank-log  1619294427.5425496  eval_accuracy: 0.7056180834770203 , global_step: 8737
- AI-Rank-log  1619294471.819018  eval_accuracy: 0.7063107490539551 , global_step: 8738
- AI-Rank-log  1619294516.7794235  eval_accuracy: 0.7066242098808289 , global_step: 8739
- AI-Rank-log  1619294560.8254845  eval_accuracy: 0.7067357301712036 , global_step: 8740
- AI-Rank-log  1619294604.9421852  eval_accuracy: 0.7068200707435608 , global_step: 8741
- AI-Rank-log  1619294649.8131237  eval_accuracy: 0.7065542936325073 , global_step: 8742
- AI-Rank-log  1619294693.8369064  eval_accuracy: 0.7071233987808228 , global_step: 8743
- AI-Rank-log  1619294738.2739146  eval_accuracy: 0.7068681120872498 , global_step: 8744
- AI-Rank-log  1619294782.413948  eval_accuracy: 0.7067144513130188 , global_step: 8745
- AI-Rank-log  1619294826.4517906  eval_accuracy: 0.7074328660964966 , global_step: 8746
- AI-Rank-log  1619294871.318198  eval_accuracy: 0.7072111964225769 , global_step: 8747
- AI-Rank-log  1619294915.4555237  eval_accuracy: 0.707028865814209 , global_step: 8748
- AI-Rank-log  1619294959.5240855  eval_accuracy: 0.7064900398254395 , global_step: 8749
- AI-Rank-log  1619295003.62789  eval_accuracy: 0.7067008018493652 , global_step: 8750
- AI-Rank-log  1619295048.5368755  eval_accuracy: 0.7066186666488647 , global_step: 8751
- AI-Rank-log  1619295092.5983713  eval_accuracy: 0.706766664981842 , global_step: 8752
- AI-Rank-log  1619295136.7462213  eval_accuracy: 0.7072598338127136 , global_step: 8753
- AI-Rank-log  1619295180.7662992  eval_accuracy: 0.7069860100746155 , global_step: 8754
- AI-Rank-log  1619295224.7838762  eval_accuracy: 0.7071542739868164 , global_step: 8755
- AI-Rank-log  1619295268.9881978  eval_accuracy: 0.7067544460296631 , global_step: 8756
- AI-Rank-log  1619295313.0004086  eval_accuracy: 0.7067463397979736 , global_step: 8757
- AI-Rank-log  1619295357.0700114  eval_accuracy: 0.7068567276000977 , global_step: 8758
- AI-Rank-log  1619295401.1770277  eval_accuracy: 0.7070271372795105 , global_step: 8759
- AI-Rank-log  1619295445.169828  eval_accuracy: 0.7060614824295044 , global_step: 8760
- AI-Rank-log  1619295489.2527065  eval_accuracy: 0.7067005634307861 , global_step: 8761
- AI-Rank-log  1619295533.2576225  eval_accuracy: 0.7065913677215576 , global_step: 8762
- AI-Rank-log  1619295577.2240613  eval_accuracy: 0.706600546836853 , global_step: 8763
- AI-Rank-log  1619295621.4126089  eval_accuracy: 0.7071325778961182 , global_step: 8764
- AI-Rank-log  1619295665.4560497  eval_accuracy: 0.7066192030906677 , global_step: 8765
- AI-Rank-log  1619295709.468695  eval_accuracy: 0.706797182559967 , global_step: 8766
- AI-Rank-log  1619295753.5481653  eval_accuracy: 0.7072084546089172 , global_step: 8767
- AI-Rank-log  1619295797.594527  eval_accuracy: 0.7070614695549011 , global_step: 8768
- AI-Rank-log  1619295841.622731  eval_accuracy: 0.7069566249847412 , global_step: 8769
- AI-Rank-log  1619295885.7803211  eval_accuracy: 0.7070319056510925 , global_step: 8770
- AI-Rank-log  1619295929.7899253  eval_accuracy: 0.70703125 , global_step: 8771
- AI-Rank-log  1619295973.9042497  eval_accuracy: 0.7070115208625793 , global_step: 8772
- AI-Rank-log  1619296017.958769  eval_accuracy: 0.7074851989746094 , global_step: 8773
- AI-Rank-log  1619296062.0549228  eval_accuracy: 0.707028329372406 , global_step: 8774
- AI-Rank-log  1619296106.1429844  eval_accuracy: 0.7071642875671387 , global_step: 8775
- AI-Rank-log  1619296150.1474366  eval_accuracy: 0.7070013880729675 , global_step: 8776
- AI-Rank-log  1619296194.1516454  eval_accuracy: 0.7066529989242554 , global_step: 8777
- AI-Rank-log  1619296238.2464857  eval_accuracy: 0.7070595622062683 , global_step: 8778
- AI-Rank-log  1619296282.3200972  eval_accuracy: 0.7066992521286011 , global_step: 8779
- AI-Rank-log  1619296326.3071241  eval_accuracy: 0.7069802284240723 , global_step: 8780
- AI-Rank-log  1619296370.3968167  eval_accuracy: 0.7068463563919067 , global_step: 8781
- AI-Rank-log  1619296414.4981854  eval_accuracy: 0.7069298624992371 , global_step: 8782
- AI-Rank-log  1619296458.5327272  eval_accuracy: 0.70702064037323 , global_step: 8783
- AI-Rank-log  1619296502.61723  eval_accuracy: 0.70702064037323 , global_step: 8783
- AI-Rank-log  1619296546.679601  eval_accuracy: 0.7066880464553833 , global_step: 8784
- AI-Rank-log  1619296590.736286  eval_accuracy: 0.706989049911499 , global_step: 8785
- AI-Rank-log  1619296634.746891  eval_accuracy: 0.7070455551147461 , global_step: 8786
- AI-Rank-log  1619296678.8254244  eval_accuracy: 0.7068797945976257 , global_step: 8787
- AI-Rank-log  1619296722.932846  eval_accuracy: 0.706735372543335 , global_step: 8788
- AI-Rank-log  1619296766.984815  eval_accuracy: 0.7071133255958557 , global_step: 8789
- AI-Rank-log  1619296819.909686  eval_accuracy: 0.7068007588386536 , global_step: 8790
- AI-Rank-log  1619296864.073235  eval_accuracy: 0.7067720890045166 , global_step: 8791
- AI-Rank-log  1619296908.070105  eval_accuracy: 0.7068575620651245 , global_step: 8792
- AI-Rank-log  1619296952.1734111  eval_accuracy: 0.7069488763809204 , global_step: 8793
- AI-Rank-log  1619296996.1582158  eval_accuracy: 0.7067254781723022 , global_step: 8794
- AI-Rank-log  1619297040.226682  eval_accuracy: 0.7069110870361328 , global_step: 8795
- AI-Rank-log  1619297084.319804  eval_accuracy: 0.7068905830383301 , global_step: 8796
- AI-Rank-log  1619297128.3412771  eval_accuracy: 0.7070168852806091 , global_step: 8797
- AI-Rank-log  1619297172.3497794  eval_accuracy: 0.7069527506828308 , global_step: 8798
- AI-Rank-log  1619297216.4773874  eval_accuracy: 0.7071131467819214 , global_step: 8799
- AI-Rank-log  1619297260.4862869  eval_accuracy: 0.7070184350013733 , global_step: 8800
- AI-Rank-log  1619297304.566545  eval_accuracy: 0.7071317434310913 , global_step: 8801
- AI-Rank-log  1619297348.5934248  eval_accuracy: 0.7073948383331299 , global_step: 8802
- AI-Rank-log  1619297392.5886583  eval_accuracy: 0.7069870233535767 , global_step: 8803
- AI-Rank-log  1619297436.6607018  eval_accuracy: 0.7068451642990112 , global_step: 8804
- AI-Rank-log  1619297481.6781285  eval_accuracy: 0.7070179581642151 , global_step: 8805
- AI-Rank-log  1619297525.6775382  eval_accuracy: 0.7072415947914124 , global_step: 8806
- AI-Rank-log  1619297569.769975  eval_accuracy: 0.7073941826820374 , global_step: 8807
- AI-Rank-log  1619297613.777184  eval_accuracy: 0.7073662281036377 , global_step: 8808
- AI-Rank-log  1619297657.7871742  eval_accuracy: 0.7069278955459595 , global_step: 8809
- AI-Rank-log  1619297702.3781362  eval_accuracy: 0.7066341042518616 , global_step: 8810
- AI-Rank-log  1619297746.3952734  eval_accuracy: 0.7069848775863647 , global_step: 8811
- AI-Rank-log  1619297790.7180521  eval_accuracy: 0.7067351937294006 , global_step: 8812
- AI-Rank-log  1619297834.8414328  eval_accuracy: 0.7072230577468872 , global_step: 8813
- AI-Rank-log  1619297878.902486  eval_accuracy: 0.7071617841720581 , global_step: 8814
- AI-Rank-log  1619297923.144983  eval_accuracy: 0.7070744037628174 , global_step: 8815
- AI-Rank-log  1619297967.160824  eval_accuracy: 0.7066925168037415 , global_step: 8816
- AI-Rank-log  1619298011.9375489  eval_accuracy: 0.7069793939590454 , global_step: 8817
- AI-Rank-log  1619298056.7651088  eval_accuracy: 0.7070414423942566 , global_step: 8818
- AI-Rank-log  1619298100.8703222  eval_accuracy: 0.7071232199668884 , global_step: 8819
- AI-Rank-log  1619298144.867694  eval_accuracy: 0.7075629234313965 , global_step: 8820
- AI-Rank-log  1619298189.2072735  eval_accuracy: 0.7074787616729736 , global_step: 8821
- AI-Rank-log  1619298233.3012033  eval_accuracy: 0.7071977257728577 , global_step: 8822
- AI-Rank-log  1619298277.3323946  eval_accuracy: 0.7069200873374939 , global_step: 8823
- AI-Rank-log  1619298321.9617186  eval_accuracy: 0.7071395516395569 , global_step: 8824
- AI-Rank-log  1619298366.2261002  eval_accuracy: 0.707633376121521 , global_step: 8825
- AI-Rank-log  1619298410.3930264  eval_accuracy: 0.7073096036911011 , global_step: 8826
- AI-Rank-log  1619298455.6481783  eval_accuracy: 0.7074863910675049 , global_step: 8827
- AI-Rank-log  1619298499.710662  eval_accuracy: 0.707288384437561 , global_step: 8828
- AI-Rank-log  1619298543.7901132  eval_accuracy: 0.7074459195137024 , global_step: 8829
- AI-Rank-log  1619298587.8261294  eval_accuracy: 0.7071928381919861 , global_step: 8830
- AI-Rank-log  1619298631.926812  eval_accuracy: 0.7070533037185669 , global_step: 8831
- AI-Rank-log  1619298676.0094922  eval_accuracy: 0.7069826126098633 , global_step: 8832
- AI-Rank-log  1619298720.0353005  eval_accuracy: 0.7071800827980042 , global_step: 8833
- AI-Rank-log  1619298764.245213  eval_accuracy: 0.7077512741088867 , global_step: 8834
- AI-Rank-log  1619298808.342004  eval_accuracy: 0.7077396512031555 , global_step: 8835
- AI-Rank-log  1619298852.4093719  eval_accuracy: 0.707586407661438 , global_step: 8836
- AI-Rank-log  1619298896.4994462  eval_accuracy: 0.7076013684272766 , global_step: 8837
- AI-Rank-log  1619298940.5000994  eval_accuracy: 0.7076874375343323 , global_step: 8838
- AI-Rank-log  1619298984.5593784  eval_accuracy: 0.707855761051178 , global_step: 8839
- AI-Rank-log  1619299028.674068  eval_accuracy: 0.7074428200721741 , global_step: 8840
- AI-Rank-log  1619299072.758389  eval_accuracy: 0.707959771156311 , global_step: 8841
- AI-Rank-log  1619299116.7765725  eval_accuracy: 0.7072681188583374 , global_step: 8842
- AI-Rank-log  1619299160.8503892  eval_accuracy: 0.7074084877967834 , global_step: 8843
- AI-Rank-log  1619299204.8803294  eval_accuracy: 0.7077623009681702 , global_step: 8844
- AI-Rank-log  1619299248.8721952  eval_accuracy: 0.7074885368347168 , global_step: 8845
- AI-Rank-log  1619299292.9695117  eval_accuracy: 0.7077207565307617 , global_step: 8846
- AI-Rank-log  1619299336.9967601  eval_accuracy: 0.7074636220932007 , global_step: 8847
- AI-Rank-log  1619299381.1211276  eval_accuracy: 0.7072626352310181 , global_step: 8848
- AI-Rank-log  1619299425.1302838  eval_accuracy: 0.7072608470916748 , global_step: 8849
- AI-Rank-log  1619299469.1540043  eval_accuracy: 0.7069740295410156 , global_step: 8850
- AI-Rank-log  1619299513.287643  eval_accuracy: 0.7073422074317932 , global_step: 8851
- AI-Rank-log  1619299557.3282638  eval_accuracy: 0.7070869207382202 , global_step: 8852
- AI-Rank-log  1619299601.3450806  eval_accuracy: 0.7069835662841797 , global_step: 8853
- AI-Rank-log  1619299645.4603236  eval_accuracy: 0.7069405317306519 , global_step: 8854
- AI-Rank-log  1619299689.4876351  eval_accuracy: 0.7069969773292542 , global_step: 8855
- AI-Rank-log  1619299733.514133  eval_accuracy: 0.7075281143188477 , global_step: 8856
- AI-Rank-log  1619299777.5731537  eval_accuracy: 0.7068881988525391 , global_step: 8857
- AI-Rank-log  1619299821.6361122  eval_accuracy: 0.7069616317749023 , global_step: 8858
- AI-Rank-log  1619299865.712113  eval_accuracy: 0.7070556879043579 , global_step: 8859
- AI-Rank-log  1619299909.8187144  eval_accuracy: 0.7071385383605957 , global_step: 8860
- AI-Rank-log  1619299953.8043478  eval_accuracy: 0.7070983052253723 , global_step: 8861
- AI-Rank-log  1619299997.9708118  eval_accuracy: 0.707298219203949 , global_step: 8862
- AI-Rank-log  1619300042.0249093  eval_accuracy: 0.7072579860687256 , global_step: 8863
- AI-Rank-log  1619300086.0249627  eval_accuracy: 0.7072685360908508 , global_step: 8864
- AI-Rank-log  1619300130.0638776  eval_accuracy: 0.7071679830551147 , global_step: 8865
- AI-Rank-log  1619300174.1010458  eval_accuracy: 0.7074642777442932 , global_step: 8866
- AI-Rank-log  1619300218.135244  eval_accuracy: 0.7072202563285828 , global_step: 8867
- AI-Rank-log  1619300262.2707987  eval_accuracy: 0.7070533633232117 , global_step: 8868
- AI-Rank-log  1619300306.2650445  eval_accuracy: 0.7068913578987122 , global_step: 8869
- AI-Rank-log  1619300350.4044716  eval_accuracy: 0.7076635360717773 , global_step: 8870
- AI-Rank-log  1619300394.4708645  eval_accuracy: 0.7079049348831177 , global_step: 8871
- AI-Rank-log  1619300438.4746618  eval_accuracy: 0.7072006464004517 , global_step: 8872
- AI-Rank-log  1619300482.6437197  eval_accuracy: 0.7073453664779663 , global_step: 8873
- AI-Rank-log  1619300526.762645  eval_accuracy: 0.7071002125740051 , global_step: 8874
- AI-Rank-log  1619300570.8215275  eval_accuracy: 0.7073805332183838 , global_step: 8875
- AI-Rank-log  1619300614.9676785  eval_accuracy: 0.7071966528892517 , global_step: 8876
- AI-Rank-log  1619300658.8089275  eval_accuracy: 0.7076260447502136 , global_step: 8877
- AI-Rank-log  1619300702.8309486  eval_accuracy: 0.7068766355514526 , global_step: 8878
- AI-Rank-log  1619300746.9452276  eval_accuracy: 0.7073951363563538 , global_step: 8879
- AI-Rank-log  1619300791.020634  eval_accuracy: 0.7074840068817139 , global_step: 8880
- AI-Rank-log  1619300835.0857694  eval_accuracy: 0.7072927355766296 , global_step: 8881
- AI-Rank-log  1619300879.9729557  eval_accuracy: 0.7073951363563538 , global_step: 8882
- AI-Rank-log  1619300924.0125606  eval_accuracy: 0.7074285745620728 , global_step: 8883
- AI-Rank-log  1619300968.142962  eval_accuracy: 0.7072625756263733 , global_step: 8884
- AI-Rank-log  1619301012.2048903  eval_accuracy: 0.7070729732513428 , global_step: 8885
- AI-Rank-log  1619301056.6814997  eval_accuracy: 0.7067070603370667 , global_step: 8886
- AI-Rank-log  1619301101.1356413  eval_accuracy: 0.7067027688026428 , global_step: 8887
- AI-Rank-log  1619301145.1529028  eval_accuracy: 0.707362711429596 , global_step: 8888
- AI-Rank-log  1619301189.9078302  eval_accuracy: 0.7066696882247925 , global_step: 8889
- AI-Rank-log  1619301234.0460873  eval_accuracy: 0.7072296142578125 , global_step: 8890
- AI-Rank-log  1619301278.0645256  eval_accuracy: 0.7070265412330627 , global_step: 8891
- AI-Rank-log  1619301322.3894541  eval_accuracy: 0.7076126933097839 , global_step: 8892
- AI-Rank-log  1619301366.4308867  eval_accuracy: 0.7074844837188721 , global_step: 8893
- AI-Rank-log  1619301411.2500315  eval_accuracy: 0.7074118852615356 , global_step: 8894
- AI-Rank-log  1619301455.3762884  eval_accuracy: 0.7076596021652222 , global_step: 8895
- AI-Rank-log  1619301500.0003457  eval_accuracy: 0.7079614400863647 , global_step: 8896
- AI-Rank-log  1619301544.0680542  eval_accuracy: 0.7074092030525208 , global_step: 8897
- AI-Rank-log  1619301588.546086  eval_accuracy: 0.7084964513778687 , global_step: 8898
- AI-Rank-log  1619301632.5541782  eval_accuracy: 0.7080157399177551 , global_step: 8899
- AI-Rank-log  1619301676.6235895  eval_accuracy: 0.7082394361495972 , global_step: 8900
- AI-Rank-log  1619301721.484531  eval_accuracy: 0.7078068852424622 , global_step: 8901
- AI-Rank-log  1619301765.4796786  eval_accuracy: 0.7078115344047546 , global_step: 8902
- AI-Rank-log  1619301809.6037683  eval_accuracy: 0.7076651453971863 , global_step: 8903
- AI-Rank-log  1619301853.6517904  eval_accuracy: 0.7078803181648254 , global_step: 8904
- AI-Rank-log  1619301898.852059  eval_accuracy: 0.708095371723175 , global_step: 8905
- AI-Rank-log  1619301942.9910448  eval_accuracy: 0.708219051361084 , global_step: 8906
- AI-Rank-log  1619301987.0377567  eval_accuracy: 0.7079089283943176 , global_step: 8907
- AI-Rank-log  1619302031.094141  eval_accuracy: 0.7078421711921692 , global_step: 8908
- AI-Rank-log  1619302075.1507876  eval_accuracy: 0.7084618806838989 , global_step: 8909
- AI-Rank-log  1619302119.1945899  eval_accuracy: 0.708293080329895 , global_step: 8910
- AI-Rank-log  1619302163.5256805  eval_accuracy: 0.7084047198295593 , global_step: 8911
- AI-Rank-log  1619302207.6234844  eval_accuracy: 0.7079082727432251 , global_step: 8912
- AI-Rank-log  1619302251.7344062  eval_accuracy: 0.7078904509544373 , global_step: 8913
- AI-Rank-log  1619302296.01288  eval_accuracy: 0.708139181137085 , global_step: 8914
- AI-Rank-log  1619302340.1103094  eval_accuracy: 0.7077582478523254 , global_step: 8915
- AI-Rank-log  1619302384.106466  eval_accuracy: 0.7080923318862915 , global_step: 8916
- AI-Rank-log  1619302428.3067098  eval_accuracy: 0.7080839276313782 , global_step: 8917
- AI-Rank-log  1619302472.3957062  eval_accuracy: 0.7079727649688721 , global_step: 8918
- AI-Rank-log  1619302516.453985  eval_accuracy: 0.7078774571418762 , global_step: 8919
- AI-Rank-log  1619302560.521681  eval_accuracy: 0.7081393003463745 , global_step: 8920
- AI-Rank-log  1619302604.624153  eval_accuracy: 0.7081368565559387 , global_step: 8921
- AI-Rank-log  1619302648.7405336  eval_accuracy: 0.7080737352371216 , global_step: 8922
- AI-Rank-log  1619302692.8533907  eval_accuracy: 0.7072797417640686 , global_step: 8923
- AI-Rank-log  1619302736.9056091  eval_accuracy: 0.70762038230896 , global_step: 8924
- AI-Rank-log  1619302780.9763389  eval_accuracy: 0.707663357257843 , global_step: 8925
- AI-Rank-log  1619302825.026665  eval_accuracy: 0.7076594233512878 , global_step: 8926
- AI-Rank-log  1619302869.0727458  eval_accuracy: 0.708051860332489 , global_step: 8927
- AI-Rank-log  1619302913.1160712  eval_accuracy: 0.7078803777694702 , global_step: 8928
- AI-Rank-log  1619302957.1557202  eval_accuracy: 0.7080676555633545 , global_step: 8929
- AI-Rank-log  1619303001.1884465  eval_accuracy: 0.708035945892334 , global_step: 8930
- AI-Rank-log  1619303045.3389094  eval_accuracy: 0.7083439826965332 , global_step: 8931
- AI-Rank-log  1619303089.418944  eval_accuracy: 0.7084622383117676 , global_step: 8932
- AI-Rank-log  1619303133.4768727  eval_accuracy: 0.7082410454750061 , global_step: 8933
- AI-Rank-log  1619303177.522729  eval_accuracy: 0.7085977792739868 , global_step: 8934
- AI-Rank-log  1619303221.5679517  eval_accuracy: 0.7078874111175537 , global_step: 8935
- AI-Rank-log  1619303265.6447659  eval_accuracy: 0.7081353664398193 , global_step: 8936
- AI-Rank-log  1619303309.6499665  eval_accuracy: 0.7079688310623169 , global_step: 8937
- AI-Rank-log  1619303353.7076929  eval_accuracy: 0.7081717848777771 , global_step: 8938
- AI-Rank-log  1619303397.8310344  eval_accuracy: 0.7081879377365112 , global_step: 8939
- AI-Rank-log  1619303441.879958  eval_accuracy: 0.7081320285797119 , global_step: 8940
- AI-Rank-log  1619303485.922873  eval_accuracy: 0.7079803943634033 , global_step: 8941
- AI-Rank-log  1619303530.040337  eval_accuracy: 0.7073888182640076 , global_step: 8942
- AI-Rank-log  1619303574.091734  eval_accuracy: 0.707883894443512 , global_step: 8943
- AI-Rank-log  1619303618.2317054  eval_accuracy: 0.707603931427002 , global_step: 8944
- AI-Rank-log  1619303662.254084  eval_accuracy: 0.7073853015899658 , global_step: 8945
- AI-Rank-log  1619303706.2869356  eval_accuracy: 0.7075008153915405 , global_step: 8946
- AI-Rank-log  1619303750.4403858  eval_accuracy: 0.7076513767242432 , global_step: 8947
- AI-Rank-log  1619303794.459556  eval_accuracy: 0.7075653672218323 , global_step: 8948
- AI-Rank-log  1619303838.5094001  eval_accuracy: 0.7074170708656311 , global_step: 8949
- AI-Rank-log  1619303882.6209369  eval_accuracy: 0.7075033187866211 , global_step: 8950
- AI-Rank-log  1619303926.5813563  eval_accuracy: 0.7072129249572754 , global_step: 8951
- AI-Rank-log  1619303970.7463405  eval_accuracy: 0.7075263857841492 , global_step: 8952
- AI-Rank-log  1619304014.830621  eval_accuracy: 0.7073541283607483 , global_step: 8953
- AI-Rank-log  1619304058.8652582  eval_accuracy: 0.7072889804840088 , global_step: 8954
- AI-Rank-log  1619304102.9956782  eval_accuracy: 0.7075394988059998 , global_step: 8955
- AI-Rank-log  1619304147.0552042  eval_accuracy: 0.7075719833374023 , global_step: 8956
- AI-Rank-log  1619304191.0949872  eval_accuracy: 0.707817554473877 , global_step: 8957
- AI-Rank-log  1619304235.2345054  eval_accuracy: 0.7083114981651306 , global_step: 8958
- AI-Rank-log  1619304279.9552388  eval_accuracy: 0.7084361910820007 , global_step: 8959
- AI-Rank-log  1619304324.0811336  eval_accuracy: 0.7078884243965149 , global_step: 8960
- AI-Rank-log  1619304368.2055073  eval_accuracy: 0.707981526851654 , global_step: 8961
- AI-Rank-log  1619304412.2321858  eval_accuracy: 0.7082682251930237 , global_step: 8962
- AI-Rank-log  1619304456.2818925  eval_accuracy: 0.7082465291023254 , global_step: 8963
- AI-Rank-log  1619304500.7607217  eval_accuracy: 0.7075130939483643 , global_step: 8964
- AI-Rank-log  1619304544.8085132  eval_accuracy: 0.7072975635528564 , global_step: 8965
- AI-Rank-log  1619304588.8746395  eval_accuracy: 0.7069416046142578 , global_step: 8966
- AI-Rank-log  1619304633.3083684  eval_accuracy: 0.7076168656349182 , global_step: 8967
- AI-Rank-log  1619304677.3328216  eval_accuracy: 0.7074013948440552 , global_step: 8968
- AI-Rank-log  1619304721.6274662  eval_accuracy: 0.7072880268096924 , global_step: 8969
- AI-Rank-log  1619304765.657112  eval_accuracy: 0.707552969455719 , global_step: 8970
- AI-Rank-log  1619304810.5173278  eval_accuracy: 0.7071210145950317 , global_step: 8971
- AI-Rank-log  1619304855.367712  eval_accuracy: 0.7075091004371643 , global_step: 8972
- AI-Rank-log  1619304900.266652  eval_accuracy: 0.7076079249382019 , global_step: 8973
- AI-Rank-log  1619304944.4001496  eval_accuracy: 0.7076775431632996 , global_step: 8974
- AI-Rank-log  1619304988.420115  eval_accuracy: 0.7074880003929138 , global_step: 8975
- AI-Rank-log  1619305032.6717768  eval_accuracy: 0.7077265381813049 , global_step: 8976
- AI-Rank-log  1619305076.781062  eval_accuracy: 0.7077850699424744 , global_step: 8977
- AI-Rank-log  1619305120.7849748  eval_accuracy: 0.7078148722648621 , global_step: 8978
- AI-Rank-log  1619305165.74305  eval_accuracy: 0.7074378132820129 , global_step: 8979
- AI-Rank-log  1619305209.9365706  eval_accuracy: 0.7074118256568909 , global_step: 8980
- AI-Rank-log  1619305253.9787433  eval_accuracy: 0.7084018588066101 , global_step: 8981
- AI-Rank-log  1619305299.0322337  eval_accuracy: 0.707343339920044 , global_step: 8982
- AI-Rank-log  1619305343.1574357  eval_accuracy: 0.7077093124389648 , global_step: 8983
- AI-Rank-log  1619305387.211297  eval_accuracy: 0.7077169418334961 , global_step: 8984
- AI-Rank-log  1619305431.407049  eval_accuracy: 0.7080865502357483 , global_step: 8985
- AI-Rank-log  1619305475.4213502  eval_accuracy: 0.7079185843467712 , global_step: 8986
- AI-Rank-log  1619305519.4458756  eval_accuracy: 0.7084996700286865 , global_step: 8987
- AI-Rank-log  1619305563.5717826  eval_accuracy: 0.7082384824752808 , global_step: 8988
- AI-Rank-log  1619305607.9109902  eval_accuracy: 0.7079227566719055 , global_step: 8989
- AI-Rank-log  1619305660.8268187  eval_accuracy: 0.7079878449440002 , global_step: 8990
- AI-Rank-log  1619305704.8890293  eval_accuracy: 0.7083479762077332 , global_step: 8991
- AI-Rank-log  1619305748.91079  eval_accuracy: 0.7083590626716614 , global_step: 8992
- AI-Rank-log  1619305792.9419854  eval_accuracy: 0.7076504826545715 , global_step: 8993
- AI-Rank-log  1619305837.1583407  eval_accuracy: 0.7083162069320679 , global_step: 8994
- AI-Rank-log  1619305881.1782072  eval_accuracy: 0.7078996300697327 , global_step: 8995
- AI-Rank-log  1619305925.234978  eval_accuracy: 0.7081274390220642 , global_step: 8996
- AI-Rank-log  1619305969.3091176  eval_accuracy: 0.7082757353782654 , global_step: 8997
- AI-Rank-log  1619306013.3332922  eval_accuracy: 0.7083556652069092 , global_step: 8998
- AI-Rank-log  1619306057.4980671  eval_accuracy: 0.7082556486129761 , global_step: 8999
- AI-Rank-log  1619306101.5435662  eval_accuracy: 0.7082446813583374 , global_step: 9000
- AI-Rank-log  1619306145.5616403  eval_accuracy: 0.7081682682037354 , global_step: 9001
- AI-Rank-log  1619306189.6132295  eval_accuracy: 0.7082556486129761 , global_step: 9002
- AI-Rank-log  1619306233.606426  eval_accuracy: 0.7083978652954102 , global_step: 9003
- AI-Rank-log  1619306277.725814  eval_accuracy: 0.7086172103881836 , global_step: 9004
- AI-Rank-log  1619306321.7325985  eval_accuracy: 0.7083908915519714 , global_step: 9005
- AI-Rank-log  1619306365.7988482  eval_accuracy: 0.7082876563072205 , global_step: 9006
- AI-Rank-log  1619306409.9374743  eval_accuracy: 0.7076570391654968 , global_step: 9007
- AI-Rank-log  1619306453.9954493  eval_accuracy: 0.7078636288642883 , global_step: 9008
- AI-Rank-log  1619306498.0311086  eval_accuracy: 0.7075376510620117 , global_step: 9009
- AI-Rank-log  1619306542.1674392  eval_accuracy: 0.7075861096382141 , global_step: 9010
- AI-Rank-log  1619306586.212303  eval_accuracy: 0.7077363729476929 , global_step: 9011
- AI-Rank-log  1619306630.2219834  eval_accuracy: 0.7072175741195679 , global_step: 9012
- AI-Rank-log  1619306674.3106403  eval_accuracy: 0.7075526118278503 , global_step: 9013
- AI-Rank-log  1619306718.3307989  eval_accuracy: 0.7074860334396362 , global_step: 9014
- AI-Rank-log  1619306762.3760157  eval_accuracy: 0.7080299854278564 , global_step: 9015
- AI-Rank-log  1619306806.4784553  eval_accuracy: 0.7080384492874146 , global_step: 9016
- AI-Rank-log  1619306850.5504453  eval_accuracy: 0.7077873349189758 , global_step: 9017
- AI-Rank-log  1619306894.6558342  eval_accuracy: 0.7075978517532349 , global_step: 9018
- AI-Rank-log  1619306938.6814733  eval_accuracy: 0.7077741026878357 , global_step: 9019
- AI-Rank-log  1619306982.710564  eval_accuracy: 0.7080041766166687 , global_step: 9020
- AI-Rank-log  1619307026.8613446  eval_accuracy: 0.7082845568656921 , global_step: 9021
- AI-Rank-log  1619307070.941458  eval_accuracy: 0.7078556418418884 , global_step: 9022
- AI-Rank-log  1619307114.9671235  eval_accuracy: 0.7078069448471069 , global_step: 9023
- AI-Rank-log  1619307159.109032  eval_accuracy: 0.7073482275009155 , global_step: 9024
- AI-Rank-log  1619307203.1798017  eval_accuracy: 0.7078589200973511 , global_step: 9025
- AI-Rank-log  1619307247.2815895  eval_accuracy: 0.7074271440505981 , global_step: 9026
- AI-Rank-log  1619307291.3025236  eval_accuracy: 0.7075454592704773 , global_step: 9027
- AI-Rank-log  1619307335.3259563  eval_accuracy: 0.707612931728363 , global_step: 9028
- AI-Rank-log  1619307379.479625  eval_accuracy: 0.70758455991745 , global_step: 9029
- AI-Rank-log  1619307423.5043578  eval_accuracy: 0.7075674533843994 , global_step: 9030
- AI-Rank-log  1619307467.565114  eval_accuracy: 0.7077595591545105 , global_step: 9031
- AI-Rank-log  1619307511.6783857  eval_accuracy: 0.7076129913330078 , global_step: 9032
- AI-Rank-log  1619307555.708884  eval_accuracy: 0.7075976133346558 , global_step: 9033
- AI-Rank-log  1619307599.7227952  eval_accuracy: 0.7078405618667603 , global_step: 9034
- AI-Rank-log  1619307643.8649802  eval_accuracy: 0.7077733874320984 , global_step: 9035
- AI-Rank-log  1619307688.7179077  eval_accuracy: 0.7072655558586121 , global_step: 9036
- AI-Rank-log  1619307732.9535518  eval_accuracy: 0.7074506878852844 , global_step: 9037
- AI-Rank-log  1619307776.9574075  eval_accuracy: 0.706879734992981 , global_step: 9038
- AI-Rank-log  1619307821.016174  eval_accuracy: 0.7076903581619263 , global_step: 9039
- AI-Rank-log  1619307865.1187546  eval_accuracy: 0.7071343064308167 , global_step: 9040
- AI-Rank-log  1619307909.2357607  eval_accuracy: 0.7074958682060242 , global_step: 9041
- AI-Rank-log  1619307953.8559105  eval_accuracy: 0.7073742151260376 , global_step: 9042
- AI-Rank-log  1619307997.9781373  eval_accuracy: 0.7073380947113037 , global_step: 9043
- AI-Rank-log  1619308042.6035926  eval_accuracy: 0.7078930735588074 , global_step: 9044
- AI-Rank-log  1619308086.73254  eval_accuracy: 0.7077107429504395 , global_step: 9045
- AI-Rank-log  1619308130.776002  eval_accuracy: 0.7080059051513672 , global_step: 9046
- AI-Rank-log  1619308175.0543716  eval_accuracy: 0.7081069350242615 , global_step: 9047
- AI-Rank-log  1619308219.1305377  eval_accuracy: 0.7081103920936584 , global_step: 9048
- AI-Rank-log  1619308263.2810557  eval_accuracy: 0.7080307006835938 , global_step: 9049
- AI-Rank-log  1619308308.1028495  eval_accuracy: 0.7078635692596436 , global_step: 9050
- AI-Rank-log  1619308352.9833794  eval_accuracy: 0.7076622843742371 , global_step: 9051
- AI-Rank-log  1619308397.0929027  eval_accuracy: 0.7077169418334961 , global_step: 9052
- AI-Rank-log  1619308441.0709734  eval_accuracy: 0.7077773213386536 , global_step: 9053
- AI-Rank-log  1619308485.319017  eval_accuracy: 0.7079012393951416 , global_step: 9054
- AI-Rank-log  1619308529.3586347  eval_accuracy: 0.7081305980682373 , global_step: 9055
- AI-Rank-log  1619308574.010811  eval_accuracy: 0.7078529596328735 , global_step: 9056
- AI-Rank-log  1619308618.1537778  eval_accuracy: 0.708214521408081 , global_step: 9057
- AI-Rank-log  1619308662.1787174  eval_accuracy: 0.7079126834869385 , global_step: 9058
- AI-Rank-log  1619308706.3131897  eval_accuracy: 0.7075251936912537 , global_step: 9059
- AI-Rank-log  1619308751.5019782  eval_accuracy: 0.7074943780899048 , global_step: 9060
- AI-Rank-log  1619308795.5380611  eval_accuracy: 0.7074063420295715 , global_step: 9061
- AI-Rank-log  1619308839.7127893  eval_accuracy: 0.7081841826438904 , global_step: 9062
- AI-Rank-log  1619308883.7564354  eval_accuracy: 0.7079492807388306 , global_step: 9063
- AI-Rank-log  1619308927.7796628  eval_accuracy: 0.7079212069511414 , global_step: 9064
- AI-Rank-log  1619308971.8945112  eval_accuracy: 0.707889974117279 , global_step: 9065
- AI-Rank-log  1619309015.9185998  eval_accuracy: 0.7079875469207764 , global_step: 9066
- AI-Rank-log  1619309060.2873154  eval_accuracy: 0.7074758410453796 , global_step: 9067
- AI-Rank-log  1619309104.310462  eval_accuracy: 0.7075439095497131 , global_step: 9068
- AI-Rank-log  1619309148.351542  eval_accuracy: 0.7078462839126587 , global_step: 9069
- AI-Rank-log  1619309192.4831834  eval_accuracy: 0.7080327868461609 , global_step: 9070
- AI-Rank-log  1619309236.4532812  eval_accuracy: 0.7079686522483826 , global_step: 9071
- AI-Rank-log  1619309280.2935739  eval_accuracy: 0.7085890173912048 , global_step: 9072
- AI-Rank-log  1619309324.406508  eval_accuracy: 0.7080115079879761 , global_step: 9073
- AI-Rank-log  1619309368.4919925  eval_accuracy: 0.7079393267631531 , global_step: 9074
- AI-Rank-log  1619309412.5645132  eval_accuracy: 0.7074466347694397 , global_step: 9075
- AI-Rank-log  1619309456.6458974  eval_accuracy: 0.7075035572052002 , global_step: 9076
- AI-Rank-log  1619309500.6363018  eval_accuracy: 0.7079538702964783 , global_step: 9077
- AI-Rank-log  1619309544.870455  eval_accuracy: 0.7078984379768372 , global_step: 9078
- AI-Rank-log  1619309588.8978786  eval_accuracy: 0.7084377408027649 , global_step: 9079
- AI-Rank-log  1619309632.9175942  eval_accuracy: 0.7083736062049866 , global_step: 9080
- AI-Rank-log  1619309677.075542  eval_accuracy: 0.708055853843689 , global_step: 9081
- AI-Rank-log  1619309721.1217842  eval_accuracy: 0.7082111835479736 , global_step: 9082
- AI-Rank-log  1619309765.1367402  eval_accuracy: 0.7081733345985413 , global_step: 9083
- AI-Rank-log  1619309809.2347026  eval_accuracy: 0.7082738876342773 , global_step: 9084
- AI-Rank-log  1619309853.2603114  eval_accuracy: 0.7079327702522278 , global_step: 9085
- AI-Rank-log  1619309897.1464634  eval_accuracy: 0.7078683972358704 , global_step: 9086
- AI-Rank-log  1619309941.1816685  eval_accuracy: 0.7082498669624329 , global_step: 9087
- AI-Rank-log  1619309985.1863947  eval_accuracy: 0.707829475402832 , global_step: 9088
- AI-Rank-log  1619310029.3611374  eval_accuracy: 0.7079643607139587 , global_step: 9089
- AI-Rank-log  1619310073.465734  eval_accuracy: 0.7076247334480286 , global_step: 9090
- AI-Rank-log  1619310117.522362  eval_accuracy: 0.7078765630722046 , global_step: 9091
- AI-Rank-log  1619310161.632379  eval_accuracy: 0.7082050442695618 , global_step: 9092
- AI-Rank-log  1619310205.6534686  eval_accuracy: 0.7079653143882751 , global_step: 9093
- AI-Rank-log  1619310249.7691658  eval_accuracy: 0.7080042362213135 , global_step: 9094
- AI-Rank-log  1619310293.8381147  eval_accuracy: 0.7079482078552246 , global_step: 9095
- AI-Rank-log  1619310337.9039466  eval_accuracy: 0.7081043720245361 , global_step: 9096
- AI-Rank-log  1619310381.9687717  eval_accuracy: 0.7082540392875671 , global_step: 9097
- AI-Rank-log  1619310426.0133584  eval_accuracy: 0.7077942490577698 , global_step: 9098
- AI-Rank-log  1619310470.073449  eval_accuracy: 0.7077614068984985 , global_step: 9099
- AI-Rank-log  1619310514.1591592  eval_accuracy: 0.7080788612365723 , global_step: 9100
- AI-Rank-log  1619310558.174367  eval_accuracy: 0.7077447772026062 , global_step: 9101
- AI-Rank-log  1619310602.1888962  eval_accuracy: 0.7078604102134705 , global_step: 9102
- AI-Rank-log  1619310646.4404926  eval_accuracy: 0.7079795002937317 , global_step: 9103
- AI-Rank-log  1619310690.4606743  eval_accuracy: 0.7086151838302612 , global_step: 9104
- AI-Rank-log  1619310734.5067558  eval_accuracy: 0.7084668874740601 , global_step: 9105
- AI-Rank-log  1619310778.658549  eval_accuracy: 0.7076859474182129 , global_step: 9106
- AI-Rank-log  1619310822.672029  eval_accuracy: 0.7086352705955505 , global_step: 9107
- AI-Rank-log  1619310866.7689126  eval_accuracy: 0.7081736922264099 , global_step: 9108
- AI-Rank-log  1619310910.774067  eval_accuracy: 0.7078930735588074 , global_step: 9109
- AI-Rank-log  1619310954.8098254  eval_accuracy: 0.7082963585853577 , global_step: 9110
- AI-Rank-log  1619310998.8744848  eval_accuracy: 0.707988977432251 , global_step: 9111
- AI-Rank-log  1619311042.9110973  eval_accuracy: 0.7078464031219482 , global_step: 9112
- AI-Rank-log  1619311086.957954  eval_accuracy: 0.708050012588501 , global_step: 9113
- AI-Rank-log  1619311131.683205  eval_accuracy: 0.7080681324005127 , global_step: 9114
- AI-Rank-log  1619311175.7007163  eval_accuracy: 0.7083632349967957 , global_step: 9115
- AI-Rank-log  1619311219.8385217  eval_accuracy: 0.7084550261497498 , global_step: 9116
- AI-Rank-log  1619311263.831839  eval_accuracy: 0.7082672715187073 , global_step: 9117
- AI-Rank-log  1619311307.9264545  eval_accuracy: 0.7081461548805237 , global_step: 9118
- AI-Rank-log  1619311352.0188568  eval_accuracy: 0.7076273560523987 , global_step: 9119
- AI-Rank-log  1619311396.274108  eval_accuracy: 0.7085073590278625 , global_step: 9120
- AI-Rank-log  1619311440.372222  eval_accuracy: 0.7081921100616455 , global_step: 9121
- AI-Rank-log  1619311484.7426066  eval_accuracy: 0.7082491517066956 , global_step: 9122
- AI-Rank-log  1619311528.7750463  eval_accuracy: 0.708630383014679 , global_step: 9123
- AI-Rank-log  1619311572.994136  eval_accuracy: 0.7082481980323792 , global_step: 9124
- AI-Rank-log  1619311617.0330813  eval_accuracy: 0.7080872058868408 , global_step: 9125
- AI-Rank-log  1619311661.0539746  eval_accuracy: 0.7079185843467712 , global_step: 9126
- AI-Rank-log  1619311705.1484873  eval_accuracy: 0.7082027792930603 , global_step: 9127
- AI-Rank-log  1619311749.8730452  eval_accuracy: 0.7083898186683655 , global_step: 9128
- AI-Rank-log  1619311793.9788506  eval_accuracy: 0.7083914875984192 , global_step: 9129
- AI-Rank-log  1619311838.1316323  eval_accuracy: 0.7086799740791321 , global_step: 9130
- AI-Rank-log  1619311882.4208508  eval_accuracy: 0.7082894444465637 , global_step: 9131
- AI-Rank-log  1619311926.4171693  eval_accuracy: 0.7080351114273071 , global_step: 9132
- AI-Rank-log  1619311970.4821186  eval_accuracy: 0.7086244821548462 , global_step: 9133
- AI-Rank-log  1619312015.1397262  eval_accuracy: 0.7087611556053162 , global_step: 9134
- AI-Rank-log  1619312059.2334814  eval_accuracy: 0.7082317471504211 , global_step: 9135
- AI-Rank-log  1619312103.411087  eval_accuracy: 0.708687424659729 , global_step: 9136
- AI-Rank-log  1619312148.5838556  eval_accuracy: 0.7084771394729614 , global_step: 9137
- AI-Rank-log  1619312192.657305  eval_accuracy: 0.7082850337028503 , global_step: 9138
- AI-Rank-log  1619312236.719065  eval_accuracy: 0.7088318467140198 , global_step: 9139
- AI-Rank-log  1619312281.5661905  eval_accuracy: 0.7090322375297546 , global_step: 9140
- AI-Rank-log  1619312325.7280862  eval_accuracy: 0.7087644934654236 , global_step: 9141
- AI-Rank-log  1619312369.7702003  eval_accuracy: 0.7089070081710815 , global_step: 9142
- AI-Rank-log  1619312413.82557  eval_accuracy: 0.7089378833770752 , global_step: 9143
- AI-Rank-log  1619312457.9963682  eval_accuracy: 0.7087969183921814 , global_step: 9144
- AI-Rank-log  1619312502.324772  eval_accuracy: 0.7088434100151062 , global_step: 9145
- AI-Rank-log  1619312546.3772933  eval_accuracy: 0.7086994647979736 , global_step: 9146
- AI-Rank-log  1619312590.5158725  eval_accuracy: 0.7088952660560608 , global_step: 9147
- AI-Rank-log  1619312634.560139  eval_accuracy: 0.7091305255889893 , global_step: 9148
- AI-Rank-log  1619312678.6412835  eval_accuracy: 0.709134578704834 , global_step: 9149
- AI-Rank-log  1619312722.7081738  eval_accuracy: 0.7090438008308411 , global_step: 9150
- AI-Rank-log  1619312766.7709053  eval_accuracy: 0.7087194323539734 , global_step: 9151
- AI-Rank-log  1619312810.885324  eval_accuracy: 0.7093032598495483 , global_step: 9152
- AI-Rank-log  1619312854.937337  eval_accuracy: 0.708907425403595 , global_step: 9153
- AI-Rank-log  1619312898.990018  eval_accuracy: 0.7090380787849426 , global_step: 9154
- AI-Rank-log  1619312943.0619028  eval_accuracy: 0.7090457081794739 , global_step: 9155
- AI-Rank-log  1619312987.1113138  eval_accuracy: 0.7091054916381836 , global_step: 9156
- AI-Rank-log  1619313030.9298267  eval_accuracy: 0.7089784145355225 , global_step: 9157
- AI-Rank-log  1619313075.0025134  eval_accuracy: 0.7087924480438232 , global_step: 9158
- AI-Rank-log  1619313119.0502415  eval_accuracy: 0.70843505859375 , global_step: 9159
- AI-Rank-log  1619313163.0829976  eval_accuracy: 0.7086740136146545 , global_step: 9160
- AI-Rank-log  1619313207.1573703  eval_accuracy: 0.7088842391967773 , global_step: 9161
- AI-Rank-log  1619313251.2172337  eval_accuracy: 0.7086334228515625 , global_step: 9162
- AI-Rank-log  1619313295.3983445  eval_accuracy: 0.7087724208831787 , global_step: 9163
- AI-Rank-log  1619313339.413478  eval_accuracy: 0.7089413404464722 , global_step: 9164
- AI-Rank-log  1619313383.489791  eval_accuracy: 0.7087233662605286 , global_step: 9165
- AI-Rank-log  1619313427.6342192  eval_accuracy: 0.7090740203857422 , global_step: 9166
- AI-Rank-log  1619313471.6444552  eval_accuracy: 0.7087563872337341 , global_step: 9167
- AI-Rank-log  1619313515.684384  eval_accuracy: 0.7082661390304565 , global_step: 9168
- AI-Rank-log  1619313559.8138626  eval_accuracy: 0.7086777687072754 , global_step: 9169
- AI-Rank-log  1619313603.9146607  eval_accuracy: 0.7088110446929932 , global_step: 9170
- AI-Rank-log  1619313648.0348027  eval_accuracy: 0.7081641554832458 , global_step: 9171
- AI-Rank-log  1619313692.1158075  eval_accuracy: 0.7083080410957336 , global_step: 9172
- AI-Rank-log  1619313736.1343937  eval_accuracy: 0.7083292007446289 , global_step: 9173
- AI-Rank-log  1619313780.2562027  eval_accuracy: 0.7085790634155273 , global_step: 9174
- AI-Rank-log  1619313824.3379042  eval_accuracy: 0.708407461643219 , global_step: 9175
- AI-Rank-log  1619313868.4210691  eval_accuracy: 0.7085185647010803 , global_step: 9176
- AI-Rank-log  1619313912.5671604  eval_accuracy: 0.7082951068878174 , global_step: 9177
- AI-Rank-log  1619313956.6953733  eval_accuracy: 0.7083982229232788 , global_step: 9178
- AI-Rank-log  1619314000.7219164  eval_accuracy: 0.7087118029594421 , global_step: 9179
- AI-Rank-log  1619314044.8550406  eval_accuracy: 0.709036111831665 , global_step: 9180
- AI-Rank-log  1619314088.8369899  eval_accuracy: 0.7085332274436951 , global_step: 9181
- AI-Rank-log  1619314132.9806209  eval_accuracy: 0.7086383104324341 , global_step: 9182
- AI-Rank-log  1619314176.9954658  eval_accuracy: 0.708534300327301 , global_step: 9183
- AI-Rank-log  1619314221.05835  eval_accuracy: 0.7084490656852722 , global_step: 9184
- AI-Rank-log  1619314265.1746788  eval_accuracy: 0.7089294195175171 , global_step: 9185
- AI-Rank-log  1619314309.2012656  eval_accuracy: 0.708869993686676 , global_step: 9186
- AI-Rank-log  1619314353.2005107  eval_accuracy: 0.7084352970123291 , global_step: 9187
- AI-Rank-log  1619314397.358898  eval_accuracy: 0.7084869742393494 , global_step: 9188
- AI-Rank-log  1619314441.4318771  eval_accuracy: 0.7091005444526672 , global_step: 9189
- AI-Rank-log  1619314494.3086193  eval_accuracy: 0.7090802192687988 , global_step: 9190
- AI-Rank-log  1619314539.1834276  eval_accuracy: 0.7094386219978333 , global_step: 9191
- AI-Rank-log  1619314583.3547294  eval_accuracy: 0.7098201513290405 , global_step: 9192
- AI-Rank-log  1619314627.2084675  eval_accuracy: 0.7095946073532104 , global_step: 9193
- AI-Rank-log  1619314671.2682798  eval_accuracy: 0.7091954946517944 , global_step: 9194
- AI-Rank-log  1619314715.3971336  eval_accuracy: 0.7092369198799133 , global_step: 9195
- AI-Rank-log  1619314759.4950778  eval_accuracy: 0.7094866037368774 , global_step: 9196
- AI-Rank-log  1619314803.9715466  eval_accuracy: 0.7094991207122803 , global_step: 9197
- AI-Rank-log  1619314848.0879102  eval_accuracy: 0.7088823318481445 , global_step: 9198
- AI-Rank-log  1619314892.290355  eval_accuracy: 0.708980917930603 , global_step: 9199
- AI-Rank-log  1619314936.356607  eval_accuracy: 0.7090917825698853 , global_step: 9200
- AI-Rank-log  1619314980.5182993  eval_accuracy: 0.7086116075515747 , global_step: 9201
- AI-Rank-log  1619315024.5911186  eval_accuracy: 0.7087033987045288 , global_step: 9202
- AI-Rank-log  1619315068.6860893  eval_accuracy: 0.7090716361999512 , global_step: 9203
- AI-Rank-log  1619315112.790041  eval_accuracy: 0.7089123129844666 , global_step: 9204
- AI-Rank-log  1619315156.837099  eval_accuracy: 0.7087585926055908 , global_step: 9205
- AI-Rank-log  1619315201.354964  eval_accuracy: 0.7088990807533264 , global_step: 9206
- AI-Rank-log  1619315245.4800632  eval_accuracy: 0.7088246941566467 , global_step: 9207
- AI-Rank-log  1619315290.3019953  eval_accuracy: 0.7088178396224976 , global_step: 9208
- AI-Rank-log  1619315334.3537173  eval_accuracy: 0.709366500377655 , global_step: 9209
- AI-Rank-log  1619315378.4806128  eval_accuracy: 0.7086058855056763 , global_step: 9210
- AI-Rank-log  1619315423.2236242  eval_accuracy: 0.7092092037200928 , global_step: 9211
- AI-Rank-log  1619315467.3788667  eval_accuracy: 0.7090097069740295 , global_step: 9212
- AI-Rank-log  1619315511.353049  eval_accuracy: 0.7089192271232605 , global_step: 9213
- AI-Rank-log  1619315555.374514  eval_accuracy: 0.7087266445159912 , global_step: 9214
- AI-Rank-log  1619315600.6514149  eval_accuracy: 0.7088568806648254 , global_step: 9215
- AI-Rank-log  1619315644.724543  eval_accuracy: 0.7092302441596985 , global_step: 9216
- AI-Rank-log  1619315688.7679825  eval_accuracy: 0.7091410756111145 , global_step: 9217
- AI-Rank-log  1619315732.925295  eval_accuracy: 0.7090444564819336 , global_step: 9218
- AI-Rank-log  1619315776.9787285  eval_accuracy: 0.7089924812316895 , global_step: 9219
- AI-Rank-log  1619315821.0070772  eval_accuracy: 0.7094204425811768 , global_step: 9220
- AI-Rank-log  1619315865.1534705  eval_accuracy: 0.7087938189506531 , global_step: 9221
- AI-Rank-log  1619315909.5350409  eval_accuracy: 0.708859920501709 , global_step: 9222
- AI-Rank-log  1619315953.6384535  eval_accuracy: 0.7092143297195435 , global_step: 9223
- AI-Rank-log  1619315997.7304294  eval_accuracy: 0.7089560031890869 , global_step: 9224
- AI-Rank-log  1619316041.7118983  eval_accuracy: 0.7089684009552002 , global_step: 9225
- AI-Rank-log  1619316085.8332226  eval_accuracy: 0.7090189456939697 , global_step: 9226
- AI-Rank-log  1619316129.8851721  eval_accuracy: 0.7084429264068604 , global_step: 9227
- AI-Rank-log  1619316173.944198  eval_accuracy: 0.7088068723678589 , global_step: 9228
- AI-Rank-log  1619316218.102869  eval_accuracy: 0.7092872262001038 , global_step: 9229
- AI-Rank-log  1619316262.1673174  eval_accuracy: 0.7087771892547607 , global_step: 9230
- AI-Rank-log  1619316306.2624347  eval_accuracy: 0.7094609141349792 , global_step: 9231
- AI-Rank-log  1619316350.325277  eval_accuracy: 0.7092950344085693 , global_step: 9232
- AI-Rank-log  1619316394.4322846  eval_accuracy: 0.7093237042427063 , global_step: 9233
- AI-Rank-log  1619316438.601956  eval_accuracy: 0.7092519402503967 , global_step: 9234
- AI-Rank-log  1619316482.6410418  eval_accuracy: 0.7092067003250122 , global_step: 9235
- AI-Rank-log  1619316526.630069  eval_accuracy: 0.7093718647956848 , global_step: 9236
- AI-Rank-log  1619316570.6906452  eval_accuracy: 0.7091796398162842 , global_step: 9237
- AI-Rank-log  1619316614.7989843  eval_accuracy: 0.7092230916023254 , global_step: 9238
- AI-Rank-log  1619316658.8627744  eval_accuracy: 0.7091558575630188 , global_step: 9239
- AI-Rank-log  1619316702.909302  eval_accuracy: 0.7092345356941223 , global_step: 9240
- AI-Rank-log  1619316746.972393  eval_accuracy: 0.7087759375572205 , global_step: 9241
- AI-Rank-log  1619316791.092329  eval_accuracy: 0.7089122533798218 , global_step: 9242
- AI-Rank-log  1619316835.173584  eval_accuracy: 0.7092732191085815 , global_step: 9243
- AI-Rank-log  1619316879.2181754  eval_accuracy: 0.7087532877922058 , global_step: 9244
- AI-Rank-log  1619316923.3494449  eval_accuracy: 0.7092278599739075 , global_step: 9245
- AI-Rank-log  1619316967.4587495  eval_accuracy: 0.7089753150939941 , global_step: 9246
- AI-Rank-log  1619317011.5118906  eval_accuracy: 0.7090557813644409 , global_step: 9247
- AI-Rank-log  1619317055.5718095  eval_accuracy: 0.7090543508529663 , global_step: 9248
- AI-Rank-log  1619317099.6278787  eval_accuracy: 0.7092724442481995 , global_step: 9249
- AI-Rank-log  1619317143.6877596  eval_accuracy: 0.7091333866119385 , global_step: 9250
- AI-Rank-log  1619317187.7400186  eval_accuracy: 0.7089307308197021 , global_step: 9251
- AI-Rank-log  1619317231.7673442  eval_accuracy: 0.7094287276268005 , global_step: 9252
- AI-Rank-log  1619317275.928423  eval_accuracy: 0.7092799544334412 , global_step: 9253
- AI-Rank-log  1619317319.903283  eval_accuracy: 0.7091069221496582 , global_step: 9254
- AI-Rank-log  1619317363.9223564  eval_accuracy: 0.7092541456222534 , global_step: 9255
- AI-Rank-log  1619317408.0939376  eval_accuracy: 0.7090403437614441 , global_step: 9256
- AI-Rank-log  1619317452.131408  eval_accuracy: 0.7090893387794495 , global_step: 9257
- AI-Rank-log  1619317496.234978  eval_accuracy: 0.709133505821228 , global_step: 9258
- AI-Rank-log  1619317540.377006  eval_accuracy: 0.7088878750801086 , global_step: 9259
- AI-Rank-log  1619317584.3875577  eval_accuracy: 0.709250271320343 , global_step: 9260
- AI-Rank-log  1619317628.5197406  eval_accuracy: 0.7087512612342834 , global_step: 9261
- AI-Rank-log  1619317672.5863738  eval_accuracy: 0.7092891335487366 , global_step: 9262
- AI-Rank-log  1619317716.6201115  eval_accuracy: 0.7095308303833008 , global_step: 9263
- AI-Rank-log  1619317760.754748  eval_accuracy: 0.7095394730567932 , global_step: 9264
- AI-Rank-log  1619317804.7868083  eval_accuracy: 0.7093514800071716 , global_step: 9265
- AI-Rank-log  1619317848.9970655  eval_accuracy: 0.7093278765678406 , global_step: 9266
- AI-Rank-log  1619317893.0743427  eval_accuracy: 0.7090599536895752 , global_step: 9267
- AI-Rank-log  1619317937.130261  eval_accuracy: 0.7088325023651123 , global_step: 9268
- AI-Rank-log  1619317981.4687154  eval_accuracy: 0.709307074546814 , global_step: 9269
- AI-Rank-log  1619318025.5523014  eval_accuracy: 0.7090780735015869 , global_step: 9270
- AI-Rank-log  1619318069.5631516  eval_accuracy: 0.7091412544250488 , global_step: 9271
- AI-Rank-log  1619318114.5178707  eval_accuracy: 0.7094578146934509 , global_step: 9272
- AI-Rank-log  1619318158.5464327  eval_accuracy: 0.7094651460647583 , global_step: 9273
- AI-Rank-log  1619318203.445908  eval_accuracy: 0.7090502977371216 , global_step: 9274
- AI-Rank-log  1619318247.5889218  eval_accuracy: 0.7096438407897949 , global_step: 9275
- AI-Rank-log  1619318292.394897  eval_accuracy: 0.7098085284233093 , global_step: 9276
- AI-Rank-log  1619318336.3831706  eval_accuracy: 0.7096548676490784 , global_step: 9277
- AI-Rank-log  1619318380.5128899  eval_accuracy: 0.709416389465332 , global_step: 9278
- AI-Rank-log  1619318424.8114028  eval_accuracy: 0.7096706032752991 , global_step: 9279
- AI-Rank-log  1619318468.9433742  eval_accuracy: 0.7093545198440552 , global_step: 9280
- AI-Rank-log  1619318512.9841812  eval_accuracy: 0.7097496390342712 , global_step: 9281
- AI-Rank-log  1619318557.0434976  eval_accuracy: 0.7096917033195496 , global_step: 9282
- AI-Rank-log  1619318601.8777976  eval_accuracy: 0.7096666097640991 , global_step: 9283
- AI-Rank-log  1619318645.9807913  eval_accuracy: 0.7097494006156921 , global_step: 9284
- AI-Rank-log  1619318690.065583  eval_accuracy: 0.7095857262611389 , global_step: 9285
- AI-Rank-log  1619318734.644937  eval_accuracy: 0.7092917561531067 , global_step: 9286
- AI-Rank-log  1619318778.6966865  eval_accuracy: 0.7093993425369263 , global_step: 9287
- AI-Rank-log  1619318822.7738287  eval_accuracy: 0.7093537449836731 , global_step: 9288
- AI-Rank-log  1619318867.832295  eval_accuracy: 0.7095217108726501 , global_step: 9289
- AI-Rank-log  1619318911.9383647  eval_accuracy: 0.7098154425621033 , global_step: 9290
- AI-Rank-log  1619318956.0746858  eval_accuracy: 0.7099397778511047 , global_step: 9291
- AI-Rank-log  1619319000.2785568  eval_accuracy: 0.7096095681190491 , global_step: 9292
- AI-Rank-log  1619319045.106173  eval_accuracy: 0.7101389765739441 , global_step: 9293
- AI-Rank-log  1619319089.2477698  eval_accuracy: 0.7094765901565552 , global_step: 9294
- AI-Rank-log  1619319133.3400087  eval_accuracy: 0.709732174873352 , global_step: 9295
- AI-Rank-log  1619319177.401411  eval_accuracy: 0.7097277045249939 , global_step: 9296
- AI-Rank-log  1619319221.520317  eval_accuracy: 0.7097349762916565 , global_step: 9297
- AI-Rank-log  1619319265.5739665  eval_accuracy: 0.7094864249229431 , global_step: 9298
- AI-Rank-log  1619319309.6198575  eval_accuracy: 0.709827721118927 , global_step: 9299
- AI-Rank-log  1619319353.820496  eval_accuracy: 0.7096265554428101 , global_step: 9300
- AI-Rank-log  1619319397.8577232  eval_accuracy: 0.7098657488822937 , global_step: 9301
- AI-Rank-log  1619319441.9550145  eval_accuracy: 0.7095143795013428 , global_step: 9302
- AI-Rank-log  1619319485.9972365  eval_accuracy: 0.7096956968307495 , global_step: 9303
- AI-Rank-log  1619319530.0156262  eval_accuracy: 0.7097625732421875 , global_step: 9304
- AI-Rank-log  1619319574.1868453  eval_accuracy: 0.709871768951416 , global_step: 9305
- AI-Rank-log  1619319618.264468  eval_accuracy: 0.7098063826560974 , global_step: 9306
- AI-Rank-log  1619319662.3185964  eval_accuracy: 0.7100158929824829 , global_step: 9307
- AI-Rank-log  1619319706.4680786  eval_accuracy: 0.7098048329353333 , global_step: 9308
- AI-Rank-log  1619319750.4876764  eval_accuracy: 0.7097897529602051 , global_step: 9309
- AI-Rank-log  1619319794.5962374  eval_accuracy: 0.710005521774292 , global_step: 9310
- AI-Rank-log  1619319838.629586  eval_accuracy: 0.7099526524543762 , global_step: 9311
- AI-Rank-log  1619319882.6561415  eval_accuracy: 0.7097731828689575 , global_step: 9312
- AI-Rank-log  1619319926.7463794  eval_accuracy: 0.7102064490318298 , global_step: 9313
- AI-Rank-log  1619319970.7875488  eval_accuracy: 0.7100810408592224 , global_step: 9314
- AI-Rank-log  1619320014.82518  eval_accuracy: 0.7098889350891113 , global_step: 9315
- AI-Rank-log  1619320058.9606419  eval_accuracy: 0.7100059390068054 , global_step: 9316
- AI-Rank-log  1619320102.9577804  eval_accuracy: 0.710048496723175 , global_step: 9317
- AI-Rank-log  1619320147.050391  eval_accuracy: 0.7096691727638245 , global_step: 9318
- AI-Rank-log  1619320191.1539974  eval_accuracy: 0.7105674743652344 , global_step: 9319
- AI-Rank-log  1619320235.2066195  eval_accuracy: 0.7095677852630615 , global_step: 9320
- AI-Rank-log  1619320279.2748344  eval_accuracy: 0.7093303203582764 , global_step: 9321
- AI-Rank-log  1619320323.3436918  eval_accuracy: 0.7098310589790344 , global_step: 9322
- AI-Rank-log  1619320367.4316435  eval_accuracy: 0.7098986506462097 , global_step: 9323
- AI-Rank-log  1619320411.4898796  eval_accuracy: 0.7095171213150024 , global_step: 9324
- AI-Rank-log  1619320455.540299  eval_accuracy: 0.7098779678344727 , global_step: 9325
- AI-Rank-log  1619320499.6112099  eval_accuracy: 0.7096656560897827 , global_step: 9326
- AI-Rank-log  1619320543.7329254  eval_accuracy: 0.7096985578536987 , global_step: 9327
- AI-Rank-log  1619320587.770962  eval_accuracy: 0.7097374796867371 , global_step: 9328
- AI-Rank-log  1619320631.5907283  eval_accuracy: 0.7098343968391418 , global_step: 9329
- AI-Rank-log  1619320675.6786547  eval_accuracy: 0.7096749544143677 , global_step: 9330
- AI-Rank-log  1619320719.729437  eval_accuracy: 0.7096570134162903 , global_step: 9331
- AI-Rank-log  1619320763.8414454  eval_accuracy: 0.7094147205352783 , global_step: 9332
- AI-Rank-log  1619320807.9170299  eval_accuracy: 0.7097995281219482 , global_step: 9333
- AI-Rank-log  1619320851.9767542  eval_accuracy: 0.7096266746520996 , global_step: 9334
- AI-Rank-log  1619320896.1016953  eval_accuracy: 0.7099341750144958 , global_step: 9335
- AI-Rank-log  1619320940.1627839  eval_accuracy: 0.709543764591217 , global_step: 9336
- AI-Rank-log  1619320984.209921  eval_accuracy: 0.7093204855918884 , global_step: 9337
- AI-Rank-log  1619321028.285691  eval_accuracy: 0.7098725438117981 , global_step: 9338
- AI-Rank-log  1619321072.325196  eval_accuracy: 0.709725558757782 , global_step: 9339
- AI-Rank-log  1619321116.4097762  eval_accuracy: 0.7094836235046387 , global_step: 9340
- AI-Rank-log  1619321160.5601482  eval_accuracy: 0.7100608944892883 , global_step: 9341
- AI-Rank-log  1619321204.6294274  eval_accuracy: 0.7096062302589417 , global_step: 9342
- AI-Rank-log  1619321248.7702403  eval_accuracy: 0.7093333601951599 , global_step: 9343
- AI-Rank-log  1619321292.8119037  eval_accuracy: 0.709371030330658 , global_step: 9344
- AI-Rank-log  1619321336.9094336  eval_accuracy: 0.7092704176902771 , global_step: 9345
- AI-Rank-log  1619321381.7248828  eval_accuracy: 0.7095919251441956 , global_step: 9346
- AI-Rank-log  1619321425.9961822  eval_accuracy: 0.7092707753181458 , global_step: 9347
- AI-Rank-log  1619321470.0900395  eval_accuracy: 0.7096458077430725 , global_step: 9348
- AI-Rank-log  1619321514.176357  eval_accuracy: 0.7097261548042297 , global_step: 9349
- AI-Rank-log  1619321558.401386  eval_accuracy: 0.709320068359375 , global_step: 9350
- AI-Rank-log  1619321602.4857533  eval_accuracy: 0.709896445274353 , global_step: 9351
- AI-Rank-log  1619321647.0478916  eval_accuracy: 0.7098522782325745 , global_step: 9352
- AI-Rank-log  1619321691.049008  eval_accuracy: 0.7097097635269165 , global_step: 9353
- AI-Rank-log  1619321735.4182763  eval_accuracy: 0.7099257707595825 , global_step: 9354
- AI-Rank-log  1619321779.494646  eval_accuracy: 0.7100611329078674 , global_step: 9355
- AI-Rank-log  1619321823.6416774  eval_accuracy: 0.7099390625953674 , global_step: 9356
- AI-Rank-log  1619321868.7658126  eval_accuracy: 0.7095645666122437 , global_step: 9357
- AI-Rank-log  1619321912.7696714  eval_accuracy: 0.7098295092582703 , global_step: 9358
- AI-Rank-log  1619321956.8225985  eval_accuracy: 0.7096457481384277 , global_step: 9359
- AI-Rank-log  1619322000.9272964  eval_accuracy: 0.7096153497695923 , global_step: 9360
- AI-Rank-log  1619322045.907746  eval_accuracy: 0.709585428237915 , global_step: 9361
- AI-Rank-log  1619322089.9725811  eval_accuracy: 0.7097553014755249 , global_step: 9362
- AI-Rank-log  1619322134.171308  eval_accuracy: 0.7094401717185974 , global_step: 9363
- AI-Rank-log  1619322178.2460444  eval_accuracy: 0.7098203301429749 , global_step: 9364
- AI-Rank-log  1619322222.4075935  eval_accuracy: 0.7103105187416077 , global_step: 9365
- AI-Rank-log  1619322267.1638  eval_accuracy: 0.7099690437316895 , global_step: 9366
- AI-Rank-log  1619322311.2332723  eval_accuracy: 0.7095449566841125 , global_step: 9367
- AI-Rank-log  1619322355.3357928  eval_accuracy: 0.7094221711158752 , global_step: 9368
- AI-Rank-log  1619322399.4012988  eval_accuracy: 0.7096020579338074 , global_step: 9369
- AI-Rank-log  1619322444.352064  eval_accuracy: 0.7095763087272644 , global_step: 9370
- AI-Rank-log  1619322488.4459183  eval_accuracy: 0.7096526026725769 , global_step: 9371
- AI-Rank-log  1619322532.4628353  eval_accuracy: 0.7099445462226868 , global_step: 9372
- AI-Rank-log  1619322576.630592  eval_accuracy: 0.7094725966453552 , global_step: 9373
- AI-Rank-log  1619322620.7633338  eval_accuracy: 0.709689199924469 , global_step: 9374
- AI-Rank-log  1619322664.802558  eval_accuracy: 0.7097814679145813 , global_step: 9375
- AI-Rank-log  1619322708.847595  eval_accuracy: 0.7098610997200012 , global_step: 9376
- AI-Rank-log  1619322753.15614  eval_accuracy: 0.709943950176239 , global_step: 9377
- AI-Rank-log  1619322797.1995509  eval_accuracy: 0.7098761200904846 , global_step: 9378
- AI-Rank-log  1619322841.3562424  eval_accuracy: 0.7101135849952698 , global_step: 9379
- AI-Rank-log  1619322885.435383  eval_accuracy: 0.7102037072181702 , global_step: 9380
- AI-Rank-log  1619322929.5163455  eval_accuracy: 0.7101921439170837 , global_step: 9381
- AI-Rank-log  1619322973.6086528  eval_accuracy: 0.709844708442688 , global_step: 9382
- AI-Rank-log  1619323017.6899745  eval_accuracy: 0.7095909714698792 , global_step: 9383
- AI-Rank-log  1619323061.839704  eval_accuracy: 0.7098090052604675 , global_step: 9384
- AI-Rank-log  1619323105.8898816  eval_accuracy: 0.7097530364990234 , global_step: 9385
- AI-Rank-log  1619323149.91228  eval_accuracy: 0.7098895311355591 , global_step: 9386
- AI-Rank-log  1619323194.028746  eval_accuracy: 0.7100251317024231 , global_step: 9387
- AI-Rank-log  1619323238.0532324  eval_accuracy: 0.7098449468612671 , global_step: 9388
- AI-Rank-log  1619323282.156664  eval_accuracy: 0.7097190022468567 , global_step: 9389
- AI-Rank-log  1619323335.1080806  eval_accuracy: 0.7100323438644409 , global_step: 9390
- AI-Rank-log  1619323379.181225  eval_accuracy: 0.7101855874061584 , global_step: 9391
- AI-Rank-log  1619323423.259619  eval_accuracy: 0.7101215124130249 , global_step: 9392
- AI-Rank-log  1619323467.366527  eval_accuracy: 0.710401713848114 , global_step: 9393
- AI-Rank-log  1619323511.4106128  eval_accuracy: 0.7105719447135925 , global_step: 9394
- AI-Rank-log  1619323555.4887795  eval_accuracy: 0.7099804878234863 , global_step: 9395
- AI-Rank-log  1619323599.576681  eval_accuracy: 0.7102131843566895 , global_step: 9396
- AI-Rank-log  1619323643.6069188  eval_accuracy: 0.7104530334472656 , global_step: 9397
- AI-Rank-log  1619323687.767273  eval_accuracy: 0.7107067108154297 , global_step: 9398
- AI-Rank-log  1619323731.853406  eval_accuracy: 0.7107972502708435 , global_step: 9399
- AI-Rank-log  1619323775.8840754  eval_accuracy: 0.7105525135993958 , global_step: 9400
- AI-Rank-log  1619323820.0035212  eval_accuracy: 0.7103469371795654 , global_step: 9401
- AI-Rank-log  1619323864.0296412  eval_accuracy: 0.7109350562095642 , global_step: 9402
- AI-Rank-log  1619323908.1583219  eval_accuracy: 0.7102451324462891 , global_step: 9403
- AI-Rank-log  1619323952.24063  eval_accuracy: 0.7105676531791687 , global_step: 9404
- AI-Rank-log  1619323996.3440912  eval_accuracy: 0.7105590105056763 , global_step: 9405
- AI-Rank-log  1619324040.502925  eval_accuracy: 0.7106437087059021 , global_step: 9406
- AI-Rank-log  1619324084.6074557  eval_accuracy: 0.7103774547576904 , global_step: 9407
- AI-Rank-log  1619324128.6542747  eval_accuracy: 0.7105830311775208 , global_step: 9408
- AI-Rank-log  1619324172.7474992  eval_accuracy: 0.710096001625061 , global_step: 9409
- AI-Rank-log  1619324216.8104215  eval_accuracy: 0.7099012732505798 , global_step: 9410
- AI-Rank-log  1619324260.8325067  eval_accuracy: 0.7103738784790039 , global_step: 9411
- AI-Rank-log  1619324304.888562  eval_accuracy: 0.7103289365768433 , global_step: 9412
- AI-Rank-log  1619324348.9439447  eval_accuracy: 0.7099816203117371 , global_step: 9413
- AI-Rank-log  1619324393.1447496  eval_accuracy: 0.7100604176521301 , global_step: 9414
- AI-Rank-log  1619324437.22995  eval_accuracy: 0.7100474238395691 , global_step: 9415
- AI-Rank-log  1619324481.307559  eval_accuracy: 0.7096973061561584 , global_step: 9416
- AI-Rank-log  1619324525.39689  eval_accuracy: 0.7097649574279785 , global_step: 9417
- AI-Rank-log  1619324569.4438825  eval_accuracy: 0.7099950313568115 , global_step: 9418
- AI-Rank-log  1619324613.485328  eval_accuracy: 0.7099558711051941 , global_step: 9419
- AI-Rank-log  1619324657.5905962  eval_accuracy: 0.7099950313568115 , global_step: 9420
- AI-Rank-log  1619324701.687813  eval_accuracy: 0.7102267146110535 , global_step: 9421
- AI-Rank-log  1619324745.7964787  eval_accuracy: 0.7099431157112122 , global_step: 9422
- AI-Rank-log  1619324790.7762394  eval_accuracy: 0.7104818224906921 , global_step: 9423
- AI-Rank-log  1619324834.8643003  eval_accuracy: 0.7104026675224304 , global_step: 9424
- AI-Rank-log  1619324878.9506228  eval_accuracy: 0.7100402116775513 , global_step: 9425
- AI-Rank-log  1619324922.9491012  eval_accuracy: 0.709831953048706 , global_step: 9426
- AI-Rank-log  1619324967.0517738  eval_accuracy: 0.7099783420562744 , global_step: 9427
- AI-Rank-log  1619325011.1936798  eval_accuracy: 0.7104634642601013 , global_step: 9428
- AI-Rank-log  1619325055.8147836  eval_accuracy: 0.7102879285812378 , global_step: 9429
- AI-Rank-log  1619325099.8752446  eval_accuracy: 0.7104792594909668 , global_step: 9430
- AI-Rank-log  1619325144.1409786  eval_accuracy: 0.7110898494720459 , global_step: 9431
- AI-Rank-log  1619325188.1918974  eval_accuracy: 0.7109521627426147 , global_step: 9432
- AI-Rank-log  1619325232.262133  eval_accuracy: 0.7103970646858215 , global_step: 9433
- AI-Rank-log  1619325276.4734871  eval_accuracy: 0.7103274464607239 , global_step: 9434
- AI-Rank-log  1619325320.5245056  eval_accuracy: 0.71028733253479 , global_step: 9435
- AI-Rank-log  1619325364.7054074  eval_accuracy: 0.7101942300796509 , global_step: 9436
- AI-Rank-log  1619325408.761742  eval_accuracy: 0.7103983759880066 , global_step: 9437
- AI-Rank-log  1619325453.6349456  eval_accuracy: 0.7102248072624207 , global_step: 9438
- AI-Rank-log  1619325497.8324566  eval_accuracy: 0.7100415825843811 , global_step: 9439
- AI-Rank-log  1619325541.9022934  eval_accuracy: 0.7097376585006714 , global_step: 9440
- AI-Rank-log  1619325586.3469012  eval_accuracy: 0.7101247310638428 , global_step: 9441
- AI-Rank-log  1619325630.522313  eval_accuracy: 0.7102711796760559 , global_step: 9442
- AI-Rank-log  1619325674.5547435  eval_accuracy: 0.7101215720176697 , global_step: 9443
- AI-Rank-log  1619325719.1133163  eval_accuracy: 0.7103195786476135 , global_step: 9444
- AI-Rank-log  1619325763.3827407  eval_accuracy: 0.7104102969169617 , global_step: 9445
- AI-Rank-log  1619325807.4746642  eval_accuracy: 0.7102303504943848 , global_step: 9446
- AI-Rank-log  1619325852.7102177  eval_accuracy: 0.7100662589073181 , global_step: 9447
- AI-Rank-log  1619325896.773585  eval_accuracy: 0.7101426720619202 , global_step: 9448
- AI-Rank-log  1619325940.8551512  eval_accuracy: 0.7104713320732117 , global_step: 9449
- AI-Rank-log  1619325984.9872556  eval_accuracy: 0.7100436091423035 , global_step: 9450
- AI-Rank-log  1619326029.0663834  eval_accuracy: 0.710195779800415 , global_step: 9451
- AI-Rank-log  1619326073.0750608  eval_accuracy: 0.7100362777709961 , global_step: 9452
- AI-Rank-log  1619326117.1839979  eval_accuracy: 0.7099409103393555 , global_step: 9453
- AI-Rank-log  1619326161.231402  eval_accuracy: 0.7100861668586731 , global_step: 9454
- AI-Rank-log  1619326205.4749212  eval_accuracy: 0.7095863819122314 , global_step: 9455
- AI-Rank-log  1619326249.5962605  eval_accuracy: 0.70988529920578 , global_step: 9456
- AI-Rank-log  1619326293.6820288  eval_accuracy: 0.7104105949401855 , global_step: 9457
- AI-Rank-log  1619326337.8291447  eval_accuracy: 0.7101284265518188 , global_step: 9458
- AI-Rank-log  1619326381.8570218  eval_accuracy: 0.7104266881942749 , global_step: 9459
- AI-Rank-log  1619326425.8634498  eval_accuracy: 0.7106102108955383 , global_step: 9460
- AI-Rank-log  1619326469.9316032  eval_accuracy: 0.7107120752334595 , global_step: 9461
- AI-Rank-log  1619326513.9784043  eval_accuracy: 0.7105047106742859 , global_step: 9462
- AI-Rank-log  1619326558.0727043  eval_accuracy: 0.710606038570404 , global_step: 9463
- AI-Rank-log  1619326602.1657248  eval_accuracy: 0.7100077867507935 , global_step: 9464
- AI-Rank-log  1619326646.190759  eval_accuracy: 0.7100599408149719 , global_step: 9465
- AI-Rank-log  1619326690.2249024  eval_accuracy: 0.7099231481552124 , global_step: 9466
- AI-Rank-log  1619326734.263246  eval_accuracy: 0.7099661827087402 , global_step: 9467
- AI-Rank-log  1619326778.3096943  eval_accuracy: 0.7102630734443665 , global_step: 9468
- AI-Rank-log  1619326822.4368474  eval_accuracy: 0.7103386521339417 , global_step: 9469
- AI-Rank-log  1619326866.503157  eval_accuracy: 0.7103580236434937 , global_step: 9470
- AI-Rank-log  1619326910.5620244  eval_accuracy: 0.7108377814292908 , global_step: 9471
- AI-Rank-log  1619326954.6592016  eval_accuracy: 0.7107307314872742 , global_step: 9472
- AI-Rank-log  1619326998.7452114  eval_accuracy: 0.7109717726707458 , global_step: 9473
- AI-Rank-log  1619327042.8937237  eval_accuracy: 0.7106771469116211 , global_step: 9474
- AI-Rank-log  1619327086.9156396  eval_accuracy: 0.7105159759521484 , global_step: 9475
- AI-Rank-log  1619327131.0481656  eval_accuracy: 0.7102211713790894 , global_step: 9476
- AI-Rank-log  1619327175.1403537  eval_accuracy: 0.7106153964996338 , global_step: 9477
- AI-Rank-log  1619327219.2133512  eval_accuracy: 0.7105352282524109 , global_step: 9478
- AI-Rank-log  1619327263.2384007  eval_accuracy: 0.7103060483932495 , global_step: 9479
- AI-Rank-log  1619327307.3305154  eval_accuracy: 0.7106481790542603 , global_step: 9480
- AI-Rank-log  1619327351.3640091  eval_accuracy: 0.7103520035743713 , global_step: 9481
- AI-Rank-log  1619327395.427511  eval_accuracy: 0.7103660106658936 , global_step: 9482
- AI-Rank-log  1619327439.536076  eval_accuracy: 0.7107394337654114 , global_step: 9483
- AI-Rank-log  1619327483.5878103  eval_accuracy: 0.7104278206825256 , global_step: 9484
- AI-Rank-log  1619327527.6418526  eval_accuracy: 0.7104553580284119 , global_step: 9485
- AI-Rank-log  1619327571.7930202  eval_accuracy: 0.7107017636299133 , global_step: 9486
- AI-Rank-log  1619327615.8583252  eval_accuracy: 0.7106578350067139 , global_step: 9487
- AI-Rank-log  1619327659.994674  eval_accuracy: 0.7106340527534485 , global_step: 9488
- AI-Rank-log  1619327704.0307178  eval_accuracy: 0.7104844450950623 , global_step: 9489
- AI-Rank-log  1619327748.0690596  eval_accuracy: 0.7105116248130798 , global_step: 9490
- AI-Rank-log  1619327792.219605  eval_accuracy: 0.7105031609535217 , global_step: 9491
- AI-Rank-log  1619327836.2404852  eval_accuracy: 0.710477888584137 , global_step: 9492
- AI-Rank-log  1619327880.2882352  eval_accuracy: 0.7109085321426392 , global_step: 9493
- AI-Rank-log  1619327924.4440773  eval_accuracy: 0.710752010345459 , global_step: 9494
- AI-Rank-log  1619327968.4780977  eval_accuracy: 0.7108017206192017 , global_step: 9495
- AI-Rank-log  1619328012.5983524  eval_accuracy: 0.7109628319740295 , global_step: 9496
- AI-Rank-log  1619328056.7839406  eval_accuracy: 0.7108275294303894 , global_step: 9497
- AI-Rank-log  1619328100.866038  eval_accuracy: 0.7107277512550354 , global_step: 9498
- AI-Rank-log  1619328144.9992297  eval_accuracy: 0.7112329602241516 , global_step: 9499
- AI-Rank-log  1619328189.9701962  eval_accuracy: 0.7108657956123352 , global_step: 9500
- AI-Rank-log  1619328234.762585  eval_accuracy: 0.7108372449874878 , global_step: 9501
- AI-Rank-log  1619328278.90281  eval_accuracy: 0.7110705375671387 , global_step: 9502
- AI-Rank-log  1619328322.9628825  eval_accuracy: 0.7113814949989319 , global_step: 9503
- AI-Rank-log  1619328367.0861504  eval_accuracy: 0.7113158106803894 , global_step: 9504
- AI-Rank-log  1619328411.1870437  eval_accuracy: 0.710923969745636 , global_step: 9505
- AI-Rank-log  1619328455.6298995  eval_accuracy: 0.7110944986343384 , global_step: 9506
- AI-Rank-log  1619328499.669077  eval_accuracy: 0.7113809585571289 , global_step: 9507
- AI-Rank-log  1619328543.7700834  eval_accuracy: 0.7113118171691895 , global_step: 9508
- AI-Rank-log  1619328588.3701003  eval_accuracy: 0.7109755277633667 , global_step: 9509
- AI-Rank-log  1619328632.4537568  eval_accuracy: 0.7106666564941406 , global_step: 9510
- AI-Rank-log  1619328676.7095792  eval_accuracy: 0.7112722992897034 , global_step: 9511
- AI-Rank-log  1619328720.7708566  eval_accuracy: 0.7109255194664001 , global_step: 9512
- AI-Rank-log  1619328764.8567462  eval_accuracy: 0.7107315063476562 , global_step: 9513
- AI-Rank-log  1619328808.9191797  eval_accuracy: 0.7109334468841553 , global_step: 9514
- AI-Rank-log  1619328853.78012  eval_accuracy: 0.7107279896736145 , global_step: 9515
- AI-Rank-log  1619328897.959431  eval_accuracy: 0.7109158039093018 , global_step: 9516
- AI-Rank-log  1619328941.9876006  eval_accuracy: 0.7110294699668884 , global_step: 9517
- AI-Rank-log  1619328986.4438756  eval_accuracy: 0.7108048796653748 , global_step: 9518
- AI-Rank-log  1619329030.463469  eval_accuracy: 0.7103731632232666 , global_step: 9519
- AI-Rank-log  1619329074.5764587  eval_accuracy: 0.7103803157806396 , global_step: 9520
- AI-Rank-log  1619329119.2737844  eval_accuracy: 0.7106383442878723 , global_step: 9521
- AI-Rank-log  1619329163.4109304  eval_accuracy: 0.7106486558914185 , global_step: 9522
- AI-Rank-log  1619329208.3584914  eval_accuracy: 0.7104988694190979 , global_step: 9523
- AI-Rank-log  1619329252.5096235  eval_accuracy: 0.7107580304145813 , global_step: 9524
- AI-Rank-log  1619329297.6511667  eval_accuracy: 0.7107436060905457 , global_step: 9525
- AI-Rank-log  1619329341.802235  eval_accuracy: 0.7107168436050415 , global_step: 9526
- AI-Rank-log  1619329385.851965  eval_accuracy: 0.7112613320350647 , global_step: 9527
- AI-Rank-log  1619329429.9092278  eval_accuracy: 0.7109664678573608 , global_step: 9528
- AI-Rank-log  1619329474.0787382  eval_accuracy: 0.7108930945396423 , global_step: 9529
- AI-Rank-log  1619329518.136303  eval_accuracy: 0.7108371257781982 , global_step: 9530
- AI-Rank-log  1619329562.2254944  eval_accuracy: 0.7107788324356079 , global_step: 9531
- AI-Rank-log  1619329606.5147505  eval_accuracy: 0.7111657857894897 , global_step: 9532
- AI-Rank-log  1619329650.5522184  eval_accuracy: 0.7112066149711609 , global_step: 9533
- AI-Rank-log  1619329694.564421  eval_accuracy: 0.7109023928642273 , global_step: 9534
- AI-Rank-log  1619329738.773123  eval_accuracy: 0.7109223008155823 , global_step: 9535
- AI-Rank-log  1619329782.7798781  eval_accuracy: 0.7109010219573975 , global_step: 9536
- AI-Rank-log  1619329826.8149953  eval_accuracy: 0.71103835105896 , global_step: 9537
- AI-Rank-log  1619329870.968859  eval_accuracy: 0.7112168073654175 , global_step: 9538
- AI-Rank-log  1619329914.95492  eval_accuracy: 0.7109957337379456 , global_step: 9539
- AI-Rank-log  1619329959.076649  eval_accuracy: 0.7108848690986633 , global_step: 9540
- AI-Rank-log  1619330003.155789  eval_accuracy: 0.710868775844574 , global_step: 9541
- AI-Rank-log  1619330047.2143624  eval_accuracy: 0.7106704115867615 , global_step: 9542
- AI-Rank-log  1619330091.3275738  eval_accuracy: 0.7110751271247864 , global_step: 9543
- AI-Rank-log  1619330135.3616133  eval_accuracy: 0.7109370827674866 , global_step: 9544
- AI-Rank-log  1619330179.372337  eval_accuracy: 0.7108233571052551 , global_step: 9545
- AI-Rank-log  1619330223.4496603  eval_accuracy: 0.710882842540741 , global_step: 9546
- AI-Rank-log  1619330267.4710958  eval_accuracy: 0.7106958627700806 , global_step: 9547
- AI-Rank-log  1619330311.543927  eval_accuracy: 0.710776150226593 , global_step: 9548
- AI-Rank-log  1619330355.6466942  eval_accuracy: 0.7112738490104675 , global_step: 9549
- AI-Rank-log  1619330399.7157497  eval_accuracy: 0.711117684841156 , global_step: 9550
- AI-Rank-log  1619330443.8892348  eval_accuracy: 0.7108070850372314 , global_step: 9551
- AI-Rank-log  1619330487.9926658  eval_accuracy: 0.7110484838485718 , global_step: 9552
- AI-Rank-log  1619330532.079622  eval_accuracy: 0.7112061381340027 , global_step: 9553
- AI-Rank-log  1619330576.1407692  eval_accuracy: 0.7110604047775269 , global_step: 9554
- AI-Rank-log  1619330620.1780703  eval_accuracy: 0.7112666964530945 , global_step: 9555
- AI-Rank-log  1619330664.1991246  eval_accuracy: 0.7113825678825378 , global_step: 9556
- AI-Rank-log  1619330708.2955914  eval_accuracy: 0.7114816308021545 , global_step: 9557
- AI-Rank-log  1619330752.3469996  eval_accuracy: 0.71142578125 , global_step: 9558
- AI-Rank-log  1619330796.4661417  eval_accuracy: 0.7112966775894165 , global_step: 9559
- AI-Rank-log  1619330840.4791753  eval_accuracy: 0.710945725440979 , global_step: 9560
- AI-Rank-log  1619330884.5744722  eval_accuracy: 0.7109096050262451 , global_step: 9561
- AI-Rank-log  1619330928.6784394  eval_accuracy: 0.7108941078186035 , global_step: 9562
- AI-Rank-log  1619330972.680147  eval_accuracy: 0.7114020586013794 , global_step: 9563
- AI-Rank-log  1619331016.7074578  eval_accuracy: 0.7112930417060852 , global_step: 9564
- AI-Rank-log  1619331060.816986  eval_accuracy: 0.7111761569976807 , global_step: 9565
- AI-Rank-log  1619331104.9093559  eval_accuracy: 0.7111420035362244 , global_step: 9566
- AI-Rank-log  1619331148.9650192  eval_accuracy: 0.7113326191902161 , global_step: 9567
- AI-Rank-log  1619331193.0669167  eval_accuracy: 0.7113461494445801 , global_step: 9568
- AI-Rank-log  1619331237.1705937  eval_accuracy: 0.7112895846366882 , global_step: 9569
- AI-Rank-log  1619331281.2660353  eval_accuracy: 0.7111729979515076 , global_step: 9570
- AI-Rank-log  1619331325.2926328  eval_accuracy: 0.7113345265388489 , global_step: 9571
- AI-Rank-log  1619331369.3141265  eval_accuracy: 0.711182713508606 , global_step: 9572
- AI-Rank-log  1619331413.4645364  eval_accuracy: 0.7107312083244324 , global_step: 9573
- AI-Rank-log  1619331457.4515054  eval_accuracy: 0.7111687660217285 , global_step: 9574
- AI-Rank-log  1619331501.4887502  eval_accuracy: 0.7105935215950012 , global_step: 9575
- AI-Rank-log  1619331545.5965793  eval_accuracy: 0.7108469009399414 , global_step: 9576
- AI-Rank-log  1619331590.2611477  eval_accuracy: 0.7114251255989075 , global_step: 9577
- AI-Rank-log  1619331634.4030294  eval_accuracy: 0.7112534642219543 , global_step: 9578
- AI-Rank-log  1619331678.4584067  eval_accuracy: 0.7111877799034119 , global_step: 9579
- AI-Rank-log  1619331722.4815586  eval_accuracy: 0.7111424803733826 , global_step: 9580
- AI-Rank-log  1619331766.5488853  eval_accuracy: 0.7113671898841858 , global_step: 9581
- AI-Rank-log  1619331810.575237  eval_accuracy: 0.711075484752655 , global_step: 9582
- AI-Rank-log  1619331855.1689105  eval_accuracy: 0.7112536430358887 , global_step: 9583
- AI-Rank-log  1619331899.2984853  eval_accuracy: 0.7110438942909241 , global_step: 9584
- AI-Rank-log  1619331943.3460906  eval_accuracy: 0.7109053730964661 , global_step: 9585
- AI-Rank-log  1619331987.9301524  eval_accuracy: 0.7112311720848083 , global_step: 9586
- AI-Rank-log  1619332032.084335  eval_accuracy: 0.711162269115448 , global_step: 9587
- AI-Rank-log  1619332076.8387012  eval_accuracy: 0.7112975716590881 , global_step: 9588
- AI-Rank-log  1619332120.8982854  eval_accuracy: 0.7113708257675171 , global_step: 9589
- AI-Rank-log  1619332173.8648663  eval_accuracy: 0.7113683819770813 , global_step: 9590
- AI-Rank-log  1619332217.9206047  eval_accuracy: 0.7116026282310486 , global_step: 9591
- AI-Rank-log  1619332262.896734  eval_accuracy: 0.7115795612335205 , global_step: 9592
- AI-Rank-log  1619332307.7344582  eval_accuracy: 0.7113246321678162 , global_step: 9593
- AI-Rank-log  1619332351.7760432  eval_accuracy: 0.7114620804786682 , global_step: 9594
- AI-Rank-log  1619332395.8971655  eval_accuracy: 0.7113472819328308 , global_step: 9595
- AI-Rank-log  1619332440.9833412  eval_accuracy: 0.7108713388442993 , global_step: 9596
- AI-Rank-log  1619332485.0665526  eval_accuracy: 0.7111186981201172 , global_step: 9597
- AI-Rank-log  1619332529.192704  eval_accuracy: 0.7113288640975952 , global_step: 9598
- AI-Rank-log  1619332573.8614268  eval_accuracy: 0.7110134959220886 , global_step: 9599
- AI-Rank-log  1619332617.9743803  eval_accuracy: 0.7111442685127258 , global_step: 9600
- AI-Rank-log  1619332662.0309918  eval_accuracy: 0.7114735841751099 , global_step: 9601
- AI-Rank-log  1619332706.067696  eval_accuracy: 0.7112487554550171 , global_step: 9602
- AI-Rank-log  1619332751.188388  eval_accuracy: 0.7112026810646057 , global_step: 9603
- AI-Rank-log  1619332795.2268713  eval_accuracy: 0.7112783193588257 , global_step: 9604
- AI-Rank-log  1619332839.342629  eval_accuracy: 0.711250364780426 , global_step: 9605
- AI-Rank-log  1619332883.505015  eval_accuracy: 0.7108803987503052 , global_step: 9606
- AI-Rank-log  1619332927.6535313  eval_accuracy: 0.7110854983329773 , global_step: 9607
- AI-Rank-log  1619332971.7394488  eval_accuracy: 0.7111102342605591 , global_step: 9608
- AI-Rank-log  1619333015.8655849  eval_accuracy: 0.7113385200500488 , global_step: 9609
- AI-Rank-log  1619333060.0222168  eval_accuracy: 0.7115350961685181 , global_step: 9610
- AI-Rank-log  1619333104.19744  eval_accuracy: 0.7113789916038513 , global_step: 9611
- AI-Rank-log  1619333148.2580528  eval_accuracy: 0.7118001580238342 , global_step: 9612
- AI-Rank-log  1619333192.303204  eval_accuracy: 0.7114132046699524 , global_step: 9613
- AI-Rank-log  1619333236.3932166  eval_accuracy: 0.7114729285240173 , global_step: 9614
- AI-Rank-log  1619333280.5260186  eval_accuracy: 0.711611270904541 , global_step: 9615
- AI-Rank-log  1619333324.6156008  eval_accuracy: 0.711879312992096 , global_step: 9616
- AI-Rank-log  1619333368.7776618  eval_accuracy: 0.7117133140563965 , global_step: 9617
- AI-Rank-log  1619333412.8305407  eval_accuracy: 0.7114706635475159 , global_step: 9618
- AI-Rank-log  1619333456.940175  eval_accuracy: 0.7115339636802673 , global_step: 9619
- AI-Rank-log  1619333501.0085053  eval_accuracy: 0.7117587327957153 , global_step: 9620
- AI-Rank-log  1619333545.000494  eval_accuracy: 0.7118831276893616 , global_step: 9621
- AI-Rank-log  1619333589.1517391  eval_accuracy: 0.7116196751594543 , global_step: 9622
- AI-Rank-log  1619333633.1942236  eval_accuracy: 0.7114356160163879 , global_step: 9623
- AI-Rank-log  1619333677.2152557  eval_accuracy: 0.7114506363868713 , global_step: 9624
- AI-Rank-log  1619333721.4243915  eval_accuracy: 0.711322546005249 , global_step: 9625
- AI-Rank-log  1619333765.5238812  eval_accuracy: 0.7114948630332947 , global_step: 9626
- AI-Rank-log  1619333809.5468216  eval_accuracy: 0.7113380432128906 , global_step: 9627
- AI-Rank-log  1619333853.6611147  eval_accuracy: 0.7115115523338318 , global_step: 9628
- AI-Rank-log  1619333897.6712186  eval_accuracy: 0.7112150192260742 , global_step: 9629
- AI-Rank-log  1619333941.753533  eval_accuracy: 0.7111786603927612 , global_step: 9630
- AI-Rank-log  1619333985.765796  eval_accuracy: 0.7116267681121826 , global_step: 9631
- AI-Rank-log  1619334029.8409224  eval_accuracy: 0.7115544080734253 , global_step: 9632
- AI-Rank-log  1619334073.9596326  eval_accuracy: 0.7116885185241699 , global_step: 9633
- AI-Rank-log  1619334117.9939048  eval_accuracy: 0.7112924456596375 , global_step: 9634
- AI-Rank-log  1619334162.0595756  eval_accuracy: 0.7112638354301453 , global_step: 9635
- AI-Rank-log  1619334206.202062  eval_accuracy: 0.7113070487976074 , global_step: 9636
- AI-Rank-log  1619334250.2503827  eval_accuracy: 0.7113280296325684 , global_step: 9637
- AI-Rank-log  1619334294.3153374  eval_accuracy: 0.7112728953361511 , global_step: 9638
- AI-Rank-log  1619334338.447782  eval_accuracy: 0.7112728953361511 , global_step: 9638
- AI-Rank-log  1619334382.4985454  eval_accuracy: 0.7114438414573669 , global_step: 9639
- AI-Rank-log  1619334426.5435739  eval_accuracy: 0.7113596796989441 , global_step: 9640
- AI-Rank-log  1619334470.7170503  eval_accuracy: 0.7113081216812134 , global_step: 9641
- AI-Rank-log  1619334514.8005276  eval_accuracy: 0.7113068699836731 , global_step: 9642
- AI-Rank-log  1619334558.8874125  eval_accuracy: 0.7113326787948608 , global_step: 9643
- AI-Rank-log  1619334603.00777  eval_accuracy: 0.7113233208656311 , global_step: 9644
- AI-Rank-log  1619334647.0645132  eval_accuracy: 0.7113773822784424 , global_step: 9645
- AI-Rank-log  1619334691.2336843  eval_accuracy: 0.7110986709594727 , global_step: 9646
- AI-Rank-log  1619334735.2709346  eval_accuracy: 0.7113831639289856 , global_step: 9647
- AI-Rank-log  1619334779.3313525  eval_accuracy: 0.7113287448883057 , global_step: 9648
- AI-Rank-log  1619334823.4515066  eval_accuracy: 0.7116023898124695 , global_step: 9649
- AI-Rank-log  1619334867.5413084  eval_accuracy: 0.7115989327430725 , global_step: 9650
- AI-Rank-log  1619334911.7041826  eval_accuracy: 0.711498498916626 , global_step: 9651
- AI-Rank-log  1619334955.7807262  eval_accuracy: 0.7118653059005737 , global_step: 9652
- AI-Rank-log  1619334999.818496  eval_accuracy: 0.7117230892181396 , global_step: 9653
- AI-Rank-log  1619335044.5473578  eval_accuracy: 0.7118350267410278 , global_step: 9654
- AI-Rank-log  1619335088.6893206  eval_accuracy: 0.7118436694145203 , global_step: 9655
- AI-Rank-log  1619335132.7446523  eval_accuracy: 0.7119326591491699 , global_step: 9656
- AI-Rank-log  1619335177.2881825  eval_accuracy: 0.711733341217041 , global_step: 9657
- AI-Rank-log  1619335221.2849631  eval_accuracy: 0.711535632610321 , global_step: 9658
- AI-Rank-log  1619335265.353877  eval_accuracy: 0.7116273641586304 , global_step: 9659
- AI-Rank-log  1619335310.0511367  eval_accuracy: 0.7118302583694458 , global_step: 9660
- AI-Rank-log  1619335354.0733306  eval_accuracy: 0.7117642760276794 , global_step: 9661
- AI-Rank-log  1619335398.764433  eval_accuracy: 0.7115601897239685 , global_step: 9662
- AI-Rank-log  1619335442.872735  eval_accuracy: 0.7118512392044067 , global_step: 9663
- AI-Rank-log  1619335486.8914886  eval_accuracy: 0.7114467024803162 , global_step: 9664
- AI-Rank-log  1619335531.063275  eval_accuracy: 0.7111130356788635 , global_step: 9665
- AI-Rank-log  1619335575.8782492  eval_accuracy: 0.7114356756210327 , global_step: 9666
- AI-Rank-log  1619335620.2535713  eval_accuracy: 0.7114225029945374 , global_step: 9667
- AI-Rank-log  1619335664.3719294  eval_accuracy: 0.7115215063095093 , global_step: 9668
- AI-Rank-log  1619335709.2381747  eval_accuracy: 0.7112807631492615 , global_step: 9669
- AI-Rank-log  1619335753.2527375  eval_accuracy: 0.7113144993782043 , global_step: 9670
- AI-Rank-log  1619335797.425879  eval_accuracy: 0.7115432024002075 , global_step: 9671
- AI-Rank-log  1619335841.6225  eval_accuracy: 0.7115655541419983 , global_step: 9672
- AI-Rank-log  1619335885.748537  eval_accuracy: 0.71151202917099 , global_step: 9673
- AI-Rank-log  1619335929.8591886  eval_accuracy: 0.7112928628921509 , global_step: 9674
- AI-Rank-log  1619335974.6296632  eval_accuracy: 0.7115274667739868 , global_step: 9675
- AI-Rank-log  1619336018.6783404  eval_accuracy: 0.7117123007774353 , global_step: 9676
- AI-Rank-log  1619336062.7158835  eval_accuracy: 0.7116815447807312 , global_step: 9677
- AI-Rank-log  1619336106.7334967  eval_accuracy: 0.7116484045982361 , global_step: 9678
- AI-Rank-log  1619336152.040755  eval_accuracy: 0.7117590308189392 , global_step: 9679
- AI-Rank-log  1619336196.0761948  eval_accuracy: 0.7120622396469116 , global_step: 9680
- AI-Rank-log  1619336196.0762591  test_finish
- AI-Rank-log  1619336196.0762591  total_use_time: 427159.6386215687 sec
- AI-Rank-log  1619336196.0762591  avg_ips: 15020.90 samples/sec
